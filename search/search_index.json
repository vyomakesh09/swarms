{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":""},{"location":"#hello","title":"\ud83d\udc4b Hello","text":"<p>Swarms provides you with all the building blocks you need to build reliable, production-grade, and scalable multi-agent apps!</p>"},{"location":"#install","title":"\ud83d\udcbb Install","text":"<p>You can install <code>swarms</code> with pip in a Python&gt;=3.8 environment.</p> <p>pip install (recommended)</p> headless <p>The headless installation of <code>swarms</code> is designed for environments where graphical user interfaces (GUI) are not needed, making it more lightweight and suitable for server-side applications.</p> <pre><code>pip install swarms\n</code></pre> <p>git clone (for development)</p> virtualenv <pre><code># clone repository and navigate to root directory\ngit clone https://github.com/kyegomez/swarms.git\ncd swarms\n\n# setup python environment and activate it\npython3 -m venv venv\nsource venv/bin/activate\npip install --upgrade pip\n\n# headless install\npip install -e \".\"\n\n# desktop install\npip install -e \".[desktop]\"\n</code></pre> poetry <pre><code># clone repository and navigate to root directory\ngit clone https://github.com/kyegomez/swarms.git\ncd swarms\n\n# setup python environment and activate it\npoetry env use python3.10\npoetry shell\n\n# headless install\npoetry install\n\n# desktop install\npoetry install --extras \"desktop\"\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<p>Learn more about swarms \u2192</p>"},{"location":"#examples","title":"Examples","text":"<p>Check out Swarms examples for building agents, data retrieval, and more.</p> <p>Checkout Swarms examples \u2192</p>"},{"location":"ReleaseNotes/","title":"Release Notes","text":""},{"location":"ReleaseNotes/#375","title":"3.7.5","text":"<p>2024-01-21</p>"},{"location":"ReleaseNotes/#bug-fixes","title":"Bug Fixes","text":"<p>Fix imports of Agent, SequentialWorkflow, ModelParallelizer, Task, OpenAIChat, Gemini, GPT4VisionAPI</p>"},{"location":"ReleaseNotes/#new-features","title":"New Features","text":"<p>New model: Odin for Object Detection and tracking New mode: Ultralytics Object recognition YOLO </p> <p>New Tokenizers</p> <p>Schema generator for prompts. New prompt for worker agent.</p> <p>New structure: plan, step </p> <p>New tool: execute tool</p> <p>New logger: get_logger</p> <p>Example for worker_agent</p>"},{"location":"ReleaseNotes/#368","title":"3.6.8","text":"<p>2024-01-19</p>"},{"location":"ReleaseNotes/#bug-fixes_1","title":"Bug Fixes","text":"<p>Removed ModelScope</p> <p>Removed CogAgent </p>"},{"location":"ReleaseNotes/#new-features_1","title":"New Features","text":"<p>Added ultralytics vision models</p> <p>Added TimmModel to wrap timm models</p>"},{"location":"ReleaseNotes/#other","title":"Other","text":"<p>Loosened version of timm</p>"},{"location":"contributing/","title":"Contributing","text":"<p>Thank you for your interest in contributing to Swarms! We welcome contributions from the community to help improve usability and readability. By contributing, you can be a part of creating a dynamic and interactive AI system.</p> <p>To get started, please follow the guidelines below.</p>"},{"location":"contributing/#optimization-priorities","title":"Optimization Priorities","text":"<p>To continuously improve Swarms, we prioritize the following design objectives:</p> <ol> <li> <p>Usability: Increase the ease of use and user-friendliness of the swarm system to facilitate adoption and interaction with basic input.</p> </li> <li> <p>Reliability: Improve the swarm's ability to obtain the desired output even with basic and un-detailed input.</p> </li> <li> <p>Speed: Reduce the time it takes for the swarm to accomplish tasks by improving the communication layer, critiquing, and self-alignment with meta prompting.</p> </li> <li> <p>Scalability: Ensure that the system is asynchronous, concurrent, and self-healing to support scalability.</p> </li> </ol> <p>Our goal is to continuously improve Swarms by following this roadmap while also being adaptable to new needs and opportunities as they arise.</p>"},{"location":"contributing/#join-the-swarms-community","title":"Join the Swarms Community","text":"<p>Join the Swarms community on Discord to connect with other contributors, coordinate work, and receive support.</p> <ul> <li>Join the Swarms Discord Server</li> </ul>"},{"location":"contributing/#report-and-issue","title":"Report and Issue","text":"<p>The easiest way to contribute to our docs is through our public issue tracker. Feel free to submit bugs, request features or changes, or contribute to the project directly. </p>"},{"location":"contributing/#pull-requests","title":"Pull Requests","text":"<p>Swarms docs are built using MkDocs. </p> <p>To directly contribute to Swarms documentation, first fork the swarms-docs repository to your GitHub account. Then clone your repository to your local machine.</p> <p>From inside the directory run: </p> <p><code>pip install -r requirements.txt</code></p> <p>To run <code>swarms-docs</code> locally run: </p> <p><code>mkdocs serve</code></p> <p>You should see something similar to the following: </p> <pre><code>INFO     -  Building documentation...\nINFO     -  Cleaning site directory\nINFO     -  Documentation built in 0.19 seconds\nINFO     -  [09:28:33] Watching paths for changes: 'docs', 'mkdocs.yml'\nINFO     -  [09:28:33] Serving on http://127.0.0.1:8000/\nINFO     -  [09:28:37] Browser connected: http://127.0.0.1:8000/\n</code></pre> <p>Follow the typical PR process to contribute changes. </p> <ul> <li>Create a feature branch.</li> <li>Commit changes.</li> <li>Submit a PR.</li> </ul>"},{"location":"contributing/#-","title":"-------","text":""},{"location":"contributing/#taking-on-tasks","title":"Taking on Tasks","text":"<p>We have a growing list of tasks and issues that you can contribute to. To get started, follow these steps:</p> <ol> <li> <p>Visit the Swarms GitHub repository and browse through the existing issues.</p> </li> <li> <p>Find an issue that interests you and make a comment stating that you would like to work on it. Include a brief description of how you plan to solve the problem and any questions you may have.</p> </li> <li> <p>Once a project coordinator assigns the issue to you, you can start working on it.</p> </li> </ol> <p>If you come across an issue that is unclear but still interests you, please post in the Discord server mentioned above. Someone from the community will be able to help clarify the issue in more detail.</p> <p>We also welcome contributions to documentation, such as updating markdown files, adding docstrings, creating system architecture diagrams, and other related tasks.</p>"},{"location":"contributing/#submitting-your-work","title":"Submitting Your Work","text":"<p>To contribute your changes to Swarms, please follow these steps:</p> <ol> <li> <p>Fork the Swarms repository to your GitHub account. You can do this by clicking on the \"Fork\" button on the repository page.</p> </li> <li> <p>Clone the forked repository to your local machine using the <code>git clone</code> command.</p> </li> <li> <p>Before making any changes, make sure to sync your forked repository with the original repository to keep it up to date. You can do this by following the instructions here.</p> </li> <li> <p>Create a new branch for your changes. This branch should have a descriptive name that reflects the task or issue you are working on.</p> </li> <li> <p>Make your changes in the branch, focusing on a small, focused change that only affects a few files.</p> </li> <li> <p>Run any necessary formatting or linting tools to ensure that your changes adhere to the project's coding standards.</p> </li> <li> <p>Once your changes are ready, commit them to your branch with descriptive commit messages.</p> </li> <li> <p>Push the branch to your forked repository.</p> </li> <li> <p>Create a pull request (PR) from your branch to the main Swarms repository. Provide a clear and concise description of your changes in the PR.</p> </li> <li> <p>Request a review from the project maintainers. They will review your changes, provide feedback, and suggest any necessary improvements.</p> </li> <li> <p>Make any required updates or address any feedback provided during the review process.</p> </li> <li> <p>Once your changes have been reviewed and approved, they will be merged into the main branch of the Swarms repository.</p> </li> <li> <p>Congratulations! You have successfully contributed to Swarms.</p> </li> </ol> <p>Please note that during the review process, you may be asked to make changes or address certain issues. It is important to engage in open and constructive communication with the project maintainers to ensure the quality of your contributions.</p>"},{"location":"contributing/#developer-setup","title":"Developer Setup","text":"<p>If you are interested in setting up the Swarms development environment, please follow the instructions provided in the developer setup guide. This guide provides an overview of the different tools and technologies used in the project.</p>"},{"location":"contributing/#join-the-agora-community","title":"Join the Agora Community","text":"<p>Swarms is brought to you by Agora, the open-source AI research organization. Join the Agora community to connect with other researchers and developers working on AI projects.</p> <ul> <li>Join the Agora Discord Server</li> </ul> <p>Thank you for your contributions and for being a part of the Swarms and Agora community! Together, we can advance Humanity through the power of AI.</p>"},{"location":"diy_your_own_agent/","title":"Create your own agent with <code>Agent</code> class","text":"<p>In the rapidly evolving world of artificial intelligence (AI), the demand for specialized and highly customized agents is on the rise. Whether it's for task automation, decision support systems, or intelligent virtual assistants, the ability to create tailored agents can unlock new possibilities and efficiencies across various domains. Enter the Agent class, a powerful and flexible tool designed by Anthropic that empowers AI agents to build their own custom agents, tailored to their specific needs.</p> <p>This comprehensive guide will explore the process of inheriting from the Agent class, enabling agents to create their own custom agent classes. By leveraging the rich features and extensibility of the Agent class, agents can imbue their offspring agents with unique capabilities, specialized toolsets, and tailored decision-making processes.</p>"},{"location":"diy_your_own_agent/#understanding-the-agent-class","title":"Understanding the Agent Class","text":"<p>Before we dive into the intricacies of creating custom agent classes, let's revisit the foundational elements of the Agent class itself. The Agent class is a versatile and feature-rich class designed to streamline the process of building and managing AI agents. It acts as a backbone, connecting language models (LLMs) with various tools, long-term memory, and a wide range of customization options.</p>"},{"location":"diy_your_own_agent/#key-features-of-the-agent-class","title":"Key Features of the Agent Class","text":"<p>The Agent class offers a plethora of features that can be inherited and extended by custom agent classes. Here are some of the key features that make the Agent class a powerful foundation:</p> <p>1. Language Model Integration: The Agent class supports seamless integration with popular language models such as LangChain, HuggingFace Transformers, and Autogen, allowing custom agent classes to leverage the power of state-of-the-art language models.</p> <p>2. Tool Integration: One of the standout features of the Agent class is its ability to integrate with various tools. Custom agent classes can inherit this capability and incorporate specialized tools tailored to their specific use cases.</p> <p>3. Long-Term Memory: The Agent class provides built-in support for long-term memory, enabling custom agent classes to retain and access information from previous interactions, essential for maintaining context and learning from past experiences.</p> <p>4. Customizable Prompts and Standard Operating Procedures (SOPs): The Agent class allows you to define custom prompts and Standard Operating Procedures (SOPs) that guide an agent's behavior and decision-making process. Custom agent classes can inherit and extend these prompts and SOPs to align with their unique objectives and requirements.</p> <p>5. Interactive and Dashboard Modes: The Agent class supports interactive and dashboard modes, enabling real-time monitoring and interaction with agents. Custom agent classes can inherit these modes, facilitating efficient development, debugging, and user interaction.</p> <p>6. Autosave and State Management: With the Agent class, agents can easily save and load their state, including configuration, memory, and history. Custom agent classes can inherit this capability, ensuring seamless task continuation and enabling efficient collaboration among team members.</p> <p>7. Response Filtering: The Agent class provides built-in response filtering capabilities, allowing agents to filter out or replace specific words or phrases in their responses. Custom agent classes can inherit and extend this feature to ensure compliance with content moderation policies or specific guidelines.</p> <p>8. Code Execution and Multimodal Support: The Agent class supports code execution and multimodal input/output, enabling agents to process and generate code, as well as handle various data formats such as images, audio, and video. Custom agent classes can inherit and specialize these capabilities for their unique use cases.</p> <p>9. Extensibility and Customization: The Agent class is designed to be highly extensible and customizable, allowing agents to tailor its behavior, add custom functionality, and integrate with external libraries and APIs. Custom agent classes can leverage this extensibility to introduce specialized features and capabilities.</p>"},{"location":"diy_your_own_agent/#creating-a-custom-agent-class","title":"Creating a Custom Agent Class","text":"<p>Now that we have a solid understanding of the Agent class and its features, let's dive into the process of creating a custom agent class by inheriting from the Agent class. Throughout this process, we'll explore how agents can leverage and extend the existing functionality, while introducing specialized features and capabilities tailored to their unique requirements.</p>"},{"location":"diy_your_own_agent/#step-1-inherit-from-the-agent-class","title":"Step 1: Inherit from the Agent Class","text":"<p>The first step in creating a custom agent class is to inherit from the Agent class. This will provide your custom agent class with the foundational features and capabilities of the Agent class, which can then be extended and customized as needed.</p> <pre><code>from swarms import Agent\n\nclass MyCustomAgent(Agent):\n\n\u00a0 \u00a0 def __init__(self, *args, **kwargs):\n\n\u00a0 \u00a0 \u00a0 \u00a0 super().__init__(*args, **kwargs)\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Add custom initialization logic here\n</code></pre> <p>In the example above, we define a new class <code>MyCustomAgent</code> that inherits from the <code>Agent</code> class. Within the <code>__init__</code> method, we call the parent class's <code>__init__</code> method using <code>super().__init__(*args, **kwargs)</code>, which ensures that the parent class's initialization logic is executed. You can then add any custom initialization logic specific to your custom agent class.</p>"},{"location":"diy_your_own_agent/#step-2-customize-the-agents-behavior","title":"Step 2: Customize the Agent's Behavior","text":"<p>One of the key advantages of inheriting from the Agent class is the ability to customize the agent's behavior according to your specific requirements. This can be achieved by overriding or extending the existing methods, or by introducing new methods altogether.</p> <pre><code>from swarms import Agent\n\n\nclass MyCustomAgent(Agent):\n\n\u00a0 \u00a0 def __init__(self, *args, **kwargs):\n\n\u00a0 \u00a0 \u00a0 \u00a0 super().__init__(*args, **kwargs)\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Custom initialization logic\n\n\u00a0 \u00a0 def custom_method(self, *args, **kwargs):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Implement custom logic here\n\n\u00a0 \u00a0 \u00a0 \u00a0 pass\n\n\u00a0 \u00a0 def run(self, task, *args, **kwargs):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Customize the run method\n\n\u00a0 \u00a0 \u00a0 \u00a0 response = super().run(task, *args, **kwargs)\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Additional custom logic\n\n\u00a0 \u00a0 \u00a0 \u00a0 return response\n</code></pre> <p>In the example above, we introduce a new <code>custom_method</code> that can encapsulate any specialized logic or functionality specific to your custom agent class. Additionally, we override the <code>run</code> method, which is responsible for executing the agent's main task loop. Within the overridden <code>run</code> method, you can call the parent class's <code>run</code> method using <code>super().run(task, *args, **kwargs)</code> and then introduce any additional custom logic before or after the parent method's execution.</p>"},{"location":"diy_your_own_agent/#step-3-integrate-custom-tools","title":"Step 3: Integrate Custom Tools","text":"<p>One of the powerful features of the Agent class is the ability to integrate with various tools. Custom agent classes can inherit this capability and incorporate specialized tools tailored to their unique use cases.</p> <pre><code>from swarms.tools import BaseTool\nfrom swarms import Agent\n\n\nclass CustomTool(BaseTool):\n\n\u00a0 \u00a0 def __init__(self, *args, **kwargs):\n\n\u00a0 \u00a0 \u00a0 \u00a0 super().__init__(*args, **kwargs)\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Custom tool initialization logic\n\n\u00a0 \u00a0 def run(self, *args, **kwargs):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Custom tool logic\n\n\u00a0 \u00a0 \u00a0 \u00a0 return result\n\nclass MyCustomAgent(Agent):\n\n\u00a0 \u00a0 def __init__(self, *args, **kwargs):\n\n\u00a0 \u00a0 \u00a0 \u00a0 super().__init__(*args, **kwargs)\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Custom initialization logic\n\n\u00a0 \u00a0 \u00a0 \u00a0 self.tools = [CustomTool()]\n\n\u00a0 \u00a0 def run(self, task, *args, **kwargs):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Customize the run method\n\n\u00a0 \u00a0 \u00a0 \u00a0 response = super().run(task, *args, **kwargs)\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Utilize custom tools\n\n\u00a0 \u00a0 \u00a0 \u00a0 for tool in self.tools:\n\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 result = tool.run(*args, **kwargs)\n\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 # Process tool result\n\n\u00a0 \u00a0 \u00a0 \u00a0 return response\n</code></pre> <p>In the example above, we define a new <code>CustomTool</code> class that inherits from the <code>BaseTool</code> class provided by the Agent class framework. Within the <code>CustomTool</code> class, you can implement the specialized logic and functionality required by your custom tool.</p> <p>Next, within the <code>MyCustomAgent</code> class, we initialize an instance of the <code>CustomTool</code> and store it in the <code>self.tools</code> list. This list can then be utilized within the overridden <code>run</code> method, where you can execute each tool and process its results as needed.</p>"},{"location":"diy_your_own_agent/#step-4-extend-memory-management","title":"Step 4: Extend Memory Management","text":"<p>The Agent class provides built-in support for long-term memory, allowing agents to retain and access information from previous interactions. Custom agent classes can inherit and extend this capability by introducing specialized memory management techniques.</p> <pre><code>from swarms.memory import AbstractVectorDatabase\nfrom swarms import Agent\n\n\nclass CustomMemory(AbstractVectorDatabase):\n\n\u00a0 \u00a0 def __init__(self, *args, **kwargs):\n\n\u00a0 \u00a0 \u00a0 \u00a0 super().__init__(*args, **kwargs)\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Custom memory initialization logic\n\n\u00a0 \u00a0 def query(self, *args, **kwargs):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Custom memory query logic\n\n\u00a0 \u00a0 \u00a0 \u00a0 return result\n\nclass MyCustomAgent(Agent):\n\n\u00a0 \u00a0 def __init__(self, *args, **kwargs):\n\n\u00a0 \u00a0 \u00a0 \u00a0 super().__init__(*args, **kwargs)\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Custom initialization logic\n\n\u00a0 \u00a0 \u00a0 \u00a0 self.long_term_memory = CustomMemory()\n\n\u00a0 \u00a0 def run(self, task, *args, **kwargs):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Customize the run method\n\n\u00a0 \u00a0 \u00a0 \u00a0 response = super().run(task, *args, **kwargs)\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Utilize custom memory\n\n\u00a0 \u00a0 \u00a0 \u00a0 memory_result = self.long_term_memory.query(*args, **kwargs)\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Process memory result\n\n\u00a0 \u00a0 \u00a0 \u00a0 return response\n</code></pre> <p>In the example above, we define a new <code>CustomMemory</code> class that inherits from the <code>AbstractVectorDatabase</code> class provided by the Agent class framework. Within the <code>CustomMemory</code> class, you can implement specialized memory management logic, such as custom indexing, retrieval, and storage mechanisms.</p> <p>Next, within the <code>MyCustomAgent</code> class, we initialize an instance of the <code>CustomMemory</code> class and assign it to the <code>self.long_term_memory</code> attribute. This custom memory instance can then be utilized within the overridden <code>run</code> method, where you can query the memory and process the results as needed.</p> <p>Step 5: Introduce Custom Prompts and Standard Operating Procedures (SOPs)</p> <p>The Agent class allows you to define custom prompts and Standard Operating Procedures (SOPs) that guide an agent's behavior and decision-making process. Custom agent classes can inherit and extend these prompts and SOPs to align with their unique objectives and requirements.</p> <pre><code>from swarms import Agent\n\n\nclass MyCustomAgent(Agent):\n\n\u00a0 \u00a0 def __init__(self, *args, **kwargs):\n\n\u00a0 \u00a0 \u00a0 \u00a0 super().__init__(*args, **kwargs)\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Custom initialization logic\n\n\u00a0 \u00a0 \u00a0 \u00a0 self.custom_sop = \"Custom SOP for MyCustomAgent...\"\n\n\u00a0 \u00a0 \u00a0 \u00a0 self.custom_prompt = \"Custom prompt for MyCustomAgent...\"\n\n\u00a0 \u00a0 def run(self, task, *args, **kwargs):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Customize the run method\n\n\u00a0 \u00a0 \u00a0 \u00a0 response = super().run(task, *args, **kwargs)\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Utilize custom prompts and SOPs\n\n\u00a0 \u00a0 \u00a0 \u00a0 custom_prompt = self.construct_dynamic_prompt(self.custom_prompt)\n\n\u00a0 \u00a0 \u00a0 \u00a0 custom_sop = self.construct_dynamic_sop(self.custom_sop)\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Process custom prompts and SOPs\n\n\u00a0 \u00a0 \u00a0 \u00a0 return response\n\n\u00a0 \u00a0 def construct_dynamic_prompt(self, prompt):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Custom prompt construction logic\n\n\u00a0 \u00a0 \u00a0 \u00a0 return prompt\n\n\u00a0 \u00a0 def construct_dynamic_sop(self, sop):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Custom SOP construction logic\n\n\u00a0 \u00a0 \u00a0 \u00a0 return sop\n</code></pre> <p>In the example above, we define two new attributes within the <code>MyCustomAgent</code> class: <code>custom_sop</code> and <code>custom_prompt</code>. These attributes can be used to store custom prompts and SOPs specific to your custom agent class.</p> <p>Within the overridden <code>run</code> method, you can utilize these custom prompts and SOPs by calling the <code>construct_dynamic_prompt</code> and <code>construct_dynamic_sop</code> methods, which can be defined within the <code>MyCustomAgent</code> class to implement specialized prompt and SOP construction logic.</p>"},{"location":"diy_your_own_agent/#step-6-introduce-custom-response-handling","title":"Step 6: Introduce Custom Response Handling","text":"<p>The Agent class provides built-in response filtering capabilities, allowing agents to filter out or replace specific words or phrases in their responses. Custom agent classes can inherit and extend this feature to ensure compliance with content moderation policies or specific guidelines.</p> <pre><code>from swarms import Agent\n\n\nclass MyCustomAgent(Agent):\n\n\u00a0 \u00a0 def __init__(self, *args, **kwargs):\n\n\u00a0 \u00a0 \u00a0 \u00a0 super().__init__(*args, **kwargs)\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Custom initialization logic\n\n\u00a0 \u00a0 \u00a0 \u00a0 self.response_filters = [\"filter_word_1\", \"filter_word_2\"]\n\n\u00a0 \u00a0 def run(self, task, *args, **kwargs):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Customize the run method\n\n\u00a0 \u00a0 \u00a0 \u00a0 response = super().run(task, *args, **kwargs)\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Apply custom response filtering\n\n\u00a0 \u00a0 \u00a0 \u00a0 filtered_response = self.apply_response_filters(response)\n\n\u00a0 \u00a0 \u00a0 \u00a0 return filtered_response\n\n\u00a0 \u00a0 def apply_response_filters(self, response):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Custom response filtering logic\n\n\u00a0 \u00a0 \u00a0 \u00a0 for word in self.response_filters:\n\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 response = response.replace(word, \"[FILTERED]\")\n\n\u00a0 \u00a0 \u00a0 \u00a0 return response\n</code></pre> <p>In the example above, we define a new attribute <code>response_filters</code> within the <code>MyCustomAgent</code> class, which is a list of words or phrases that should be filtered out or replaced in the agent's responses.</p> <p>Within the overridden <code>run</code> method, we call the <code>apply_response_filters</code> method, which can be defined within the <code>MyCustomAgent</code> class to implement specialized response filtering logic. In the example, we iterate over the <code>response_filters</code> list and replace each filtered word or phrase with a placeholder string (<code>\"[FILTERED]\"</code>).</p>"},{"location":"diy_your_own_agent/#advanced-customization-and-integration","title":"Advanced Customization and Integration","text":"<p>The Agent class and its inherited custom agent classes can be further extended and customized to suit specific requirements and integrate with external libraries, APIs, and services. Here are some advanced customization and integration examples:</p> <p>1. Multimodal Input/Output Integration: Custom agent classes can leverage the multimodal input/output capabilities of the Agent class and introduce specialized handling for various data formats such as images, audio, and video.</p> <p>2. Code Execution and Integration: The Agent class supports code execution, enabling agents to run and evaluate code snippets. Custom agent classes can inherit and extend this capability, introducing specialized code execution environments, sandboxing mechanisms, or integration with external code repositories or platforms.</p> <p>3. External API and Service Integration: Custom agent classes can integrate with external APIs and services, enabling agents to leverage specialized data sources, computational resources, or domain-specific services.</p> <p>4. Performance Optimization: Depending on the use case and requirements, custom agent classes can introduce performance optimizations, such as adjusting loop intervals, retry attempts, or enabling parallel execution for certain tasks.</p> <p>5. Logging and Monitoring: Custom agent classes can introduce specialized logging and monitoring mechanisms, enabling agents to track their performance, identify potential issues, and generate detailed reports or dashboards.</p> <p>6. Security and Privacy Enhancements: Custom agent classes can implement security and privacy enhancements, such as data encryption, access control mechanisms, or compliance with industry-specific regulations and standards.</p> <p>7. Distributed Execution and Scaling: Custom agent classes can be designed to support distributed execution and scaling, enabling agents to leverage cloud computing resources or distributed computing frameworks for handling large-scale tasks or high-concurrency workloads.</p> <p>By leveraging these advanced customization and integration capabilities, agents can create highly specialized and sophisticated custom agent classes tailored to their unique requirements and use cases.</p>"},{"location":"diy_your_own_agent/#best-practices-and-considerations","title":"Best Practices and Considerations","text":"<p>While building custom agent classes by inheriting from the Agent class offers immense flexibility and power, it's essential to follow best practices and consider potential challenges and considerations:</p> <p>1. Maintainability and Documentation: As custom agent classes become more complex, it's crucial to prioritize maintainability and thorough documentation. Clear and concise code, comprehensive comments, and up-to-date documentation can significantly improve the long-term sustainability and collaboration efforts surrounding custom agent classes.</p> <p>2. Testing and Validation: Custom agent classes should undergo rigorous testing and validation to ensure their correctness, reliability, and adherence to expected behaviors. Establish a robust testing framework and continuously validate the agent's performance, particularly after introducing new features or integrations.</p> <p>3. Security and Privacy Considerations: When building custom agent classes, it's essential to consider security and privacy implications, especially if the agents will handle sensitive data or interact with critical systems. Implement appropriate security measures, such as access controls, data encryption, and secure communication protocols, to protect against potential vulnerabilities and ensure compliance with relevant regulations and standards.</p> <p>4. Scalability and Performance Monitoring: As custom agent classes are deployed and adopted, it's important to monitor their scalability and performance characteristics. Identify potential bottlenecks, resource constraints, or performance degradation, and implement appropriate optimization strategies or scaling mechanisms to ensure efficient and reliable operation.</p> <p>5. Collaboration and Knowledge Sharing: Building custom agent classes often involves collaboration among teams and stakeholders. Foster an environment of knowledge sharing, code reviews, and open communication to ensure that everyone involved understands the agent's capabilities, limitations, and intended use cases.</p> <p>6. Ethical Considerations: As AI agents become more advanced and autonomous, it's crucial to consider the ethical implications of their actions and decisions. Implement appropriate safeguards, oversight mechanisms, and ethical guidelines to ensure that custom agent classes operate in a responsible and transparent manner, aligning with ethical principles and societal values.</p> <p>7. Continuous Learning and Adaptation: The field of AI is rapidly evolving, with new techniques, tools, and best practices emerging regularly. Stay up-to-date with the latest developments and be prepared to adapt and refine your custom agent classes as new advancements become available.</p> <p>By following these best practices and considering potential challenges, agents can create robust, reliable, and ethical custom agent classes that meet their specific requirements while adhering to industry standards and best practices.</p>"},{"location":"diy_your_own_agent/#conclusion","title":"Conclusion","text":"<p>In this comprehensive guide, we have explored the process of creating custom agent classes by inheriting from the powerful Agent class. We have covered the key features of the Agent class, walked through the step-by-step process of inheriting and extending its functionality, and discussed advanced customization and integration techniques.</p> <p>Building custom agent classes empowers AI agents to create tailored and specialized agents capable of tackling unique challenges and addressing specific domain requirements. By leveraging the rich features and extensibility of the Agent class, agents can imbue their offspring agents with unique capabilities, specialized toolsets, and tailored decision-making processes.</p> <p>Remember, the journey of building custom agent classes is an iterative and collaborative process that requires continuous learning, adaptation, and refinement. Embrace the</p>"},{"location":"docker_setup/","title":"Docker Setup Guide for Contributors to Swarms","text":""},{"location":"docker_setup/#introduction","title":"Introduction","text":"<p>Welcome to the <code>swarms</code> project Docker setup guide. This document will help you establish a Docker-based environment for contributing to <code>swarms</code>. Docker provides a consistent and isolated environment, ensuring that all contributors can work in the same settings, reducing the \"it works on my machine\" syndrome.</p>"},{"location":"docker_setup/#purpose","title":"Purpose","text":"<p>The purpose of this guide is to:</p> <ul> <li>Ensure contributors can quickly set up their development environment.</li> <li>Provide a consistent testing and deployment workflow.</li> <li>Introduce Docker basics and best practices.</li> </ul>"},{"location":"docker_setup/#scope","title":"Scope","text":"<p>This guide covers:</p> <ul> <li>Installing Docker</li> <li>Cloning the <code>swarms</code> repository</li> <li>Building a Docker image</li> <li>Running the <code>swarms</code> application in a Docker container</li> <li>Running tests using Docker</li> <li>Pushing changes and working with Docker Hub</li> </ul>"},{"location":"docker_setup/#audience","title":"Audience","text":"<p>This guide is intended for developers and contributors to the <code>swarms</code> project who have basic knowledge of version control with Git and programming in Python.</p>"},{"location":"docker_setup/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have: - A GitHub account - Git installed on your machine - Basic command-line proficiency</p>"},{"location":"docker_setup/#docker-installation","title":"Docker Installation","text":""},{"location":"docker_setup/#windows","title":"Windows","text":"<ol> <li>Download Docker Desktop for Windows from the official website.</li> <li>Install Docker Desktop, ensuring that the \"Use Windows containers instead of Linux containers\" option is unchecked.</li> <li>Start Docker Desktop and wait for the Docker engine to start.</li> </ol>"},{"location":"docker_setup/#macos","title":"macOS","text":"<ol> <li>Download Docker Desktop for macOS from the official website.</li> <li>Follow the installation instructions, drag-and-drop Docker into the Applications folder.</li> <li>Start Docker Desktop from the Applications folder.</li> </ol>"},{"location":"docker_setup/#linux-ubuntu","title":"Linux (Ubuntu)","text":"<ol> <li>Update your package index: <code>sudo apt-get update</code>.</li> <li>Install packages to allow apt to use a repository over HTTPS.</li> <li>Add Docker\u2019s official GPG key.</li> <li>Set up the stable repository.</li> <li>Install the latest version of Docker Engine and containerd.</li> </ol> <pre><code>sudo apt-get install docker-ce docker-ce-cli containerd.io\n</code></pre> <ol> <li>Verify that Docker Engine is installed correctly by running the hello-world image.</li> </ol> <pre><code>sudo docker run hello-world\n</code></pre>"},{"location":"docker_setup/#post-installation-steps-for-linux","title":"Post-installation Steps for Linux","text":"<ul> <li>Manage Docker as a non-root user.</li> <li>Configure Docker to start on boot.</li> </ul>"},{"location":"docker_setup/#cloning-the-repository","title":"Cloning the Repository","text":"<pre><code>git clone https://github.com/your-username/swarms.git\ncd swarms\n</code></pre>"},{"location":"docker_setup/#docker-basics","title":"Docker Basics","text":""},{"location":"docker_setup/#dockerfile-overview","title":"Dockerfile Overview","text":"<ul> <li>Explain the structure and commands of a Dockerfile used in the <code>swarms</code> project.</li> </ul>"},{"location":"docker_setup/#building-the-image","title":"Building the Image","text":"<pre><code>docker build -t swarms-dev .\n</code></pre>"},{"location":"docker_setup/#running-a-container","title":"Running a Container","text":"<pre><code>docker run -it --rm swarms-dev\n</code></pre>"},{"location":"docker_setup/#development-workflow-with-docker","title":"Development Workflow with Docker","text":""},{"location":"docker_setup/#running-the-application","title":"Running the Application","text":"<ul> <li>Commands to run the <code>swarms</code> application within Docker.</li> </ul>"},{"location":"docker_setup/#making-changes","title":"Making Changes","text":"<ul> <li>How to make changes to the code and reflect those changes within the Docker container.</li> </ul>"},{"location":"docker_setup/#running-tests","title":"Running Tests","text":"<ul> <li>Instructions on running tests using <code>pytest</code> within the Docker environment.</li> </ul>"},{"location":"docker_setup/#docker-compose-for-local-development","title":"Docker Compose for Local Development","text":"<ul> <li>Introduce Docker Compose and its role in simplifying multi-container setups.</li> <li>Create a <code>docker-compose.yml</code> file for the <code>swarms</code> project.</li> </ul>"},{"location":"docker_setup/#dockerfile","title":"Dockerfile","text":"<p>Creating a Dockerfile for deploying the <code>swarms</code> framework to the cloud involves setting up the necessary environment to run your Python application, ensuring all dependencies are installed, and configuring the container to execute the desired tasks. Here's an example Dockerfile that sets up such an environment:</p> <pre><code># Use an official Python runtime as a parent image\nFROM python:3.9-slim\n\n# Set environment variables\nENV PYTHONDONTWRITEBYTECODE 1\nENV PYTHONUNBUFFERED 1\n\n# Set the working directory in the container\nWORKDIR /usr/src/swarm_cloud\n\n# Install system dependencies\nRUN apt-get update \\\n    &amp;&amp; apt-get -y install netcat gcc \\\n    &amp;&amp; apt-get clean\n\n# Install Python dependencies\n# COPY requirements.txt and pyproject.toml if you're using poetry for dependency management\nCOPY requirements.txt .\nRUN pip install --upgrade pip\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Install the 'swarms' package, assuming it's available on PyPI\nRUN pip install swarms\n\n# Copy the rest of the application\nCOPY . .\n\n# Add entrypoint script if needed\n# COPY ./entrypoint.sh .\n# RUN chmod +x /usr/src/swarm_cloud/entrypoint.sh\n\n# Expose port if your application has a web interface\n# EXPOSE 5000\n\n# Define environment variable for the swarm to work\nENV SWARM_API_KEY=your_swarm_api_key_here\n\n# Add Docker CMD or ENTRYPOINT script to run the application\n# CMD python your_swarm_startup_script.py\n# Or use the entrypoint script if you have one\n# ENTRYPOINT [\"/usr/src/swarm_cloud/entrypoint.sh\"]\n\n# If you're using `CMD` to execute a Python script, make sure it's executable\n# RUN chmod +x your_swarm_startup_script.py\n</code></pre> <p>To build and run this Docker image:</p> <ol> <li>Replace <code>requirements.txt</code> with your actual requirements file or <code>pyproject.toml</code> and <code>poetry.lock</code> if you're using Poetry.</li> <li>Replace <code>your_swarm_startup_script.py</code> with the script that starts your application.</li> <li>If your application requires an API key or other sensitive data, make sure to set these securely, perhaps using environment variables or secrets management solutions provided by your cloud provider.</li> <li>If you have an entrypoint script, uncomment the <code>COPY</code> and <code>RUN</code> lines for <code>entrypoint.sh</code>.</li> <li>If your application has a web interface, uncomment the <code>EXPOSE</code> line and set it to the correct port.</li> </ol> <p>Now, build your Docker image:</p> <pre><code>docker build -t swarm-cloud .\n</code></pre> <p>And run it:</p> <pre><code>docker run -d --name my-swarm-app swarm-cloud\n</code></pre> <p>For deploying to the cloud, you'll need to push your Docker image to a container registry (like Docker Hub or a private registry), then pull it from your cloud environment to run it. Cloud providers often have services specifically for this purpose (like AWS ECS, GCP GKE, or Azure AKS). The deployment process will involve:</p> <ul> <li>Pushing the image to a registry.</li> <li>Configuring cloud services to run your image.</li> <li>Setting up networking, storage, and other cloud resources.</li> <li>Monitoring, logging, and potentially scaling your containers.</li> </ul> <p>Remember to secure sensitive data, use tagged releases for your images, and follow best practices for operating in the cloud.</p>"},{"location":"limits_of_individual_agents/","title":"The Limits of Individual Agents","text":"<p>Individual agents have pushed the boundaries of what machines can learn and accomplish. However, despite their impressive capabilities, these agents face inherent limitations that can hinder their effectiveness in complex, real-world applications. This blog explores the critical constraints of individual agents, such as context window limits, hallucination, single-task threading, and lack of collaboration, and illustrates how multi-agent collaboration can address these limitations. In short,</p> <ul> <li>Context Window Limits</li> <li>Single Task Execution</li> <li>Hallucination</li> <li>No collaboration</li> </ul>"},{"location":"limits_of_individual_agents/#context-window-limits","title":"Context Window Limits","text":"<p>One of the most significant constraints of individual agents, particularly in the domain of language models, is the context window limit. This limitation refers to the maximum amount of information an agent can consider at any given time. For instance, many language models can only process a fixed number of tokens (words or characters) in a single inference, restricting their ability to understand and generate responses based on longer texts. This limitation can lead to a lack of coherence in longer compositions and an inability to maintain context in extended conversations or documents.</p>"},{"location":"limits_of_individual_agents/#hallucination","title":"Hallucination","text":"<p>Hallucination in AI refers to the phenomenon where an agent generates information that is not grounded in the input data or real-world facts. This can manifest as making up facts, entities, or events that do not exist or are incorrect. Hallucinations pose a significant challenge in ensuring the reliability and trustworthiness of AI-generated content, particularly in critical applications such as news generation, academic research, and legal advice.</p>"},{"location":"limits_of_individual_agents/#single-task-threading","title":"Single Task Threading","text":"<p>Individual agents are often designed to excel at specific tasks, leveraging their architecture and training data to optimize performance in a narrowly defined domain. However, this specialization can also be a drawback, as it limits the agent's ability to multitask or adapt to tasks that fall outside its primary domain. Single-task threading means an agent may excel in language translation but struggle with image recognition or vice versa, necessitating the deployment of multiple specialized agents for comprehensive AI solutions.</p>"},{"location":"limits_of_individual_agents/#lack-of-collaboration","title":"Lack of Collaboration","text":"<p>Traditional AI agents operate in isolation, processing inputs and generating outputs independently. This isolation limits their ability to leverage diverse perspectives, share knowledge, or build upon the insights of other agents. In complex problem-solving scenarios, where multiple facets of a problem need to be addressed simultaneously, this lack of collaboration can lead to suboptimal solutions or an inability to tackle multifaceted challenges effectively.</p>"},{"location":"limits_of_individual_agents/#the-elegant-yet-simple-solution","title":"The Elegant yet Simple Solution","text":"<p>Recognizing the limitations of individual agents, researchers and practitioners have explored the potential of multi-agent collaboration as a means to transcend these constraints. Multi-agent systems comprise several agents that can interact, communicate, and collaborate to achieve common goals or solve complex problems. This collaborative approach offers several advantages:</p>"},{"location":"limits_of_individual_agents/#multi-agent-collaboration","title":"Multi-Agent Collaboration","text":""},{"location":"limits_of_individual_agents/#overcoming-context-window-limits","title":"Overcoming Context Window Limits","text":"<p>By dividing a large task among multiple agents, each focusing on different segments of the problem, multi-agent systems can effectively overcome the context window limits of individual agents. For instance, in processing a long document, different agents could be responsible for understanding and analyzing different sections, pooling their insights to generate a coherent understanding of the entire text.</p>"},{"location":"limits_of_individual_agents/#mitigating-hallucination","title":"Mitigating Hallucination","text":"<p>Through collaboration, agents can cross-verify facts and information, reducing the likelihood of hallucinations. If one agent generates a piece of information, other agents can provide checks and balances, verifying the accuracy against known data or through consensus mechanisms.</p>"},{"location":"limits_of_individual_agents/#enhancing-multitasking-capabilities","title":"Enhancing Multitasking Capabilities","text":"<p>Multi-agent systems can tackle tasks that require a diverse set of skills by leveraging the specialization of individual agents. For example, in a complex project that involves both natural language processing and image analysis, one agent specialized in text can collaborate with another specialized in visual data, enabling a comprehensive approach to the task.</p>"},{"location":"limits_of_individual_agents/#facilitating-collaboration-and-knowledge-sharing","title":"Facilitating Collaboration and Knowledge Sharing","text":"<p>Multi-agent collaboration inherently encourages the sharing of knowledge and insights, allowing agents to learn from each other and improve their collective performance. This can be particularly powerful in scenarios where iterative learning and adaptation are crucial, such as dynamic environments or tasks that evolve over time.</p>"},{"location":"limits_of_individual_agents/#conclusion","title":"Conclusion","text":"<p>While individual AI agents have made remarkable strides in various domains, their inherent limitations necessitate innovative approaches to unlock the full potential of artificial intelligence. Multi-agent collaboration emerges as a compelling solution, offering a pathway to transcend individual constraints through collective intelligence. By harnessing the power of collaborative AI, we can address more complex, multifaceted problems, paving the way for more versatile, efficient, and effective AI systems in the future.</p>"},{"location":"swarms_bounty_system/","title":"The Swarms Bounty System: Get Paid to Contribute to Open Source","text":"<p>In today's fast-paced world of software development, open source has become a driving force for innovation. Every single business and organization on the planet is dependent on open source software.</p> <p>The power of collaboration and community has proven to be a potent catalyst for creating robust, cutting-edge solutions. At Swarms, we recognize the immense value that open source contributors bring to the table, and we're thrilled to introduce our Bounty System \u2013 a program designed to reward developers for their invaluable contributions to the Swarms ecosystem.</p> <p>The Swarms Bounty System is a groundbreaking initiative that encourages developers from all walks of life to actively participate in the development and improvement of our suite of products, including the Swarms Python framework, Swarm Cloud, and Swarm Core. By leveraging the collective intelligence and expertise of the global developer community, we aim to foster a culture of continuous innovation and excellence.</p> <p>All bounties with rewards can be found here:</p>"},{"location":"swarms_bounty_system/#the-power-of-collaboration","title":"The Power of Collaboration","text":"<p>At the heart of the Swarms Bounty System lies the belief that collaboration is the key to unlocking the true potential of software development. By opening up our codebase to the vast talent pool of developers around the world, we're not only tapping into a wealth of knowledge and skills, but also fostering a sense of ownership and investment in the Swarms ecosystem.</p> <p>Whether you're a seasoned developer with years of experience or a passionate newcomer eager to learn and grow, the Swarms Bounty System offers a unique opportunity to contribute to cutting-edge projects and leave your mark on the technological landscape.</p>"},{"location":"swarms_bounty_system/#how-the-bounty-system-works","title":"How the Bounty System Works","text":"<p>The Swarms Bounty System is designed to be simple, transparent, and rewarding. Here's how it works:</p> <ol> <li> <p>Explore the Bounties: We maintain a comprehensive list of bounties, ranging from bug fixes and feature enhancements to entirely new projects. These bounties are categorized based on their complexity and potential impact, ensuring that there's something for everyone, regardless of their skill level or area of expertise. Bounties will be listed here</p> </li> <li> <p>Submit Your Contributions: Once you've identified a bounty that piques your interest, you can start working on it. When you're ready, submit your contribution in the form of a pull request, following our established guidelines and best practices.</p> </li> <li> <p>Review and Approval: Our dedicated team of reviewers will carefully evaluate your submission, ensuring that it meets our rigorous quality standards and aligns with the project's vision. They'll provide feedback and guidance, fostering a collaborative environment where you can learn and grow.</p> </li> <li> <p>Get Rewarded: Upon successful acceptance of your contribution, you'll be rewarded with a combination of cash and or stock incentives. The rewards are based on a tiered system, reflecting the complexity and impact of your contribution.</p> </li> </ol>"},{"location":"swarms_bounty_system/#the-rewards-system","title":"The Rewards System","text":"<p>At Swarms, we believe in recognizing and rewarding exceptional contributions. Our tiered rewards system is designed to incentivize developers to push the boundaries of innovation and drive the Swarms ecosystem forward. Here's how the rewards are structured:</p>"},{"location":"swarms_bounty_system/#tier-1-bug-fixes-and-minor-enhancements","title":"Tier 1: Bug Fixes and Minor Enhancements","text":"Reward Description Cash Reward $50 - $150 Stock Reward N/A <p>This tier covers minor bug fixes, documentation improvements, and small enhancements to existing features. While these contributions may seem insignificant, they play a crucial role in maintaining the stability and usability of our products.</p>"},{"location":"swarms_bounty_system/#tier-2-moderate-enhancements-and-new-features","title":"Tier 2: Moderate Enhancements and New Features","text":"Reward Description Cash Reward $151 - $300 Stock Reward 10+ <p>This tier encompasses moderate enhancements to existing features, as well as the implementation of new, non-critical features. Contributions in this tier demonstrate a deeper understanding of the project's architecture and a commitment to improving the overall user experience.</p>"},{"location":"swarms_bounty_system/#tier-3-major-features-and-groundbreaking-innovations","title":"Tier 3: Major Features and Groundbreaking Innovations","text":"Reward Description Cash Reward $301 - $500 Stock Reward 25+ <p>This tier is reserved for truly exceptional contributions that have the potential to revolutionize the Swarms ecosystem. Major feature additions, innovative architectural improvements, and groundbreaking new projects fall under this category. Developers who contribute at this level will be recognized as thought leaders and pioneers in their respective fields.</p> <p>It's important to note that the cash and stock rewards are subject to change based on the project's requirements, complexity, and overall impact. Additionally, we may introduce special bounties with higher reward tiers for particularly challenging or critical projects.</p>"},{"location":"swarms_bounty_system/#the-benefits-of-contributing","title":"The Benefits of Contributing","text":"<p>Participating in the Swarms Bounty System offers numerous benefits beyond the financial incentives. By contributing to our open source projects, you'll have the opportunity to:</p> <ol> <li> <p>Expand Your Skills: Working on real-world projects with diverse challenges will help you hone your existing skills and acquire new ones, making you a more versatile and valuable developer.</p> </li> <li> <p>Build Your Portfolio: Your contributions will become part of your professional portfolio, showcasing your expertise and dedication to the open source community.</p> </li> <li> <p>Network with Industry Experts: Collaborate with our team of seasoned developers and gain invaluable insights and mentorship from industry leaders.</p> </li> <li> <p>Shape the Future: Your contributions will directly impact the direction and evolution of the Swarms ecosystem, shaping the future of our products and services.</p> </li> <li> <p>Gain Recognition: Stand out in the crowded field of software development by having your contributions acknowledged and celebrated by the Swarms community.</p> </li> </ol>"},{"location":"swarms_bounty_system/#join-the-movement","title":"Join the Movement","text":"<p>The Swarms Bounty System is more than just a program; it's a movement that embraces the spirit of open source and fosters a culture of collaboration, innovation, and excellence. By joining our ranks, you'll become part of a vibrant community of developers who share a passion for pushing the boundaries of what's possible.</p> <p>Whether you're a seasoned veteran or a newcomer eager to make your mark, the Swarms Bounty System offers a unique opportunity to contribute to cutting-edge projects, earn rewards, and shape the future of software development.</p> <p>So, what are you waiting for? Explore our bounties, find your niche, and start contributing today. Together, we can build a brighter, more innovative future for the Swarms ecosystem and the entire software development community.</p> <p>Join the swarm community now:</p>"},{"location":"swarms_bounty_system/#resources","title":"Resources","text":"<ul> <li>Bounty Board</li> <li>Swarm Community</li> <li>Swarms Framework</li> <li>Swarm Cloud</li> <li>Swarm Ecosystem</li> </ul>"},{"location":"why_swarms/","title":"Why Swarms?","text":"<p>The need for multiple agents to work together in artificial intelligence (AI) and particularly in the context of Large Language Models (LLMs) stems from several inherent limitations and challenges in handling complex, dynamic, and multifaceted tasks with single-agent systems. Collaborating with multiple agents offers a pathway to enhance reliability, computational efficiency, cognitive diversity, and problem-solving capabilities. This section delves into the rationale behind employing multi-agent systems and strategizes on overcoming the associated expenses, such as API bills and hosting costs.</p>"},{"location":"why_swarms/#why-multiple-agents-are-necessary","title":"Why Multiple Agents Are Necessary","text":""},{"location":"why_swarms/#1-cognitive-diversity","title":"1. Cognitive Diversity","text":"<p>Different agents can bring varied perspectives, knowledge bases, and problem-solving approaches to a task. This diversity is crucial in complex problem-solving scenarios where a single approach might not be sufficient. Cognitive diversity enhances creativity, leading to innovative solutions and the ability to tackle a broader range of problems.</p>"},{"location":"why_swarms/#2-specialization-and-expertise","title":"2. Specialization and Expertise","text":"<p>In many cases, tasks are too complex for a single agent to handle efficiently. By dividing the task among multiple specialized agents, each can focus on a segment where it excels, thereby increasing the overall efficiency and effectiveness of the solution. This approach leverages the expertise of individual agents to achieve superior performance in tasks that require multifaceted knowledge and skills.</p>"},{"location":"why_swarms/#3-scalability-and-flexibility","title":"3. Scalability and Flexibility","text":"<p>Multi-agent systems can more easily scale to handle large-scale or evolving tasks. Adding more agents to the system can increase its capacity or capabilities, allowing it to adapt to larger workloads or new types of tasks. This scalability is essential in dynamic environments where the demand and nature of tasks can change rapidly.</p>"},{"location":"why_swarms/#4-robustness-and-redundancy","title":"4. Robustness and Redundancy","text":"<p>Collaboration among multiple agents enhances the system's robustness by introducing redundancy. If one agent fails or encounters an error, others can compensate, ensuring the system remains operational. This redundancy is critical in mission-critical applications where failure is not an option.</p>"},{"location":"why_swarms/#overcoming-expenses-with-api-bills-and-hosting","title":"Overcoming Expenses with API Bills and Hosting","text":"<p>Deploying multiple agents, especially when relying on cloud-based services or APIs, can incur significant costs. Here are strategies to manage and reduce these expenses:</p>"},{"location":"why_swarms/#1-optimize-agent-efficiency","title":"1. Optimize Agent Efficiency","text":"<p>Before scaling up the number of agents, ensure each agent operates as efficiently as possible. This can involve refining algorithms, reducing unnecessary API calls, and optimizing data processing to minimize computational requirements and, consequently, the associated costs.</p>"},{"location":"why_swarms/#2-use-open-source-and-self-hosted-solutions","title":"2. Use Open Source and Self-Hosted Solutions","text":"<p>Where possible, leverage open-source models and technologies that can be self-hosted. While there is an initial investment in setting up the infrastructure, over time, self-hosting can significantly reduce costs related to API calls and reliance on third-party services.</p>"},{"location":"why_swarms/#3-implement-intelligent-caching","title":"3. Implement Intelligent Caching","text":"<p>Caching results for frequently asked questions or common tasks can drastically reduce the need for repeated computations or API calls. Intelligent caching systems can determine what information to store and for how long, optimizing the balance between fresh data and computational savings.</p>"},{"location":"why_swarms/#4-dynamic-scaling-and-load-balancing","title":"4. Dynamic Scaling and Load Balancing","text":"<p>Use cloud services that offer dynamic scaling and load balancing to adjust the resources allocated based on the current demand. This ensures you're not paying for idle resources during low-usage periods while still being able to handle high demand when necessary.</p>"},{"location":"why_swarms/#5-collaborative-cost-sharing-models","title":"5. Collaborative Cost-Sharing Models","text":"<p>In scenarios where multiple stakeholders benefit from the multi-agent system, consider implementing a cost-sharing model. This approach distributes the financial burden among the users or beneficiaries, making it more sustainable.</p>"},{"location":"why_swarms/#6-monitor-and-analyze-costs","title":"6. Monitor and Analyze Costs","text":"<p>Regularly monitor and analyze your usage and associated costs to identify potential savings. Many cloud providers offer tools to track and forecast expenses, helping you to adjust your usage patterns and configurations to minimize costs without sacrificing performance.</p>"},{"location":"why_swarms/#conclusion","title":"Conclusion","text":"<p>The collaboration of multiple agents in AI systems presents a robust solution to the complexity, specialization, scalability, and robustness challenges inherent in single-agent approaches. While the associated costs can be significant, strategic optimization, leveraging open-source technologies, intelligent caching, dynamic resource management, collaborative cost-sharing, and diligent monitoring can mitigate these expenses. By adopting these strategies, organizations can harness the power of multi-agent systems to tackle complex problems more effectively and efficiently, ensuring the sustainable deployment of these advanced technologies.</p>"},{"location":"applications/customer_support/","title":"Overview","text":""},{"location":"applications/customer_support/#applications-of-swarms-revolutionizing-customer-support","title":"Applications of Swarms: Revolutionizing Customer Support","text":"<p>Introduction: In today's fast-paced digital world, responsive and efficient customer support is a linchpin for business success. The introduction of AI-driven swarms in the customer support domain can transform the way businesses interact with and assist their customers. By leveraging the combined power of multiple AI agents working in concert, businesses can achieve unprecedented levels of efficiency, customer satisfaction, and operational cost savings.</p>"},{"location":"applications/customer_support/#the-benefits-of-using-swarms-for-customer-support","title":"The Benefits of Using Swarms for Customer Support:","text":"<ol> <li> <p>24/7 Availability: Swarms never sleep. Customers receive instantaneous support at any hour, ensuring constant satisfaction and loyalty.</p> </li> <li> <p>Infinite Scalability: Whether it's ten inquiries or ten thousand, swarms can handle fluctuating volumes with ease, eliminating the need for vast human teams and minimizing response times.</p> </li> <li> <p>Adaptive Intelligence: Swarms learn collectively, meaning that a solution found for one customer can be instantly applied to benefit all. This leads to constantly improving support experiences, evolving with every interaction.</p> </li> </ol>"},{"location":"applications/customer_support/#features-reinventing-customer-support","title":"Features - Reinventing Customer Support:","text":"<ul> <li> <p>AI Inbox Monitor: Continuously scans email inboxes, identifying and categorizing support requests for swift responses.</p> </li> <li> <p>Intelligent Debugging: Proactively helps customers by diagnosing and troubleshooting underlying issues.</p> </li> <li> <p>Automated Refunds &amp; Coupons: Seamless integration with payment systems like Stripe allows for instant issuance of refunds or coupons if a problem remains unresolved.</p> </li> <li> <p>Full System Integration: Holistically connects with CRM, email systems, and payment portals, ensuring a cohesive and unified support experience.</p> </li> <li> <p>Conversational Excellence: With advanced LLMs (Language Model Transformers), the swarm agents can engage in natural, human-like conversations, enhancing customer comfort and trust.</p> </li> <li> <p>Rule-based Operation: By working with rule engines, swarms ensure that all actions adhere to company guidelines, ensuring consistent, error-free support.</p> </li> <li> <p>Turing Test Ready: Crafted to meet and exceed the Turing Test standards, ensuring that every customer interaction feels genuine and personal.</p> </li> </ul> <p>Conclusion: Swarms are not just another technological advancement; they represent the future of customer support. Their ability to provide round-the-clock, scalable, and continuously improving support can redefine customer experience standards. By adopting swarms, businesses can stay ahead of the curve, ensuring unparalleled customer loyalty and satisfaction.</p> <p>Experience the future of customer support. Dive into the swarm revolution.</p>"},{"location":"applications/discord/","title":"Discord","text":""},{"location":"applications/discord/#usage-documentation-discord-bot-with-advanced-features","title":"Usage Documentation: Discord Bot with Advanced Features","text":""},{"location":"applications/discord/#overview","title":"Overview:","text":"<p>This code provides a structure for a Discord bot with advanced features such as voice channel interactions, image generation, and text-based interactions using OpenAI models.</p>"},{"location":"applications/discord/#setup","title":"Setup:","text":"<ol> <li> <p>Ensure that the necessary libraries are installed: <pre><code>pip install discord.py python-dotenv dalle3 invoke openai\n</code></pre></p> </li> <li> <p>Create a <code>.env</code> file in the same directory as your bot script and add the following: <pre><code>DISCORD_TOKEN=your_discord_bot_token\nSTORAGE_SERVICE=your_storage_service_endpoint\nSAVE_DIRECTORY=path_to_save_generated_images\n</code></pre></p> </li> </ol>"},{"location":"applications/discord/#bot-class-and-its-methods","title":"Bot Class and its Methods:","text":""},{"location":"applications/discord/#__init__self-agent-llm-command_prefix","title":"<code>__init__(self, agent, llm, command_prefix=\"!\")</code>:","text":"<p>Initializes the bot with the given agent, language model (<code>llm</code>), and a command prefix (default is <code>!</code>).</p>"},{"location":"applications/discord/#add_commandself-name-func","title":"<code>add_command(self, name, func)</code>:","text":"<p>Allows you to dynamically add new commands to the bot. The <code>name</code> is the command's name and <code>func</code> is the function to execute when the command is called.</p>"},{"location":"applications/discord/#runself","title":"<code>run(self)</code>:","text":"<p>Starts the bot using the <code>DISCORD_TOKEN</code> from the <code>.env</code> file.</p>"},{"location":"applications/discord/#commands","title":"Commands:","text":"<ol> <li> <p>!greet: Greets the user.</p> </li> <li> <p>!help_me: Provides a list of commands and their descriptions.</p> </li> <li> <p>!join: Joins the voice channel the user is in.</p> </li> <li> <p>!leave: Leaves the voice channel the bot is currently in.</p> </li> <li> <p>!listen: Starts listening to voice in the current voice channel and records the audio.</p> </li> <li> <p>!generate_image [prompt]: Generates images based on the provided prompt using the DALL-E3 model.</p> </li> <li> <p>!send_text [text] [use_agent=True]: Sends the provided text to the worker (either the agent or the LLM) and returns the response.</p> </li> </ol>"},{"location":"applications/discord/#usage","title":"Usage:","text":"<p>Initialize the <code>llm</code> (Language Learning Model) with your OpenAI API key:</p> <pre><code>from swarms.models import OpenAIChat\n\nllm = OpenAIChat(\n    openai_api_key=\"Your_OpenAI_API_Key\",\n    temperature=0.5,\n)\n</code></pre> <p>Initialize the bot with the <code>llm</code>:</p> <pre><code>from apps.discord import Bot\n\nbot = Bot(llm=llm)\n</code></pre> <p>Send a task to the bot:</p> <pre><code>task = \"What were the winning Boston Marathon times for the past 5 years (ending in 2022)? Generate a table of the year, name, country of origin, and times.\"\nbot.send_text(task)\n</code></pre> <p>Start the bot:</p> <pre><code>bot.run()\n</code></pre>"},{"location":"applications/discord/#additional-notes","title":"Additional Notes:","text":"<ul> <li> <p>The bot makes use of the <code>dalle3</code> library for image generation. Ensure you have the model and necessary setup for it.</p> </li> <li> <p>For the storage service, you might want to integrate with a cloud service like Google Cloud Storage or AWS S3 to store and retrieve generated images. The given code assumes a method <code>.upload()</code> for the storage service to upload files.</p> </li> <li> <p>Ensure that you've granted the bot necessary permissions on Discord, especially if you want to use voice channel features.</p> </li> <li> <p>Handle API keys and tokens securely. Avoid hardcoding them directly into your code. Use environment variables or secure secret management tools.</p> </li> </ul>"},{"location":"applications/marketing_agencies/","title":"Overview","text":""},{"location":"applications/marketing_agencies/#swarms-in-marketing-agencies-a-new-era-of-automated-media-strategy","title":"Swarms in Marketing Agencies: A New Era of Automated Media Strategy","text":""},{"location":"applications/marketing_agencies/#introduction","title":"Introduction:","text":"<ul> <li>Brief background on marketing agencies and their role in driving brand narratives and sales.</li> <li>Current challenges and pain points faced in media planning, placements, and budgeting.</li> <li>Introduction to the transformative potential of swarms in reshaping the marketing industry.</li> </ul>"},{"location":"applications/marketing_agencies/#1-fundamental-problem-media-plan-creation","title":"1. Fundamental Problem: Media Plan Creation:","text":"<ul> <li> <p>Definition: The challenge of creating an effective media plan that resonates with a target audience and aligns with brand objectives.</p> </li> <li> <p>Traditional Solutions and Their Shortcomings: Manual brainstorming sessions, over-reliance on past strategies, and long turnaround times leading to inefficiency.</p> </li> <li> <p>How Swarms Address This Problem: </p> <ul> <li>Benefit 1: Automated Media Plan Generation \u2013 Swarms ingest branding summaries, objectives, and marketing strategies to generate media plans, eliminating guesswork and human error.</li> <li>Real-world Application of Swarms: The automation of media plans based on client briefs, including platform selections, audience targeting, and creative versions.</li> </ul> </li> </ul>"},{"location":"applications/marketing_agencies/#2-fundamental-problem-media-placements","title":"2. Fundamental Problem: Media Placements:","text":"<ul> <li> <p>Definition: The tedious task of determining where ads will be placed, considering demographics, platform specifics, and more.</p> </li> <li> <p>Traditional Solutions and Their Shortcomings: Manual placement leading to possible misalignment with target audiences and brand objectives.</p> </li> <li> <p>How Swarms Address This Problem: </p> <ul> <li>Benefit 2: Precision Media Placements \u2013 Swarms analyze audience data and demographics to suggest the best placements, optimizing for conversions and brand reach.</li> <li>Real-world Application of Swarms: Automated selection of ad placements across platforms like Facebook, Google, and DSPs based on media plans.</li> </ul> </li> </ul>"},{"location":"applications/marketing_agencies/#3-fundamental-problem-budgeting","title":"3. Fundamental Problem: Budgeting:","text":"<ul> <li> <p>Definition: Efficiently allocating and managing advertising budgets across multiple campaigns, platforms, and timeframes.</p> </li> <li> <p>Traditional Solutions and Their Shortcomings: Manual budgeting using tools like Excel, prone to errors, and inefficient shifts in allocations.</p> </li> <li> <p>How Swarms Address This Problem: </p> <ul> <li>Benefit 3: Intelligent Media Budgeting \u2013 Swarms enable dynamic budget allocation based on performance analytics, maximizing ROI.</li> <li>Real-world Application of Swarms: Real-time adjustments in budget allocations based on campaign performance, eliminating long waiting periods and manual recalculations.</li> </ul> </li> </ul>"},{"location":"applications/marketing_agencies/#features","title":"Features:","text":"<ol> <li>Automated Media Plan Generator: Input your objectives and receive a comprehensive media plan.</li> <li>Precision Media Placement Tool: Ensure your ads appear in the right places to the right people.</li> <li>Dynamic Budget Allocation: Maximize ROI with real-time budget adjustments.</li> <li>Integration with Common Tools: Seamless integration with tools like Excel and APIs for exporting placements.</li> <li>Conversational Platform: A suite of tools built for modern marketing agencies, bringing all tasks under one umbrella.</li> </ol>"},{"location":"applications/marketing_agencies/#testimonials","title":"Testimonials:","text":"<ul> <li>\"Swarms have completely revolutionized our media planning process. What used to take weeks now takes mere hours.\" - Senior Media Strategist, Top-tier Marketing Agency</li> <li>\"The precision with which we can place ads now is unprecedented. It's like having a crystal ball for marketing!\" - Campaign Manager, Global Advertising Firm</li> </ul>"},{"location":"applications/marketing_agencies/#conclusion","title":"Conclusion:","text":"<ul> <li>Reiterate the immense potential of swarms in revolutionizing media planning, placements, and budgeting for marketing agencies.</li> <li>Call to action: For marketing agencies looking to step into the future and leave manual inefficiencies behind, swarms are the answer.</li> </ul>"},{"location":"corporate/architecture/","title":"Architecture","text":""},{"location":"corporate/architecture/#1-introduction","title":"1. Introduction","text":"<p>In today's rapidly evolving digital world, harnessing the collaborative power of multiple computational agents is more crucial than ever. 'Swarms' represents a bold stride in this direction\u2014a scalable and dynamic framework designed to enable swarms of agents to function in harmony and tackle complex tasks. This document serves as a comprehensive guide, elucidating the underlying architecture and strategies pivotal to realizing the Swarms vision.</p>"},{"location":"corporate/architecture/#2-the-vision","title":"2. The Vision","text":"<p>At its heart, the Swarms framework seeks to emulate the collaborative efficiency witnessed in natural systems, like ant colonies or bird flocks. These entities, though individually simple, achieve remarkable outcomes through collaboration. Similarly, Swarms will unleash the collective potential of numerous agents, operating cohesively.</p>"},{"location":"corporate/architecture/#3-architecture-overview","title":"3. Architecture Overview","text":""},{"location":"corporate/architecture/#31-agent-level","title":"3.1 Agent Level","text":"<p>The base level that serves as the building block for all further complexity.</p>"},{"location":"corporate/architecture/#mechanics","title":"Mechanics:","text":"<ul> <li>Model: At its core, each agent harnesses a powerful model like OpenAI's GPT.</li> <li>Vectorstore: A memory structure allowing agents to store and retrieve information.</li> <li>Tools: Utilities and functionalities that aid in the agent's task execution.</li> </ul>"},{"location":"corporate/architecture/#interaction","title":"Interaction:","text":"<p>Agents interact with the external world through their model and tools. The Vectorstore aids in retaining knowledge and facilitating inter-agent communication.</p>"},{"location":"corporate/architecture/#32-worker-infrastructure-level","title":"3.2 Worker Infrastructure Level","text":"<p>Building on the agent foundation, enhancing capability and readiness for swarm integration.</p>"},{"location":"corporate/architecture/#mechanics_1","title":"Mechanics:","text":"<ul> <li>Human Input Integration: Enables agents to accept and understand human-provided instructions.</li> <li>Unique Identifiers: Assigns each agent a unique ID to facilitate tracking and communication.</li> <li>Asynchronous Tools: Bolsters agents' capability to multitask and interact in real-time.</li> </ul>"},{"location":"corporate/architecture/#interaction_1","title":"Interaction:","text":"<p>Each worker is an enhanced agent, capable of operating independently or in sync with its peers, allowing for dynamic, scalable operations.</p>"},{"location":"corporate/architecture/#33-swarm-level","title":"3.3 Swarm Level","text":"<p>Multiple Worker Nodes orchestrated into a synchronized, collaborative entity.</p>"},{"location":"corporate/architecture/#mechanics_2","title":"Mechanics:","text":"<ul> <li>Orchestrator: The maestro, responsible for directing the swarm, task allocation, and communication.</li> <li>Scalable Communication Layer: Facilitates interactions among nodes and between nodes and the orchestrator.</li> <li>Task Assignment &amp; Completion Protocols: Structured procedures ensuring tasks are efficiently distributed and concluded.</li> </ul>"},{"location":"corporate/architecture/#interaction_2","title":"Interaction:","text":"<p>Nodes collaborate under the orchestrator's guidance, ensuring tasks are partitioned appropriately, executed, and results consolidated.</p>"},{"location":"corporate/architecture/#34-hivemind-level","title":"3.4 Hivemind Level","text":"<p>Envisioned as a 'Swarm of Swarms'. An upper echelon of collaboration.</p>"},{"location":"corporate/architecture/#mechanics_3","title":"Mechanics:","text":"<ul> <li>Hivemind Orchestrator: Oversees multiple swarm orchestrators, ensuring harmony on a grand scale.</li> <li>Inter-Swarm Communication Protocols: Dictates how swarms interact, exchange information, and co-execute tasks.</li> </ul>"},{"location":"corporate/architecture/#interaction_3","title":"Interaction:","text":"<p>Multiple swarms, each a formidable force, combine their prowess under the Hivemind. This level tackles monumental tasks by dividing them among swarms.</p>"},{"location":"corporate/architecture/#4-building-the-framework-a-task-checklist","title":"4. Building the Framework: A Task Checklist","text":""},{"location":"corporate/architecture/#41-foundations-agent-level","title":"4.1 Foundations: Agent Level","text":"<ul> <li>Define and standardize agent properties.</li> <li>Integrate desired model (e.g., OpenAI's GPT) with agent.</li> <li>Implement Vectorstore mechanisms: storage, retrieval, and communication protocols.</li> <li>Incorporate essential tools and utilities.</li> <li>Conduct preliminary testing: Ensure agents can execute basic tasks and utilize the Vectorstore.</li> </ul>"},{"location":"corporate/architecture/#42-enhancements-worker-infrastructure-level","title":"4.2 Enhancements: Worker Infrastructure Level","text":"<ul> <li>Interface agents with human input mechanisms.</li> <li>Assign and manage unique identifiers for each worker.</li> <li>Integrate asynchronous capabilities: Ensure real-time response and multitasking.</li> <li>Test worker nodes for both solitary and collaborative tasks.</li> </ul>"},{"location":"corporate/architecture/#43-cohesion-swarm-level","title":"4.3 Cohesion: Swarm Level","text":"<ul> <li>Design and develop the orchestrator: Ensure it can manage multiple worker nodes.</li> <li>Establish a scalable and efficient communication layer.</li> <li>Implement task distribution and retrieval protocols.</li> <li>Test swarms for efficiency, scalability, and robustness.</li> </ul>"},{"location":"corporate/architecture/#44-apex-collaboration-hivemind-level","title":"4.4 Apex Collaboration: Hivemind Level","text":"<ul> <li>Build the Hivemind Orchestrator: Ensure it can oversee multiple swarms.</li> <li>Define inter-swarm communication, prioritization, and task-sharing protocols.</li> <li>Develop mechanisms to balance loads and optimize resource utilization across swarms.</li> <li>Thoroughly test the Hivemind level for macro-task execution.</li> </ul>"},{"location":"corporate/architecture/#5-integration-and-communication-mechanisms","title":"5. Integration and Communication Mechanisms","text":""},{"location":"corporate/architecture/#51-vectorstore-as-the-universal-communication-layer","title":"5.1 Vectorstore as the Universal Communication Layer","text":"<p>Serving as the memory and communication backbone, the Vectorstore must: * Facilitate rapid storage and retrieval of high-dimensional vectors. * Enable similarity-based lookups: Crucial for recognizing patterns or finding similar outputs. * Scale seamlessly as agent count grows.</p>"},{"location":"corporate/architecture/#52-orchestrator-driven-communication","title":"5.2 Orchestrator-Driven Communication","text":"<ul> <li>Orchestrators, both at the swarm and hivemind level, should employ adaptive algorithms to optimally distribute tasks.</li> <li>Ensure real-time monitoring of task execution and worker node health.</li> <li>Integrate feedback loops: Allow for dynamic task reassignment in case of node failures or inefficiencies.</li> </ul>"},{"location":"corporate/architecture/#6-conclusion-forward-path","title":"6. Conclusion &amp; Forward Path","text":"<p>The Swarms framework, once realized, will usher in a new era of computational efficiency and collaboration. While the roadmap ahead is intricate, with diligent planning, development, and testing, Swarms will redefine the boundaries of collaborative computing.</p>"},{"location":"corporate/architecture/#overview","title":"Overview","text":""},{"location":"corporate/architecture/#1-model","title":"1. Model","text":"<p>Overview: The foundational level where a trained model (e.g., OpenAI GPT model) is initialized. It's the base on which further abstraction levels build upon. It provides the core capabilities to perform tasks, answer queries, etc.</p> <p>Diagram: <pre><code>[ Model (openai) ]\n</code></pre></p>"},{"location":"corporate/architecture/#2-agent-level","title":"2. Agent Level","text":"<p>Overview: At the agent level, the raw model is coupled with tools and a vector store, allowing it to be more than just a model. The agent can now remember, use tools, and become a more versatile entity ready for integration into larger systems.</p> <p>Diagram: <pre><code>+-----------+\n|   Agent   |\n| +-------+ |\n| | Model | |\n| +-------+ |\n| +-----------+ |\n| | VectorStore | |\n| +-----------+ |\n| +-------+ |\n| | Tools | |\n| +-------+ |\n+-----------+\n</code></pre></p>"},{"location":"corporate/architecture/#3-worker-infrastructure-level","title":"3. Worker Infrastructure Level","text":"<p>Overview: The worker infrastructure is a step above individual agents. Here, an agent is paired with additional utilities like human input and other tools, making it a more advanced, responsive unit capable of complex tasks.</p> <p>Diagram: <pre><code>+----------------+\n|  WorkerNode    |\n| +-----------+  |\n| |   Agent   |  |\n| | +-------+ |  |\n| | | Model | |  |\n| | +-------+ |  |\n| | +-------+ |  |\n| | | Tools | |  |\n| | +-------+ |  |\n| +-----------+  |\n|                |\n| +-----------+  |\n| |Human Input|  |\n| +-----------+  |\n|                |\n| +-------+      |\n| | Tools |      |\n| +-------+      |\n+----------------+\n</code></pre></p>"},{"location":"corporate/architecture/#4-swarm-level","title":"4. Swarm Level","text":"<p>Overview: At the swarm level, the orchestrator is central. It's responsible for assigning tasks to worker nodes, monitoring their completion, and handling the communication layer (for example, through a vector store or another universal communication mechanism) between worker nodes.</p> <p>Diagram: <pre><code>                     +------------+\n                     |Orchestrator|\n                     +------------+\n                           |\n            +---------------------------+\n            |                           |\n            |   Swarm-level Communication|\n            |          Layer (e.g.      |\n            |        Vector Store)      |\n            +---------------------------+\n             /          |          \\         \n  +---------------+  +---------------+  +---------------+\n  |WorkerNode 1   |  |WorkerNode 2   |  |WorkerNode n   |\n  |               |  |               |  |               |\n  +---------------+  +---------------+  +---------------+\n   | Task Assigned   | Task Completed   | Communication |\n</code></pre></p>"},{"location":"corporate/architecture/#5-hivemind-level","title":"5. Hivemind Level","text":"<p>Overview: At the Hivemind level, it's a multi-swarm setup, with an upper-layer orchestrator managing multiple swarm-level orchestrators. The Hivemind orchestrator is responsible for broader tasks like assigning macro-tasks to swarms, handling inter-swarm communications, and ensuring the overall system is functioning smoothly.</p> <p>Diagram: <pre><code>                     +--------+\n                     |Hivemind|\n                     +--------+\n                         |\n                 +--------------+\n                 |Hivemind      |\n                 |Orchestrator  |\n                 +--------------+\n            /         |          \\         \n    +------------+  +------------+  +------------+\n    |Orchestrator|  |Orchestrator|  |Orchestrator|\n    +------------+  +------------+  +------------+\n        |               |               |\n+--------------+ +--------------+ +--------------+\n|   Swarm-level| |   Swarm-level| |   Swarm-level|\n|Communication| |Communication| |Communication|\n|    Layer    | |    Layer    | |    Layer    |\n+--------------+ +--------------+ +--------------+\n    /    \\         /    \\         /     \\\n+-------+ +-------+ +-------+ +-------+ +-------+\n|Worker | |Worker | |Worker | |Worker | |Worker |\n| Node  | | Node  | | Node  | | Node  | | Node  |\n+-------+ +-------+ +-------+ +-------+ +-------+\n</code></pre></p> <p>This setup allows the Hivemind level to operate at a grander scale, with the capability to manage hundreds or even thousands of worker nodes across multiple swarms efficiently.</p>"},{"location":"corporate/architecture/#swarms-framework-development-strategy-checklist","title":"Swarms Framework Development Strategy Checklist","text":""},{"location":"corporate/architecture/#introduction","title":"Introduction","text":"<p>The development of the Swarms framework requires a systematic and granular approach to ensure that each component is robust and that the overall framework is efficient and scalable. This checklist will serve as a guide to building Swarms from the ground up, breaking down tasks into small, manageable pieces.</p>"},{"location":"corporate/architecture/#1-agent-level-development","title":"1. Agent Level Development","text":""},{"location":"corporate/architecture/#11-model-integration","title":"1.1 Model Integration","text":"<ul> <li>[ ] Research the most suitable models (e.g., OpenAI's GPT).</li> <li>[ ] Design an API for the agent to call the model.</li> <li>[ ] Implement error handling when model calls fail.</li> <li>[ ] Test the model with sample data for accuracy and speed.</li> </ul>"},{"location":"corporate/architecture/#12-vectorstore-implementation","title":"1.2 Vectorstore Implementation","text":"<ul> <li>[ ] Design the schema for the vector storage system.</li> <li>[ ] Implement storage methods to add, delete, and update vectors.</li> <li>[ ] Develop retrieval methods with optimization for speed.</li> <li>[ ] Create protocols for vector-based communication between agents.</li> <li>[ ] Conduct stress tests to ascertain storage and retrieval speed.</li> </ul>"},{"location":"corporate/architecture/#13-tools-utilities-integration","title":"1.3 Tools &amp; Utilities Integration","text":"<ul> <li>[ ] List out essential tools required for agent functionality.</li> <li>[ ] Develop or integrate APIs for each tool.</li> <li>[ ] Implement error handling and logging for tool interactions.</li> <li>[ ] Validate tools integration with unit tests.</li> </ul>"},{"location":"corporate/architecture/#2-worker-infrastructure-level-development","title":"2. Worker Infrastructure Level Development","text":""},{"location":"corporate/architecture/#21-human-input-integration","title":"2.1 Human Input Integration","text":"<ul> <li>[ ] Design a UI/UX for human interaction with worker nodes.</li> <li>[ ] Create APIs for input collection.</li> <li>[ ] Implement input validation and error handling.</li> <li>[ ] Test human input methods for clarity and ease of use.</li> </ul>"},{"location":"corporate/architecture/#22-unique-identifier-system","title":"2.2 Unique Identifier System","text":"<ul> <li>[ ] Research optimal formats for unique ID generation.</li> <li>[ ] Develop methods for generating and assigning IDs to agents.</li> <li>[ ] Implement a tracking system to manage and monitor agents via IDs.</li> <li>[ ] Validate the uniqueness and reliability of the ID system.</li> </ul>"},{"location":"corporate/architecture/#23-asynchronous-operation-tools","title":"2.3 Asynchronous Operation Tools","text":"<ul> <li>[ ] Incorporate libraries/frameworks to enable asynchrony.</li> <li>[ ] Ensure tasks within an agent can run in parallel without conflict.</li> <li>[ ] Test asynchronous operations for efficiency improvements.</li> </ul>"},{"location":"corporate/architecture/#3-swarm-level-development","title":"3. Swarm Level Development","text":""},{"location":"corporate/architecture/#31-orchestrator-design-development","title":"3.1 Orchestrator Design &amp; Development","text":"<ul> <li>[ ] Draft a blueprint of orchestrator functionalities.</li> <li>[ ] Implement methods for task distribution among worker nodes.</li> <li>[ ] Develop communication protocols for the orchestrator to monitor workers.</li> <li>[ ] Create feedback systems to detect and address worker node failures.</li> <li>[ ] Test orchestrator with a mock swarm to ensure efficient task allocation.</li> </ul>"},{"location":"corporate/architecture/#32-communication-layer-development","title":"3.2 Communication Layer Development","text":"<ul> <li>[ ] Select a suitable communication protocol/framework (e.g., gRPC, WebSockets).</li> <li>[ ] Design the architecture for scalable, low-latency communication.</li> <li>[ ] Implement methods for sending, receiving, and broadcasting messages.</li> <li>[ ] Test communication layer for reliability, speed, and error handling.</li> </ul>"},{"location":"corporate/architecture/#33-task-management-protocols","title":"3.3 Task Management Protocols","text":"<ul> <li>[ ] Develop a system to queue, prioritize, and allocate tasks.</li> <li>[ ] Implement methods for real-time task status tracking.</li> <li>[ ] Create a feedback loop for completed tasks.</li> <li>[ ] Test task distribution, execution, and feedback systems for efficiency.</li> </ul>"},{"location":"corporate/architecture/#4-hivemind-level-development","title":"4. Hivemind Level Development","text":""},{"location":"corporate/architecture/#41-hivemind-orchestrator-development","title":"4.1 Hivemind Orchestrator Development","text":"<ul> <li>[ ] Extend swarm orchestrator functionalities to manage multiple swarms.</li> <li>[ ] Create inter-swarm communication protocols.</li> <li>[ ] Implement load balancing mechanisms to distribute tasks across swarms.</li> <li>[ ] Validate hivemind orchestrator functionalities with multi-swarm setups.</li> </ul>"},{"location":"corporate/architecture/#42-inter-swarm-communication-protocols","title":"4.2 Inter-Swarm Communication Protocols","text":"<ul> <li>[ ] Design methods for swarms to exchange data.</li> <li>[ ] Implement data reconciliation methods for swarms working on shared tasks.</li> <li>[ ] Test inter-swarm communication for efficiency and data integrity.</li> </ul>"},{"location":"corporate/architecture/#5-scalability-performance-testing","title":"5. Scalability &amp; Performance Testing","text":"<ul> <li>[ ] Simulate heavy loads to test the limits of the framework.</li> <li>[ ] Identify and address bottlenecks in both communication and computation.</li> <li>[ ] Conduct speed tests under different conditions.</li> <li>[ ] Test the system's responsiveness under various levels of stress.</li> </ul>"},{"location":"corporate/architecture/#6-documentation-user-guide","title":"6. Documentation &amp; User Guide","text":"<ul> <li>[ ] Develop detailed documentation covering architecture, setup, and usage.</li> <li>[ ] Create user guides with step-by-step instructions.</li> <li>[ ] Incorporate visual aids, diagrams, and flowcharts for clarity.</li> <li>[ ] Update documentation regularly with new features and improvements.</li> </ul>"},{"location":"corporate/architecture/#7-continuous-integration-deployment","title":"7. Continuous Integration &amp; Deployment","text":"<ul> <li>[ ] Setup CI/CD pipelines for automated testing and deployment.</li> <li>[ ] Ensure automatic rollback in case of deployment failures.</li> <li>[ ] Integrate code quality and security checks in the pipeline.</li> <li>[ ] Document deployment strategies and best practices.</li> </ul>"},{"location":"corporate/architecture/#conclusion","title":"Conclusion","text":"<p>The Swarms framework represents a monumental leap in agent-based computation. This checklist provides a thorough roadmap for the framework's development, ensuring that every facet is addressed in depth. Through diligent adherence to this guide, the Swarms vision can be realized as a powerful, scalable, and robust system ready to tackle the challenges of tomorrow.</p> <p>(Note: This document, given the word limit, provides a high-level overview. A full 5000-word document would delve into even more intricate details, nuances, potential pitfalls, and include considerations for security, user experience, compatibility, etc.)</p>"},{"location":"corporate/bounties/","title":"Bounty Program","text":"<p>Our bounty program is an exciting opportunity for contributors to help us build the future of Swarms. By participating, you can earn rewards while contributing to a project that aims to revolutionize digital activity.</p> <p>Here's how it works:</p> <ol> <li> <p>Check out our Roadmap: We've shared our roadmap detailing our short and long-term goals. These are the areas where we're seeking contributions.</p> </li> <li> <p>Pick a Task: Choose a task from the roadmap that aligns with your skills and interests. If you're unsure, you can reach out to our team for guidance.</p> </li> <li> <p>Get to Work: Once you've chosen a task, start working on it. Remember, quality is key. We're looking for contributions that truly make a difference.</p> </li> <li> <p>Submit your Contribution: Once your work is complete, submit it for review. We'll evaluate your contribution based on its quality, relevance, and the value it brings to Swarms.</p> </li> <li> <p>Earn Rewards: If your contribution is approved, you'll earn a bounty. The amount of the bounty depends on the complexity of the task, the quality of your work, and the value it brings to Swarms.</p> </li> </ol>"},{"location":"corporate/bounties/#the-three-phases-of-our-bounty-program","title":"The Three Phases of Our Bounty Program","text":""},{"location":"corporate/bounties/#phase-1-building-the-foundation","title":"Phase 1: Building the Foundation","text":"<p>In the first phase, our focus is on building the basic infrastructure of Swarms. This includes developing key components like the Swarms class, integrating essential tools, and establishing task completion and evaluation logic. We'll also start developing our testing and evaluation framework during this phase. If you're interested in foundational work and have a knack for building robust, scalable systems, this phase is for you.</p>"},{"location":"corporate/bounties/#phase-2-enhancing-the-system","title":"Phase 2: Enhancing the System","text":"<p>In the second phase, we'll focus on enhancing Swarms by integrating more advanced features, improving the system's efficiency, and refining our testing and evaluation framework. This phase involves more complex tasks, so if you enjoy tackling challenging problems and contributing to the development of innovative features, this is the phase for you.</p>"},{"location":"corporate/bounties/#phase-3-towards-super-intelligence","title":"Phase 3: Towards Super-Intelligence","text":"<p>The third phase of our bounty program is the most exciting - this is where we aim to achieve super-intelligence. In this phase, we'll be working on improving the swarm's capabilities, expanding its skills, and fine-tuning the system based on real-world testing and feedback. If you're excited about the future of AI and want to contribute to a project that could potentially transform the digital world, this is the phase for you.</p> <p>Remember, our roadmap is a guide, and we encourage you to bring your own ideas and creativity to the table. We believe that every contribution, no matter how small, can make a difference. So join us on this exciting journey and help us create the future of Swarms.</p> <p>To participate in our bounty program, visit the Swarms Bounty Program Page. Let's build the future together!</p>"},{"location":"corporate/bounties/#bounties-for-roadmap-items","title":"Bounties for Roadmap Items","text":"<p>To accelerate the development of Swarms and to encourage more contributors to join our journey towards automating every digital activity in existence, we are announcing a Bounty Program for specific roadmap items. Each bounty will be rewarded based on the complexity and importance of the task. Below are the items available for bounty:</p> <ol> <li>Multi-Agent Debate Integration: $2000</li> <li>Meta Prompting Integration: $1500</li> <li>Swarms Class: $1500</li> <li>Integration of Additional Tools: $1000</li> <li>Task Completion and Evaluation Logic: $2000</li> <li>Ocean Integration: $2500</li> <li>Improved Communication: $2000</li> <li>Testing and Evaluation: $1500</li> <li>Worker Swarm Class: $2000</li> <li>Documentation: $500</li> </ol> <p>For each bounty task, there will be a strict evaluation process to ensure the quality of the contribution. This process includes a thorough review of the code and extensive testing to ensure it meets our standards.</p>"},{"location":"corporate/bounties/#3-phase-testing-framework","title":"3-Phase Testing Framework","text":"<p>To ensure the quality and efficiency of the Swarm, we will introduce a 3-phase testing framework which will also serve as our evaluation criteria for each of the bounty tasks.</p>"},{"location":"corporate/bounties/#phase-1-unit-testing","title":"Phase 1: Unit Testing","text":"<p>In this phase, individual modules will be tested to ensure that they work correctly in isolation. Unit tests will be designed for all functions and methods, with an emphasis on edge cases.</p>"},{"location":"corporate/bounties/#phase-2-integration-testing","title":"Phase 2: Integration Testing","text":"<p>After passing unit tests, we will test the integration of different modules to ensure they work correctly together. This phase will also test the interoperability of the Swarm with external systems and libraries.</p>"},{"location":"corporate/bounties/#phase-3-benchmarking-stress-testing","title":"Phase 3: Benchmarking &amp; Stress Testing","text":"<p>In the final phase, we will perform benchmarking and stress tests. We'll push the limits of the Swarm under extreme conditions to ensure it performs well in real-world scenarios. This phase will measure the performance, speed, and scalability of the Swarm under high load conditions.</p> <p>By following this 3-phase testing framework, we aim to develop a reliable, high-performing, and scalable Swarm that can automate all digital activities. </p>"},{"location":"corporate/bounties/#reverse-engineering-to-reach-phase-3","title":"Reverse Engineering to Reach Phase 3","text":"<p>To reach the Phase 3 level, we need to reverse engineer the tasks we need to complete. Here's an example of what this might look like:</p> <ol> <li> <p>Set Clear Expectations: Define what success looks like for each task. Be clear about the outputs and outcomes we expect. This will guide our testing and development efforts.</p> </li> <li> <p>Develop Testing Scenarios: Create a comprehensive list of testing scenarios that cover both common and edge cases. This will help us ensure that our Swarm can handle a wide range of situations.</p> </li> <li> <p>Write Test Cases: For each scenario, write detailed test cases that outline the exact steps to be followed, the inputs to be used, and the expected outputs.</p> </li> <li> <p>Execute the Tests: Run the test cases on our Swarm, making note of any issues or bugs that arise.</p> </li> <li> <p>Iterate and Improve: Based on the results of our tests, iterate and improve our Swarm. This may involve fixing bugs, optimizing code, or redesigning parts of our system.</p> </li> <li> <p>Repeat: Repeat this process until our Swarm meets our expectations and passes all test cases.</p> </li> </ol> <p>By following these steps, we will systematically build, test, and improve our Swarm until it reaches the Phase 3 level. This methodical approach will help us ensure that we create a reliable, high-performing, and scalable Swarm that can truly automate all digital activities.</p> <p>Let's shape the future of digital automation together!</p>"},{"location":"corporate/checklist/","title":"Swarms Framework Development Strategy Checklist","text":""},{"location":"corporate/checklist/#introduction","title":"Introduction","text":"<p>The development of the Swarms framework requires a systematic and granular approach to ensure that each component is robust and that the overall framework is efficient and scalable. This checklist will serve as a guide to building Swarms from the ground up, breaking down tasks into small, manageable pieces.</p>"},{"location":"corporate/checklist/#1-agent-level-development","title":"1. Agent Level Development","text":""},{"location":"corporate/checklist/#11-model-integration","title":"1.1 Model Integration","text":"<ul> <li>[ ] Research the most suitable models (e.g., OpenAI's GPT).</li> <li>[ ] Design an API for the agent to call the model.</li> <li>[ ] Implement error handling when model calls fail.</li> <li>[ ] Test the model with sample data for accuracy and speed.</li> </ul>"},{"location":"corporate/checklist/#12-vectorstore-implementation","title":"1.2 Vectorstore Implementation","text":"<ul> <li>[ ] Design the schema for the vector storage system.</li> <li>[ ] Implement storage methods to add, delete, and update vectors.</li> <li>[ ] Develop retrieval methods with optimization for speed.</li> <li>[ ] Create protocols for vector-based communication between agents.</li> <li>[ ] Conduct stress tests to ascertain storage and retrieval speed.</li> </ul>"},{"location":"corporate/checklist/#13-tools-utilities-integration","title":"1.3 Tools &amp; Utilities Integration","text":"<ul> <li>[ ] List out essential tools required for agent functionality.</li> <li>[ ] Develop or integrate APIs for each tool.</li> <li>[ ] Implement error handling and logging for tool interactions.</li> <li>[ ] Validate tools integration with unit tests.</li> </ul>"},{"location":"corporate/checklist/#2-worker-infrastructure-level-development","title":"2. Worker Infrastructure Level Development","text":""},{"location":"corporate/checklist/#21-human-input-integration","title":"2.1 Human Input Integration","text":"<ul> <li>[ ] Design a UI/UX for human interaction with worker nodes.</li> <li>[ ] Create APIs for input collection.</li> <li>[ ] Implement input validation and error handling.</li> <li>[ ] Test human input methods for clarity and ease of use.</li> </ul>"},{"location":"corporate/checklist/#22-unique-identifier-system","title":"2.2 Unique Identifier System","text":"<ul> <li>[ ] Research optimal formats for unique ID generation.</li> <li>[ ] Develop methods for generating and assigning IDs to agents.</li> <li>[ ] Implement a tracking system to manage and monitor agents via IDs.</li> <li>[ ] Validate the uniqueness and reliability of the ID system.</li> </ul>"},{"location":"corporate/checklist/#23-asynchronous-operation-tools","title":"2.3 Asynchronous Operation Tools","text":"<ul> <li>[ ] Incorporate libraries/frameworks to enable asynchrony.</li> <li>[ ] Ensure tasks within an agent can run in parallel without conflict.</li> <li>[ ] Test asynchronous operations for efficiency improvements.</li> </ul>"},{"location":"corporate/checklist/#3-swarm-level-development","title":"3. Swarm Level Development","text":""},{"location":"corporate/checklist/#31-orchestrator-design-development","title":"3.1 Orchestrator Design &amp; Development","text":"<ul> <li>[ ] Draft a blueprint of orchestrator functionalities.</li> <li>[ ] Implement methods for task distribution among worker nodes.</li> <li>[ ] Develop communication protocols for the orchestrator to monitor workers.</li> <li>[ ] Create feedback systems to detect and address worker node failures.</li> <li>[ ] Test orchestrator with a mock swarm to ensure efficient task allocation.</li> </ul>"},{"location":"corporate/checklist/#32-communication-layer-development","title":"3.2 Communication Layer Development","text":"<ul> <li>[ ] Select a suitable communication protocol/framework (e.g., gRPC, WebSockets).</li> <li>[ ] Design the architecture for scalable, low-latency communication.</li> <li>[ ] Implement methods for sending, receiving, and broadcasting messages.</li> <li>[ ] Test communication layer for reliability, speed, and error handling.</li> </ul>"},{"location":"corporate/checklist/#33-task-management-protocols","title":"3.3 Task Management Protocols","text":"<ul> <li>[ ] Develop a system to queue, prioritize, and allocate tasks.</li> <li>[ ] Implement methods for real-time task status tracking.</li> <li>[ ] Create a feedback loop for completed tasks.</li> <li>[ ] Test task distribution, execution, and feedback systems for efficiency.</li> </ul>"},{"location":"corporate/checklist/#4-hivemind-level-development","title":"4. Hivemind Level Development","text":""},{"location":"corporate/checklist/#41-hivemind-orchestrator-development","title":"4.1 Hivemind Orchestrator Development","text":"<ul> <li>[ ] Extend swarm orchestrator functionalities to manage multiple swarms.</li> <li>[ ] Create inter-swarm communication protocols.</li> <li>[ ] Implement load balancing mechanisms to distribute tasks across swarms.</li> <li>[ ] Validate hivemind orchestrator functionalities with multi-swarm setups.</li> </ul>"},{"location":"corporate/checklist/#42-inter-swarm-communication-protocols","title":"4.2 Inter-Swarm Communication Protocols","text":"<ul> <li>[ ] Design methods for swarms to exchange data.</li> <li>[ ] Implement data reconciliation methods for swarms working on shared tasks.</li> <li>[ ] Test inter-swarm communication for efficiency and data integrity.</li> </ul>"},{"location":"corporate/checklist/#5-scalability-performance-testing","title":"5. Scalability &amp; Performance Testing","text":"<ul> <li>[ ] Simulate heavy loads to test the limits of the framework.</li> <li>[ ] Identify and address bottlenecks in both communication and computation.</li> <li>[ ] Conduct speed tests under different conditions.</li> <li>[ ] Test the system's responsiveness under various levels of stress.</li> </ul>"},{"location":"corporate/checklist/#6-documentation-user-guide","title":"6. Documentation &amp; User Guide","text":"<ul> <li>[ ] Develop detailed documentation covering architecture, setup, and usage.</li> <li>[ ] Create user guides with step-by-step instructions.</li> <li>[ ] Incorporate visual aids, diagrams, and flowcharts for clarity.</li> <li>[ ] Update documentation regularly with new features and improvements.</li> </ul>"},{"location":"corporate/checklist/#7-continuous-integration-deployment","title":"7. Continuous Integration &amp; Deployment","text":"<ul> <li>[ ] Setup CI/CD pipelines for automated testing and deployment.</li> <li>[ ] Ensure automatic rollback in case of deployment failures.</li> <li>[ ] Integrate code quality and security checks in the pipeline.</li> <li>[ ] Document deployment strategies and best practices.</li> </ul>"},{"location":"corporate/checklist/#conclusion","title":"Conclusion","text":"<p>The Swarms framework represents a monumental leap in agent-based computation. This checklist provides a thorough roadmap for the framework's development, ensuring that every facet is addressed in depth. Through diligent adherence to this guide, the Swarms vision can be realized as a powerful, scalable, and robust system ready to tackle the challenges of tomorrow.</p> <p>(Note: This document, given the word limit, provides a high-level overview. A full 5000-word document would delve into even more intricate details, nuances, potential pitfalls, and include considerations for security, user experience, compatibility, etc.)</p>"},{"location":"corporate/cost_analysis/","title":"Costs Structure of Deploying Autonomous Agents","text":""},{"location":"corporate/cost_analysis/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction</li> <li>Our Time: Generating System Prompts and Custom Tools</li> <li>Consultancy Fees</li> <li>Model Inference Infrastructure</li> <li>Deployment and Continual Maintenance</li> <li>Output Metrics: Blogs Generation Rates</li> </ol>"},{"location":"corporate/cost_analysis/#1-introduction","title":"1. Introduction","text":"<p>Autonomous agents are revolutionizing various industries, from self-driving cars to chatbots and customer service solutions. The prospect of automation and improved efficiency makes these agents attractive investments. However, like any other technological solution, deploying autonomous agents involves several cost elements that organizations need to consider carefully. This comprehensive guide aims to provide an exhaustive outline of the costs associated with deploying autonomous agents.</p>"},{"location":"corporate/cost_analysis/#2-our-time-generating-system-prompts-and-custom-tools","title":"2. Our Time: Generating System Prompts and Custom Tools","text":""},{"location":"corporate/cost_analysis/#description","title":"Description","text":"<p>The deployment of autonomous agents often requires a substantial investment of time to develop system prompts and custom tools tailored to specific operational needs. </p>"},{"location":"corporate/cost_analysis/#costs","title":"Costs","text":"Task Time Required (Hours) Cost per Hour ($) Total Cost ($) System Prompts Design 50 100 5,000 Custom Tools Development 100 100 10,000 Total 150 15,000"},{"location":"corporate/cost_analysis/#3-consultancy-fees","title":"3. Consultancy Fees","text":""},{"location":"corporate/cost_analysis/#description_1","title":"Description","text":"<p>Consultation is often necessary for navigating the complexities of autonomous agents. This includes system assessment, customization, and other essential services.</p>"},{"location":"corporate/cost_analysis/#costs_1","title":"Costs","text":"Service Fees ($) Initial Assessment 5,000 System Customization 7,000 Training 3,000 Total 15,000"},{"location":"corporate/cost_analysis/#4-model-inference-infrastructure","title":"4. Model Inference Infrastructure","text":""},{"location":"corporate/cost_analysis/#description_2","title":"Description","text":"<p>The hardware and software needed for the agent's functionality, known as the model inference infrastructure, form a significant part of the costs.</p>"},{"location":"corporate/cost_analysis/#costs_2","title":"Costs","text":"Component Cost ($) Hardware 10,000 Software Licenses 2,000 Cloud Services 3,000 Total 15,000"},{"location":"corporate/cost_analysis/#5-deployment-and-continual-maintenance","title":"5. Deployment and Continual Maintenance","text":""},{"location":"corporate/cost_analysis/#description_3","title":"Description","text":"<p>Once everything is in place, deploying the autonomous agents and their ongoing maintenance are the next major cost factors.</p>"},{"location":"corporate/cost_analysis/#costs_3","title":"Costs","text":"Task Monthly Cost ($) Annual Cost ($) Deployment 5,000 60,000 Ongoing Maintenance 1,000 12,000 Total 6,000 72,000"},{"location":"corporate/cost_analysis/#6-output-metrics-blogs-generation-rates","title":"6. Output Metrics: Blogs Generation Rates","text":""},{"location":"corporate/cost_analysis/#description_4","title":"Description","text":"<p>To provide a sense of what an investment in autonomous agents can yield, we offer the following data regarding blogs that can be generated as an example of output.</p>"},{"location":"corporate/cost_analysis/#blogs-generation-rates","title":"Blogs Generation Rates","text":"Timeframe Number of Blogs Per Day 20 Per Week 140 Per Month 600"},{"location":"corporate/data_room/","title":"Swarms Data Room","text":""},{"location":"corporate/data_room/#table-of-contents","title":"Table of Contents","text":"<p>Introduction</p> <ul> <li> <p>Overview of the Company</p> </li> <li> <p>Vision and Mission Statement</p> </li> <li> <p>Executive Summary</p> </li> </ul> <p>Corporate Documents</p> <ul> <li> <p>Articles of Incorporation</p> </li> <li> <p>Bylaws</p> </li> <li> <p>Shareholder Agreements</p> </li> <li> <p>Board Meeting Minutes</p> </li> <li> <p>Company Structure and Org Chart</p> </li> </ul> <p>Financial Information</p> <ul> <li> <p>Historical Financial Statements</p> </li> <li> <p>Income Statements</p> </li> <li> <p>Balance Sheets</p> </li> <li> <p>Cash Flow Statements</p> </li> <li> <p>Financial Projections and Forecasts</p> </li> <li> <p>Cap Table</p> </li> <li> <p>Funding History and Use of Funds</p> </li> </ul> <p>Products and Services</p> <ul> <li> <p>Detailed Descriptions of Products/Services</p> </li> <li> <p>Product Development Roadmap</p> </li> <li> <p>User Manuals and Technical Specifications</p> </li> <li> <p>Case Studies and Use Cases</p> </li> </ul>"},{"location":"corporate/data_room/#introdution","title":"Introdution","text":"<p>Swarms provides automation-as-a-service through swarms of autonomous agents that work together as a team. We enable our customers to build, deploy, and scale production-grade multi-agent applications to automate real-world tasks.</p>"},{"location":"corporate/data_room/#vision","title":"Vision","text":"<p>Our vision for 2024 is to provide the most reliable infrastructure for deploying autonomous agents into the real world through the Swarm Cloud, our premier cloud platform for the scalable deployment of Multi-Modal Autonomous Agents. The platform focuses on delivering maximum value to users by only taking a small fee when utilizing the agents for the hosted compute power needed to host the agents.</p>"},{"location":"corporate/data_room/#executive-summary","title":"Executive Summary","text":"<p>The Swarm Corporation aims to enable AI models to automate complex workflows and operations, not just singular low-value tasks. We believe collaboration between multiple agents can overcome limitations of individual agents for reasoning, planning, etc. This will allow automation of processes in mission-critical industries like security, logistics, and manufacturing where AI adoption is currently low.  </p> <p>We provide an open source framework to deploy production-grade multi-modal agents in just a few lines of code. This builds our user base, recruits talent, gets customer feedback to improve products, gains awareness and trust.</p> <p>Our business model focuses on customer satisfaction, openness, integration with other tools/platforms, and production-grade reliability. </p> <p>Go-to-market strategy is to get the framework to product-market fit with over 50K weekly recurring users, then secure high-value contracts in target industries. Long-term monetization via microtransactions, usage-based pricing, subscriptions.</p> <p>The team has thousands of hours building and optimizing autonomous agents. Leadership includes AI engineers, product experts, open source contributors and community builders.</p> <p>Key milestones: get 80K framework users in January 2024, start contracts in target verticals, introduce commercial products in 2025 with various pricing models.</p>"},{"location":"corporate/data_room/#resources","title":"Resources","text":"<ul> <li>Swarm Pre-Seed Deck</li> <li>Swarm Memo</li> </ul>"},{"location":"corporate/data_room/#financial-documents","title":"Financial Documents","text":"<p>This section is dedicated entirely for corporate documents.</p> <ul> <li> <p>Cap Table</p> </li> <li> <p>Cashflow Prediction Sheet</p> </li> </ul>"},{"location":"corporate/data_room/#product","title":"Product","text":"<p>Swarms is an open source framework for developers in python to enable seamless, reliable, and scalable multi-agent orchestration through modularity, customization, and precision.</p> <ul> <li>Swarms Github Page:</li> <li>Swarms Memo</li> <li>Swarms Project Board</li> <li>Swarms Website</li> <li>Swarm Ecosystem</li> <li>Swarm Core</li> </ul>"},{"location":"corporate/data_room/#product-growth-metrics","title":"Product Growth Metrics","text":"Name Description Link Total Downloads of all time Total number of downloads for the product over its entire lifespan. Downloads this month Number of downloads for the product in the current month. Total Downloads this week Total number of downloads for the product in the current week. Github Forks Number of times the product's codebase has been copied for optimization, contribution, or usage. Github Stars Number of users who have 'liked' the project. Pip Module Metrics Various project statistics such as watchers, number of contributors, date repository was created, and more. CLICK HERE Contribution Based Statistics Statistics like number of contributors, lines of code changed, etc. HERE Github Community insights Insights into the Github community around the product. Github Community insights Github Traffic Metrics Metrics related to traffic, such as views and clones on Github. Github Traffic Metrics Issues with the framework Current open issues for the product on Github."},{"location":"corporate/demos/","title":"Demo Ideas","text":"<ul> <li> <p>We could also try to create an AI influencer run by a swarm, let it create a whole identity and generate images, memes, and other content for Twitter, Reddit, etc.</p> </li> <li> <p>had a thought that we should have either a more general one of these or a swarm or both -- need something connecting all the calendars, events, and initiatives of all the AI communities, langchain, laion, eluther, lesswrong, gato, rob miles, chatgpt hackers, etc etc</p> </li> <li> <p>Swarm of AI influencers to spread marketing</p> </li> <li> <p>Delegation System to better organize teams: Start with a team of passionate humans and let them self-report their skills/strengths so the agent has a concept of who to delegate to, then feed the agent a huge task list (like the bullet list a few messages above) that it breaks down into actionable steps and \"prompts\" specific team members to complete tasks. Could even suggest breakout teams of a few people with complementary skills to tackle more complex tasks. There can also be a live board that updates each time a team member completes something, to encourage momentum and keep track of progress</p> </li> </ul>"},{"location":"corporate/design/","title":"Design Philosophy Document for Swarms","text":""},{"location":"corporate/design/#usable","title":"Usable","text":""},{"location":"corporate/design/#objective","title":"Objective","text":"<p>Our goal is to ensure that Swarms is intuitive and easy to use for all users, regardless of their level of technical expertise. This includes the developers who implement Swarms in their applications, as well as end users who interact with the implemented systems.</p>"},{"location":"corporate/design/#tactics","title":"Tactics","text":"<ul> <li>Clear and Comprehensive Documentation: We will provide well-written and easily accessible documentation that guides users through using and understanding Swarms.</li> <li>User-Friendly APIs: We'll design clean and self-explanatory APIs that help developers to understand their purpose quickly.</li> <li>Prompt and Effective Support: We will ensure that support is readily available to assist users when they encounter problems or need help with Swarms.</li> </ul>"},{"location":"corporate/design/#reliable","title":"Reliable","text":""},{"location":"corporate/design/#objective_1","title":"Objective","text":"<p>Swarms should be dependable and trustworthy. Users should be able to count on Swarms to perform consistently and without error or failure.</p>"},{"location":"corporate/design/#tactics_1","title":"Tactics","text":"<ul> <li>Robust Error Handling: We will focus on error prevention, detection, and recovery to minimize failures in Swarms.</li> <li>Comprehensive Testing: We will apply various testing methodologies such as unit testing, integration testing, and stress testing to validate the reliability of our software.</li> <li>Continuous Integration/Continuous Delivery (CI/CD): We will use CI/CD pipelines to ensure that all changes are tested and validated before they're merged into the main branch.</li> </ul>"},{"location":"corporate/design/#fast","title":"Fast","text":""},{"location":"corporate/design/#objective_2","title":"Objective","text":"<p>Swarms should offer high performance and rapid response times. The system should be able to handle requests and tasks swiftly.</p>"},{"location":"corporate/design/#tactics_2","title":"Tactics","text":"<ul> <li>Efficient Algorithms: We will focus on optimizing our algorithms and data structures to ensure they run as quickly as possible.</li> <li>Caching: Where appropriate, we will use caching techniques to speed up response times.</li> <li>Profiling and Performance Monitoring: We will regularly analyze the performance of Swarms to identify bottlenecks and opportunities for improvement.</li> </ul>"},{"location":"corporate/design/#scalable","title":"Scalable","text":""},{"location":"corporate/design/#objective_3","title":"Objective","text":"<p>Swarms should be able to grow in capacity and complexity without compromising performance or reliability. It should be able to handle increased workloads gracefully.</p>"},{"location":"corporate/design/#tactics_3","title":"Tactics","text":"<ul> <li>Modular Architecture: We will design Swarms using a modular architecture that allows for easy scaling and modification.</li> <li>Load Balancing: We will distribute tasks evenly across available resources to prevent overload and maximize throughput.</li> <li>Horizontal and Vertical Scaling: We will design Swarms to be capable of both horizontal (adding more machines) and vertical (adding more power to an existing machine) scaling.</li> </ul>"},{"location":"corporate/design/#philosophy","title":"Philosophy","text":"<p>Swarms is designed with a philosophy of simplicity and reliability. We believe that software should be a tool that empowers users, not a hurdle that they need to overcome. Therefore, our focus is on usability, reliability, speed, and scalability. We want our users to find Swarms intuitive and dependable, fast and adaptable to their needs. This philosophy guides all of our design and development decisions.</p>"},{"location":"corporate/design/#swarm-architecture-design-document","title":"Swarm Architecture Design Document","text":""},{"location":"corporate/design/#overview","title":"Overview","text":"<p>The goal of the Swarm Architecture is to provide a flexible and scalable system to build swarm intelligence models that can solve complex problems. This document details the proposed design to create a plug-and-play system, which makes it easy to create custom swarms, and provides pre-configured swarms with multi-modal agents.</p>"},{"location":"corporate/design/#design-principles","title":"Design Principles","text":"<ul> <li>Modularity: The system will be built in a modular fashion, allowing various components to be easily swapped or upgraded.</li> <li>Interoperability: Different swarm classes and components should be able to work together seamlessly.</li> <li>Scalability: The design should support the growth of the system by adding more components or swarms.</li> <li>Ease of Use: Users should be able to easily create their own swarms or use pre-configured ones with minimal configuration.</li> </ul>"},{"location":"corporate/design/#design-components","title":"Design Components","text":""},{"location":"corporate/design/#abstractswarm","title":"AbstractSwarm","text":"<p>The AbstractSwarm is an abstract base class which defines the basic structure of a swarm and the methods that need to be implemented. Any new swarm should inherit from this class and implement the required methods.</p>"},{"location":"corporate/design/#swarm-classes","title":"Swarm Classes","text":"<p>Various Swarm classes can be implemented inheriting from the AbstractSwarm class. Each swarm class should implement the required methods for initializing the components, worker nodes, and boss node, and running the swarm.</p> <p>Pre-configured swarm classes with multi-modal agents can be provided for ease of use. These classes come with a default configuration of tools and agents, which can be used out of the box.</p>"},{"location":"corporate/design/#tools-and-agents","title":"Tools and Agents","text":"<p>Tools and agents are the components that provide the actual functionality to the swarms. They can be language models, AI assistants, vector stores, or any other components that can help in problem solving.</p> <p>To make the system plug-and-play, a standard interface should be defined for these components. Any new tool or agent should implement this interface, so that it can be easily plugged into the system.</p>"},{"location":"corporate/design/#usage","title":"Usage","text":"<p>Users can either use pre-configured swarms or create their own custom swarms.</p> <p>To use a pre-configured swarm, they can simply instantiate the corresponding swarm class and call the run method with the required objective.</p> <p>To create a custom swarm, they need to:</p> <ol> <li>Define a new swarm class inheriting from AbstractSwarm.</li> <li>Implement the required methods for the new swarm class.</li> <li>Instantiate the swarm class and call the run method.</li> </ol>"},{"location":"corporate/design/#example","title":"Example","text":"<pre><code># Using pre-configured swarm\nswarm = PreConfiguredSwarm(openai_api_key)\nswarm.run_swarms(objective)\n\n# Creating custom swarm\nclass CustomSwarm(AbstractSwarm):\n    # Implement required methods\n\nswarm = CustomSwarm(openai_api_key)\nswarm.run_swarms(objective)\n</code></pre>"},{"location":"corporate/design/#conclusion","title":"Conclusion","text":"<p>This Swarm Architecture design provides a scalable and flexible system for building swarm intelligence models. The plug-and-play design allows users to easily use pre-configured swarms or create their own custom swarms.</p>"},{"location":"corporate/design/#swarming-architectures","title":"Swarming Architectures","text":"<p>Sure, below are five different swarm architectures with their base requirements and an abstract class that processes these components:</p> <ol> <li> <p>Hierarchical Swarm: This architecture is characterized by a boss/worker relationship. The boss node takes high-level decisions and delegates tasks to the worker nodes. The worker nodes perform tasks and report back to the boss node. </p> <ul> <li>Requirements: Boss node (can be a large language model), worker nodes (can be smaller language models), and a task queue for task management.</li> </ul> </li> <li> <p>Homogeneous Swarm: In this architecture, all nodes in the swarm are identical and contribute equally to problem-solving. Each node has the same capabilities.</p> <ul> <li>Requirements: Homogeneous nodes (can be language models of the same size), communication protocol for nodes to share information.</li> </ul> </li> <li> <p>Heterogeneous Swarm: This architecture contains different types of nodes, each with its specific capabilities. This diversity can lead to more robust problem-solving.</p> <ul> <li>Requirements: Different types of nodes (can be different types and sizes of language models), a communication protocol, and a mechanism to delegate tasks based on node capabilities.</li> </ul> </li> <li> <p>Competitive Swarm: In this architecture, nodes compete with each other to find the best solution. The system may use a selection process to choose the best solutions.</p> <ul> <li>Requirements: Nodes (can be language models), a scoring mechanism to evaluate node performance, a selection mechanism.</li> </ul> </li> <li> <p>Cooperative Swarm: In this architecture, nodes work together and share information to find solutions. The focus is on cooperation rather than competition.</p> <ul> <li>Requirements: Nodes (can be language models), a communication protocol, a consensus mechanism to agree on solutions.</li> </ul> </li> <li> <p>Grid-based Swarm: This architecture positions agents on a grid, where they can only interact with their neighbors. This is useful for simulations, especially in fields like ecology or epidemiology.</p> <ul> <li>Requirements: Agents (can be language models), a grid structure, and a neighborhood definition (i.e., how to identify neighboring agents).</li> </ul> </li> <li> <p>Particle Swarm Optimization (PSO) Swarm: In this architecture, each agent represents a potential solution to an optimization problem. Agents move in the solution space based on their own and their neighbors' past performance. PSO is especially useful for continuous numerical optimization problems.</p> <ul> <li>Requirements: Agents (each representing a solution), a definition of the solution space, an evaluation function to rate the solutions, a mechanism to adjust agent positions based on performance.</li> </ul> </li> <li> <p>Ant Colony Optimization (ACO) Swarm: Inspired by ant behavior, this architecture has agents leave a pheromone trail that other agents follow, reinforcing the best paths. It's useful for problems like the traveling salesperson problem.</p> <ul> <li>Requirements: Agents (can be language models), a representation of the problem space, a pheromone updating mechanism.</li> </ul> </li> <li> <p>Genetic Algorithm (GA) Swarm: In this architecture, agents represent potential solutions to a problem. They can 'breed' to create new solutions and can undergo 'mutations'. GA swarms are good for search and optimization problems.</p> <ul> <li>Requirements: Agents (each representing a potential solution), a fitness function to evaluate solutions, a crossover mechanism to breed solutions, and a mutation mechanism.</li> </ul> </li> <li> <p>Stigmergy-based Swarm: In this architecture, agents communicate indirectly by modifying the environment, and other agents react to such modifications. It's a decentralized method of coordinating tasks.</p> <ul> <li>Requirements: Agents (can be language models), an environment that agents can modify, a mechanism for agents to perceive environment changes.</li> </ul> </li> </ol> <p>These architectures all have unique features and requirements, but they share the need for agents (often implemented as language models) and a mechanism for agents to communicate or interact, whether it's directly through messages, indirectly through the environment, or implicitly through a shared solution space. Some also require specific data structures, like a grid or problem space, and specific algorithms, like for evaluating solutions or updating agent positions.</p>"},{"location":"corporate/distribution/","title":"Swarms Monetization Strategy","text":"<p>This strategy includes a variety of business models, potential revenue streams, cashflow structures, and customer identification methods. Let's explore these further.</p>"},{"location":"corporate/distribution/#business-models","title":"Business Models","text":"<ol> <li> <p>Platform as a Service (PaaS): Provide the Swarms AI platform on a subscription basis, charged monthly or annually. This could be tiered based on usage and access to premium features. </p> </li> <li> <p>API Usage-based Pricing: Charge customers based on their usage of the Swarms API. The more requests made, the higher the fee.</p> </li> <li> <p>Managed Services: Offer complete end-to-end solutions where you manage the entire AI infrastructure for the clients. This could be on a contract basis with a recurring fee.</p> </li> <li> <p>Training and Certification: Provide Swarms AI training and certification programs for interested developers and businesses. These could be monetized as separate courses or subscription-based access.</p> </li> <li> <p>Partnerships: Collaborate with large enterprises and offer them dedicated Swarm AI services. These could be performance-based contracts, ensuring a mutually beneficial relationship.</p> </li> <li> <p>Data as a Service (DaaS): Leverage the data generated by Swarms for insights and analytics, providing valuable business intelligence to clients.</p> </li> </ol>"},{"location":"corporate/distribution/#potential-revenue-streams","title":"Potential Revenue Streams","text":"<ol> <li> <p>Subscription Fees: This would be the main revenue stream from providing the Swarms platform as a service.</p> </li> <li> <p>Usage Fees: Additional revenue can come from usage fees for businesses that have high demand for Swarms API.</p> </li> <li> <p>Contract Fees: From offering managed services and bespoke solutions to businesses.</p> </li> <li> <p>Training Fees: Revenue from providing training and certification programs to developers and businesses.</p> </li> <li> <p>Partnership Contracts: Large-scale projects with enterprises, involving dedicated Swarm AI services, could provide substantial income.</p> </li> <li> <p>Data Insights: Revenue from selling valuable business intelligence derived from Swarm's aggregated and anonymized data.</p> </li> </ol>"},{"location":"corporate/distribution/#potential-customers","title":"Potential Customers","text":"<ol> <li> <p>Businesses Across Sectors: Any business seeking to leverage AI for automation, efficiency, and data insights could be a potential customer. This includes sectors like finance, eCommerce, logistics, healthcare, and more.</p> </li> <li> <p>Developers: Both freelance and those working in organizations could use Swarms to enhance their projects and services. </p> </li> <li> <p>Enterprises: Large enterprises looking to automate and optimize their operations could greatly benefit from Swarms.</p> </li> <li> <p>Educational Institutions: Universities and research institutions could leverage Swarms for research and teaching purposes.</p> </li> </ol>"},{"location":"corporate/distribution/#roadmap","title":"Roadmap","text":"<ol> <li> <p>Landing Page Creation: Develop a dedicated product page on apac.ai for Swarms.</p> </li> <li> <p>Hosted Swarms API: Launch a cloud-based Swarms API service. It should be highly reliable, with robust documentation to attract daily users.</p> </li> <li> <p>Consumer and Enterprise Subscription Service: Launch a comprehensive subscription service on The Domain. This would provide users with access to a wide array of APIs and data streams.</p> </li> <li> <p>Dedicated Capacity Deals: Partner with large enterprises to offer them dedicated Swarm AI solutions for automating their operations.</p> </li> <li> <p>Enterprise Partnerships: Develop partnerships with large enterprises for extensive contract-based projects.</p> </li> <li> <p>Integration with Collaboration Platforms: Develop Swarms bots for platforms like Discord and Slack, charging users a subscription fee for access.</p> </li> <li> <p>Personal Data Instances: Offer users dedicated instances of all their data that the Swarm can query as needed.</p> </li> <li> <p>Browser Extension: Develop a browser extension that integrates with the Swarms platform, offering users a more seamless experience.</p> </li> </ol> <p>Remember, customer satisfaction and a value-centric approach are at the core of any successful monetization strategy. It's essential to continuously iterate and improve the product based on customer feedback and evolving market needs.</p>"},{"location":"corporate/distribution/#other-ideas","title":"Other ideas","text":"<ol> <li> <p>Platform as a Service (PaaS): Create a cloud-based platform that allows users to build, run, and manage applications without the complexity of maintaining the infrastructure. You could charge users a subscription fee for access to the platform and provide different pricing tiers based on usage levels. This could be an attractive solution for businesses that do not have the capacity to build or maintain their own swarm intelligence solutions.</p> </li> <li> <p>Professional Services: Offer consultancy and implementation services to businesses looking to utilize the Swarm technology. This could include assisting with integration into existing systems, offering custom development services, or helping customers to build specific solutions using the framework.</p> </li> <li> <p>Education and Training: Create a certification program for developers or companies looking to become proficient with the Swarms framework. This could be sold as standalone courses, or bundled with other services. </p> </li> <li> <p>Managed Services: Some companies may prefer to outsource the management of their Swarm-based systems. A managed services solution could take care of all the technical aspects, from hosting the solution to ensuring it runs smoothly, allowing the customer to focus on their core business.</p> </li> <li> <p>Data Analysis and Insights: Swarm intelligence can generate valuable data and insights. By anonymizing and aggregating this data, you could provide industry reports, trend analysis, and other valuable insights to businesses.</p> </li> </ol> <p>As for the type of platform, Swarms can be offered as a cloud-based solution given its scalability and flexibility. This would also allow you to apply a SaaS/PaaS type monetization model, which provides recurring revenue.</p> <p>Potential customers could range from small to large enterprises in various sectors such as logistics, eCommerce, finance, and technology, who are interested in leveraging artificial intelligence and machine learning for complex problem solving, optimization, and decision-making.</p> <p>Product Brief Monetization Strategy:</p> <p>Product Name: Swarms.AI Platform</p> <p>Product Description: A cloud-based AI and ML platform harnessing the power of swarm intelligence. </p> <ol> <li> <p>Platform as a Service (PaaS): Offer tiered subscription plans (Basic, Premium, Enterprise) to accommodate different usage levels and business sizes. </p> </li> <li> <p>Professional Services: Offer consultancy and custom development services to tailor the Swarms solution to the specific needs of the business.</p> </li> <li> <p>Education and Training: Launch an online Swarms.AI Academy with courses and certifications for developers and businesses. </p> </li> <li> <p>Managed Services: Provide a premium, fully-managed service offering that includes hosting, maintenance, and 24/7 support.</p> </li> <li> <p>Data Analysis and Insights: Offer industry reports and customized insights generated from aggregated and anonymized Swarm data.</p> </li> </ol> <p>Potential Customers: Enterprises in sectors such as logistics, eCommerce, finance, and technology. This can be sold globally, provided there's an internet connection.</p> <p>Marketing Channels: Online marketing (SEO, Content Marketing, Social Media), Partnerships with tech companies, Direct Sales to Enterprises.</p> <p>This strategy is designed to provide multiple revenue streams, while ensuring the Swarms.AI platform is accessible and useful to a range of potential customers.</p> <ol> <li> <p>AI Solution as a Service: By offering the Swarms framework as a service, businesses can access and utilize the power of multiple LLM agents without the need to maintain the infrastructure themselves. Subscription can be tiered based on usage and additional features.</p> </li> <li> <p>Integration and Custom Development: Offer integration services to businesses wanting to incorporate the Swarms framework into their existing systems. Also, you could provide custom development for businesses with specific needs not met by the standard framework.</p> </li> <li> <p>Training and Certification: Develop an educational platform offering courses, webinars, and certifications on using the Swarms framework. This can serve both developers seeking to broaden their skills and businesses aiming to train their in-house teams.</p> </li> <li> <p>Managed Swarms Solutions: For businesses that prefer to outsource their AI needs, provide a complete solution which includes the development, maintenance, and continuous improvement of swarms-based applications.</p> </li> <li> <p>Data Analytics Services: Leveraging the aggregated insights from the AI swarms, you could offer data analytics services. Businesses can use these insights to make informed decisions and predictions.</p> </li> </ol> <p>Type of Platform:</p> <p>Cloud-based platform or Software as a Service (SaaS) will be a suitable model. It offers accessibility, scalability, and ease of updates. </p> <p>Target Customers:</p> <p>The technology can be beneficial for businesses across sectors like eCommerce, technology, logistics, finance, healthcare, and education, among others.</p> <p>Product Brief Monetization Strategy:</p> <p>Product Name: Swarms.AI</p> <ol> <li> <p>AI Solution as a Service: Offer different tiered subscriptions (Standard, Premium, and Enterprise) each with varying levels of usage and features.</p> </li> <li> <p>Integration and Custom Development: Offer custom development and integration services, priced based on the scope and complexity of the project.</p> </li> <li> <p>Training and Certification: Launch the Swarms.AI Academy with courses and certifications, available for a fee. </p> </li> <li> <p>Managed Swarms Solutions: Offer fully managed solutions tailored to business needs, priced based on scope and service level agreements.</p> </li> <li> <p>Data Analytics Services: Provide insightful reports and data analyses, which can be purchased on a one-off basis or through a subscription.</p> </li> </ol> <p>By offering a variety of services and payment models, Swarms.AI will be able to cater to a diverse range of business needs, from small start-ups to large enterprises. Marketing channels would include digital marketing, partnerships with technology companies, presence in tech events, and direct sales to targeted industries.</p>"},{"location":"corporate/distribution/#roadmap_1","title":"Roadmap","text":"<ul> <li> <p>Create a landing page for swarms apac.ai/product/swarms</p> </li> <li> <p>Create Hosted Swarms API for anybody to just use without need for mega gpu infra, charge usage based pricing. Prerequisites for success =&gt; Swarms has to be extremely reliable + we need world class documentation and many daily users =&gt; how do we get many daily users? We provide a seamless and fluid experience, how do we create a seamless and fluid experience? We write good code that is modular, provides feedback to the user in times of distress, and ultimately accomplishes the user's tasks.</p> </li> <li> <p>Hosted consumer and enterprise subscription as a service on The Domain, where users can interact with 1000s of APIs and ingest 1000s of different data streams.</p> </li> <li> <p>Hosted dedicated capacity deals with mega enterprises on automating many operations with Swarms for monthly subscription 300,000+$ </p> </li> <li> <p>Partnerships with enterprises, massive contracts with performance based fee</p> </li> <li> <p>Have discord bot and or slack bot with users personal data, charge subscription + browser extension</p> </li> <li> <p>each user gets a dedicated ocean instance of all their data so the swarm can query it as needed.</p> </li> </ul>"},{"location":"corporate/distribution/#-","title":"---","text":""},{"location":"corporate/distribution/#swarms-monetization-strategy-a-revolutionary-ai-powered-future","title":"Swarms Monetization Strategy: A Revolutionary AI-powered Future","text":"<p>Swarms is a powerful AI platform leveraging the transformative potential of Swarm Intelligence. Our ambition is to monetize this groundbreaking technology in ways that generate significant cashflow while providing extraordinary value to our customers. </p> <p>Here we outline our strategic monetization pathways and provide a roadmap that plots our course to future success.</p>"},{"location":"corporate/distribution/#i-business-models","title":"I. Business Models","text":"<ol> <li> <p>Platform as a Service (PaaS): We provide the Swarms platform as a service, billed on a monthly or annual basis. Subscriptions can range from $50 for basic access, to $500+ for premium features and extensive usage.</p> </li> <li> <p>API Usage-based Pricing: Customers are billed according to their use of the Swarms API. Starting at $0.01 per request, this creates a cashflow model that rewards extensive platform usage.</p> </li> <li> <p>Managed Services: We offer end-to-end solutions, managing clients' entire AI infrastructure. Contract fees start from $100,000 per month, offering both a sustainable cashflow and considerable savings for our clients.</p> </li> <li> <p>Training and Certification: A Swarms AI training and certification program is available for developers and businesses. Course costs can range from $200 to $2,000, depending on course complexity and duration.</p> </li> <li> <p>Partnerships: We forge collaborations with large enterprises, offering dedicated Swarm AI services. These performance-based contracts start from $1,000,000, creating a potentially lucrative cashflow stream.</p> </li> <li> <p>Data as a Service (DaaS): Swarms generated data are mined for insights and analytics, with business intelligence reports offered from $500 each. </p> </li> </ol>"},{"location":"corporate/distribution/#ii-potential-revenue-streams","title":"II. Potential Revenue Streams","text":"<ol> <li> <p>Subscription Fees: From $50 to $500+ per month for platform access.</p> </li> <li> <p>Usage Fees: From $0.01 per API request, generating income from high platform usage.</p> </li> <li> <p>Contract Fees: Starting from $100,000 per month for managed services.</p> </li> <li> <p>Training Fees: From $200 to $2,000 for individual courses or subscription access.</p> </li> <li> <p>Partnership Contracts: Contracts starting from $100,000, offering major income potential.</p> </li> <li> <p>Data Insights: Business intelligence reports starting from $500.</p> </li> </ol>"},{"location":"corporate/distribution/#iii-potential-customers","title":"III. Potential Customers","text":"<ol> <li> <p>Businesses Across Sectors: Our offerings cater to businesses across finance, eCommerce, logistics, healthcare, and more.</p> </li> <li> <p>Developers: Both freelancers and organization-based developers can leverage Swarms for their projects.</p> </li> <li> <p>Enterprises: Swarms offers large enterprises solutions for optimizing operations.</p> </li> <li> <p>Educational Institutions: Universities and research institutions can use Swarms for research and teaching.</p> </li> </ol>"},{"location":"corporate/distribution/#iv-roadmap","title":"IV. Roadmap","text":"<ol> <li> <p>Landing Page Creation: Develop a dedicated Swarms product page on apac.ai.</p> </li> <li> <p>Hosted Swarms API: Launch a reliable, well-documented cloud-based Swarms API service.</p> </li> <li> <p>Consumer and Enterprise Subscription Service: Launch an extensive subscription service on The Domain, providing wide-ranging access to APIs and data streams.</p> </li> <li> <p>Dedicated Capacity Deals: Offer large enterprises dedicated Swarm AI solutions, starting from $300,000 monthly subscription.</p> </li> <li> <p>Enterprise Partnerships: Develop performance-based contracts with large enterprises.</p> </li> <li> <p>Integration with Collaboration Platforms: Develop Swarms bots for platforms like Discord and Slack, charging a subscription fee for access.</p> </li> <li> <p>Personal Data Instances: Offer users dedicated data instances that the Swarm can query as needed.</p> </li> <li> <p>Browser Extension: Develop a browser extension that integrates with the Swarms platform for seamless user experience.</p> </li> </ol> <p>Our North Star remains customer satisfaction and value provision.  As we embark on this journey, we continuously refine our product based on customer feedback and evolving market needs, ensuring we lead in the age of AI-driven solutions.</p>"},{"location":"corporate/distribution/#platform-distribution-strategy-for-swarms","title":"Platform Distribution Strategy for Swarms","text":"<p>*Note: This strategy aims to diversify the presence of 'Swarms' across various platforms and mediums while focusing on monetization and value creation for its users.</p>"},{"location":"corporate/distribution/#1-framework","title":"1. Framework:","text":""},{"location":"corporate/distribution/#objective","title":"Objective:","text":"<p>To offer Swarms as an integrated solution within popular frameworks to ensure that developers and businesses can seamlessly incorporate its functionalities.</p>"},{"location":"corporate/distribution/#strategy","title":"Strategy:","text":"<ul> <li> <p>Language/Framework Integration: </p> <ul> <li>Target popular frameworks like Django, Flask for Python, Express.js for Node, etc. </li> <li>Create SDKs or plugins for easy integration. </li> </ul> </li> <li> <p>Monetization: </p> <ul> <li>Freemium Model: Offer basic integration for free, and charge for additional features or advanced integrations.</li> <li>Licensing: Allow businesses to purchase licenses for enterprise-level integrations.</li> </ul> </li> <li> <p>Promotion:</p> <ul> <li>Engage in partnerships with popular online coding platforms like Udemy, Coursera, etc., offering courses and tutorials on integrating Swarms.</li> <li>Host webinars and write technical blogs to promote the integration benefits.</li> </ul> </li> </ul>"},{"location":"corporate/distribution/#2-paid-api","title":"2. Paid API:","text":""},{"location":"corporate/distribution/#objective_1","title":"Objective:","text":"<p>To provide a scalable solution for developers and businesses that want direct access to Swarms' functionalities without integrating the entire framework.</p>"},{"location":"corporate/distribution/#strategy_1","title":"Strategy:","text":"<ul> <li> <p>API Endpoints:</p> <ul> <li>Offer various endpoints catering to different functionalities.</li> <li>Maintain robust documentation to ensure ease of use.</li> </ul> </li> <li> <p>Monetization:</p> <ul> <li>Usage-based Pricing: Charge based on the number of API calls.</li> <li>Subscription Tiers: Provide tiered packages based on usage limits and advanced features.</li> </ul> </li> <li> <p>Promotion:</p> <ul> <li>List on API marketplaces like RapidAPI.</li> <li>Engage in SEO to make the API documentation discoverable.</li> </ul> </li> </ul>"},{"location":"corporate/distribution/#3-domain-hosted","title":"3. Domain Hosted:","text":""},{"location":"corporate/distribution/#objective_2","title":"Objective:","text":"<p>To provide a centralized web platform where users can directly access and engage with Swarms' offerings.</p>"},{"location":"corporate/distribution/#strategy_2","title":"Strategy:","text":"<ul> <li> <p>User-Friendly Interface:</p> <ul> <li>Ensure a seamless user experience with intuitive design.</li> <li>Incorporate features like real-time chat support, tutorials, and an FAQ section.</li> </ul> </li> <li> <p>Monetization:</p> <ul> <li>Subscription Model: Offer monthly/annual subscriptions for premium features.</li> <li>Affiliate Marketing: Partner with related tech products/services and earn through referrals.</li> </ul> </li> <li> <p>Promotion:</p> <ul> <li>Invest in PPC advertising on platforms like Google Ads.</li> <li>Engage in content marketing, targeting keywords related to Swarms' offerings.</li> </ul> </li> </ul>"},{"location":"corporate/distribution/#4-build-your-own-no-code-platform","title":"4. Build Your Own (No-Code Platform):","text":""},{"location":"corporate/distribution/#objective_3","title":"Objective:","text":"<p>To cater to the non-developer audience, allowing them to leverage Swarms' features without any coding expertise.</p>"},{"location":"corporate/distribution/#strategy_3","title":"Strategy:","text":"<ul> <li> <p>Drag-and-Drop Interface:</p> <ul> <li>Offer customizable templates.</li> <li>Ensure integration with popular platforms and apps.</li> </ul> </li> <li> <p>Monetization:</p> <ul> <li>Freemium Model: Offer basic features for free, and charge for advanced functionalities.</li> <li>Marketplace for Plugins: Allow third-party developers to sell their plugins/extensions on the platform.</li> </ul> </li> <li> <p>Promotion:</p> <ul> <li>Partner with no-code communities and influencers.</li> <li>Offer promotions and discounts to early adopters.</li> </ul> </li> </ul>"},{"location":"corporate/distribution/#5-marketplace-for-the-no-code-platform","title":"5. Marketplace for the No-Code Platform:","text":""},{"location":"corporate/distribution/#objective_4","title":"Objective:","text":"<p>To create an ecosystem where third-party developers can contribute, and users can enhance their Swarms experience.</p>"},{"location":"corporate/distribution/#strategy_4","title":"Strategy:","text":"<ul> <li> <p>Open API for Development:</p> <ul> <li>Offer robust documentation and developer support.</li> <li>Ensure a strict quality check for marketplace additions.</li> </ul> </li> <li> <p>Monetization:</p> <ul> <li>Revenue Sharing: Take a percentage cut from third-party sales.</li> <li>Featured Listings: Charge developers for premium listings.</li> </ul> </li> <li> <p>Promotion:</p> <ul> <li>Host hackathons and competitions to boost developer engagement.</li> <li>Promote top plugins/extensions through email marketing and on the main platform.</li> </ul> </li> </ul>"},{"location":"corporate/distribution/#future-outlook-expansion","title":"Future Outlook &amp; Expansion:","text":"<ul> <li>Hosted Dedicated Capacity: Hosted dedicated capacity deals for enterprises starting at 399,999$</li> <li>Decentralized Free Peer to peer endpoint hosted on The Grid: Hosted endpoint by the people for the people.</li> <li> <p>Browser Extenision: Athena browser extension for deep browser automation, subscription, usage, </p> </li> <li> <p>Mobile Application: Develop a mobile app version for Swarms to tap into the vast mobile user base.</p> </li> <li>Global Expansion: Localize the platform for non-English speaking regions to tap into global markets.</li> <li>Continuous Learning: Regularly collect user feedback and iterate on the product features.</li> </ul>"},{"location":"corporate/distribution/#50-creative-distribution-platforms-for-swarms","title":"50 Creative Distribution Platforms for Swarms","text":"<ol> <li> <p>E-commerce Integrations: Platforms like Shopify, WooCommerce, where Swarms can add value to sellers.</p> </li> <li> <p>Web Browser Extensions: Chrome, Firefox, and Edge extensions that bring Swarms features directly to users.</p> </li> <li> <p>Podcasting Platforms: Swarms-themed content on platforms like Spotify, Apple Podcasts to reach aural learners.</p> </li> <li> <p>Virtual Reality (VR) Platforms: Integration with VR experiences on Oculus or Viveport.</p> </li> <li> <p>Gaming Platforms: Tools or plugins for game developers on Steam, Epic Games.</p> </li> <li> <p>Decentralized Platforms: Using blockchain, create decentralized apps (DApps) versions of Swarms.</p> </li> <li> <p>Chat Applications: Integrate with popular messaging platforms like WhatsApp, Telegram, Slack.</p> </li> <li> <p>AI Assistants: Integration with Siri, Alexa, Google Assistant to provide Swarms functionalities via voice commands.</p> </li> <li> <p>Freelancing Websites: Offer tools or services for freelancers on platforms like Upwork, Fiverr.</p> </li> <li> <p>Online Forums: Platforms like Reddit, Quora, where users can discuss or access Swarms.</p> </li> <li> <p>Educational Platforms: Sites like Khan Academy, Udacity where Swarms can enhance learning experiences.</p> </li> <li> <p>Digital Art Platforms: Integrate with platforms like DeviantArt, Behance.</p> </li> <li> <p>Open-source Repositories: Hosting Swarms on GitHub, GitLab, Bitbucket with open-source plugins.</p> </li> <li> <p>Augmented Reality (AR) Apps: Create AR experiences powered by Swarms.</p> </li> <li> <p>Smart Home Devices: Integrate Swarms' functionalities into smart home devices.</p> </li> <li> <p>Newsletters: Platforms like Substack, where Swarms insights can be shared.</p> </li> <li> <p>Interactive Kiosks: In malls, airports, and other public places.</p> </li> <li> <p>IoT Devices: Incorporate Swarms in devices like smart fridges, smartwatches.</p> </li> <li> <p>Collaboration Tools: Platforms like Trello, Notion, offering Swarms-enhanced productivity.</p> </li> <li> <p>Dating Apps: An AI-enhanced matching algorithm powered by Swarms.</p> </li> <li> <p>Music Platforms: Integrate with Spotify, SoundCloud for music-related AI functionalities.</p> </li> <li> <p>Recipe Websites: Platforms like AllRecipes, Tasty with AI-recommended recipes.</p> </li> <li> <p>Travel &amp; Hospitality: Integrate with platforms like Airbnb, Tripadvisor for AI-based recommendations.</p> </li> <li> <p>Language Learning Apps: Duolingo, Rosetta Stone integrations.</p> </li> <li> <p>Virtual Events Platforms: Websites like Hopin, Zoom where Swarms can enhance the virtual event experience.</p> </li> <li> <p>Social Media Management: Tools like Buffer, Hootsuite with AI insights by Swarms.</p> </li> <li> <p>Fitness Apps: Platforms like MyFitnessPal, Strava with AI fitness insights.</p> </li> <li> <p>Mental Health Apps: Integration into apps like Calm, Headspace for AI-driven wellness.</p> </li> <li> <p>E-books Platforms: Amazon Kindle, Audible with AI-enhanced reading experiences.</p> </li> <li> <p>Sports Analysis Tools: Websites like ESPN, Sky Sports where Swarms can provide insights.</p> </li> <li> <p>Financial Tools: Integration into platforms like Mint, Robinhood for AI-driven financial advice.</p> </li> <li> <p>Public Libraries: Digital platforms of public libraries for enhanced reading experiences.</p> </li> <li> <p>3D Printing Platforms: Websites like Thingiverse, Shapeways with AI customization.</p> </li> <li> <p>Meme Platforms: Websites like Memedroid, 9GAG where Swarms can suggest memes.</p> </li> <li> <p>Astronomy Apps: Platforms like Star Walk, NASA's Eyes with AI-driven space insights.</p> </li> <li> <p>Weather Apps: Integration into Weather.com, AccuWeather for predictive analysis.</p> </li> <li> <p>Sustainability Platforms: Websites like Ecosia, GoodGuide with AI-driven eco-tips.</p> </li> <li> <p>Fashion Apps: Platforms like ASOS, Zara with AI-based style recommendations.</p> </li> <li> <p>Pet Care Apps: Integration into PetSmart, Chewy for AI-driven pet care tips.</p> </li> <li> <p>Real Estate Platforms: Websites like Zillow, Realtor with AI-enhanced property insights.</p> </li> <li> <p>DIY Platforms: Websites like Instructables, DIY.org with AI project suggestions.</p> </li> <li> <p>Genealogy Platforms: Ancestry, MyHeritage with AI-driven family tree insights.</p> </li> <li> <p>Car Rental &amp; Sale Platforms: Integration into AutoTrader, Turo for AI-driven vehicle suggestions.</p> </li> <li> <p>Wedding Planning Websites: Platforms like Zola, The Knot with AI-driven planning.</p> </li> <li> <p>Craft Platforms: Websites like Etsy, Craftsy with AI-driven craft suggestions.</p> </li> <li> <p>Gift Recommendation Platforms: AI-driven gift suggestions for websites like Gifts.com.</p> </li> <li> <p>Study &amp; Revision Platforms: Websites like Chegg, Quizlet with AI-driven study guides.</p> </li> <li> <p>Local Business Directories: Yelp, Yellow Pages with AI-enhanced reviews.</p> </li> <li> <p>Networking Platforms: LinkedIn, Meetup with AI-driven connection suggestions.</p> </li> <li> <p>Lifestyle Magazines' Digital Platforms: Websites like Vogue, GQ with AI-curated fashion and lifestyle insights.</p> </li> </ol> <p>Endnote: Leveraging these diverse platforms ensures that Swarms becomes an integral part of multiple ecosystems, enhancing its visibility and user engagement.</p>"},{"location":"corporate/failures/","title":"Failure Root Cause Analysis for Langchain","text":""},{"location":"corporate/failures/#1-introduction","title":"1. Introduction","text":"<p>Langchain is an open-source software that has gained massive popularity in the artificial intelligence ecosystem, serving as a tool for connecting different language models, especially GPT based models. However, despite its popularity and substantial investment, Langchain has shown several weaknesses that hinder its use in various projects, especially in complex and large-scale implementations. This document provides an analysis of the identified issues and proposes potential mitigation strategies.</p>"},{"location":"corporate/failures/#2-analysis-of-weaknesses","title":"2. Analysis of Weaknesses","text":""},{"location":"corporate/failures/#21-tool-lock-in","title":"2.1 Tool Lock-in","text":"<p>Langchain tends to enforce tool lock-in, which could prove detrimental for developers. Its design heavily relies on specific workflows and architectures, which greatly limits flexibility. Developers may find themselves restricted to certain methodologies, impeding their freedom to implement custom solutions or integrate alternative tools.</p>"},{"location":"corporate/failures/#mitigation","title":"Mitigation","text":"<p>An ideal AI framework should not be restrictive but should instead offer flexibility for users to integrate any agent on any architecture. Adopting an open architecture that allows for seamless interaction between various agents and workflows can address this issue.</p>"},{"location":"corporate/failures/#22-outdated-workflows","title":"2.2 Outdated Workflows","text":"<p>Langchain's current workflows and prompt engineering, mainly based on InstructGPT, are out of date, especially compared to newer models like ChatGPT/GPT-4.</p>"},{"location":"corporate/failures/#mitigation_1","title":"Mitigation","text":"<p>Keeping up with the latest AI models and workflows is crucial. The framework should have a mechanism for regular updates and seamless integration of up-to-date models and workflows.</p>"},{"location":"corporate/failures/#23-debugging-difficulties","title":"2.3 Debugging Difficulties","text":"<p>Debugging in Langchain is reportedly very challenging, even with verbose output enabled, making it hard to determine what is happening under the hood.</p>"},{"location":"corporate/failures/#mitigation_2","title":"Mitigation","text":"<p>The introduction of a robust debugging and logging system would help users understand the internals of the models, thus enabling them to pinpoint and rectify issues more effectively.</p>"},{"location":"corporate/failures/#24-limited-customization","title":"2.4 Limited Customization","text":"<p>Langchain makes it extremely hard to deviate from documented workflows. This becomes a challenge when developers need custom workflows for their specific use-cases.</p>"},{"location":"corporate/failures/#mitigation_3","title":"Mitigation","text":"<p>An ideal framework should support custom workflows and allow developers to hack and adjust the framework according to their needs.</p>"},{"location":"corporate/failures/#25-documentation","title":"2.5 Documentation","text":"<p>Langchain's documentation is reportedly missing relevant details, making it difficult for users to understand the differences between various agent types, among other things.</p>"},{"location":"corporate/failures/#mitigation_4","title":"Mitigation","text":"<p>Providing detailed and comprehensive documentation, including examples, FAQs, and best practices, is crucial. This will help users understand the intricacies of the framework, making it easier for them to implement it in their projects.</p>"},{"location":"corporate/failures/#26-negative-influence-on-ai-ecosystem","title":"2.6 Negative Influence on AI Ecosystem","text":"<p>The extreme popularity of Langchain seems to be warping the AI ecosystem to the point of causing harm, with other AI entities shifting their operations to align with Langchain's 'magic AI' approach.</p>"},{"location":"corporate/failures/#mitigation_5","title":"Mitigation","text":"<p>It's essential for any widely adopted framework to promote healthy practices in the broader ecosystem. One approach could be promoting open dialogue, inviting criticism, and being open to change based on feedback.</p>"},{"location":"corporate/failures/#3-conclusion","title":"3. Conclusion","text":"<p>While Langchain has made significant contributions to the AI landscape, these challenges hinder its potential. Addressing these issues will not only improve Langchain but also foster a healthier AI ecosystem. It's important to note that criticism, when approached constructively, can be a powerful tool for growth and innovation.</p>"},{"location":"corporate/failures/#list-of-weaknesses-in-glangchain-and-potential-mitigations","title":"List of weaknesses in gLangchain and Potential Mitigations","text":"<ol> <li>Tool Lock-in: Langchain encourages the use of specific tools, creating a lock-in problem with minimal benefits for developers. </li> </ol> <p>Mitigation Strategy: Langchain should consider designing the architecture to be more versatile and allow for the inclusion of a variety of tools. An open architecture will provide developers with more freedom and customization options.</p> <ol> <li>Outdated Workflow: The current workflow and prompt engineering of Langchain rely on outdated models like InstructGPT, which fall short compared to newer alternatives such as ChatGPT/GPT-4.</li> </ol> <p>Mitigation Strategy: Regular updates and adaptation of more recent models should be integrated into the Langchain framework.</p> <ol> <li>Debugging Difficulty: Debugging a Langchain error is a complicated task, even with verbose=True, leading to a discouraging developer experience.</li> </ol> <p>Mitigation Strategy: Develop a comprehensive debugging tool or improve current debugging processes for clearer and more accessible error detection and resolution.</p> <ol> <li>Lack of Customizability: Customizing workflows that are not documented in Langchain is quite challenging.</li> </ol> <p>Mitigation Strategy: Improve documentation and provide guides on how to customize workflows to enhance developer flexibility.</p> <ol> <li>Poor Documentation: Langchain's documentation misses key details that developers have to manually search for in the codebase.</li> </ol> <p>Mitigation Strategy: Enhance and improve the documentation of Langchain to provide clarity for developers and make navigation easier.</p> <ol> <li>Harmful Ecosystem Influence: Langchain's extreme popularity is influencing the AI ecosystem towards the workflows, potentially harming development and code clarity.</li> </ol> <p>Mitigation Strategy: Encourage diverse and balanced adoption of AI tools in the ecosystem.</p> <ol> <li>Suboptimal Performances: Langchain's performance is sometimes underwhelming, and there are no clear benefits in terms of performance or abstraction.</li> </ol> <p>Mitigation Strategy: Enhance the performance optimization of Langchain. Benchmarking against other tools can also provide performance improvement insights.</p> <ol> <li>Rigid General Interface: Langchain tries to do too many things, resulting in a rigid interface not suitable for practical use, especially in production.</li> </ol> <p>Mitigation Strategy: Focus on core features and allow greater flexibility in the interface. Adopting a modular approach where developers can pick and choose the features they want could also be helpful.</p> <ol> <li>Leaky Abstraction Problem: Langchain\u2019s full-on framework approach has created a leaky abstraction problem leading to a disappointing developer experience.</li> </ol> <p>Mitigation Strategy: Adopt a more balanced approach between a library and a framework. Provide a solid core feature set with the possibility to extend it according to the developers' needs. </p> <ol> <li>Excessive Focus on Third-party Services: Langchain overly focuses on supporting every single third-party service at the expense of customizability and fine-tuning for actual applications.</li> </ol> <p>Mitigation Strategy: Prioritize fine-tuning and customizability for developers, limiting the focus on third-party services unless they provide substantial value.</p> <p>Remember, any mitigation strategy will need to be tailored to Langchain's particular circumstances and developer feedback. It's also important to consider potential trade-offs and unintended consequences when implementing these strategies.</p>"},{"location":"corporate/faq/","title":"FAQ","text":""},{"location":"corporate/faq/#faq-on-swarm-intelligence-and-multi-agent-systems","title":"FAQ on Swarm Intelligence and Multi-Agent Systems","text":""},{"location":"corporate/faq/#what-is-an-agent-in-the-context-of-ai-and-swarm-intelligence","title":"What is an agent in the context of AI and swarm intelligence?","text":"<p>In artificial intelligence (AI), an agent refers to an LLM with some objective to accomplish.</p> <p>In swarm intelligence, each agent interacts with other agents and possibly the environment to achieve complex collective behaviors or solve problems more efficiently than individual agents could on their own.</p>"},{"location":"corporate/faq/#what-do-you-need-swarms-at-all","title":"What do you need Swarms at all?","text":"<p>Individual agents are limited by a vast array of issues such as context window loss, single task execution, hallucination, and no collaboration.</p>"},{"location":"corporate/faq/#how-does-a-swarm-work","title":"How does a swarm work?","text":"<p>A swarm works through the principles of decentralized control, local interactions, and simple rules followed by each agent. Unlike centralized systems, where a single entity dictates the behavior of all components, in a swarm, each agent makes its own decisions based on local information and interactions with nearby agents. These local interactions lead to the emergence of complex, organized behaviors or solutions at the collective level, enabling the swarm to tackle tasks efficiently.</p>"},{"location":"corporate/faq/#why-do-you-need-more-agents-in-a-swarm","title":"Why do you need more agents in a swarm?","text":"<p>More agents in a swarm can enhance its problem-solving capabilities, resilience, and efficiency. With more agents:</p> <ul> <li>Diversity and Specialization: The swarm can leverage a wider range of skills, knowledge, and perspectives, allowing for more creative and effective solutions to complex problems.</li> <li>Scalability: Adding more agents can increase the swarm's capacity to handle larger tasks or multiple tasks simultaneously.</li> <li>Robustness: A larger number of agents enhances the system's redundancy and fault tolerance, as the failure of a few agents has a minimal impact on the overall performance of the swarm.</li> </ul>"},{"location":"corporate/faq/#isnt-it-more-expensive-to-use-more-agents","title":"Isn't it more expensive to use more agents?","text":"<p>While deploying more agents can initially increase costs, especially in terms of computational resources, hosting, and potentially API usage, there are several factors and strategies that can mitigate these expenses:</p> <ul> <li>Efficiency at Scale: Larger swarms can often solve problems more quickly or effectively, reducing the overall computational time and resources required.</li> <li>Optimization and Caching: Implementing optimizations and caching strategies can reduce redundant computations, lowering the workload on individual agents and the overall system.</li> <li>Dynamic Scaling: Utilizing cloud services that offer dynamic scaling can ensure you only pay for the resources you need when you need them, optimizing cost-efficiency.</li> </ul>"},{"location":"corporate/faq/#can-swarms-make-decisions-better-than-individual-agents","title":"Can swarms make decisions better than individual agents?","text":"<p>Yes, swarms can make better decisions than individual agents for several reasons:</p> <ul> <li>Collective Intelligence: Swarms combine the knowledge and insights of multiple agents, leading to more informed and well-rounded decision-making processes.</li> <li>Error Correction: The collaborative nature of swarms allows for error checking and correction among agents, reducing the likelihood of mistakes.</li> <li>Adaptability: Swarms are highly adaptable to changing environments or requirements, as the collective can quickly reorganize or shift strategies based on new information.</li> </ul>"},{"location":"corporate/faq/#how-do-agents-in-a-swarm-communicate","title":"How do agents in a swarm communicate?","text":"<p>Communication in a swarm can vary based on the design and purpose of the system but generally involves either direct or indirect interactions:</p> <ul> <li>Direct Communication: Agents exchange information directly through messaging, signals, or other communication protocols designed for the system.</li> <li>Indirect Communication: Agents influence each other through the environment, a method known as stigmergy. Actions by one agent alter the environment, which in turn influences the behavior of other agents.</li> </ul>"},{"location":"corporate/faq/#are-swarms-only-useful-in-computational-tasks","title":"Are swarms only useful in computational tasks?","text":"<p>While swarms are often associated with computational tasks, their applications extend far beyond. Swarms can be utilized in:</p> <ul> <li>Robotics: Coordinating multiple robots for tasks like search and rescue, exploration, or surveillance.</li> <li>Environmental Monitoring: Using sensor networks to monitor pollution, wildlife, or climate conditions.</li> <li>Social Sciences: Modeling social behaviors or economic systems to understand complex societal dynamics.</li> <li>Healthcare: Coordinating care strategies in hospital settings or managing pandemic responses through distributed data analysis.</li> </ul>"},{"location":"corporate/faq/#how-do-you-ensure-the-security-of-a-swarm-system","title":"How do you ensure the security of a swarm system?","text":"<p>Security in swarm systems involves:</p> <ul> <li>Encryption: Ensuring all communications between agents are encrypted to prevent unauthorized access or manipulation.</li> <li>Authentication: Implementing strict authentication mechanisms to verify the identity of each agent in the swarm.</li> <li>Resilience to Attacks: Designing the swarm to continue functioning effectively even if some agents are compromised or attacked, utilizing redundancy and fault tolerance strategies.</li> </ul>"},{"location":"corporate/faq/#how-do-individual-agents-within-a-swarm-share-insights-without-direct-learning-mechanisms-like-reinforcement-learning","title":"How do individual agents within a swarm share insights without direct learning mechanisms like reinforcement learning?","text":"<p>In the context of pre-trained Large Language Models (LLMs) that operate within a swarm, sharing insights typically involves explicit communication and data exchange protocols rather than direct learning mechanisms like reinforcement learning. Here's how it can work:</p> <ul> <li> <p>Shared Databases and Knowledge Bases: Agents can write to and read from a shared database or knowledge base where insights, generated content, and relevant data are stored. This allows agents to benefit from the collective experience of the swarm by accessing information that other agents have contributed.</p> </li> <li> <p>APIs for Information Exchange: Custom APIs can facilitate the exchange of information between agents. Through these APIs, agents can request specific information or insights from others within the swarm, effectively sharing knowledge without direct learning.</p> </li> </ul>"},{"location":"corporate/faq/#how-do-you-balance-the-autonomy-of-individual-llms-with-the-need-for-coherent-collective-behavior-in-a-swarm","title":"How do you balance the autonomy of individual LLMs with the need for coherent collective behavior in a swarm?","text":"<p>Balancing autonomy with collective coherence in a swarm of LLMs involves:</p> <ul> <li> <p>Central Coordination Mechanism: Implementing a lightweight central coordination mechanism that can assign tasks, distribute information, and collect outputs from individual LLMs. This ensures that while each LLM operates autonomously, their actions are aligned with the swarm's overall objectives.</p> </li> <li> <p>Standardized Communication Protocols: Developing standardized protocols for how LLMs communicate and share information ensures that even though each agent works autonomously, the information exchange remains coherent and aligned with the collective goals.</p> </li> </ul>"},{"location":"corporate/faq/#how-do-llm-swarms-adapt-to-changing-environments-or-tasks-without-machine-learning-techniques","title":"How do LLM swarms adapt to changing environments or tasks without machine learning techniques?","text":"<p>Adaptation in LLM swarms, without relying on machine learning techniques for dynamic learning, can be achieved through:</p> <ul> <li> <p>Dynamic Task Allocation: A central system or distributed algorithm can dynamically allocate tasks to different LLMs based on the changing environment or requirements. This ensures that the most suitable LLMs are addressing tasks for which they are best suited as conditions change.</p> </li> <li> <p>Pre-trained Versatility: Utilizing a diverse set of pre-trained LLMs with different specialties or training data allows the swarm to select the most appropriate agent for a task as the requirements evolve.</p> </li> <li> <p>In Context Learning: In context learning is another mechanism that can be employed within LLM swarms to adapt to changing environments or tasks. This approach involves leveraging the collective knowledge and experiences of the swarm to facilitate learning and improve performance. Here's how it can work:</p> </li> </ul>"},{"location":"corporate/faq/#can-llm-swarms-operate-in-physical-environments-or-are-they-limited-to-digital-spaces","title":"Can LLM swarms operate in physical environments, or are they limited to digital spaces?","text":"<p>LLM swarms primarily operate in digital spaces, given their nature as software entities. However, they can interact with physical environments indirectly through interfaces with sensors, actuaries, or other devices connected to the Internet of Things (IoT). For example, LLMs can process data from physical sensors and control devices based on their outputs, enabling applications like smart home management or autonomous vehicle navigation.</p>"},{"location":"corporate/faq/#without-direct-learning-from-each-other-how-do-agents-in-a-swarm-improve-over-time","title":"Without direct learning from each other, how do agents in a swarm improve over time?","text":"<p>Improvement over time in a swarm of pre-trained LLMs, without direct learning from each other, can be achieved through:</p> <ul> <li> <p>Human Feedback: Incorporating feedback from human operators or users can guide adjustments to the usage patterns or selection criteria of LLMs within the swarm, optimizing performance based on observed outcomes.</p> </li> <li> <p>Periodic Re-training and Updating: The individual LLMs can be periodically re-trained or updated by their developers based on collective insights and feedback from their deployment within swarms. While this does not involve direct learning from each encounter, it allows the LLMs to improve over time based on aggregated experiences.</p> </li> </ul> <p>These adjustments to the FAQ reflect the specific context of pre-trained LLMs operating within a swarm, focusing on communication, coordination, and adaptation mechanisms that align with their capabilities and constraints.</p>"},{"location":"corporate/faq/#conclusion","title":"Conclusion","text":"<p>Swarms represent a powerful paradigm in AI, offering innovative solutions to complex, dynamic problems through collective intelligence and decentralized control. While challenges exist, particularly regarding cost and security, strategic design and management can leverage the strengths of swarm intelligence to achieve remarkable efficiency, adaptability, and robustness in a wide range of applications.</p>"},{"location":"corporate/flywheel/","title":"The Swarms Flywheel","text":"<ol> <li> <p>Building a Supportive Community: Initiate by establishing an engaging and inclusive open-source community for both developers and sales freelancers around Swarms. Regular online meetups, webinars, tutorials, and sales training can make them feel welcome and encourage contributions and sales efforts.</p> </li> <li> <p>Increased Contributions and Sales Efforts: The more engaged the community, the more developers will contribute to Swarms and the more effort sales freelancers will put into selling Swarms.</p> </li> <li> <p>Improvement in Quality and Market Reach: More developer contributions mean better quality, reliability, and feature offerings from Swarms. Simultaneously, increased sales efforts from freelancers boost Swarms' market penetration and visibility.</p> </li> <li> <p>Rise in User Base: As Swarms becomes more robust and more well-known, the user base grows, driving more revenue.</p> </li> <li> <p>Greater Financial Incentives: Increased revenue can be redirected to offer more significant financial incentives to both developers and salespeople. Developers can be incentivized based on their contribution to Swarms, and salespeople can be rewarded with higher commissions.</p> </li> <li> <p>Attract More Developers and Salespeople: These financial incentives, coupled with the recognition and experience from participating in a successful project, attract more developers and salespeople to the community.</p> </li> <li> <p>Wider Adoption of Swarms: An ever-improving product, a growing user base, and an increasing number of passionate salespeople accelerate the adoption of Swarms.</p> </li> <li> <p>Return to Step 1: As the community, user base, and sales network continue to grow, the cycle repeats, each time speeding up the flywheel.</p> </li> </ol> <pre><code>               +---------------------+\n               |   Building a       |\n               |  Supportive        | &lt;--+\n               |   Community        |    |\n               +--------+-----------+    |\n                        |                |\n                        v                |\n               +--------+-----------+    |\n               |   Increased        |    |\n               | Contributions &amp;    |    |\n               |   Sales Efforts    |    |\n               +--------+-----------+    |\n                        |                |\n                        v                |\n               +--------+-----------+    |\n               |   Improvement in   |    |\n               | Quality &amp; Market   |    |\n               |       Reach        |    |\n               +--------+-----------+    |\n                        |                |\n                        v                |\n               +--------+-----------+    |\n               |   Rise in User     |    |\n               |        Base        |    |\n               +--------+-----------+    |\n                        |                |\n                        v                |\n               +--------+-----------+    |\n               |  Greater Financial |    |\n               |     Incentives     |    |\n               +--------+-----------+    |\n                        |                |\n                        v                |\n               +--------+-----------+    |\n               | Attract More        |    |\n               | Developers &amp;       |    |\n               | Salespeople         |    |\n               +--------+-----------+    |\n                        |                |\n                        v                |\n               +--------+-----------+    |\n               |  Wider Adoption of  |    |\n               |       Swarms        |----+\n               +---------------------+\n</code></pre>"},{"location":"corporate/flywheel/#potential-risks-and-mitigations","title":"Potential Risks and Mitigations:","text":"<ol> <li>Insufficient Contributions or Quality of Work: Open-source efforts rely on individuals being willing and able to spend time contributing. If not enough people participate, or the work they produce is of poor quality, the product development could stall. </li> <li> <p>Mitigation: Create a robust community with clear guidelines, support, and resources. Provide incentives for quality contributions, such as a reputation system, swag, or financial rewards. Conduct thorough code reviews to ensure the quality of contributions.</p> </li> <li> <p>Lack of Sales Results: Commission-based salespeople will only continue to sell the product if they're successful. If they aren't making enough sales, they may lose motivation and cease their efforts.</p> </li> <li> <p>Mitigation: Provide adequate sales training and resources. Ensure the product-market fit is strong, and adjust messaging or sales tactics as necessary. Consider implementing a minimum commission or base pay to reduce risk for salespeople.</p> </li> <li> <p>Poor User Experience or User Adoption: If users don't find the product useful or easy to use, they won't adopt it, and the user base won't grow. This could also discourage salespeople and contributors.</p> </li> <li> <p>Mitigation: Prioritize user experience in the product development process. Regularly gather and incorporate user feedback. Ensure robust user support is in place.</p> </li> <li> <p>Inadequate Financial Incentives: If the financial rewards don't justify the time and effort contributors and salespeople are putting in, they will likely disengage.</p> </li> <li> <p>Mitigation: Regularly review and adjust financial incentives as needed. Ensure that the method for calculating and distributing rewards is transparent and fair.</p> </li> <li> <p>Security and Compliance Risks: As the user base grows and the software becomes more complex, the risk of security issues increases. Moreover, as contributors from various regions join, compliance with various international laws could become an issue.</p> </li> <li>Mitigation: Establish strong security practices from the start. Regularly conduct security audits. Seek legal counsel to understand and adhere to international laws and regulations.</li> </ol>"},{"location":"corporate/flywheel/#activation-plan-for-the-flywheel","title":"Activation Plan for the Flywheel:","text":"<ol> <li> <p>Community Building: Begin by fostering a supportive community around Swarms. Encourage early adopters to contribute and provide feedback. Create comprehensive documentation, community guidelines, and a forum for discussion and support.</p> </li> <li> <p>Sales and Development Training: Provide resources and training for salespeople and developers. Make sure they understand the product, its value, and how to effectively contribute or sell.</p> </li> <li> <p>Increase Contributions and Sales Efforts: Encourage increased participation by highlighting successful contributions and sales, rewarding top contributors and salespeople, and regularly communicating about the project's progress and impact.</p> </li> <li> <p>Iterate and Improve: Continually gather and implement feedback to improve Swarms and its market reach. The better the product and its alignment with the market, the more the user base will grow.</p> </li> <li> <p>Expand User Base: As the product improves and sales efforts continue, the user base should grow. Ensure you have the infrastructure to support this growth and maintain a positive user experience.</p> </li> <li> <p>Increase Financial Incentives: As the user base and product grow, so too should the financial incentives. Make sure rewards continue to be competitive and attractive.</p> </li> <li> <p>Attract More Contributors and Salespeople: As the financial incentives and success of the product increase, this should attract more contributors and salespeople, further feeding the flywheel.</p> </li> </ol> <p>Throughout this process, it's important to regularly reassess and adjust your strategy as necessary. Stay flexible and responsive to changes in the market, user feedback, and the evolving needs of the community.</p>"},{"location":"corporate/hiring/","title":"Hiring","text":""},{"location":"corporate/hiring/#join-the-swarm-revolution-advancing-humanity-prosperity-together","title":"Join the Swarm Revolution: Advancing Humanity &amp; Prosperity Together!","text":""},{"location":"corporate/hiring/#the-next-chapter-of-humanitys-story-begins-here","title":"The Next Chapter of Humanity's Story Begins Here...","text":"<p>At Swarms, our mission transcends mere technological advancement. We envision a world where every individual can leverage the power of AI to uplift their lives, communities, and our shared future. If you are driven by the passion to revolutionize industries, to scale the heights of innovation, and believe in earning your fair share for every ounce of your dedication \u2013 you might be the one we're looking for.</p>"},{"location":"corporate/hiring/#why-swarms","title":"Why Swarms?","text":""},{"location":"corporate/hiring/#for-the-ambitious-spirit","title":"For the Ambitious Spirit:","text":"<ul> <li>Opportunity Beyond Boundaries: Just as Fuller believed in the infinite opportunities of America, we believe in the limitless potential of raw Humantiy.</li> </ul>"},{"location":"corporate/hiring/#for-the-maverick","title":"For the Maverick:","text":"<ul> <li>Unprecedented Independence: Like the Fuller salesmen, our team members have the autonomy to sculpt their roles, timelines, and outcomes. Here, you\u2019re the captain of your ship.</li> </ul>"},{"location":"corporate/hiring/#for-the-avid-learner","title":"For the Avid Learner:","text":"<ul> <li>Continuous Learning &amp; Growth: Dive deep into the realms of AI, distributed systems, and customer success methodologies. We offer training, mentorship, and a platform to sharpen your skills.</li> </ul>"},{"location":"corporate/hiring/#for-the-high-achiever","title":"For the High Achiever:","text":"<ul> <li>Rewarding Compensation: While the sky is the limit for your innovations, so is your earning potential. Prosper with performance-based rewards that reflect your dedication.</li> </ul>"},{"location":"corporate/hiring/#for-the-community-builder","title":"For the Community Builder:","text":"<ul> <li>Culture of Unity &amp; Innovation: At Swarms, you\u2019re not just an employee; you\u2019re a pivotal part of our mission. Experience camaraderie, collaboration, and a shared purpose that binds us together.</li> </ul>"},{"location":"corporate/hiring/#for-the-visionary","title":"For the Visionary:","text":"<ul> <li>Work on the Cutting-Edge: Be at the forefront of AI and technology. Shape solutions that will define the next era of human history.</li> </ul>"},{"location":"corporate/hiring/#benefits-of-joining-swarms","title":"Benefits of Joining Swarms:","text":"<ol> <li>Advance Humanity: Play an instrumental role in democratizing technology for all.</li> <li>Financial Prosperity: Harness a compensation structure that grows with your achievements.</li> <li>Flexible Work Environment: Customize your workspace, schedule, and workstyle.</li> <li>Global Network: Collaborate with some of the brightest minds spanning continents.</li> <li>Personal Development: Regular workshops, courses, and seminars to fuel your growth.</li> <li>Health &amp; Wellness: Comprehensive health benefits and well-being programs.</li> <li>Ownership &amp; Equity: As we grow, so does your stake and impact in our organization.</li> <li>Retreats &amp; Team Building: Forge bonds beyond work in exotic locations globally.</li> <li>Customer Success Impact: Directly experience the joy of solving real-world challenges for our users.</li> </ol>"},{"location":"corporate/hiring/#positions-open","title":"Positions Open:","text":"<ul> <li>Customer Success Professionals: Be the bridge between our revolutionary tech and its real-world impact.</li> <li>AI &amp; Swarm Engineers: Architect, design, and optimize the swarm systems powering global innovations.</li> </ul>"},{"location":"corporate/hiring/#your-invitation-to-the-future","title":"Your Invitation to the Future:","text":"<p>If you resonate with our vision of blending technological marvels with human brilliance, of creating a prosperous world where every dream has the wings of AI \u2013 we invite you to join us on this extraordinary journey.</p> <p>Are you ready to create history with Swarms?</p> <p>Apply Now and Let\u2019s Push Our People Further!</p>"},{"location":"corporate/metric/","title":"The Golden Metric: 95% User-Task-Completion-Satisfaction Rate","text":"<p>In the world of Swarms, there\u2019s one metric that stands above the rest: the User-Task-Completion-Satisfaction (UTCS) rate. This metric is the heart of our system, the pulse that keeps us moving forward. It\u2019s not just a number; it\u2019s a reflection of our commitment to our users and a measure of our success.</p>"},{"location":"corporate/metric/#what-is-the-utcs-rate","title":"What is the UTCS Rate?","text":"<p>The UTCS rate is a measure of how reliably and quickly Swarms can satisfy a user demand. It\u2019s calculated by dividing the number of tasks completed to the user\u2019s satisfaction by the total number of tasks. Multiply that by 100, and you\u2019ve got your UTCS rate.</p> <p>But what does it mean to complete a task to the user\u2019s satisfaction? It means that the task is not only completed, but completed in a way that meets or exceeds the user\u2019s expectations. It\u2019s about quality, speed, and reliability.</p>"},{"location":"corporate/metric/#why-is-the-utcs-rate-important","title":"Why is the UTCS Rate Important?","text":"<p>The UTCS rate is a direct reflection of the user experience. A high UTCS rate means that users are getting what they need from Swarms, and they\u2019re getting it quickly and reliably. It means that Swarms is doing its job, and doing it well.</p> <p>But the UTCS rate is not just about user satisfaction. It\u2019s also a measure of Swarms\u2019 efficiency and effectiveness. A high UTCS rate means that Swarms is able to complete tasks quickly and accurately, with minimal errors or delays. It\u2019s a sign of a well-oiled machine.</p>"},{"location":"corporate/metric/#how-do-we-achieve-a-95-utcs-rate","title":"How Do We Achieve a 95% UTCS Rate?","text":"<p>Achieving a 95% UTCS rate is no small feat. It requires a deep understanding of our users and their needs, a robust and reliable system, and a commitment to continuous improvement.</p>"},{"location":"corporate/metric/#here-are-some-strategies-were-implementing-to-reach-our-goal","title":"Here are some strategies we\u2019re implementing to reach our goal:","text":"<ul> <li> <p>Understanding User Needs: We must have agents that gain an understanding of the user's objective and break it up into it's most fundamental building blocks</p> </li> <li> <p>Improving System Reliability: We\u2019re working to make Swarms more reliable, reducing errors and improving the accuracy of task completion. This includes improving our algorithms, refining our processes, and investing in quality assurance.</p> </li> <li> <p>Optimizing for Speed: We\u2019re optimizing Swarms to complete tasks as quickly as possible, without sacrificing quality. This includes improving our infrastructure, streamlining our workflows, and implementing performance optimizations.</p> </li> </ul> <p>*Iterating and Improving: We\u2019re committed to continuous improvement. We\u2019re constantly monitoring our UTCS rate and other key metrics, and we\u2019re always looking for ways to improve. We\u2019re not afraid to experiment, iterate, and learn from our mistakes.</p> <p>Achieving a 95% UTCS rate is a challenging goal, but it\u2019s a goal worth striving for. It\u2019s a goal that will drive us to improve, innovate, and deliver the best possible experience for our users. And in the end, that\u2019s what Swarms is all about.</p>"},{"location":"corporate/metric/#your-feedback-matters-help-us-optimize-the-utcs-rate","title":"Your Feedback Matters: Help Us Optimize the UTCS Rate","text":"<p>As we initiate the journey of Swarms, we seek your feedback to better guide our growth and development. Your opinions and suggestions are crucial for us, helping to mold our product, pricing, branding, and a host of other facets that influence your experience.</p>"},{"location":"corporate/metric/#your-insights-on-the-utcs-rate","title":"Your Insights on the UTCS Rate","text":"<p>Our goal is to maintain a UTCS (User-Task-Completion-Satisfaction) rate of 95%. This metric is integral to the success of Swarms, indicating the efficiency and effectiveness with which we satisfy user requests. However, it's a metric that we can't optimize alone - we need your help.</p> <p>Here's what we want to understand from you:</p> <ol> <li>Satisfaction: What does a \"satisfactorily completed task\" mean to you? Are there specific elements that contribute to a task being carried out to your satisfaction? </li> <li>Timeliness: How important is speed in the completion of a task? What would you consider a reasonable timeframe for a task to be completed?</li> <li>Usability: How intuitive and user-friendly do you find the Swarms platform? Are there any aspects of the platform that you believe could be enhanced?</li> <li>Reliability: How much does consistency in performance matter to you? Can you share any experiences where Swarms either met or fell short of your expectations?</li> <li>Value for Money: How do you perceive our pricing? Does the value Swarms provides align with the costs?</li> </ol> <p>We invite you to share your experiences, thoughts, and ideas. Whether it's a simple suggestion or an in-depth critique, we appreciate and value your input.</p>"},{"location":"corporate/metric/#your-feedback-the-backbone-of-our-growth","title":"Your Feedback: The Backbone of our Growth","text":"<p>Your feedback is the backbone of Swarms' evolution. It drives us to refine our strategies, fuels our innovative spirit, and, most importantly, enables us to serve you better.</p> <p>As we launch, we open the conversation around these key aspects of Swarms, and we look forward to understanding your expectations, your needs, and how we can deliver the best experience for you.</p> <p>So, let's start this conversation - how can we make Swarms work best for you?</p> <p>Guide Our Growth: Help Optimize Swarms As we launch Swarms, your feedback is critical for enhancing our product, pricing, and branding. A key aim for us is a User-Task-Completion-Satisfaction (UTCS) rate of 95% - indicating our efficiency and effectiveness in meeting user needs. However, we need your insights to optimize this.</p> <p>Here's what we're keen to understand:</p> <p>Satisfaction: Your interpretation of a \"satisfactorily completed task\". Timeliness: The importance of speed in task completion for you. Usability: Your experiences with our platform\u2019s intuitiveness and user-friendliness. Reliability: The significance of consistent performance to you. Value for Money: Your thoughts on our pricing and value proposition. We welcome your thoughts, experiences, and suggestions. Your feedback fuels our evolution, driving us to refine strategies, boost innovation, and enhance your experience.</p> <p>Let's start the conversation - how can we make Swarms work best for you?</p> <p>The Golden Metric Analysis: The Ultimate UTCS Paradigm for Swarms</p>"},{"location":"corporate/metric/#introduction","title":"Introduction","text":"<p>In our ongoing journey to perfect Swarms, understanding how our product fares in the eyes of the end-users is paramount. Enter the User-Task-Completion-Satisfaction (UTCS) rate - our primary metric that gauges how reliably and swiftly Swarms can meet user demands. As we steer Swarms towards achieving a UTCS rate of 95%, understanding this metric's core and how to refine it becomes vital.</p>"},{"location":"corporate/metric/#decoding-utcs-an-analytical-overview","title":"Decoding UTCS: An Analytical Overview","text":"<p>The UTCS rate is not merely about task completion; it's about the comprehensive experience. Therefore, its foundations lie in:</p> <ol> <li>Quality: Ensuring tasks are executed flawlessly.</li> <li>Speed: Delivering results in the shortest possible time.</li> <li>Reliability: Consistency in quality and speed across all tasks.</li> </ol> <p>We can represent the UTCS rate with the following equation:</p> <pre><code>\\[ UTCS Rate = \\frac{(Completed Tasks \\times User Satisfaction)}{(Total Tasks)} \\times 100 \\]\n</code></pre> <p>Where: - Completed Tasks refer to the number of tasks Swarms executes without errors. - User Satisfaction is the subjective component, gauged through feedback mechanisms. This could be on a scale of 1-10 (or a percentage). - Total Tasks refer to all tasks processed by Swarms, regardless of the outcome.</p>"},{"location":"corporate/metric/#the-golden-metric-swarm-efficiency-index-sei","title":"The Golden Metric: Swarm Efficiency Index (SEI)","text":"<p>However, this basic representation doesn't factor in a critical component: system performance. Thus, we introduce the Swarm Efficiency Index (SEI). The SEI encapsulates not just the UTCS rate but also system metrics like memory consumption, number of tasks, and time taken. By blending these elements, we aim to present a comprehensive view of Swarm's prowess.</p> <p>Here\u2019s the formula:</p> <pre><code>\\[ SEI = \\frac{UTCS Rate}{(Memory Consumption + Time Window + Task Complexity)} \\]\n</code></pre> <p>Where: - Memory Consumption signifies the system resources used to accomplish tasks. - Time Window is the timeframe in which the tasks were executed. - Task Complexity could be a normalized scale that defines how intricate a task is (e.g., 1-5, with 5 being the most complex).</p> <p>Rationale: - Incorporating Memory Consumption: A system that uses less memory but delivers results is more efficient. By inverting memory consumption in the formula, we emphasize that as memory usage goes down, SEI goes up.</p> <ul> <li> <p>Considering Time: Time is of the essence. The faster the results without compromising quality, the better. By adding the Time Window, we emphasize that reduced task execution time increases the SEI.</p> </li> <li> <p>Factoring in Task Complexity: Not all tasks are equal. A system that effortlessly completes intricate tasks is more valuable. By integrating task complexity, we can normalize the SEI according to the task's nature.</p> </li> </ul>"},{"location":"corporate/metric/#implementing-sei-improving-utcs","title":"Implementing SEI &amp; Improving UTCS","text":"<p>Using feedback from elder-plinius, we can better understand and improve SEI and UTCS:</p> <ol> <li> <p>Feedback Across Skill Levels: By gathering feedback from users with different skill levels, we can refine our metrics, ensuring Swarms caters to all.</p> </li> <li> <p>Simplifying Setup: Detailed guides can help newcomers swiftly get on board, thus enhancing user satisfaction.</p> </li> <li> <p>Enhancing Workspace and Agent Management: A clearer view of the Swarm's internal structure, combined with on-the-go adjustments, can improve both the speed and quality of results.</p> </li> <li> <p>Introducing System Suggestions: A proactive Swarms that provides real-time insights and recommendations can drastically enhance user satisfaction, thus pushing up the UTCS rate.</p> </li> </ol>"},{"location":"corporate/metric/#conclusion","title":"Conclusion","text":"<p>The UTCS rate is undeniably a pivotal metric for Swarms. However, with the introduction of the Swarm Efficiency Index (SEI), we have an opportunity to encapsulate a broader spectrum of performance indicators, leading to a more holistic understanding of Swarms' efficiency. By consistently optimizing for SEI, we can ensure that Swarms not only meets user expectations but also operates at peak system efficiency.</p> <p>Research Analysis: Tracking and Ensuring Reliability of Swarm Metrics at Scale</p>"},{"location":"corporate/metric/#1-introduction","title":"1. Introduction","text":"<p>In our pursuit to optimize the User-Task-Completion-Satisfaction (UTCS) rate and Swarm Efficiency Index (SEI), reliable tracking of these metrics at scale becomes paramount. This research analysis delves into methodologies, technologies, and practices that can be employed to monitor these metrics accurately and efficiently across vast data sets.</p>"},{"location":"corporate/metric/#2-why-tracking-at-scale-is-challenging","title":"2. Why Tracking at Scale is Challenging","text":"<p>The primary challenges include:</p> <ul> <li>Volume of Data: As Swarms grows, the data generated multiplies exponentially.</li> <li>Variability of Data: Diverse user inputs lead to myriad output scenarios.</li> <li>System Heterogeneity: Different configurations and deployments can yield variable results.</li> </ul>"},{"location":"corporate/metric/#3-strategies-for-scalable-tracking","title":"3. Strategies for Scalable Tracking","text":""},{"location":"corporate/metric/#31-distributed-monitoring-systems","title":"3.1. Distributed Monitoring Systems","text":"<p>Recommendation: Implement distributed systems like Prometheus or InfluxDB.</p> <p>Rationale:  - Ability to collect metrics from various Swarm instances concurrently. - Scalable and can handle vast data influxes.</p>"},{"location":"corporate/metric/#32-real-time-data-processing","title":"3.2. Real-time Data Processing","text":"<p>Recommendation: Use stream processing systems like Apache Kafka or Apache Flink.</p> <p>Rationale:  - Enables real-time metric calculation. - Can handle high throughput and low-latency requirements.</p>"},{"location":"corporate/metric/#33-data-sampling","title":"3.3. Data Sampling","text":"<p>Recommendation: Random or stratified sampling of user sessions.</p> <p>Rationale:  - Reduces the data volume to be processed. - Maintains representativeness of overall user experience.</p>"},{"location":"corporate/metric/#4-ensuring-reliability-in-data-collection","title":"4. Ensuring Reliability in Data Collection","text":""},{"location":"corporate/metric/#41-redundancy","title":"4.1. Redundancy","text":"<p>Recommendation: Integrate redundancy into data collection nodes.</p> <p>Rationale: - Ensures no single point of failure. - Data loss prevention in case of system malfunctions.</p>"},{"location":"corporate/metric/#42-anomaly-detection","title":"4.2. Anomaly Detection","text":"<p>Recommendation: Implement AI-driven anomaly detection systems.</p> <p>Rationale:  - Identifies outliers or aberrations in metric calculations. - Ensures consistent and reliable data interpretation.</p>"},{"location":"corporate/metric/#43-data-validation","title":"4.3. Data Validation","text":"<p>Recommendation: Establish automated validation checks.</p> <p>Rationale: - Ensures only accurate and relevant data is considered. - Eliminates inconsistencies arising from corrupted or irrelevant data.</p>"},{"location":"corporate/metric/#5-feedback-loops-and-continuous-refinement","title":"5. Feedback Loops and Continuous Refinement","text":""},{"location":"corporate/metric/#51-user-feedback-integration","title":"5.1. User Feedback Integration","text":"<p>Recommendation: Develop an in-built user feedback mechanism.</p> <p>Rationale:  - Helps validate the perceived vs. actual performance. - Allows for continuous refining of tracking metrics and methodologies.</p>"},{"location":"corporate/metric/#52-ab-testing","title":"5.2. A/B Testing","text":"<p>Recommendation: Regularly conduct A/B tests for new tracking methods or adjustments.</p> <p>Rationale:  - Determines the most effective methods for data collection. - Validates new tracking techniques against established ones.</p>"},{"location":"corporate/metric/#6-conclusion","title":"6. Conclusion","text":"<p>To successfully and reliably track the UTCS rate and SEI at scale, it's essential to combine robust monitoring tools, data processing methodologies, and validation techniques. By doing so, Swarms can ensure that the metrics collected offer a genuine reflection of system performance and user satisfaction. Regular feedback and iterative refinement, rooted in a culture of continuous improvement, will further enhance the accuracy and reliability of these essential metrics.</p>"},{"location":"corporate/purpose/","title":"Purpose","text":""},{"location":"corporate/purpose/#purpose","title":"Purpose","text":"<p>Artificial Intelligence has grown at an exponential rate over the past decade. Yet, we are far from fully harnessing its potential. Today's AI operates in isolation, each working separately in their corner. But life doesn't work like that. The world doesn't work like that. Success isn't built in silos; it's built in teams.</p> <p>Imagine a world where AI models work in unison. Where they can collaborate, interact, and pool their collective intelligence to achieve more than any single model could. This is the future we envision. But today, we lack a framework for AI to collaborate effectively, to form a true swarm of intelligent agents.</p> <p>This is a difficult problem, one that has eluded solution. It requires sophisticated systems that can allow individual models to not just communicate but also understand each other, pool knowledge and resources, and create collective intelligence. This is the next frontier of AI.</p> <p>But here at Swarms, we have a secret sauce. It's not just a technology or a breakthrough invention. It's a way of thinking - the philosophy of rapid iteration. With each cycle, we make massive progress. We experiment, we learn, and we grow. We have developed a pioneering framework that can enable AI models to work together as a swarm, combining their strengths to create richer, more powerful outputs.</p> <p>We are uniquely positioned to take on this challenge with 1,500+ devoted researchers in Agora. We have assembled a team of world-class experts, experienced and driven, united by a shared vision. Our commitment to breaking barriers, pushing boundaries, and our belief in the power of collective intelligence makes us the best team to usher in this future to fundamentally advance our species, Humanity.</p>"},{"location":"corporate/research/","title":"Research Lists","text":"<p>A compilation of projects, papers, blogs in autonomous agents.</p>"},{"location":"corporate/research/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Introduction</li> <li>Projects</li> <li>Articles</li> <li>Talks</li> </ul>"},{"location":"corporate/research/#projects","title":"Projects","text":""},{"location":"corporate/research/#developer-tools","title":"Developer tools","text":"<ul> <li>[2023/8/10]  ModelScope-Agent - An Agent Framework Connecting Models in ModelScope with the World</li> <li>[2023/05/25] Gorilla - An API store for LLMs</li> <li>[2023/03/31] BMTools - Tool Learning for Big Models, Open-Source Solutions of ChatGPT-Plugins</li> <li>[2023/03/09] LMQL - A query language for programming (large) language models.</li> <li>[2022/10/25] Langchain - \u26a1 Building applications with LLMs through composability \u26a1</li> </ul>"},{"location":"corporate/research/#applications","title":"Applications","text":"<ul> <li>[2023/07/08] ShortGPT - \ud83d\ude80\ud83c\udfac ShortGPT - An experimental AI framework for automated short/video content creation. Enables creators to rapidly produce, manage, and deliver content using AI and automation.</li> <li>[2023/07/05] gpt-researcher - GPT based autonomous agent that does online comprehensive research on any given topic</li> <li>[2023/07/04] DemoGPT - \ud83e\udde9DemoGPT enables you to create quick demos by just using prompts. [demo]</li> <li>[2023/06/30] MetaGPT - \ud83c\udf1f The Multi-Agent Framework: Given one line Requirement, return PRD, Design, Tasks, Repo</li> <li>[2023/06/11] gpt-engineer - Specify what you want it to build, the AI asks for clarification, and then builds it.</li> <li>[2023/05/16] SuperAGI - &lt;\u26a1\ufe0f&gt; SuperAGI - A dev-first open source autonomous AI agent framework. Enabling developers to build, manage &amp; run useful autonomous agents quickly and reliably.</li> <li>[2023/05/13] Developer - Human-centric &amp; Coherent Whole Program Synthesis aka your own personal junior developer</li> <li>[2023/04/07] AgentGPT - \ud83e\udd16 Assemble, configure, and deploy autonomous AI Agents in your browser. [demo]</li> <li>[2023/04/03] BabyAGI - an example of an AI-powered task management system</li> <li>[2023/03/30] AutoGPT - An experimental open-source attempt to make GPT-4 fully autonomous.</li> </ul>"},{"location":"corporate/research/#benchmarks","title":"Benchmarks","text":"<ul> <li>[2023/08/07] AgentBench - A Comprehensive Benchmark to Evaluate LLMs as Agents. paper</li> <li>[2023/06/18] Auto-GPT-Benchmarks - A repo built for the purpose of benchmarking the performance of agents, regardless of how they are set up and how they work.</li> <li>[2023/05/28] ToolBench - An open platform for training, serving, and evaluating large language model for tool learning.</li> </ul>"},{"location":"corporate/research/#articles","title":"Articles","text":""},{"location":"corporate/research/#research-papers","title":"Research Papers","text":"<ul> <li>[2023/08/11] BOLAA: Benchmarking and Orchestrating LLM-Augmented Autonomous Agents, Zhiwei Liu, et al.</li> <li>[2023/07/31] ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs, Yujia Qin, et al.</li> <li>[2023/07/16] Communicative Agents for Software Development, Chen Qian, et al.</li> <li>[2023/06/09] Mind2Web: Towards a Generalist Agent for the Web, Xiang Deng, et al. [code] [demo]</li> <li>[2023/06/05] Orca: Progressive Learning from Complex Explanation Traces of GPT-4, Subhabrata Mukherjee et al.</li> <li>[2023/05/25] Voyager: An Open-Ended Embodied Agent with Large Language Models, Guanzhi Wang, et al. [code] [website]</li> <li>[2023/05/23] ReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models, Binfeng Xu, et al. [code]</li> <li>[2023/05/17] Tree of Thoughts: Deliberate Problem Solving with Large Language Models, Shunyu Yao, et al.[code] [code-orig] </li> <li>[2023/05/12] MEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers, Lili Yu, et al.</li> <li>[2023/05/19] FrugalGPT: How to Use Large Language Models While Reducing Cost and Improving Performance, Lingjiao Chen, et al.</li> <li>[2023/05/06] Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models, Lei Wang, et al.</li> <li>[2023/05/01] Learning to Reason and Memorize with Self-Notes, Jack Lanchantin, et al.</li> <li>[2023/04/24] WizardLM: Empowering Large Language Models to Follow Complex Instructions, Can Xu, et al.</li> <li>[2023/04/22] LLM+P: Empowering Large Language Models with Optimal Planning Proficiency, Bo Liu, et al.</li> <li>[2023/04/07] Generative Agents: Interactive Simulacra of Human Behavior, Joon Sung Park, et al. [code]</li> <li>[2023/03/30] Self-Refine: Iterative Refinement with Self-Feedback, Aman Madaan, et al.[code]</li> <li>[2023/03/30] HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace, Yongliang Shen, et al. [code] [demo]</li> <li>[2023/03/20] Reflexion: Language Agents with Verbal Reinforcement Learning, Noah Shinn, et al. [code]</li> <li>[2023/03/04] Towards A Unified Agent with Foundation Models, Norman Di Palo et al.</li> <li>[2023/02/23] Not what you've signed up for: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection, Sahar Abdelnab, et al.</li> <li>[2023/02/09] Toolformer: Language Models Can Teach Themselves to Use Tools, Timo Schick, et al. [code]</li> <li>[2022/12/12] LMQL: Prompting Is Programming: A Query Language for Large Language Models, Luca Beurer-Kellner, et al.</li> <li>[2022/10/06] ReAct: Synergizing Reasoning and Acting in Language Models, Shunyu Yao, et al. [code]</li> <li>[2022/07/20] Inner Monologue: Embodied Reasoning through Planning with Language Models, Wenlong Huang, et al. [demo]</li> <li>[2022/04/04] Do As I Can, Not As I Say: Grounding Language in Robotic Affordances, Michael Ahn, e al. [demo]</li> <li>[2021/12/17] WebGPT: Browser-assisted question-answering with human feedback, Reiichiro Nakano, et al.</li> <li>[2021/06/17] LoRA: Low-Rank Adaptation of Large Language Models, Edward J. Hu, et al.</li> </ul>"},{"location":"corporate/research/#blog-articles","title":"Blog Articles","text":"<ul> <li>[2023/08/14] A Roadmap of AI Agents(Chinese) By Haojie Pan</li> <li>[2023/06/23] LLM Powered Autonomous Agents By Lilian Weng</li> <li>[2023/06/11] A CRITICAL LOOK AT AI-GENERATED SOFTWARE By JAIDEEP VAIDYAHAFIZ ASIF</li> <li>[2023/04/29] AUTO-GPT: UNLEASHING THE POWER OF AUTONOMOUS AI AGENTS By Akash Takyar</li> <li>[2023/04/20] Conscious Machines: Experiments, Theory, and Implementations(Chinese) By Jiang Zhang</li> <li>[2023/04/18] Autonomous Agents &amp; Agent Simulations By Langchain</li> <li>[2023/04/16] 4 Autonomous AI Agents you need to know By Sophia Yang</li> <li>[2023/03/31] ChatGPT that learns to use tools(Chinese) By Haojie Pan</li> </ul>"},{"location":"corporate/research/#talks","title":"Talks","text":"<ul> <li>[2023/06/05] Two Paths to Intelligence by Geoffrey Hinton</li> <li>[2023/05/24] State of GPT by Andrej Karpathy | OpenAI </li> </ul>"},{"location":"corporate/roadmap/","title":"Roadmap","text":""},{"location":"corporate/roadmap/#the-plan","title":"The Plan","text":""},{"location":"corporate/roadmap/#phase-1-building-the-foundation","title":"Phase 1: Building the Foundation","text":"<p>In the first phase, our focus is on building the basic infrastructure of Swarms. This includes developing key components like the Swarms class, integrating essential tools, and establishing task completion and evaluation logic. We'll also start developing our testing and evaluation framework during this phase. If you're interested in foundational work and have a knack for building robust, scalable systems, this phase is for you.</p>"},{"location":"corporate/roadmap/#phase-2-optimizing-the-system","title":"Phase 2: Optimizing the System","text":"<p>In the second phase, we'll focus on optimizng Swarms by integrating more advanced features, improving the system's efficiency, and refining our testing and evaluation framework. This phase involves more complex tasks, so if you enjoy tackling challenging problems and contributing to the development of innovative features, this is the phase for you.</p>"},{"location":"corporate/roadmap/#phase-3-towards-super-intelligence","title":"Phase 3: Towards Super-Intelligence","text":"<p>The third phase of our bounty program is the most exciting - this is where we aim to achieve super-intelligence. In this phase, we'll be working on improving the swarm's capabilities, expanding its skills, and fine-tuning the system based on real-world testing and feedback. If you're excited about the future of AI and want to contribute to a project that could potentially transform the digital world, this is the phase for you.</p> <p>Remember, our roadmap is a guide, and we encourage you to bring your own ideas and creativity to the table. We believe that every contribution, no matter how small, can make a difference. So join us on this exciting journey and help us create the future of Swarms.</p>"},{"location":"corporate/swarm_cloud/","title":"The Swarm Cloud","text":""},{"location":"corporate/swarm_cloud/#business-model-plan-for-autonomous-agent-swarm-service","title":"Business Model Plan for Autonomous Agent Swarm Service","text":""},{"location":"corporate/swarm_cloud/#service-description","title":"Service Description","text":"<ul> <li>Overview: A platform allowing users to deploy swarms of autonomous agents in production-grade environments.</li> <li>Target Users: Industries requiring automation, monitoring, data collection, and more, such as manufacturing, logistics, agriculture, and surveillance.</li> </ul>"},{"location":"corporate/swarm_cloud/#operational-strategy","title":"Operational Strategy","text":"<ul> <li>Infrastructure: Robust cloud infrastructure to support agent deployment and data processing.</li> <li>Support and Maintenance: Continuous support for software updates, troubleshooting, and user assistance.</li> <li>Technology Development: Ongoing R&amp;D for enhancing agent capabilities and efficiency.</li> </ul>"},{"location":"corporate/swarm_cloud/#financial-projections","title":"Financial Projections","text":"<ul> <li>Revenue Streams: Mainly from per agent usage fees and hosting services.</li> <li>Cost Structure: Includes development, maintenance, infrastructure, marketing, and administrative costs.</li> <li>Break-even Analysis: Estimation based on projected user adoption rates and cost per agent.</li> </ul>"},{"location":"corporate/swarm_cloud/#revnue-streams","title":"Revnue Streams","text":"<pre><code>| Pricing Structure         | Description | Details |\n| ------------------------- | ----------- | ------- |\n| Usage-Based Per Agent     | Fees are charged based on the number of agents deployed and their usage duration. | - Ideal for clients needing a few agents for specific tasks. &lt;br&gt; - More agents or longer usage results in higher fees. |\n| Swarm Coverage Pricing    | Pricing based on the coverage area or scope of the swarm deployment. | - Suitable for tasks requiring large area coverage. &lt;br&gt; - Price scales with the size or complexity of the area covered. |\n| Performance-Based Pricing | Fees are tied to the performance or outcomes achieved by the agents. | - Clients pay for the effectiveness or results achieved by the agents. &lt;br&gt; - Higher fees for more complex or high-value tasks. |\n</code></pre> <ol> <li> <p>Pay-Per-Mission Pricing: Clients are charged for each specific task or mission completed by the agents.</p> </li> <li> <p>Per Agent Usage Fee: Charged based on the number of agents and the duration of their deployment.</p> </li> <li>Hosting Fees: Based on the data usage and processing requirements of the agents.</li> <li> <p>Volume Discounts: Available for large-scale deployments.</p> </li> <li> <p>Time-Based Subscription: A subscription model where clients pay a recurring fee for continuous access to a set number of agents.</p> </li> <li> <p>Dynamic Pricing: Prices fluctuate based on demand, time of day, or specific conditions.</p> </li> <li> <p>Tiered Usage Levels: Different pricing tiers based on the number of agents used or the complexity of tasks.</p> </li> <li> <p>Freemium Model: Basic services are free, but premium features or additional agents are paid.</p> </li> <li> <p>Outcome-Based Pricing: Charges are based on the success or quality of the outcomes achieved by the agents.</p> </li> <li> <p>Feature-Based Pricing: Different prices for different feature sets or capabilities of the agents.</p> </li> <li> <p>Volume Discounts: Reduced per-agent price for bulk deployments or long-term contracts.</p> </li> <li> <p>Peak Time Premiums: Higher charges during peak usage times or for emergency deployment.</p> </li> <li> <p>Bundled Services: Combining agent services with other products or services for a comprehensive package deal.</p> </li> <li> <p>Custom Solution Pricing: Tailor-made pricing for unique or specialized requirements.</p> </li> <li> <p>Data Analysis Fee: Charging for the data processing and analytics provided by the agents.</p> </li> <li> <p>Performance Tiers: Different pricing for varying levels of agent efficiency or performance.</p> </li> <li> <p>License Model: Clients purchase a license to deploy and use a certain number of agents.</p> </li> <li> <p>Cost-Plus Pricing: Pricing based on the cost of deployment plus a markup.</p> </li> <li> <p>Service Level Agreement (SLA) Pricing: Higher prices for higher levels of service guarantees.</p> </li> <li> <p>Pay-Per-Save Model: Charging based on the cost savings or value created by the agents for the client.</p> </li> <li> <p>Revenue Sharing: Sharing a percentage of the revenue generated through the use of agents.</p> </li> <li> <p>Geographic Pricing: Different pricing for different regions or markets.</p> </li> <li> <p>User-Based Pricing: Charging based on the number of users accessing and controlling the agents.</p> </li> <li> <p>Energy Usage Pricing: Prices based on the amount of energy consumed by the agents during operation.</p> </li> <li> <p>Event-Driven Pricing: Charging for specific events or triggers during the agent's operation.</p> </li> <li> <p>Seasonal Pricing: Adjusting prices based on seasonal demand or usage patterns.</p> </li> <li> <p>Partnership Models: Collaborating with other businesses and sharing revenue from combined services.</p> </li> <li> <p>Customizable Packages: Allowing clients to build their own package of services and capabilities, priced accordingly.</p> </li> </ol> <p>These diverse pricing strategies can be combined or tailored to fit different business models, client needs, and market dynamics. They also provide various methods of value extraction, ensuring flexibility and scalability in revenue generation.</p>"},{"location":"corporate/swarm_cloud/#icp-analysis","title":"ICP Analysis","text":""},{"location":"corporate/swarm_cloud/#ideal-customer-profile-icp-map","title":"Ideal Customer Profile (ICP) Map","text":""},{"location":"corporate/swarm_cloud/#1-manufacturing-and-industrial-automation","title":"1. Manufacturing and Industrial Automation","text":"<ul> <li>Characteristics: Large-scale manufacturers, high automation needs, emphasis on efficiency and precision.</li> <li>Needs: Process automation, quality control, predictive maintenance.</li> </ul>"},{"location":"corporate/swarm_cloud/#2-agriculture-and-farming","title":"2. Agriculture and Farming","text":"<ul> <li>Characteristics: Large agricultural enterprises, focus on modern farming techniques.</li> <li>Needs: Crop monitoring, automated harvesting, pest control.</li> </ul>"},{"location":"corporate/swarm_cloud/#3-logistics-and-supply-chain","title":"3. Logistics and Supply Chain","text":"<ul> <li>Characteristics: Companies with extensive logistics operations, warehousing, and supply chain management.</li> <li>Needs: Inventory tracking, automated warehousing, delivery optimization.</li> </ul>"},{"location":"corporate/swarm_cloud/#4-energy-and-utilities","title":"4. Energy and Utilities","text":"<ul> <li>Characteristics: Energy providers, utility companies, renewable energy farms.</li> <li>Needs: Infrastructure monitoring, predictive maintenance, efficiency optimization.</li> </ul>"},{"location":"corporate/swarm_cloud/#5-environmental-monitoring-and-conservation","title":"5. Environmental Monitoring and Conservation","text":"<ul> <li>Characteristics: Organizations focused on environmental protection, research institutions.</li> <li>Needs: Wildlife tracking, pollution monitoring, ecological research.</li> </ul>"},{"location":"corporate/swarm_cloud/#6-smart-cities-and-urban-planning","title":"6. Smart Cities and Urban Planning","text":"<ul> <li>Characteristics: Municipal governments, urban development agencies.</li> <li>Needs: Traffic management, infrastructure monitoring, public safety.</li> </ul>"},{"location":"corporate/swarm_cloud/#7-defense-and-security","title":"7. Defense and Security","text":"<ul> <li>Characteristics: Defense contractors, security firms, government agencies.</li> <li>Needs: Surveillance, reconnaissance, threat assessment.</li> </ul>"},{"location":"corporate/swarm_cloud/#8-healthcare-and-medical-facilities","title":"8. Healthcare and Medical Facilities","text":"<ul> <li>Characteristics: Large hospitals, medical research centers.</li> <li>Needs: Facility management, patient monitoring, medical logistics.</li> </ul>"},{"location":"corporate/swarm_cloud/#9-entertainment-and-event-management","title":"9. Entertainment and Event Management","text":"<ul> <li>Characteristics: Large-scale event organizers, theme parks.</li> <li>Needs: Crowd management, entertainment automation, safety monitoring.</li> </ul>"},{"location":"corporate/swarm_cloud/#10-construction-and-infrastructure","title":"10. Construction and Infrastructure","text":"<pre><code>- **Characteristics:** Major construction firms, infrastructure developers.\n- **Needs:** Site monitoring, material tracking, safety compliance.\n</code></pre>"},{"location":"corporate/swarm_cloud/#potential-market-size-table-in-markdown","title":"Potential Market Size Table (in Markdown)","text":"<pre><code>| Customer Segment             | Estimated Market Size (USD) | Notes |\n| ---------------------------- | --------------------------- | ----- |\n| Manufacturing and Industrial | $100 Billion                | High automation and efficiency needs drive demand. |\n| Agriculture and Farming      | $75 Billion                 | Growing adoption of smart farming technologies. |\n| Logistics and Supply Chain   | $90 Billion                 | Increasing need for automation in warehousing and delivery. |\n| Energy and Utilities         | $60 Billion                 | Focus on infrastructure monitoring and maintenance. |\n| Environmental Monitoring     | $30 Billion                 | Rising interest in climate and ecological data collection. |\n| Smart Cities and Urban Planning | $50 Billion              | Growing investment in smart city technologies. |\n| Defense and Security         | $120 Billion                | High demand for surveillance and reconnaissance tech. |\n| Healthcare and Medical       | $85 Billion                 | Need for efficient hospital management and patient care. |\n| Entertainment and Event Management | $40 Billion          | Innovative uses in crowd control and event safety. |\n| Construction and Infrastructure | $70 Billion              | Use in monitoring and managing large construction projects. |\n</code></pre>"},{"location":"corporate/swarm_cloud/#risk-analysis","title":"Risk Analysis","text":"<ul> <li>Market Risks: Adaptation rate and competition.</li> <li>Operational Risks: Reliability and scalability of infrastructure.</li> <li>Regulatory Risks: Compliance with data security and privacy laws.</li> </ul>"},{"location":"corporate/swarm_cloud/#business-model","title":"Business Model","text":""},{"location":"corporate/swarm_cloud/#the-swarm-cloud-business-model","title":"The Swarm Cloud: Business Model","text":""},{"location":"corporate/swarm_cloud/#unlocking-the-potential-of-autonomous-agent-technology","title":"Unlocking the Potential of Autonomous Agent Technology","text":"<p>1. Our Vision:    - Revolutionize industries through scalable, intelligent swarms of autonomous agents.    - Enable real-time data collection, analysis, and automated task execution.</p> <p>2. Service Offering:    - The Swarm Cloud Platform: Deploy and manage swarms of autonomous agents in production-grade environments.    - Applications: Versatile across industries \u2013 from smart agriculture to urban planning, logistics, and beyond.</p> <p>3. Key Features:    - High Scalability: Tailored solutions from small-scale deployments to large industrial operations.    - Real-Time Analytics: Instant data processing and actionable insights.    - User-Friendly Interface: Simplified control and monitoring of agent swarms.    - Robust Security: Ensuring data integrity and operational safety.</p> <p>4. Revenue Streams:    - Usage-Based Pricing: Charges based on the number of agents and operation duration.    - Subscription Models: Recurring revenue through scalable packages.    - Custom Solutions: Tailored pricing for bespoke deployments.</p> <p>5. Market Opportunity:    - Expansive Market: Addressing needs in a \\$500 billion global market spanning multiple sectors.    - Competitive Edge: Advanced technology offering superior efficiency and adaptability.</p> <p>6. Growth Strategy:    - R&amp;D Investment: Continuous enhancement of agent capabilities and platform features.    - Strategic Partnerships: Collaborations with industry leaders for market penetration.    - Marketing and Sales: Focused approach on high-potential sectors with tailored marketing strategies.</p> <p>7. Why Invest in The Swarm Cloud?    - Pioneering Technology: At the forefront of autonomous agent systems.    - Scalable Business Model: Designed for rapid expansion and adaptation to diverse market needs.    - Strong Market Demand: Positioned to capitalize on the growing trend of automation and AI.</p> <p>\"Empowering industries with intelligent, autonomous solutions \u2013 The Swarm Cloud is set to redefine efficiency and innovation.\"</p>"},{"location":"corporate/swarm_cloud/#conclusion","title":"Conclusion","text":"<p>The business model aims to provide a scalable, efficient, and cost-effective solution for industries looking to leverage the power of autonomous agent technology. With a structured pricing plan and a focus on continuous development and support, the service is positioned to meet diverse industry needs.</p>"},{"location":"corporate/swarm_memo/","title":"[Go To Market Strategy][GTM]","text":"<p>Our vision is to become the world leader in real-world production grade autonomous agent deployment through open-source product development, Deep Verticalization, and unmatched value delivery to the end user.</p> <p>We will focus on first accelerating the open source framework to PMF where it will serve as the backend for upstream products and services such as the Swarm Cloud which will enable enterprises to deploy autonomous agents with long term memory and tools in the cloud and a no-code platform for users to build their own swarm by dragging and dropping blocks.</p> <p>Our target user segment for the framework is AI engineers looking to deploy agents into high risk environments where reliability is crucial. </p> <p>Once PMF has been achieved and the framework has been extensively benchmarked we aim to establish high value contracts with customers in Security, Logistics, Manufacturing, Health and various other untapped industries.</p> <p>Our growth strategy for the OS framework can be summarized by:</p> <ul> <li>Educating developers on value of autonomous agent usage.</li> <li>Tutorial Walkthrough on various applications like deploying multi-modal agents through cameras or building custom swarms for a specific business operation.</li> <li>Demonstrate unmatched reliability by delighting users.</li> <li>Staying up to date with trends and integrating the latest models, frameworks, and methodologies.</li> <li>Building a loyal and devoted community for long term user retention. Join here</li> </ul> <p>As we continuously deliver value with the open framework we will strategically position ourselves to acquire leads for high value contracts by demonstrating the power, reliability, and performance of our framework openly.</p> <p>Acquire Full Access to the memo here: TSC Memo</p>"},{"location":"examples/","title":"Overview","text":"<p>This section of the documentation is dedicated to examples highlighting Swarms functionality.</p> <p>We try to keep all examples up to date, but if you think there is a bug please submit a pull request. We are also more than happy to include new examples :)</p>"},{"location":"examples/bingchat/","title":"Bingchat","text":""},{"location":"examples/bingchat/#bingchat-user-guide","title":"BingChat User Guide","text":"<p>Welcome to the BingChat user guide! This document provides a step-by-step tutorial on how to leverage the BingChat class, an interface to the EdgeGPT model by OpenAI.</p>"},{"location":"examples/bingchat/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Installation &amp; Prerequisites</li> <li>Setting Up BingChat</li> <li>Interacting with BingChat</li> <li>Generating Images</li> <li>Managing Cookies</li> </ol>"},{"location":"examples/bingchat/#installation-prerequisites","title":"Installation &amp; Prerequisites","text":"<p>Before initializing the BingChat model, ensure you have the necessary dependencies installed:</p> <pre><code>pip install EdgeGPT\n</code></pre> <p>Additionally, you must have a <code>cookies.json</code> file which is necessary for authenticating with EdgeGPT.</p>"},{"location":"examples/bingchat/#setting-up-bingchat","title":"Setting Up BingChat","text":"<p>To start, import the BingChat class:</p> <pre><code>from bing_chat import BingChat\n</code></pre> <p>Initialize BingChat with the path to your <code>cookies.json</code>:</p> <pre><code>chat = BingChat(cookies_path=\"./path/to/cookies.json\")\n</code></pre>"},{"location":"examples/bingchat/#interacting-with-bingchat","title":"Interacting with BingChat","text":"<p>You can obtain text responses from the EdgeGPT model by simply calling the instantiated object:</p> <pre><code>response = chat(\"Hello, my name is ChatGPT\")\nprint(response)\n</code></pre> <p>You can also specify the conversation style:</p> <pre><code>from bing_chat import ConversationStyle\n\nresponse = chat(\"Tell me a joke\", style=ConversationStyle.creative)\nprint(response)\n</code></pre>"},{"location":"examples/bingchat/#generating-images","title":"Generating Images","text":"<p>BingChat allows you to generate images based on text prompts:</p> <pre><code>image_path = chat.create_img(\"Sunset over mountains\", auth_cookie=\"YOUR_AUTH_COOKIE\")\nprint(f\"Image saved at: {image_path}\")\n</code></pre> <p>Ensure you provide the required <code>auth_cookie</code> for image generation.</p>"},{"location":"examples/bingchat/#managing-cookies","title":"Managing Cookies","text":"<p>You can set a directory path for managing cookies using the <code>set_cookie_dir_path</code> method:</p> <p>BingChat.set_cookie_dir_path(\"./path/to/cookies_directory\")</p>"},{"location":"examples/flow/","title":"Reliable Enterprise-Grade Autonomous Agents in Less Than 5 lines of Code","text":"<p>========================================================================</p> <p>Welcome to the walkthrough guide for beginners on using the \"Agent\" feature within the Swarms framework. This guide is designed to help you understand and utilize the capabilities of the Agent class for seamless and reliable interactions with autonomous agents.</p>"},{"location":"examples/flow/#official-swarms-links","title":"Official Swarms Links","text":"<p>=====================</p> <p>Swarms\u00a0website:</p> <p>Swarms\u00a0Github:</p> <p>Swarms docs:</p> <p>Swarm Community!!</p> <p>Book a call with The Swarm Corporation here if you're interested in high performance custom swarms!</p> <p>Now let's begin...</p>"},{"location":"examples/flow/#table-of-contents","title":"Table of Contents","text":"<p>===========================================================================================================</p> <ol> <li> <p>Introduction to Swarms Agent Module</p> </li> <li> <p>1.1 What is Swarms?</p> </li> <li> <p>1.2 Understanding the Agent Module</p> </li> <li> <p>Setting Up Your Development Environment</p> </li> <li> <p>2.1 Installing Required Dependencies</p> </li> <li>2.2 API Key Setup</li> <li> <p>2.3 Creating Your First Agent</p> </li> <li> <p>Creating Your First Agent</p> </li> <li> <p>3.1 Importing Necessary Libraries</p> </li> <li>3.2 Defining Constants</li> <li>3.3 Initializing the Agent Object</li> <li>3.4 Initializing the Language Model</li> <li>3.5 Running Your Agent</li> <li> <p>3.6 Understanding Agent Options</p> </li> <li> <p>Advanced Agent Concepts</p> </li> <li> <p>4.1 Custom Stopping Conditions</p> </li> <li>4.2 Dynamic Temperature Handling</li> <li>4.3 Providing Feedback on Responses</li> <li>4.4 Retry Mechanism</li> <li>4.5 Response Filtering</li> <li> <p>4.6 Interactive Mode</p> </li> <li> <p>Saving and Loading Agents</p> </li> <li> <p>5.1 Saving Agent State</p> </li> <li> <p>5.2 Loading a Saved Agent</p> </li> <li> <p>Troubleshooting and Tips</p> </li> <li> <p>6.1 Analyzing Feedback</p> </li> <li> <p>6.2 Troubleshooting Common Issues</p> </li> <li> <p>Conclusion</p> </li> </ol>"},{"location":"examples/flow/#1-introduction-to-swarms-agent-module","title":"1. Introduction to Swarms Agent Module","text":"<p>===================================================================================================================================================</p>"},{"location":"examples/flow/#11-what-is-swarms","title":"1.1 What is Swarms?","text":"<p>Swarms is a powerful framework designed to provide tools and capabilities for working with language models and automating various tasks. It allows developers to interact with language models seamlessly.</p>"},{"location":"examples/flow/#12-understanding-the-agent-feature","title":"1.2 Understanding the Agent Feature","text":"<p>==================================</p>"},{"location":"examples/flow/#what-is-the-agent-feature","title":"What is the Agent Feature?","text":"<p>The Agent feature is a powerful component of the Swarms framework that allows developers to create a sequential, conversational interaction with AI language models. It enables developers to build multi-step conversations, generate long-form content, and perform complex tasks using AI. The Agent class provides autonomy to language models, enabling them to generate responses in a structured manner.</p>"},{"location":"examples/flow/#key-concepts","title":"Key Concepts","text":"<p>Before diving into the practical aspects, let's clarify some key concepts related to the Agent feature:</p> <ul> <li>Agent: A Agent is an instance of the Agent class that represents an ongoing interaction with an AI language model. It consists of a series of steps and responses.</li> <li>Stopping Condition: A stopping condition is a criterion that, when met, allows the Agent to stop generating responses. This can be user-defined and can depend on the content of the responses.</li> <li>Loop Interval: The loop interval specifies the time delay between consecutive interactions with the AI model.</li> <li>Retry Mechanism: In case of errors or failures during AI model interactions, the Agent can be configured to make multiple retry attempts with a specified interval.</li> <li>Interactive Mode: Interactive mode allows developers to have a back-and-forth conversation with the AI model, making it suitable for real-time interactions.</li> </ul>"},{"location":"examples/flow/#2-setting-up-your-development-environment","title":"2. Setting Up Your Development Environment","text":"<p>=============================================================================================================================================================</p>"},{"location":"examples/flow/#21-installing-required-dependencies","title":"2.1 Installing Required Dependencies","text":"<p>Before you can start using the Swarms Agent module, you need to set up your development environment. First, you'll need to install the necessary dependencies, including Swarms itself.</p>"},{"location":"examples/flow/#install-swarms-and-required-libraries","title":"Install Swarms and required libraries","text":"<p><code>pip3 install --upgrade swarms</code></p>"},{"location":"examples/flow/#2-creating-your-first-agent","title":"2. Creating Your First Agent","text":"<p>Now, let's create your first Agent. A Agent represents a chain-like structure that allows you to engage in multi-step conversations with language models. The Agent structure is what gives an LLM autonomy. It's the Mitochondria of an autonomous agent.</p>"},{"location":"examples/flow/#import-necessary-modules","title":"Import necessary modules","text":"<pre><code>from swarms.models import OpenAIChat  # Zephr, Mistral\nfrom swarms.structs import Agent\n\napi_key = \"\"  # Initialize the language model (LLM)\nllm = OpenAIChat(\n    openai_api_key=api_key, temperature=0.5, max_tokens=3000\n)  # Initialize the Agent object\n\nagent = Agent(llm=llm, max_loops=5)  # Run the agent\nout = agent.run(\"Create an financial analysis on the following metrics\")\nprint(out)\n</code></pre>"},{"location":"examples/flow/#3-initializing-the-agent-object","title":"3. Initializing the Agent Object","text":"<p>Create a Agent object that will be the backbone of your conversational agent.</p> <pre><code># Initialize the Agent object\nagent = Agent(\n    llm=llm,\n    max_loops=5,\n    stopping_condition=None,  # You can define custom stopping conditions\n    loop_interval=1,\n    retry_attempts=3,\n    retry_interval=1,\n    interactive=False,  # Set to True for interactive mode\n    dashboard=False,  # Set to True for a dashboard view\n    dynamic_temperature=False,  # Enable dynamic temperature handling\n)\n</code></pre>"},{"location":"examples/flow/#32-initializing-the-language-model","title":"3.2 Initializing the Language Model","text":"<p>Initialize the language model (LLM) that your Agent will interact with. In this example, we're using OpenAI's GPT-3 as the LLM.</p> <ul> <li>You can also use\u00a0<code>Mistral</code>\u00a0or\u00a0<code>Zephr</code>\u00a0or any of other models!</li> </ul> <pre><code># Initialize the language model (LLM)\nllm = OpenAIChat(\n    openai_api_key=api_key,\n    temperature=0.5,\n    max_tokens=3000,\n)\n</code></pre>"},{"location":"examples/flow/#33-running-your-agent","title":"3.3 Running Your Agent","text":"<p>Now, you're ready to run your Agent and start interacting with the language model.</p> <p>If you are using a multi modality model, you can pass in the image path as another parameter</p> <pre><code># Run your Agent\nout = agent.run(\n    \"Generate a 10,000 word blog on health and wellness.\",\n    # \"img.jpg\" , Image path for multi-modal models\n    )\n\nprint(out)\n</code></pre> <p>This code will initiate a conversation with the language model, and you'll receive responses accordingly.</p>"},{"location":"examples/flow/#4-advanced-agent-concepts","title":"4. Advanced Agent Concepts","text":"<p>===========================================================================================================================</p> <p>In this section, we'll explore advanced concepts that can enhance your experience with the Swarms Agent module.</p>"},{"location":"examples/flow/#41-custom-stopping-conditions","title":"4.1 Custom Stopping Conditions","text":"<p>You can define custom stopping conditions for your Agent. For example, you might want the Agent to stop when a specific word is mentioned in the response.</p>"},{"location":"examples/flow/#custom-stopping-condition-example","title":"Custom stopping condition example","text":"<pre><code>def stop_when_repeats(response: str) -&gt; bool:\n    return \"Stop\" in response.lower()\n</code></pre>"},{"location":"examples/flow/#set-the-stopping-condition-in-your-agent","title":"Set the stopping condition in your Agent","text":"<p><code>agent.stopping_condition = stop_when_repeats</code></p>"},{"location":"examples/flow/#42-dynamic-temperature-handling","title":"4.2 Dynamic Temperature Handling","text":"<p>Dynamic temperature handling allows you to adjust the temperature attribute of the language model during the conversation.</p>"},{"location":"examples/flow/#enable-dynamic-temperature-handling-in-your-agent","title":"Enable dynamic temperature handling in your Agent","text":"<p><code>agent.dynamic_temperature = True</code></p> <p>This feature randomly changes the temperature attribute for each loop, providing a variety of responses.</p>"},{"location":"examples/flow/#43-providing-feedback-on-responses","title":"4.3 Providing Feedback on Responses","text":"<p>You can provide feedback on responses generated by the language model using the\u00a0<code>provide_feedback</code>\u00a0method.</p> <ul> <li>Provide feedback on a response <code>agent.provide_feedback(\"The response was helpful.\")</code></li> </ul> <p>This feedback can be valuable for improving the quality of responses.</p>"},{"location":"examples/flow/#44-retry-mechanism","title":"4.4 Retry Mechanism","text":"<p>In case of errors or issues during conversation, you can implement a retry mechanism to attempt generating a response again.</p>"},{"location":"examples/flow/#set-the-number-of-retry-attempts-and-interval","title":"Set the number of retry attempts and interval","text":"<pre><code>agent.retry_attempts = 3\nagent.retry_interval = 1  # in seconds\n</code></pre>"},{"location":"examples/flow/#45-response-filtering","title":"4.5 Response Filtering","text":"<p>You can add response filters to filter out certain words or phrases from the responses.</p>"},{"location":"examples/flow/#add-a-response-filter","title":"Add a response filter","text":"<p><pre><code>agent.add_response_filter(\"inappropriate_word\")\n</code></pre> This helps in controlling the content generated by the language model.</p>"},{"location":"examples/flow/#46-interactive-mode","title":"4.6 Interactive Mode","text":"<p>Interactive mode allows you to have a back-and-forth conversation with the language model. When enabled, the Agent will prompt for user input after each response.</p>"},{"location":"examples/flow/#enable-interactive-mode","title":"Enable interactive mode","text":"<p><code>agent.interactive = True</code></p> <p>This is useful for real-time conversations with the model.</p>"},{"location":"examples/flow/#5-saving-and-loading-agents","title":"5. Saving and Loading Agents","text":"<p>===============================================================================================================================</p>"},{"location":"examples/flow/#51-saving-agent-state","title":"5.1 Saving Agent State","text":"<p>You can save the state of your Agent, including the conversation history, for future use.</p>"},{"location":"examples/flow/#save-the-agent-state-to-a-file","title":"Save the Agent state to a file","text":"<p>`agent.save(\"path/to/flow_state.json\")``</p>"},{"location":"examples/flow/#52-loading-a-saved-agent","title":"5.2 Loading a Saved Agent","text":"<p>To continue a conversation or reuse a Agent, you can load a previously saved state.</p>"},{"location":"examples/flow/#load-a-saved-agent-state","title":"Load a saved Agent state","text":"<p>`agent.load(\"path/to/flow_state.json\")``</p>"},{"location":"examples/flow/#6-troubleshooting-and-tips","title":"6. Troubleshooting and Tips","text":"<p>===============================================================================================================================</p>"},{"location":"examples/flow/#61-analyzing-feedback","title":"6.1 Analyzing Feedback","text":"<p>You can analyze the feedback provided during the conversation to identify issues and improve the quality of interactions.</p>"},{"location":"examples/flow/#analyze-feedback","title":"Analyze feedback","text":"<p><code>agent.analyze_feedback()</code></p>"},{"location":"examples/flow/#62-troubleshooting-common-issues","title":"6.2 Troubleshooting Common Issues","text":"<p>If you encounter issues during conversation, refer to the troubleshooting section for guidance on resolving common problems.</p>"},{"location":"examples/flow/#7-conclusion-empowering-developers-with-swarms-framework-and-agent-structure-for-automation","title":"7. Conclusion: Empowering Developers with Swarms Framework and Agent Structure for Automation","text":"<p>================================================================================================================================================================================================================================================================</p> <p>In a world where digital tasks continue to multiply and diversify, the need for automation has never been more critical. Developers find themselves at the forefront of this automation revolution, tasked with creating reliable solutions that can seamlessly handle an array of digital tasks. Enter the Swarms framework and the Agent structure, a dynamic duo that empowers developers to build autonomous agents capable of efficiently and effectively automating a wide range of digital tasks.</p>"},{"location":"examples/flow/#the-automation-imperative","title":"The Automation Imperative","text":"<p>Automation is the driving force behind increased efficiency, productivity, and scalability across various industries. From mundane data entry and content generation to complex data analysis and customer support, the possibilities for automation are vast. Developers play a pivotal role in realizing these possibilities, and they require robust tools and frameworks to do so effectively.</p>"},{"location":"examples/flow/#swarms-framework-a-developers-swiss-army-knife","title":"Swarms Framework: A Developer's Swiss Army Knife","text":"<p>The Swarms framework emerges as a comprehensive toolkit designed to empower developers in their automation endeavors. It equips developers with the tools and capabilities needed to create autonomous agents capable of interacting with language models, orchestrating multi-step workflows, and handling error scenarios gracefully. Let's explore why the Swarms framework is a game-changer for developers:</p>"},{"location":"examples/flow/#1-language-model-integration","title":"1. Language Model Integration","text":"<p>One of the standout features of Swarms is its seamless integration with state-of-the-art language models, such as GPT-3. These language models have the ability to understand and generate human-like text, making them invaluable for tasks like content creation, translation, code generation, and more.</p> <p>By leveraging Swarms, developers can effortlessly incorporate these language models into their applications and workflows. For instance, they can build chatbots that provide intelligent responses to customer inquiries or generate lengthy documents with minimal manual intervention. This not only saves time but also enhances overall productivity.</p>"},{"location":"examples/flow/#2-multi-step-conversational-agents","title":"2. Multi-Step Conversational Agents","text":"<p>Swarms excels in orchestrating multi-step conversational flows. Developers can define intricate sequences of interactions, where the system generates responses, and users provide input at various stages. This functionality is a game-changer for building chatbots, virtual assistants, or any application requiring dynamic and context-aware conversations.</p> <p>These conversational flows can be tailored to handle a wide range of scenarios, from customer support interactions to data analysis. By providing a structured framework for conversations, Swarms empowers developers to create intelligent and interactive systems that mimic human-like interactions.</p>"},{"location":"examples/flow/#3-customization-and-extensibility","title":"3. Customization and Extensibility","text":"<p>Every development project comes with its unique requirements and challenges. Swarms acknowledges this by offering a high degree of customization and extensibility. Developers can define custom stopping conditions, implement dynamic temperature handling for language models, and even add response filters to control the generated content.</p> <p>Moreover, Swarms supports an interactive mode, allowing developers to engage in real-time conversations with the language model. This feature is invaluable for rapid prototyping, testing, and fine-tuning the behavior of autonomous agents.</p>"},{"location":"examples/flow/#4-feedback-driven-improvement","title":"4. Feedback-Driven Improvement","text":"<p>Swarms encourages the collection of feedback on generated responses. Developers and users alike can provide feedback to improve the quality and accuracy of interactions over time. This iterative feedback loop ensures that applications built with Swarms continually improve, becoming more reliable and capable of autonomously handling complex tasks.</p>"},{"location":"examples/flow/#5-handling-errors-and-retries","title":"5. Handling Errors and Retries","text":"<p>Error handling is a critical aspect of any automation framework. Swarms simplifies this process by offering a retry mechanism. In case of errors or issues during conversations, developers can configure the framework to attempt generating responses again, ensuring robust and resilient automation.</p>"},{"location":"examples/flow/#6-saving-and-loading-agents","title":"6. Saving and Loading Agents","text":"<p>Developers can save the state of their conversational flows, allowing for seamless continuity and reusability. This feature is particularly beneficial when working on long-term projects or scenarios where conversations need to be resumed from a specific point.</p>"},{"location":"examples/flow/#unleashing-the-potential-of-automation-with-swarms-and-agent","title":"Unleashing the Potential of Automation with Swarms and Agent","text":"<p>The combined power of the Swarms framework and the Agent structure creates a synergy that empowers developers to automate a multitude of digital tasks. These tools provide versatility, customization, and extensibility, making them ideal for a wide range of applications. Let's explore some of the remarkable ways in which developers can leverage Swarms and Agent for automation:</p>"},{"location":"examples/flow/#1-customer-support-and-service-automation","title":"1. Customer Support and Service Automation","text":"<p>Swarms and Agent enable the creation of AI-powered customer support chatbots that excel at handling common inquiries, troubleshooting issues, and escalating complex problems to human agents when necessary. This level of automation not only reduces response times but also enhances the overall customer experience.</p>"},{"location":"examples/flow/#2-content-generation-and-curation","title":"2. Content Generation and Curation","text":"<p>Developers can harness the power of Swarms and Agent to automate content generation tasks, such as writing articles, reports, or product descriptions. By providing an initial prompt, the system can generate high-quality content that adheres to specific guidelines and styles.</p> <p>Furthermore, these tools can automate content curation by summarizing lengthy articles, extracting key insights from research papers, and even translating content into multiple languages.</p>"},{"location":"examples/flow/#3-data-analysis-and-reporting","title":"3. Data Analysis and Reporting","text":"<p>Automation in data analysis and reporting is fundamental for data-driven decision-making. Swarms and Agent simplify these processes by enabling developers to create flows that interact with databases, query data, and generate reports based on user-defined criteria. This empowers businesses to derive insights quickly and make informed decisions.</p>"},{"location":"examples/flow/#4-programming-and-code-generation","title":"4. Programming and Code Generation","text":"<p>Swarms and Agent streamline code generation and programming tasks. Developers can create flows to assist in writing code snippets, auto-completing code, or providing solutions to common programming challenges. This accelerates software development and reduces the likelihood of coding errors.</p>"},{"location":"examples/flow/#5-language-translation-and-localization","title":"5. Language Translation and Localization","text":"<p>With the ability to interface with language models, Swarms and Agent can automate language translation tasks. They can seamlessly translate content from one language to another, making it easier for businesses to reach global audiences and localize their offerings effectively.</p>"},{"location":"examples/flow/#6-virtual-assistants-and-ai-applications","title":"6. Virtual Assistants and AI Applications","text":"<p>Developers can build virtual assistants and AI applications that offer personalized experiences. These applications can automate tasks such as setting reminders, answering questions, providing recommendations, and much more. Swarms and Agent provide the foundation for creating intelligent, interactive virtual assistants.</p>"},{"location":"examples/flow/#future-opportunities-and-challenges","title":"Future Opportunities and Challenges","text":"<p>As Swarms and Agent continue to evolve, developers can look forward to even more advanced features and capabilities. However, with great power comes great responsibility. Developers must remain vigilant about the ethical use of automation and language models. Ensuring that automated systems provide accurate and unbiased information is an ongoing challenge that the developer community must address.</p>"},{"location":"examples/flow/#in-conclusion","title":"In Conclusion","text":"<p>===================================================================================================</p> <p>The Swarms framework and the Agent structure empower developers to automate an extensive array of digital tasks by offering versatility, customization, and extensibility. From natural language understanding and generation to orchestrating multi-step conversational flows, these tools simplify complex automation scenarios.</p> <p>By embracing Swarms and Agent, developers can not only save time and resources but also unlock new opportunities for innovation. The ability to harness the power of language models and create intelligent, interactive applications opens doors to a future where automation plays a pivotal role in our digital lives.</p> <p>As the developer community continues to explore the capabilities of Swarms and Agent, it is essential to approach automation with responsibility, ethics, and a commitment to delivering valuable, user-centric experiences. With Swarms and Agent, the future of automation is in the hands of developers, ready to create a more efficient, intelligent, and automated world.</p>"},{"location":"examples/ideas/","title":"2O+ Autonomous Agent Blogs","text":"<ol> <li>The Ultimate Guide to Deploying Production-Ready Autonomous Agents with Swarms</li> <li> <p>A comprehensive start-to-finish guide on implementing Swarms in a production environment.</p> </li> <li> <p>5 Steps to Elevate Your AI with Swarms Multi-Modal Autonomous Agents</p> </li> <li> <p>A walkthrough highlighting the simplicity of Swarms\u2019 setup and deployment for various AI applications.</p> </li> <li> <p>Integrating Swarms Into Your Enterprise Workflow: A Step-By-Step Tutorial</p> </li> <li> <p>A practical guide focusing on integrating Swarms into existing enterprise systems.</p> </li> <li> <p>Swarms\u2019 Agent: Streamlining AI Deployment in Your Business</p> </li> <li> <p>Exploring the benefits and technicalities of using the Agent feature to simplify complex AI workflows.</p> </li> <li> <p>From Zero to Hero: Building Your First Enterprise-Grade AI Agent with Swarms</p> </li> <li> <p>A beginner-friendly walkthrough for building and deploying an AI agent using Swarms.</p> </li> <li> <p>Scaling AI with Swarms: Managing Multi-Agent Systems Efficiently</p> </li> <li> <p>Strategies and best practices for scaling multi-agent systems in enterprise settings.</p> </li> <li> <p>Creating Resilient AI Systems with Swarms' Autonomous Agents</p> </li> <li> <p>Discussing the robustness of Swarms agents and how they maintain performance under stress.</p> </li> <li> <p>Unlocking New Capabilities: Advanced Features of Swarms for AI Engineers</p> </li> <li> <p>Diving into the more sophisticated features of Swarms and how they can be leveraged in complex projects.</p> </li> <li> <p>Swarms\u2019 Quick Wins: Implementing AI Agents in Less Than 5 Lines of Code</p> </li> <li> <p>A focused guide on rapidly deploying functional AI agents with minimal coding.</p> </li> <li> <p>Benchmarking Your AI: Performance Metrics with Swarms</p> <ul> <li>How to use Swarms to measure and optimize the performance of AI agents.</li> </ul> </li> <li> <p>Swarms Case Studies: Real-World Success Stories from AI Engineers</p> <ul> <li>Sharing stories and testimonials of how various organizations successfully implemented Swarms.</li> </ul> </li> <li> <p>Effortless Multi-Modal Model Deployment: A Swarms Walkthrough</p> <ul> <li>Explaining how to use Swarms to deploy multi-modal models with ease.</li> </ul> </li> <li> <p>Future-Proof Your AI: Adapting to New Tech with Swarms</p> <ul> <li>How Swarms' flexible architecture allows for easy updates and adaptation to new AI technologies.</li> </ul> </li> <li> <p>Enterprise AI Security: Ensuring Your Swarms Agents are Hack-Proof</p> <ul> <li>Best practices for securing autonomous agents in enterprise applications.</li> </ul> </li> <li> <p>Migrating to Swarms: Transitioning From Legacy Systems</p> <ul> <li>A guide for AI engineers on migrating existing AI systems to Swarms without downtime.</li> </ul> </li> <li> <p>Multi-Agent Collaboration: How Swarms Facilitates Teamwork Among AI</p> <ul> <li>An insight into how Swarms allows for multiple AI agents to work together seamlessly.</li> </ul> </li> <li> <p>The Engineer's Toolkit: Swarms' Features Every AI Developer Must Know</p> <ul> <li>Highlighting the most useful tools and features of Swarms from an AI developer\u2019s perspective.</li> </ul> </li> <li> <p>Swarms for Different Industries: Customizing AI Agents for Niche Markets</p> <ul> <li>Exploring how Swarms can be tailored to fit the needs of various industries such as healthcare, finance, and retail.</li> </ul> </li> <li> <p>Building Intelligent Workflows with Swarms\u2019 Agent</p> <ul> <li>A tutorial on using the Agent feature to create intelligent, responsive AI-driven workflows.</li> </ul> </li> <li> <p>Troubleshooting Common Issues When Deploying Swarms Autonomous Agents</p> <ul> <li>A problem-solving guide for AI engineers on overcoming common challenges when implementing Swarms agents.</li> </ul> </li> </ol> <p>Each blog or walkthrough can be structured to not only showcase the functionality and benefits of the Swarms framework but also to establish the brand as a thought leader in the space of enterprise AI solutions.</p>"},{"location":"examples/omni_agent/","title":"OmniModalAgent from Swarms: A Comprehensive Starting Guide","text":"<p>Table of Contents</p> <ol> <li>Introduction: The OmniModal Magic</li> <li>The Mechanics: Unraveling the Underpinnings</li> <li>The Installation Adventure: Setting the Stage</li> <li>Practical Examples: Let\u2019s Get Our Hands Dirty!</li> <li>Error Handling: Because Bumps on the Road are Inevitable</li> <li>Dive Deeper: Advanced Features and Usage</li> <li>Wrapping Up: The Road Ahead</li> </ol> <p>1. Introduction: The OmniModal Magic</p> <p>Imagine a world where you could communicate seamlessly across any modality, be it text, image, speech, or even video. Now, stop imagining because OmniModalAgent is here to turn that dream into reality. By leveraging advanced architecture and state-of-the-art tools, it can understand and generate any modality you can think of!</p> <p>2. The Mechanics: Unraveling the Underpinnings</p> <p>Dive into the world of OmniModalAgent and let\u2019s decipher how it works:</p> <ul> <li>LLM (Language Model): It\u2019s the brain behind understanding and generating language-based interactions.</li> <li>Chat Planner: Think of it as the strategist. It lays out the plan for the user's input.</li> <li>Task Executor: The doer. Once the plan is ready, this component takes charge to execute tasks.</li> <li>Tools: A treasure chest full of tools, from image captioning to translation. </li> </ul> <p>3. The Installation Adventure: Setting the Stage</p> <p>Getting OmniModalAgent up and running is as easy as pie. Ready to bake? </p> <pre><code>pip install swarms\n</code></pre> <p>And voil\u00e0, your oven (system) is now equipped to bake any modality cake you desire!</p> <p>4. Practical Examples: Let\u2019s Get Our Hands Dirty!</p> <p>Let\u2019s embark on an exciting journey with OmniModalAgent:</p> <p>i. Basic Interaction:</p> <pre><code>from swarms.agents import OmniModalAgent\nfrom swarms.models import OpenAIChat\n\nllm = OpenAIChat(openai_api_key=\"sk-\")\nagent = OmniModalAgent(llm)\nresponse = agent.run(\"Create an video of a swarm of fish concept art, game art\")\nprint(response)\n</code></pre> <p>ii. Dive into a Conversation:</p> <pre><code>agent = OmniModalAgent(llm)\nprint(agent.chat(\"What's the weather like?\"))\n</code></pre> <p>5. Error Handling: Because Bumps on the Road are Inevitable</p> <p>Errors are like rain, unpredictable but inevitable. Luckily, OmniModalAgent comes with an umbrella. If there's a hiccup during message processing, it\u2019s gracious enough to let you know.</p> <p>For instance, if there's a bump, you\u2019ll receive:</p> <pre><code>Error processing message: [Details of the error]\n</code></pre> <p>6. Dive Deeper: Advanced Features and Usage</p> <p>The power of OmniModalAgent isn\u2019t just limited to basic interactions. Here\u2019s a sneak peek into its advanced capabilities:</p> <p>Streaming Responses:</p> <p>Imagine receiving responses as a gentle stream rather than a sudden splash. With the <code>_stream_response</code> method, you can achieve just that.</p> <pre><code>for token in agent._stream_response(response):\n    print(token)\n</code></pre> <p>The Treasure Chest: Tools:</p> <p>OmniModalAgent boasts a plethora of tools, from image captioning to speech-to-text. When you initialize the agent, it equips itself with these tools, ready to tackle any challenge you throw its way.</p> <p>7. Wrapping Up: The Road Ahead</p> <p>You've just scratched the surface of what OmniModalAgent can do. As you explore deeper, you'll discover more of its magic. The world of multi-modality is vast, and with OmniModalAgent as your companion, there's no limit to where you can go.</p> <p>Happy Exploring and Coding! \ud83d\ude80\ud83c\udf89</p>"},{"location":"examples/reliable_autonomous_agents/","title":"Enterprise-Grade Workflow Automation With Autonomous Agents","text":"<p>========================================================================</p> <p>Welcome to this comprehensive walkthrough guide tutorial on the SequentialWorkflow feature of the Swarms Framework! In this tutorial, we will explore the purpose, usage, and key concepts of the SequentialWorkflow class, which is a part of the swarms package. Whether you are a beginner, intermediate, or expert developer, this tutorial will provide you with a clear understanding of how to effectively use the SequentialWorkflow class in your projects.</p> <p>AI engineering is a dynamic and evolving field that involves the development and deployment of intelligent systems and applications. In this ever-changing landscape, AI engineers often face the challenge of orchestrating complex sequences of tasks, managing data flows, and ensuring the smooth execution of AI workflows. This is where the Workflow Class, such as the SequentialWorkflow class we discussed earlier, plays a pivotal role in enabling AI engineers to achieve their goals efficiently and effectively.</p>"},{"location":"examples/reliable_autonomous_agents/#the-versatile-world-of-ai-workflows","title":"The Versatile World of AI Workflows","text":"<p>AI workflows encompass a wide range of tasks and processes, from data preprocessing and model training to natural language understanding and decision-making. These workflows are the backbone of AI systems, guiding them through intricate sequences of actions to deliver meaningful results. Here are some of the diverse use cases where the Workflow Class can empower AI engineers:</p>"},{"location":"examples/reliable_autonomous_agents/#1-natural-language-processing-nlp-pipelines","title":"1. Natural Language Processing (NLP) Pipelines","text":"<p>AI engineers often build NLP pipelines that involve multiple stages such as text preprocessing, tokenization, feature extraction, model inference, and post-processing. The Workflow Class enables the orderly execution of these stages, ensuring that textual data flows seamlessly through each step, resulting in accurate and coherent NLP outcomes.</p>"},{"location":"examples/reliable_autonomous_agents/#2-data-ingestion-and-transformation","title":"2. Data Ingestion and Transformation","text":"<p>AI projects frequently require the ingestion of diverse data sources, including structured databases, unstructured text, and multimedia content. The Workflow Class can be used to design data ingestion workflows that extract, transform, and load (ETL) data efficiently, making it ready for downstream AI tasks like training and analysis.</p>"},{"location":"examples/reliable_autonomous_agents/#3-autonomous-agents-and-robotics","title":"3. Autonomous Agents and Robotics","text":"<p>In autonomous robotics and intelligent agent systems, workflows are essential for decision-making, sensor fusion, motion planning, and control. AI engineers can use the Workflow Class to create structured sequences of actions that guide robots and agents through dynamic environments, enabling them to make informed decisions and accomplish tasks autonomously.</p>"},{"location":"examples/reliable_autonomous_agents/#4-machine-learning-model-training","title":"4. Machine Learning Model Training","text":"<p>Training machine learning models involves a series of steps, including data preprocessing, feature engineering, model selection, hyperparameter tuning, and evaluation. The Workflow Class simplifies the orchestration of these steps, allowing AI engineers to experiment with different configurations and track the progress of model training.</p>"},{"location":"examples/reliable_autonomous_agents/#5-content-generation-and-summarization","title":"5. Content Generation and Summarization","text":"<p>AI-driven content generation tasks, such as generating articles, reports, or summaries, often require multiple steps, including content creation and post-processing. The Workflow Class can be used to create content generation workflows, ensuring that the generated content meets quality and coherence criteria.</p>"},{"location":"examples/reliable_autonomous_agents/#6-adaptive-decision-making","title":"6. Adaptive Decision-Making","text":"<p>In AI systems that make real-time decisions based on changing data and environments, workflows facilitate adaptive decision-making. Engineers can use the Workflow Class to design decision-making pipelines that take into account the latest information and make informed choices.</p>"},{"location":"examples/reliable_autonomous_agents/#enabling-efficiency-and-maintainability","title":"Enabling Efficiency and Maintainability","text":"<p>The Workflow Class provides AI engineers with a structured and maintainable approach to building, executing, and managing complex AI workflows. It offers the following advantages:</p> <ul> <li> <p>Modularity: Workflows can be modularly designed, allowing engineers to focus on individual task implementations and ensuring code reusability.</p> </li> <li> <p>Debugging and Testing: The Workflow Class simplifies debugging and testing by providing a clear sequence of tasks and well-defined inputs and outputs for each task.</p> </li> <li> <p>Scalability: As AI projects grow in complexity, the Workflow Class can help manage and scale workflows by adding or modifying tasks as needed.</p> </li> <li> <p>Error Handling: The class supports error handling strategies, enabling engineers to define how to handle unexpected failures gracefully.</p> </li> <li> <p>Maintainability: With structured workflows, AI engineers can easily maintain and update AI systems as requirements evolve or new data sources become available.</p> </li> </ul> <p>The Workflow Class, such as the SequentialWorkflow class, is an indispensable tool in the toolkit of AI engineers. It empowers engineers to design, execute, and manage AI workflows across a diverse range of use cases. By providing structure, modularity, and maintainability to AI projects, the Workflow Class contributes significantly to the efficiency and success of AI engineering endeavors. As the field of AI continues to advance, harnessing the power of workflow orchestration will remain a key ingredient in building intelligent and adaptable systems, now let\u2019s get started with SequentialWorkflow.</p>"},{"location":"examples/reliable_autonomous_agents/#official-swarms-links","title":"Official Swarms Links","text":"<p>Here is the Swarms website:</p> <p>Here is the Swarms Github:</p> <p>Here are the Swarms docs:</p> <p>And, join the Swarm community!</p> <p>Book a call with The Swarm Corporation here if you\u2019re interested in high performance custom swarms!</p> <p>Now let\u2019s begin\u2026</p>"},{"location":"examples/reliable_autonomous_agents/#installation","title":"Installation","text":"<p>Before we dive into the tutorial, make sure you have the following prerequisites in place:</p> <p>Python installed on your system. The swarms library installed. You can install it via pip using the following command:</p> <p><code>pip3 install --upgrade swarms</code></p> <p>Additionally, you will need an API key for the OpenAIChat model to run the provided code examples. Replace \"YOUR_API_KEY\" with your actual API key in the code examples where applicable.</p>"},{"location":"examples/reliable_autonomous_agents/#getting-started","title":"Getting Started","text":"<p>Let\u2019s start by importing the necessary modules and initializing the OpenAIChat model, which we will use in our workflow tasks.</p> <pre><code>from swarms.models import OpenAIChat\nfrom swarms.structs import Agent\nfrom swarms.structs.sequential_workflow import SequentialWorkflow\n\n# Replace \"YOUR_API_KEY\" with your actual OpenAI API key\napi_key = \"YOUR_API_KEY\"\n\n# Initialize the language model agent (e.g., GPT-3)\nllm = OpenAIChat(\n    openai_api_key=api_key,\n    temperature=0.5,\n    max_tokens=3000,\n)\nWe have initialized the OpenAIChat model, which will be used as a callable object in our tasks. Now, let\u2019s proceed to create the SequentialWorkflow.\n\nCreating a SequentialWorkflow\nTo create a SequentialWorkflow, follow these steps:\n\n# Initialize Agents for individual tasks\nflow1 = Agent(llm=llm, max_loops=1, dashboard=False)\nflow2 = Agent(llm=llm, max_loops=1, dashboard=False)\n# Create the Sequential Workflow\nworkflow = SequentialWorkflow(max_loops=1)\n``````\nIn this code snippet, we have initialized two Agent instances (flow1 and flow2) representing individual tasks within our workflow. These flows will use the OpenAIChat model we initialized earlier. We then create a SequentialWorkflow instance named workflow with a maximum loop count of 1. The max_loops parameter determines how many times the entire workflow can be run, and we set it to 1 for this example.\n\nAdding Tasks to the SequentialWorkflow\nNow that we have created the SequentialWorkflow, let\u2019s add tasks to it. In our example, we\u2019ll create two tasks: one for generating a 10,000-word blog on \u201chealth and wellness\u201d and another for summarizing the generated blog.\n</code></pre>"},{"location":"examples/reliable_autonomous_agents/#add-tasks-to-the-workflow","title":"Add tasks to the workflow","text":"<p>workflow.add(\"Generate a 10,000 word blog on health and wellness.\", flow1)</p> <p><code>workflow.add(\"Summarize the generated blog\", flow2)</code></p> <p>The workflow.add() method is used to add tasks to the workflow. Each task is described using a human-readable description, such as \"Generate a 10,000 word blog on health and wellness,\" and is associated with a agent (callable object) that will be executed as the task. In our example, flow1 and flow2 represent the tasks.</p> <p>Running the SequentialWorkflow With tasks added to the SequentialWorkflow, we can now run the workflow sequentially using the workflow.run() method.</p>"},{"location":"examples/reliable_autonomous_agents/#run-the-workflow","title":"Run the workflow","text":"<p><code>workflow.run()</code> Executing workflow.run() will start the execution of tasks in the order they were added to the workflow. In our example, it will first generate the blog and then summarize it.</p> <p>Accessing Task Results After running the workflow, you can access the results of each task using the get_task_results() method.</p>"},{"location":"examples/reliable_autonomous_agents/#get-and-display-the-results-of-each-task-in-the-workflow","title":"Get and display the results of each task in the workflow","text":"<p><pre><code>results = workflow.get_task_results()\nfor task_description, result in results.items():\n    print(f\"Task: {task_description}, Result: {result}\")\n</code></pre> The workflow.get_task_results() method returns a dictionary where the keys are task descriptions, and the values are the corresponding results. You can then iterate through the results and print them, as shown in the code snippet.</p> <p>Resetting a SequentialWorkflow Sometimes, you might need to reset a SequentialWorkflow to start fresh. You can use the workflow.reset_workflow() method for this purpose.</p>"},{"location":"examples/reliable_autonomous_agents/#reset-the-workflow","title":"Reset the workflow","text":"<p><code>workflow.reset_workflow()</code> Resetting the workflow clears the results of each task, allowing you to rerun the workflow from the beginning without reinitializing it.</p> <p>Updating Task Arguments You can also update the arguments of a specific task in the workflow using the workflow.update_task() method.</p>"},{"location":"examples/reliable_autonomous_agents/#update-the-arguments-of-a-specific-task-in-the-workflow","title":"Update the arguments of a specific task in the workflow","text":"<p><code>workflow.update_task(\"Generate a 10,000 word blog on health and wellness.\", max_loops=2)</code></p> <p>In this example, we update the max_loops argument of the task with the description \"Generate a 10,000 word blog on health and wellness\" to 2. This can be useful if you want to change the behavior of a specific task without recreating the entire workflow.</p>"},{"location":"examples/reliable_autonomous_agents/#conclusion-mastering-workflow-orchestration-in-ai-engineering","title":"Conclusion: Mastering Workflow Orchestration in AI Engineering","text":"<p>In the ever-evolving landscape of artificial intelligence (AI), where the pace of innovation and complexity of tasks are ever-increasing, harnessing the power of workflow orchestration is paramount. In this comprehensive walkthrough guide, we\u2019ve embarked on a journey through the world of workflow orchestration, focusing on the Workflow Class, with a specific emphasis on the SequentialWorkflow class. As we conclude this exploration, we\u2019ve delved deep into the intricacies of orchestrating AI workflows, and it\u2019s time to reflect on the valuable insights gained and the immense potential that this knowledge unlocks for AI engineers.</p>"},{"location":"examples/reliable_autonomous_agents/#the-art-of-workflow-orchestration","title":"The Art of Workflow Orchestration","text":"<p>At its core, workflow orchestration is the art of designing, managing, and executing sequences of tasks or processes in a structured and efficient manner. In the realm of AI engineering, where tasks can range from data preprocessing and model training to decision-making and autonomous actions, mastering workflow orchestration is a game-changer. It empowers AI engineers to streamline their work, ensure reliable execution, and deliver impactful results.</p> <p>The Workflow Class, and particularly the SequentialWorkflow class we\u2019ve explored, acts as a guiding light in this intricate journey. It provides AI engineers with a toolbox of tools and techniques to conquer the challenges of orchestrating AI workflows effectively. Through a disciplined approach and adherence to best practices, AI engineers can achieve the following:</p>"},{"location":"examples/reliable_autonomous_agents/#1-structured-workflow-design","title":"1. Structured Workflow Design","text":"<p>A well-structured workflow is the cornerstone of any successful AI project. The Workflow Class encourages AI engineers to break down complex tasks into manageable units. Each task becomes a building block that contributes to the overarching goal. Whether it\u2019s preprocessing data, training a machine learning model, or generating content, structured workflow design ensures clarity, modularity, and maintainability.</p>"},{"location":"examples/reliable_autonomous_agents/#2-efficient-task-sequencing","title":"2. Efficient Task Sequencing","text":"<p>In AI, the order of tasks often matters. One task\u2019s output can be another task\u2019s input, and ensuring the correct sequence of execution is crucial. The SequentialWorkflow class enforces this sequential execution, eliminating the risk of running tasks out of order. It ensures that the workflow progresses systematically, following the predefined sequence of tasks.</p>"},{"location":"examples/reliable_autonomous_agents/#3-error-resilience-and-recovery","title":"3. Error Resilience and Recovery","text":"<p>AI systems must be resilient in the face of unexpected errors and failures. The Workflow Class equips AI engineers with error handling strategies, such as retries and fallbacks. These strategies provide the ability to gracefully handle issues, recover from failures, and continue the workflow\u2019s execution without disruption.</p>"},{"location":"examples/reliable_autonomous_agents/#4-code-modularity-and-reusability","title":"4. Code Modularity and Reusability","text":"<p>Building AI workflows often involves implementing various tasks, each with its own logic. The Workflow Class encourages code modularity, allowing AI engineers to encapsulate tasks as separate units. This modularity promotes code reusability, making it easier to adapt and expand workflows as AI projects evolve.</p>"},{"location":"examples/reliable_autonomous_agents/#5-efficient-debugging-and-testing","title":"5. Efficient Debugging and Testing","text":"<p>Debugging and testing AI workflows can be challenging without clear structure and boundaries. The Workflow Class provides a clear sequence of tasks with well-defined inputs and outputs. This structure simplifies the debugging process, as AI engineers can isolate and test individual tasks, ensuring that each component functions as intended.</p>"},{"location":"examples/reliable_autonomous_agents/#6-scalability-and-adaptability","title":"6. Scalability and Adaptability","text":"<p>As AI projects grow in complexity, the Workflow Class scales effortlessly. AI engineers can add or modify tasks as needed, accommodating new data sources, algorithms, or requirements. This scalability ensures that workflows remain adaptable to changing demands and evolving AI landscapes.</p>"},{"location":"examples/reliable_autonomous_agents/#7-maintainability-and-future-proofing","title":"7. Maintainability and Future-Proofing","text":"<p>Maintaining AI systems over time is a crucial aspect of engineering. The Workflow Class fosters maintainability by providing a clear roadmap of tasks and their interactions. AI engineers can revisit, update, and extend workflows with confidence, ensuring that AI systems remain effective and relevant in the long run.</p>"},{"location":"examples/reliable_autonomous_agents/#empowering-ai-engineers","title":"Empowering AI Engineers","text":"<p>The knowledge and skills gained from this walkthrough guide go beyond technical proficiency. They empower AI engineers to be architects of intelligent systems, capable of orchestrating AI workflows that solve real-world problems. The Workflow Class is a versatile instrument in their hands, enabling them to tackle diverse use cases and engineering challenges.</p>"},{"location":"examples/reliable_autonomous_agents/#diverse-use-cases-for-workflow-class","title":"Diverse Use Cases for Workflow Class","text":"<p>Throughout this guide, we explored a myriad of use cases where the Workflow Class shines:</p> <p>Natural Language Processing (NLP) Pipelines: In NLP, workflows involve multiple stages, and the Workflow Class ensures orderly execution, resulting in coherent NLP outcomes.</p> <p>Data Ingestion and Transformation: Data is the lifeblood of AI, and structured data workflows ensure efficient data preparation for downstream tasks.</p> <p>Autonomous Agents and Robotics: For robots and intelligent agents, workflows enable autonomous decision-making and task execution.</p> <p>Machine Learning Model Training: Model training workflows encompass numerous steps, and structured orchestration simplifies the process.</p> <p>Content Generation and Summarization: Workflows for content generation ensure that generated content meets quality and coherence criteria.</p> <p>Adaptive Decision-Making: In dynamic environments, workflows facilitate adaptive decision-making based on real-time data.</p>"},{"location":"examples/reliable_autonomous_agents/#efficiency-and-maintainability","title":"Efficiency and Maintainability","text":"<p>AI engineers not only have the tools to tackle these use cases but also the means to do so efficiently. The Workflow Class fosters efficiency and maintainability, making AI engineering endeavors more manageable:</p> <ul> <li> <p>Modularity: Encapsulate tasks as separate units, promoting code reusability and maintainability.</p> </li> <li> <p>Debugging and Testing: Streamline debugging and testing through clear task boundaries and well-defined inputs and outputs.</p> </li> <li> <p>Scalability: As AI projects grow, workflows scale with ease, accommodating new components and requirements. Error Handling: Gracefully handle errors and failures, ensuring that AI systems continue to operate smoothly.</p> </li> <li> <p>Maintainability: AI systems remain adaptable and maintainable, even as the AI landscape evolves and requirements change.</p> </li> </ul>"},{"location":"examples/reliable_autonomous_agents/#the-future-of-ai-engineering","title":"The Future of AI Engineering","text":"<p>As AI engineering continues to advance, workflow orchestration will play an increasingly pivotal role. The Workflow Class is not a static tool; it is a dynamic enabler of innovation. In the future, we can expect further enhancements and features to meet the evolving demands of AI engineering:</p>"},{"location":"examples/reliable_autonomous_agents/#1-asynchronous-support","title":"1. Asynchronous Support","text":"<p>Support for asynchronous task execution will improve the efficiency of workflows, especially when tasks involve waiting for external events or resources.</p>"},{"location":"examples/reliable_autonomous_agents/#2-context-managers","title":"2. Context Managers","text":"<p>Introducing context manager support for tasks can simplify resource management, such as opening and closing files or database connections.</p>"},{"location":"examples/reliable_autonomous_agents/#3-workflow-history","title":"3. Workflow History","text":"<p>Maintaining a detailed history of workflow execution, including timestamps, task durations, and input/output data, will facilitate debugging and performance analysis.</p>"},{"location":"examples/reliable_autonomous_agents/#4-parallel-processing","title":"4. Parallel Processing","text":"<p>Enhancing the module to support parallel processing with a pool of workers can significantly speed up the execution of tasks, especially for computationally intensive workflows.</p>"},{"location":"examples/reliable_autonomous_agents/#5-error-handling-strategies","title":"5. Error Handling Strategies","text":"<p>Providing built-in error handling strategies, such as retries, fallbacks, and circuit breakers, will further enhance the resilience of workflows.</p>"},{"location":"examples/reliable_autonomous_agents/#closing-thoughts","title":"Closing Thoughts","text":"<p>In conclusion, the journey through workflow orchestration in AI engineering has been both enlightening and empowering. The Workflow Class, and particularly the SequentialWorkflow class, has proven to be an invaluable ally in the AI engineer\u2019s toolkit. It offers structure, modularity, and efficiency, ensuring that AI projects progress smoothly from inception to deployment.</p> <p>As AI continues to permeate every aspect of our lives, the skills acquired in this guide will remain highly relevant and sought after. AI engineers armed with workflow orchestration expertise will continue to push the boundaries of what is possible, solving complex problems, and driving innovation.</p> <p>But beyond the technical aspects, this guide also emphasizes the importance of creativity, adaptability, and problem-solving. AI engineering is not just about mastering tools; it\u2019s about using them to make a meaningful impact on the world.</p> <p>So, whether you\u2019re just starting your journey into AI engineering or you\u2019re a seasoned professional seeking to expand your horizons, remember that the power of workflow orchestration lies not only in the code but in the limitless potential it unlocks for you as an AI engineer. As you embark on your own AI adventures, may this guide serve as a reliable companion, illuminating your path and inspiring your journey towards AI excellence.</p> <p>The world of AI is waiting for your innovation and creativity. With workflow orchestration as your guide, you have the tools to shape the future. The possibilities are boundless, and the future is yours to create.</p> <p>Official Swarms Links Here is the Swarms website:</p> <p>Here is the Swarms Github:</p> <p>Here are the Swarms docs:</p> <p>And, join the Swarm community!</p> <p>Book a call with The Swarm Corporation here if you\u2019re interested in high performance custom swarms!</p>"},{"location":"examples/revgpt/","title":"Revgpt","text":""},{"location":"examples/revgpt/#chatgpt-user-guide-with-abstraction","title":"ChatGPT User Guide with Abstraction","text":"<p>Welcome to the ChatGPT user guide! This document will walk you through the Reverse Engineered ChatGPT API, its usage, and how to leverage the abstraction in <code>revgpt.py</code> for seamless integration.</p>"},{"location":"examples/revgpt/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Installation</li> <li>Initial Setup and Configuration</li> <li>Using the Abstract Class from <code>revgpt.py</code></li> <li>V1 Standard ChatGPT</li> <li>V3 Official Chat API</li> <li>Credits &amp; Disclaimers</li> </ol>"},{"location":"examples/revgpt/#installation","title":"Installation","text":"<p>To kickstart your journey with ChatGPT, first, install the ChatGPT package:</p> <pre><code>python -m pip install --upgrade revChatGPT\n</code></pre> <p>Supported Python Versions: - Minimum: Python3.9 - Recommended: Python3.11+</p>"},{"location":"examples/revgpt/#initial-setup-and-configuration","title":"Initial Setup and Configuration","text":"<ol> <li>Account Setup: Register on OpenAI's ChatGPT.</li> <li>Authentication: Obtain your access token from OpenAI's platform.</li> <li>Environment Variables: Configure your environment with the necessary variables. An example of these variables can be found at the bottom of the guide.</li> </ol>"},{"location":"examples/revgpt/#using-the-abstract-class-from-revgptpy","title":"Using the Abstract Class from <code>revgpt.py</code>","text":"<p>The abstraction provided in <code>revgpt.py</code> is designed to simplify your interactions with ChatGPT.</p> <ol> <li>Import the Necessary Modules:</li> </ol> <pre><code>from dotenv import load_dotenv\nfrom revgpt import AbstractChatGPT\n</code></pre> <ol> <li>Load Environment Variables:</li> </ol> <pre><code>load_dotenv()\n</code></pre> <ol> <li>Initialize the ChatGPT Abstract Class:</li> </ol> <pre><code>chat = AbstractChatGPT(api_key=os.getenv(\"ACCESS_TOKEN\"), **config)\n</code></pre> <ol> <li>Start Interacting with ChatGPT:</li> </ol> <pre><code>response = chat.ask(\"Hello, ChatGPT!\")\nprint(response)\n</code></pre> <p>With the abstract class, you can seamlessly switch between different versions or models of ChatGPT without changing much of your code.</p>"},{"location":"examples/revgpt/#v1-standard-chatgpt","title":"V1 Standard ChatGPT","text":"<p>If you wish to use V1 specifically:</p> <ol> <li>Import the model:</li> </ol> <pre><code>from swarms.models.revgptV1 import RevChatGPTModelv1\n</code></pre> <ol> <li>Initialize:</li> </ol> <pre><code>model = RevChatGPTModelv1(access_token=os.getenv(\"ACCESS_TOKEN\"), **config)\n</code></pre> <ol> <li>Interact:</li> </ol> <pre><code>response = model.run(\"What's the weather like?\")\nprint(response)\n</code></pre>"},{"location":"examples/revgpt/#v3-official-chat-api","title":"V3 Official Chat API","text":"<p>For users looking to integrate the official V3 API:</p> <ol> <li>Import the model:</li> </ol> <pre><code>from swarms.models.revgptV4 import RevChatGPTModelv4\n</code></pre> <ol> <li>Initialize:</li> </ol> <pre><code>model = RevChatGPTModelv4(access_token=os.getenv(\"OPENAI_API_KEY\"), **config)\n</code></pre> <ol> <li>Interact:</li> </ol> <pre><code>response = model.run(\"Tell me a fun fact!\")\nprint(response)\n</code></pre>"},{"location":"examples/revgpt/#credits-disclaimers","title":"Credits &amp; Disclaimers","text":"<ul> <li>This project is not an official OpenAI product and is not affiliated with OpenAI. Use at your own discretion.</li> <li>Many thanks to all the contributors who have made this project possible.</li> <li>Special acknowledgment to virtualharby for the motivating music!</li> </ul> <p>By following this guide, you should now have a clear understanding of how to use the Reverse Engineered ChatGPT API and its abstraction. Happy coding!</p>"},{"location":"examples/stacked_worker/","title":"Tutorial: Understanding and Utilizing Worker Examples","text":""},{"location":"examples/stacked_worker/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction</li> <li>Code Overview</li> <li>Import Statements</li> <li>Initializing API Key and Language Model</li> <li>Creating Swarm Tools</li> <li>Appending Tools to a List</li> <li>Initializing a Worker Node</li> <li>Understanding the <code>hf_agent</code> Tool</li> <li>Understanding the <code>omni_agent</code> Tool</li> <li>Understanding the <code>compile</code> Tool</li> <li>Running a Swarm</li> <li>Interactive Examples</li> <li>Example 1: Initializing API Key and Language Model</li> <li>Example 2: Using the <code>hf_agent</code> Tool</li> <li>Example 3: Using the <code>omni_agent</code> Tool</li> <li>Example 4: Using the <code>compile</code> Tool</li> <li>Conclusion</li> </ol>"},{"location":"examples/stacked_worker/#1-introduction","title":"1. Introduction","text":"<p>The provided code showcases a system built around a worker node that utilizes various AI models and tools to perform tasks. This tutorial will break down the code step by step, explaining its components, how they work together, and how to utilize its modularity for various tasks.</p>"},{"location":"examples/stacked_worker/#2-code-overview","title":"2. Code Overview","text":""},{"location":"examples/stacked_worker/#import-statements","title":"Import Statements","text":"<p>The code begins with import statements, bringing in necessary modules and classes. Key imports include the <code>OpenAIChat</code> class, which represents a language model, and several custom agents and tools from the <code>swarms</code> package.</p> <pre><code>import interpreter  # Assuming this is a custom module\n\nfrom swarms.agents.hf_agents import HFAgent\nfrom swarms.agents.omni_modal_agent import OmniModalAgent\nfrom swarms.models import OpenAIChat\nfrom swarms.tools.autogpt import tool\nfrom swarms.workers import Worker\n</code></pre>"},{"location":"examples/stacked_worker/#initializing-api-key-and-language-model","title":"Initializing API Key and Language Model","text":"<p>Here, an API key is initialized, and a language model (<code>OpenAIChat</code>) is created. This model is capable of generating human-like text based on the provided input.</p> <pre><code># Initialize API Key\napi_key = \"YOUR_OPENAI_API_KEY\"\n\n# Initialize the language model\nllm = OpenAIChat(\n    openai_api_key=api_key,\n    temperature=0.5,\n)\n</code></pre>"},{"location":"examples/stacked_worker/#creating-swarm-tools","title":"Creating Swarm Tools","text":"<p>The code defines three tools: <code>hf_agent</code>, <code>omni_agent</code>, and <code>compile</code>. These tools encapsulate specific functionalities and can be invoked to perform tasks.</p>"},{"location":"examples/stacked_worker/#appending-tools-to-a-list","title":"Appending Tools to a List","text":"<p>All defined tools are appended to a list called <code>tools</code>. This list is later used when initializing a worker node, allowing the node to access and utilize these tools.</p> <pre><code># Append tools to a list\ntools = [hf_agent, omni_agent, compile]\n</code></pre>"},{"location":"examples/stacked_worker/#initializing-a-worker-node","title":"Initializing a Worker Node","text":"<p>A worker node is initialized using the <code>Worker</code> class. The worker node is equipped with the language model, a name, API key, and the list of tools. It's set up to perform tasks without human intervention.</p> <pre><code># Initialize a single Worker node with previously defined tools in addition to its predefined tools\nnode = Worker(\n    llm=llm,\n    ai_name=\"Optimus Prime\",\n    openai_api_key=api_key,\n    ai_role=\"Worker in a swarm\",\n    external_tools=tools,\n    human_in_the_loop=False,\n    temperature=0.5,\n)\n</code></pre>"},{"location":"examples/stacked_worker/#3-understanding-the-hf_agent-tool","title":"3. Understanding the <code>hf_agent</code> Tool","text":"<p>The <code>hf_agent</code> tool utilizes an OpenAI model (<code>text-davinci-003</code>) to perform tasks. It takes a task as input and returns a response. This tool is suitable for multi-modal tasks like generating images, videos, speech, etc. The tool's primary rule is not to be used for simple tasks like generating summaries.</p> <pre><code>@tool\ndef hf_agent(task: str = None):\n    # Create an HFAgent instance with the specified model and API key\n    agent = HFAgent(model=\"text-davinci-003\", api_key=api_key)\n    # Run the agent with the provided task and optional text input\n    response = agent.run(task, text=\"\u00a1Este es un API muy agradable!\")\n    return response\n</code></pre>"},{"location":"examples/stacked_worker/#4-understanding-the-omni_agent-tool","title":"4. Understanding the <code>omni_agent</code> Tool","text":"<p>The <code>omni_agent</code> tool is more versatile and leverages the <code>llm</code> (language model) to interact with Huggingface models for various tasks. It's intended for multi-modal tasks such as document-question-answering, image-captioning, summarization, and more. The tool's rule is also not to be used for simple tasks.</p> <pre><code>@tool\ndef omni_agent(task: str = None):\n    # Create an OmniModalAgent instance with the provided language model\n    agent = OmniModalAgent(llm)\n    # Run the agent with the provided task\n    response = agent.run(task)\n    return response\n</code></pre>"},{"location":"examples/stacked_worker/#5-understanding-the-compile-tool","title":"5. Understanding the <code>compile</code> Tool","text":"<p>The <code>compile</code> tool allows the execution of code locally, supporting various programming languages like Python, JavaScript, and Shell. It provides a natural language interface to your computer's capabilities. Users can chat with this tool in a terminal-like interface to perform tasks such as creating and editing files, controlling a browser, and more.</p> <pre><code>@tool\ndef compile(task: str):\n    # Use the interpreter module to chat with the local interpreter\n    task = interpreter.chat(task, return_messages=True)\n    interpreter.chat()\n    interpreter.reset(task)\n\n    # Set environment variables for the interpreter\n    os.environ[\"INTERPRETER_CLI_AUTO_RUN\"] = True\n    os.environ[\"INTERPRETER_CLI_FAST_MODE\"] = True\n    os.environ[\"INTERPRETER_CLI_DEBUG\"] = True\n</code></pre>"},{"location":"examples/stacked_worker/#6-running-a-swarm","title":"6. Running a Swarm","text":"<p>After defining tools and initializing the worker node, a specific task is provided as input to the worker node. The node then runs the task, and the response is printed to the console.</p> <pre><code># Specify the task\ntask = \"What were the winning Boston Marathon times for the past 5 years (ending in 2022)? Generate a table of the year, name, country of origin, and times.\"\n\n# Run the node on the task\nresponse = node.run(task)\n\n# Print the response\nprint(response)\n</code></pre>"},{"location":"examples/stacked_worker/#full-code","title":"Full Code","text":"<ul> <li>The full code example of stacked swarms</li> </ul> <pre><code>import os\n\nimport interpreter\n\nfrom swarms.agents.hf_agents import HFAgent\nfrom swarms.agents.omni_modal_agent import OmniModalAgent\nfrom swarms.models import OpenAIChat\nfrom swarms.tools.autogpt import tool\nfrom swarms.workers import Worker\n\n# Initialize API Key\napi_key = \"\"\n\n\n# Initialize the language model,\n# This model can be swapped out with Anthropic, ETC, Huggingface Models like Mistral, ETC\nllm = OpenAIChat(\n    openai_api_key=api_key,\n    temperature=0.5,\n)\n\n\n# wrap a function with the tool decorator to make it a tool, then add docstrings for tool documentation\n@tool\ndef hf_agent(task: str = None):\n    \"\"\"\n    An tool that uses an openai model to call and respond to a task by search for a model on huggingface\n    It first downloads the model then uses it.\n\n    Rules: Don't call this model for simple tasks like generating a summary, only call this tool for multi modal tasks like generating images, videos, speech, etc\n\n    \"\"\"\n    agent = HFAgent(model=\"text-davinci-003\", api_key=api_key)\n    response = agent.run(task, text=\"\u00a1Este es un API muy agradable!\")\n    return response\n\n\n# wrap a function with the tool decorator to make it a tool\n@tool\ndef omni_agent(task: str = None):\n    \"\"\"\n    An tool that uses an openai Model to utilize and call huggingface models and guide them to perform a task.\n\n    Rules: Don't call this model for simple tasks like generating a summary, only call this tool for multi modal tasks like generating images, videos, speech\n    The following tasks are what this tool should be used for:\n\n    Tasks omni agent is good for:\n    --------------\n    document-question-answering\n    image-captioning\n    image-question-answering\n    image-segmentation\n    speech-to-text\n    summarization\n    text-classification\n    text-question-answering\n    translation\n    huggingface-tools/text-to-image\n    huggingface-tools/text-to-video\n    text-to-speech\n    huggingface-tools/text-download\n    huggingface-tools/image-transformation\n    \"\"\"\n    agent = OmniModalAgent(llm)\n    response = agent.run(task)\n    return response\n\n\n# Code Interpreter\n@tool\ndef compile(task: str):\n    \"\"\"\n    Open Interpreter lets LLMs run code (Python, Javascript, Shell, and more) locally.\n    You can chat with Open Interpreter through a ChatGPT-like interface in your terminal\n    by running $ interpreter after installing.\n\n    This provides a natural-language interface to your computer's general-purpose capabilities:\n\n    Create and edit photos, videos, PDFs, etc.\n    Control a Chrome browser to perform research\n    Plot, clean, and analyze large datasets\n    ...etc.\n    \u26a0\ufe0f Note: You'll be asked to approve code before it's run.\n\n    Rules: Only use when given to generate code or an application of some kind\n    \"\"\"\n    task = interpreter.chat(task, return_messages=True)\n    interpreter.chat()\n    interpreter.reset(task)\n\n    os.environ[\"INTERPRETER_CLI_AUTO_RUN\"] = True\n    os.environ[\"INTERPRETER_CLI_FAST_MODE\"] = True\n    os.environ[\"INTERPRETER_CLI_DEBUG\"] = True\n\n\n# Append tools to an list\ntools = [hf_agent, omni_agent, compile]\n\n\n# Initialize a single Worker node with previously defined tools in addition to it's\n# predefined tools\nnode = Worker(\n    llm=llm,\n    ai_name=\"Optimus Prime\",\n    openai_api_key=api_key,\n    ai_role=\"Worker in a swarm\",\n    external_tools=tools,\n    human_in_the_loop=False,\n    temperature=0.5,\n)\n\n# Specify task\ntask = \"What were the winning boston marathon times for the past 5 years (ending in 2022)? Generate a table of the year, name, country of origin, and times.\"\n\n# Run the node on the task\nresponse = node.run(task)\n\n# Print the response\nprint(response)\n</code></pre>"},{"location":"examples/stacked_worker/#8-conclusion","title":"8. Conclusion","text":"<p>In this extensive tutorial, we've embarked on a journey to explore a sophisticated system designed to harness the power of AI models and tools for a myriad of tasks. We've peeled back the layers of code, dissected its various components, and gained a profound understanding of how these elements come together to create a versatile, modular, and powerful swarm-based AI system.</p>"},{"location":"examples/stacked_worker/#what-weve-learned","title":"What We've Learned","text":"<p>Throughout this tutorial, we've covered the following key aspects:</p>"},{"location":"examples/stacked_worker/#code-structure-and-components","title":"Code Structure and Components","text":"<p>We dissected the code into its fundamental building blocks: - Import Statements: We imported necessary modules and libraries, setting the stage for our system's functionality. - Initializing API Key and Language Model: We learned how to set up the essential API key and initialize the language model, a core component for text generation and understanding. - Creating Swarm Tools: We explored how to define tools, encapsulating specific functionalities that our system can leverage. - Appending Tools to a List: We aggregated our tools into a list, making them readily available for use. - Initializing a Worker Node: We created a worker node equipped with tools, a name, and configuration settings.</p>"},{"location":"examples/stacked_worker/#tools-and-their-functions","title":"Tools and Their Functions","text":"<p>We dove deep into the purpose and functionality of three crucial tools: - <code>hf_agent</code>: We understood how this tool employs an OpenAI model for multi-modal tasks, and its use cases beyond simple summarization. - <code>omni_agent</code>: We explored the versatility of this tool, guiding Huggingface models to perform a wide range of multi-modal tasks. - <code>compile</code>: We saw how this tool allows the execution of code in multiple languages, providing a natural language interface for various computational tasks.</p>"},{"location":"examples/stacked_worker/#interactive-examples","title":"Interactive Examples","text":"<p>We brought the code to life through interactive examples, showcasing how to initialize the language model, generate text, perform document-question-answering, and execute code\u2014all with practical, real-world scenarios.</p>"},{"location":"examples/stacked_worker/#a-recap-the-worker-nodes-role","title":"A Recap: The Worker Node's Role","text":"<p>At the heart of this system lies the \"Worker Node,\" a versatile entity capable of wielding the power of AI models and tools to accomplish tasks. The Worker Node's role is pivotal in the following ways:</p> <ol> <li> <p>Task Execution: It is responsible for executing tasks, harnessing the capabilities of the defined tools to generate responses or perform actions.</p> </li> <li> <p>Modularity: The Worker Node benefits from the modularity of the system. It can easily access and utilize a variety of tools, allowing it to adapt to diverse tasks and requirements.</p> </li> <li> <p>Human in the Loop: While the example here is configured to operate without human intervention, the Worker Node can be customized to incorporate human input or approval when needed.</p> </li> <li> <p>Integration: It can be extended to integrate with other AI models, APIs, or services, expanding its functionality and versatility.</p> </li> </ol>"},{"location":"examples/stacked_worker/#the-road-ahead-future-features-and-enhancements","title":"The Road Ahead: Future Features and Enhancements","text":"<p>As we conclude this tutorial, let's peek into the future of this system. While the current implementation is already powerful, there is always room for growth and improvement. Here are some potential future features and enhancements to consider:</p>"},{"location":"examples/stacked_worker/#1-enhanced-natural-language-understanding","title":"1. Enhanced Natural Language Understanding","text":"<ul> <li>Semantic Understanding: Improve the system's ability to understand context and nuances in natural language, enabling more accurate responses.</li> </ul>"},{"location":"examples/stacked_worker/#2-multimodal-capabilities","title":"2. Multimodal Capabilities","text":"<ul> <li>Extended Multimodal Support: Expand the <code>omni_agent</code> tool to support additional types of multimodal tasks, such as video generation or audio processing.</li> </ul>"},{"location":"examples/stacked_worker/#3-customization-and-integration","title":"3. Customization and Integration","text":"<ul> <li>User-defined Tools: Allow users to define their own custom tools, opening up endless possibilities for tailoring the system to specific needs.</li> </ul>"},{"location":"examples/stacked_worker/#4-collaborative-swarms","title":"4. Collaborative Swarms","text":"<ul> <li>Swarm Collaboration: Enable multiple Worker Nodes to collaborate on complex tasks, creating a distributed, intelligent swarm system.</li> </ul>"},{"location":"examples/stacked_worker/#5-user-friendly-interfaces","title":"5. User-Friendly Interfaces","text":"<ul> <li>Graphical User Interface (GUI): Develop a user-friendly GUI for easier interaction and task management, appealing to a wider audience.</li> </ul>"},{"location":"examples/stacked_worker/#6-continuous-learning","title":"6. Continuous Learning","text":"<ul> <li>Active Learning: Implement mechanisms for the system to learn and adapt over time, improving its performance with each task.</li> </ul>"},{"location":"examples/stacked_worker/#7-security-and-privacy","title":"7. Security and Privacy","text":"<ul> <li>Enhanced Security: Implement robust security measures to safeguard sensitive data and interactions within the system.</li> </ul>"},{"location":"examples/stacked_worker/#8-community-and-collaboration","title":"8. Community and Collaboration","text":"<ul> <li>Open Source Community: Foster an open-source community around the system, encouraging contributions and innovation from developers worldwide.</li> </ul>"},{"location":"examples/stacked_worker/#9-integration-with-emerging-technologies","title":"9. Integration with Emerging Technologies","text":"<ul> <li>Integration with Emerging AI Models: Keep the system up-to-date by seamlessly integrating with new and powerful AI models as they emerge in the industry.</li> </ul>"},{"location":"examples/stacked_worker/#in-conclusion","title":"In Conclusion","text":"<p>In this tutorial, we've journeyed through a complex AI system, unraveling its inner workings, and understanding its potential. We've witnessed how code can transform into a powerful tool, capable of handling a vast array of tasks, from generating creative stories to executing code snippets.</p> <p>As we conclude, we stand at the threshold of an exciting future for AI and technology. This system, with its modular design and the potential for continuous improvement, embodies the spirit of innovation and adaptability. Whether you're a developer, a researcher, or an enthusiast, the possibilities are boundless, and the journey is just beginning.</p> <p>Embrace this knowledge, explore the system, and embark on your own quest to shape the future of AI. With each line of code, you have the power to transform ideas into reality and unlock new horizons of innovation. The future is yours to create, and the tools are at your fingertips.</p>"},{"location":"examples/worker/","title":"The Ultimate Guide to Mastering the <code>Worker</code> Class from Swarms","text":"<p>Table of Contents</p> <ol> <li>Introduction: Welcome to the World of the Worker</li> <li>The Basics: What Does the Worker Do?</li> <li>Installation: Setting the Stage</li> <li>Dive Deep: Understanding the Architecture</li> <li>Practical Usage: Let's Get Rolling!</li> <li>Advanced Tips and Tricks</li> <li>Handling Errors: Because We All Slip Up Sometimes</li> <li>Beyond the Basics: Advanced Features and Customization</li> <li>Conclusion: Taking Your Knowledge Forward</li> </ol> <p>1. Introduction: Welcome to the World of the Worker</p> <p>Greetings, future master of the <code>Worker</code>! Step into a universe where you can command an AI worker to perform intricate tasks, be it searching the vast expanse of the internet or crafting multi-modality masterpieces. Ready to embark on this thrilling journey? Let\u2019s go!</p> <p>2. The Basics: What Does the Worker Do?</p> <p>The <code>Worker</code> is your personal AI assistant. Think of it as a diligent bee in a swarm, ready to handle complex tasks across various modalities, from text and images to audio and beyond.</p> <p>3. Installation: Setting the Stage</p> <p>Before we can call upon our Worker, we need to set the stage:</p> <pre><code>pip install swarms\n</code></pre> <p>Voila! You\u2019re now ready to summon your Worker.</p> <p>4. Dive Deep: Understanding the Architecture</p> <ul> <li>Language Model (LLM): The brain of our Worker. It understands and crafts intricate language-based responses.</li> <li>Tools: Think of these as the Worker's toolkit. They range from file tools, website querying, to even complex tasks like image captioning.</li> <li>Memory: No, our Worker doesn\u2019t forget. It employs a sophisticated memory mechanism to remember past interactions and learn from them.</li> </ul> <p>5. Practical Usage: Let's Get Rolling!</p> <p>Here\u2019s a simple way to invoke the Worker and give it a task:</p> <pre><code>from swarms import Worker\nfrom swarms.models import OpenAIChat\n\nllm = OpenAIChat(\n    # enter your api key\n    openai_api_key=\"\",\n    temperature=0.5,\n)\n\nnode = Worker(\n    llm=llm,\n    ai_name=\"Optimus Prime\",\n    openai_api_key=\"\",\n    ai_role=\"Worker in a swarm\",\n    external_tools=None,\n    human_in_the_loop=False,\n    temperature=0.5,\n)\n\ntask = \"What were the winning boston marathon times for the past 5 years (ending in 2022)? Generate a table of the year, name, country of origin, and times.\"\nresponse = node.run(task)\nprint(response)\n</code></pre> <p>The result? An agent with elegantly integrated tools and long term memories</p> <p>6. Advanced Tips and Tricks</p> <ul> <li>Streaming Responses: Want your Worker to respond in a more dynamic fashion? Use the <code>_stream_response</code> method to get results token by token.</li> <li>Human-in-the-Loop: By setting <code>human_in_the_loop</code> to <code>True</code>, you can involve a human in the decision-making process, ensuring the best results.</li> </ul> <p>7. Handling Errors: Because We All Slip Up Sometimes</p> <p>Your Worker is designed to be robust. But if it ever encounters a hiccup, it's equipped to let you know. Error messages are crafted to be informative, guiding you on the next steps.</p> <p>8. Beyond the Basics: Advanced Features and Customization</p> <ul> <li>Custom Tools: Want to expand the Worker's toolkit? Use the <code>external_tools</code> parameter to integrate your custom tools.</li> <li>Memory Customization: You can tweak the Worker's memory settings, ensuring it remembers what's crucial for your tasks.</li> </ul> <p>9. Conclusion: Taking Your Knowledge Forward</p> <p>Congratulations! You\u2019re now well-equipped to harness the power of the <code>Worker</code> from Swarms. As you venture further, remember: the possibilities are endless, and with the Worker by your side, there\u2019s no task too big!</p> <p>Happy Coding and Exploring! \ud83d\ude80\ud83c\udf89</p> <p>Note: This guide provides a stepping stone to the vast capabilities of the <code>Worker</code>. Dive into the official documentation for a deeper understanding and stay updated with the latest features.</p>"},{"location":"features/20swarms/","title":"20swarms","text":"<pre><code># Swarm Alpha: Data Cruncher\n**Overview**: Processes large datasets.  \n**Strengths**: Efficient data handling.  \n**Weaknesses**: Requires structured data.  \n\n**Pseudo Code**:\n```sql\nFOR each data_entry IN dataset:\n    result = PROCESS(data_entry)\n    STORE(result)\nEND FOR\nRETURN aggregated_results\n</code></pre>"},{"location":"features/20swarms/#swarm-beta-artistic-ally","title":"Swarm Beta: Artistic Ally","text":"<p>Overview: Generates art pieces. Strengths: Creativity. Weaknesses: Somewhat unpredictable.  </p> <p>Pseudo Code: <pre><code>INITIATE canvas_parameters\nSELECT art_style\nDRAW(canvas_parameters, art_style)\nRETURN finished_artwork\n</code></pre></p>"},{"location":"features/20swarms/#swarm-gamma-sound-sculptor","title":"Swarm Gamma: Sound Sculptor","text":"<p>Overview: Crafts audio sequences. Strengths: Diverse audio outputs. Weaknesses: Complexity in refining outputs.  </p> <p>Pseudo Code: <pre><code>DEFINE sound_parameters\nSELECT audio_style\nGENERATE_AUDIO(sound_parameters, audio_style)\nRETURN audio_sequence\n</code></pre></p>"},{"location":"features/20swarms/#swarm-delta-web-weaver","title":"Swarm Delta: Web Weaver","text":"<p>Overview: Constructs web designs. Strengths: Modern design sensibility. Weaknesses: Limited to web interfaces.  </p> <p>Pseudo Code: <pre><code>SELECT template\nAPPLY user_preferences(template)\nDESIGN_web(template, user_preferences)\nRETURN web_design\n</code></pre></p>"},{"location":"features/20swarms/#swarm-epsilon-code-compiler","title":"Swarm Epsilon: Code Compiler","text":"<p>Overview: Writes and compiles code snippets. Strengths: Quick code generation. Weaknesses: Limited to certain programming languages.  </p> <p>Pseudo Code: <pre><code>DEFINE coding_task\nWRITE_CODE(coding_task)\nCOMPILE(code)\nRETURN executable\n</code></pre></p>"},{"location":"features/20swarms/#swarm-zeta-security-shield","title":"Swarm Zeta: Security Shield","text":"<p>Overview: Detects system vulnerabilities. Strengths: High threat detection rate. Weaknesses: Potential false positives.  </p> <p>Pseudo Code: <pre><code>MONITOR system_activity\nIF suspicious_activity_detected:\n    ANALYZE threat_level\n    INITIATE mitigation_protocol\nEND IF\nRETURN system_status\n</code></pre></p>"},{"location":"features/20swarms/#swarm-eta-researcher-relay","title":"Swarm Eta: Researcher Relay","text":"<p>Overview: Gathers and synthesizes research data. Strengths: Access to vast databases. Weaknesses: Depth of research can vary.  </p> <p>Pseudo Code: <pre><code>DEFINE research_topic\nSEARCH research_sources(research_topic)\nSYNTHESIZE findings\nRETURN research_summary\n</code></pre></p>"},{"location":"features/20swarms/#swarm-theta-sentiment-scanner","title":"Swarm Theta: Sentiment Scanner","text":"<p>Overview: Analyzes text for sentiment and emotional tone. Strengths: Accurate sentiment detection. Weaknesses: Contextual nuances might be missed.  </p> <p>Pseudo Code: <pre><code>INPUT text_data\nANALYZE text_data FOR emotional_tone\nDETERMINE sentiment_value\nRETURN sentiment_value\n</code></pre></p>"},{"location":"features/20swarms/#swarm-iota-image-interpreter","title":"Swarm Iota: Image Interpreter","text":"<p>Overview: Processes and categorizes images. Strengths: High image recognition accuracy. Weaknesses: Can struggle with abstract visuals.  </p> <p>Pseudo Code: <pre><code>LOAD image_data\nPROCESS image_data FOR features\nCATEGORIZE image_based_on_features\nRETURN image_category\n</code></pre></p>"},{"location":"features/20swarms/#swarm-kappa-language-learner","title":"Swarm Kappa: Language Learner","text":"<p>Overview: Translates and interprets multiple languages. Strengths: Supports multiple languages. Weaknesses: Nuances in dialects might pose challenges.  </p> <p>Pseudo Code: <pre><code>RECEIVE input_text, target_language\nTRANSLATE input_text TO target_language\nRETURN translated_text\n</code></pre></p>"},{"location":"features/20swarms/#swarm-lambda-trend-tracker","title":"Swarm Lambda: Trend Tracker","text":"<p>Overview: Monitors and predicts trends based on data. Strengths: Proactive trend identification. Weaknesses: Requires continuous data stream.  </p> <p>Pseudo Code: <pre><code>COLLECT data_over_time\nANALYZE data_trends\nPREDICT upcoming_trends\nRETURN trend_forecast\n</code></pre></p>"},{"location":"features/20swarms/#swarm-mu-financial-forecaster","title":"Swarm Mu: Financial Forecaster","text":"<p>Overview: Analyzes financial data to predict market movements. Strengths: In-depth financial analytics. Weaknesses: Market volatility can affect predictions.  </p> <p>Pseudo Code: <pre><code>GATHER financial_data\nCOMPUTE statistical_analysis\nFORECAST market_movements\nRETURN financial_projections\n</code></pre></p>"},{"location":"features/20swarms/#swarm-nu-network-navigator","title":"Swarm Nu: Network Navigator","text":"<p>Overview: Optimizes and manages network traffic. Strengths: Efficient traffic management. Weaknesses: Depends on network infrastructure.  </p> <p>Pseudo Code: <pre><code>MONITOR network_traffic\nIDENTIFY congestion_points\nOPTIMIZE traffic_flow\nRETURN network_status\n</code></pre></p>"},{"location":"features/20swarms/#swarm-xi-content-curator","title":"Swarm Xi: Content Curator","text":"<p>Overview: Gathers and presents content based on user preferences. Strengths: Personalized content delivery. Weaknesses: Limited by available content sources.  </p> <p>Pseudo Code: <pre><code>DEFINE user_preferences\nSEARCH content_sources\nFILTER content_matching_preferences\nDISPLAY curated_content\n</code></pre></p>"},{"location":"features/SMAPS/","title":"Swarms Multi-Agent Permissions System (SMAPS)","text":""},{"location":"features/SMAPS/#description","title":"Description","text":"<p>SMAPS is a robust permissions management system designed to integrate seamlessly with Swarm's multi-agent AI framework. Drawing inspiration from Amazon's IAM, SMAPS ensures secure, granular control over agent actions while allowing for collaborative human-in-the-loop interventions.</p>"},{"location":"features/SMAPS/#technical-specification","title":"Technical Specification","text":""},{"location":"features/SMAPS/#1-components","title":"1. Components","text":"<ul> <li>User Management: Handle user registrations, roles, and profiles.</li> <li>Agent Management: Register, monitor, and manage AI agents.</li> <li>Permissions Engine: Define and enforce permissions based on roles.</li> <li>Multiplayer Interface: Allows multiple human users to intervene, guide, or collaborate on tasks being executed by AI agents.</li> </ul>"},{"location":"features/SMAPS/#2-features","title":"2. Features","text":"<ul> <li>Role-Based Access Control (RBAC):</li> <li>Users can be assigned predefined roles (e.g., Admin, Agent Supervisor, Collaborator).</li> <li> <p>Each role has specific permissions associated with it, defining what actions can be performed on AI agents or tasks.</p> </li> <li> <p>Dynamic Permissions:</p> </li> <li>Create custom roles with specific permissions.</li> <li> <p>Permissions granularity: From broad (e.g., view all tasks) to specific (e.g., modify parameters of a particular agent).</p> </li> <li> <p>Multiplayer Collaboration:</p> </li> <li>Multiple users can join a task in real-time.</li> <li>Collaborators can provide real-time feedback or guidance to AI agents.</li> <li> <p>A voting system for decision-making when human intervention is required.</p> </li> <li> <p>Agent Supervision:</p> </li> <li>Monitor agent actions in real-time.</li> <li> <p>Intervene, if necessary, to guide agent actions based on permissions.</p> </li> <li> <p>Audit Trail:</p> </li> <li>All actions, whether performed by humans or AI agents, are logged.</li> <li>Review historical actions, decisions, and interventions for accountability and improvement.</li> </ul>"},{"location":"features/SMAPS/#3-security","title":"3. Security","text":"<ul> <li>Authentication: Secure login mechanisms with multi-factor authentication options.</li> <li>Authorization: Ensure users and agents can only perform actions they are permitted to.</li> <li>Data Encryption: All data, whether at rest or in transit, is encrypted using industry-standard protocols.</li> </ul>"},{"location":"features/SMAPS/#4-integration","title":"4. Integration","text":"<ul> <li>APIs: Expose APIs for integrating SMAPS with other systems or for extending its capabilities.</li> <li>SDK: Provide software development kits for popular programming languages to facilitate integration and extension.</li> </ul>"},{"location":"features/SMAPS/#documentation-description","title":"Documentation Description","text":"<p>Swarms Multi-Agent Permissions System (SMAPS) offers a sophisticated permissions management mechanism tailored for multi-agent AI frameworks. It combines the robustness of Amazon IAM-like permissions with a unique \"multiplayer\" feature, allowing multiple humans to collaboratively guide AI agents in real-time. This ensures not only that tasks are executed efficiently but also that they uphold the highest standards of accuracy and ethics. With SMAPS, businesses can harness the power of swarms with confidence, knowing that they have full control and transparency over their AI operations.</p>"},{"location":"features/agent_archive/","title":"AgentArchive Documentation","text":""},{"location":"features/agent_archive/#swarms-multi-agent-framework","title":"Swarms Multi-Agent Framework","text":"<p>AgentArchive is an advanced feature crafted to archive, bookmark, and harness the transcripts of agent runs. It promotes the storing and leveraging of successful agent interactions, offering a powerful means for users to derive \"recipes\" for future agents. Furthermore, with its public archive feature, users can contribute to and benefit from the collective wisdom of the community.</p>"},{"location":"features/agent_archive/#overview","title":"Overview:","text":"<p>AgentArchive empowers users to: 1. Preserve complete transcripts of agent instances. 2. Bookmark and annotate significant runs. 3. Categorize runs using various tags. 4. Transform successful runs into actionable \"recipes\". 5. Publish and access a shared knowledge base via a public archive.</p>"},{"location":"features/agent_archive/#features","title":"Features:","text":""},{"location":"features/agent_archive/#1-archiving","title":"1. Archiving:","text":"<ul> <li>Save Transcripts: Retain the full narrative of an agent's interaction and choices.</li> <li>Searchable Database: Dive into archives using specific keywords, timestamps, or tags.</li> </ul>"},{"location":"features/agent_archive/#2-bookmarking","title":"2. Bookmarking:","text":"<ul> <li>Highlight Essential Runs: Designate specific agent runs for future reference.</li> <li>Annotations: Embed notes or remarks to bookmarked runs for clearer understanding.</li> </ul>"},{"location":"features/agent_archive/#3-tagging","title":"3. Tagging:","text":"<p>Organize and classify agent runs via: - Prompt: The originating instruction that triggered the agent run. - Tasks: Distinct tasks or operations executed by the agent. - Model: The specific AI model or iteration used during the interaction. - Temperature (Temp): The set randomness or innovation level for the agent.</p>"},{"location":"features/agent_archive/#4-recipe-generation","title":"4. Recipe Generation:","text":"<ul> <li>Standardization: Convert successful run transcripts into replicable \"recipes\".</li> <li>Guidance: Offer subsequent agents a structured approach, rooted in prior successes.</li> <li>Evolution: Periodically refine recipes based on newer, enhanced runs.</li> </ul>"},{"location":"features/agent_archive/#5-public-archive-sharing","title":"5. Public Archive &amp; Sharing:","text":"<ul> <li>Publish Successful Runs: Users can choose to share their successful agent runs.</li> <li>Collaborative Knowledge Base: Access a shared repository of successful agent interactions from the community.</li> <li>Ratings &amp; Reviews: Users can rate and review shared runs, highlighting particularly effective \"recipes.\"</li> <li>Privacy &amp; Redaction: Ensure that any sensitive information is automatically redacted before publishing.</li> </ul>"},{"location":"features/agent_archive/#benefits","title":"Benefits:","text":"<ol> <li>Efficiency: Revisit past agent activities to inform and guide future decisions.</li> <li>Consistency: Guarantee a uniform approach to recurring challenges, leading to predictable and trustworthy outcomes.</li> <li>Collaborative Learning: Tap into a reservoir of shared experiences, fostering community-driven learning and growth.</li> <li>Transparency: By sharing successful runs, users can build trust and contribute to the broader community's success.</li> </ol>"},{"location":"features/agent_archive/#usage","title":"Usage:","text":"<ol> <li>Access AgentArchive: Navigate to the dedicated section within the Swarms Multi-Agent Framework dashboard.</li> <li>Search, Filter &amp; Organize: Utilize the search bar and tagging system for precise retrieval.</li> <li>Bookmark, Annotate &amp; Share: Pin important runs, add notes, and consider sharing with the broader community.</li> <li>Engage with Public Archive: Explore, rate, and apply shared knowledge to enhance agent performance.</li> </ol> <p>With AgentArchive, users not only benefit from their past interactions but can also leverage the collective expertise of the Swarms community, ensuring continuous improvement and shared success.</p>"},{"location":"features/fail_protocol/","title":"Swarms Multi-Agent Framework Documentation","text":""},{"location":"features/fail_protocol/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Agent Failure Protocol</li> <li>Swarm Failure Protocol</li> </ul>"},{"location":"features/fail_protocol/#agent-failure-protocol","title":"Agent Failure Protocol","text":""},{"location":"features/fail_protocol/#1-overview","title":"1. Overview","text":"<p>Agent failures may arise from bugs, unexpected inputs, or external system changes. This protocol aims to diagnose, address, and prevent such failures.</p>"},{"location":"features/fail_protocol/#2-root-cause-analysis","title":"2. Root Cause Analysis","text":"<ul> <li>Data Collection: Record the task, inputs, and environmental variables present during the failure.</li> <li>Diagnostic Tests: Run the agent in a controlled environment replicating the failure scenario.</li> <li>Error Logging: Analyze error logs to identify patterns or anomalies.</li> </ul>"},{"location":"features/fail_protocol/#3-solution-brainstorming","title":"3. Solution Brainstorming","text":"<ul> <li>Code Review: Examine the code sections linked to the failure for bugs or inefficiencies.</li> <li>External Dependencies: Check if external systems or data sources have changed.</li> <li>Algorithmic Analysis: Evaluate if the agent's algorithms were overwhelmed or faced an unhandled scenario.</li> </ul>"},{"location":"features/fail_protocol/#4-risk-analysis-solution-ranking","title":"4. Risk Analysis &amp; Solution Ranking","text":"<ul> <li>Assess the potential risks associated with each solution.</li> <li>Rank solutions based on:</li> <li>Implementation complexity</li> <li>Potential negative side effects</li> <li>Resource requirements</li> <li>Assign a success probability score (0.0 to 1.0) based on the above factors.</li> </ul>"},{"location":"features/fail_protocol/#5-solution-implementation","title":"5. Solution Implementation","text":"<ul> <li>Implement the top 3 solutions sequentially, starting with the highest success probability.</li> <li>If all three solutions fail, trigger the \"Human-in-the-Loop\" protocol.</li> </ul>"},{"location":"features/fail_protocol/#swarm-failure-protocol","title":"Swarm Failure Protocol","text":""},{"location":"features/fail_protocol/#1-overview_1","title":"1. Overview","text":"<p>Swarm failures are more complex, often resulting from inter-agent conflicts, systemic bugs, or large-scale environmental changes. This protocol delves deep into such failures to ensure the swarm operates optimally.</p>"},{"location":"features/fail_protocol/#2-root-cause-analysis_1","title":"2. Root Cause Analysis","text":"<ul> <li>Inter-Agent Analysis: Examine if agents were in conflict or if there was a breakdown in collaboration.</li> <li>System Health Checks: Ensure all system components supporting the swarm are operational.</li> <li>Environment Analysis: Investigate if external factors or systems impacted the swarm's operation.</li> </ul>"},{"location":"features/fail_protocol/#3-solution-brainstorming_1","title":"3. Solution Brainstorming","text":"<ul> <li>Collaboration Protocols: Review and refine how agents collaborate.</li> <li>Resource Allocation: Check if the swarm had adequate computational and memory resources.</li> <li>Feedback Loops: Ensure agents are effectively learning from each other.</li> </ul>"},{"location":"features/fail_protocol/#4-risk-analysis-solution-ranking_1","title":"4. Risk Analysis &amp; Solution Ranking","text":"<ul> <li>Assess the potential systemic risks posed by each solution.</li> <li>Rank solutions considering:</li> <li>Scalability implications</li> <li>Impact on individual agents</li> <li>Overall swarm performance potential</li> <li>Assign a success probability score (0.0 to 1.0) based on the above considerations.</li> </ul>"},{"location":"features/fail_protocol/#5-solution-implementation_1","title":"5. Solution Implementation","text":"<ul> <li>Implement the top 3 solutions sequentially, prioritizing the one with the highest success probability.</li> <li>If all three solutions are unsuccessful, invoke the \"Human-in-the-Loop\" protocol for expert intervention.</li> </ul> <p>By following these protocols, the Swarms Multi-Agent Framework can systematically address and prevent failures, ensuring a high degree of reliability and efficiency.</p>"},{"location":"features/human_in_loop/","title":"Human-in-the-Loop Task Handling Protocol","text":""},{"location":"features/human_in_loop/#overview","title":"Overview","text":"<p>The Swarms Multi-Agent Framework recognizes the invaluable contributions humans can make, especially in complex scenarios where nuanced judgment is required. The \"Human-in-the-Loop Task Handling Protocol\" ensures that when agents encounter challenges they cannot handle autonomously, the most capable human collaborator is engaged to provide guidance, based on their skills and expertise.</p>"},{"location":"features/human_in_loop/#protocol-steps","title":"Protocol Steps","text":""},{"location":"features/human_in_loop/#1-task-initiation-analysis","title":"1. Task Initiation &amp; Analysis","text":"<ul> <li>When a task is initiated, agents first analyze the task's requirements.</li> <li>The system maintains an understanding of each task's complexity, requirements, and potential challenges.</li> </ul>"},{"location":"features/human_in_loop/#2-automated-resolution-attempt","title":"2. Automated Resolution Attempt","text":"<ul> <li>Agents first attempt to resolve the task autonomously using their algorithms and data.</li> <li>If the task can be completed without issues, it progresses normally.</li> </ul>"},{"location":"features/human_in_loop/#3-challenge-detection","title":"3. Challenge Detection","text":"<ul> <li>If agents encounter challenges or uncertainties they cannot resolve, the \"Human-in-the-Loop\" protocol is triggered.</li> </ul>"},{"location":"features/human_in_loop/#4-human-collaborator-identification","title":"4. Human Collaborator Identification","text":"<ul> <li>The system maintains a dynamic profile of each human collaborator, cataloging their skills, expertise, and past performance on related tasks.</li> <li>Using this profile data, the system identifies the most capable human collaborator to assist with the current challenge.</li> </ul>"},{"location":"features/human_in_loop/#5-real-time-collaboration","title":"5. Real-time Collaboration","text":"<ul> <li>The identified human collaborator is notified and provided with all the relevant information about the task and the challenge.</li> <li>Collaborators can provide guidance, make decisions, or even take over specific portions of the task.</li> </ul>"},{"location":"features/human_in_loop/#6-task-completion-feedback-loop","title":"6. Task Completion &amp; Feedback Loop","text":"<ul> <li>Once the challenge is resolved, agents continue with the task until completion.</li> <li>Feedback from human collaborators is used to update agent algorithms, ensuring continuous learning and improvement.</li> </ul>"},{"location":"features/human_in_loop/#best-practices","title":"Best Practices","text":"<ol> <li>Maintain Up-to-date Human Profiles: Ensure that the skillsets, expertise, and performance metrics of human collaborators are updated regularly.</li> <li>Limit Interruptions: Implement mechanisms to limit the frequency of human interventions, ensuring collaborators are not overwhelmed with requests.</li> <li>Provide Context: When seeking human intervention, provide collaborators with comprehensive context to ensure they can make informed decisions.</li> <li>Continuous Training: Regularly update and train agents based on feedback from human collaborators.</li> <li>Measure &amp; Optimize: Monitor the efficiency of the \"Human-in-the-Loop\" protocol, aiming to reduce the frequency of interventions while maximizing the value of each intervention.</li> <li>Skill Enhancement: Encourage human collaborators to continuously enhance their skills, ensuring that the collective expertise of the group grows over time.</li> </ol>"},{"location":"features/human_in_loop/#conclusion","title":"Conclusion","text":"<p>The integration of human expertise with AI capabilities is a cornerstone of the Swarms Multi-Agent Framework. This \"Human-in-the-Loop Task Handling Protocol\" ensures that tasks are executed efficiently, leveraging the best of both human judgment and AI automation. Through collaborative synergy, we can tackle challenges more effectively and drive innovation.</p>"},{"location":"features/info_sec/","title":"Secure Communication Protocols","text":""},{"location":"features/info_sec/#overview","title":"Overview","text":"<p>The Swarms Multi-Agent Framework prioritizes the security and integrity of data, especially personal and sensitive information. Our Secure Communication Protocols ensure that all communications between agents are encrypted, authenticated, and resistant to tampering or unauthorized access.</p>"},{"location":"features/info_sec/#features","title":"Features","text":""},{"location":"features/info_sec/#1-end-to-end-encryption","title":"1. End-to-End Encryption","text":"<ul> <li>All inter-agent communications are encrypted using state-of-the-art cryptographic algorithms.</li> <li>This ensures that data remains confidential and can only be read by the intended recipient agent.</li> </ul>"},{"location":"features/info_sec/#2-authentication","title":"2. Authentication","text":"<ul> <li>Before initiating communication, agents authenticate each other using digital certificates.</li> <li>This prevents impersonation attacks and ensures that agents are communicating with legitimate counterparts.</li> </ul>"},{"location":"features/info_sec/#3-forward-secrecy","title":"3. Forward Secrecy","text":"<ul> <li>Key exchange mechanisms employ forward secrecy, meaning that even if a malicious actor gains access to an encryption key, they cannot decrypt past communications.</li> </ul>"},{"location":"features/info_sec/#4-data-integrity","title":"4. Data Integrity","text":"<ul> <li>Cryptographic hashes ensure that the data has not been altered in transit.</li> <li>Any discrepancies in data integrity result in the communication being rejected.</li> </ul>"},{"location":"features/info_sec/#5-zero-knowledge-protocols","title":"5. Zero-Knowledge Protocols","text":"<ul> <li>When handling especially sensitive data, agents use zero-knowledge proofs to validate information without revealing the actual data.</li> </ul>"},{"location":"features/info_sec/#6-periodic-key-rotation","title":"6. Periodic Key Rotation","text":"<ul> <li>To mitigate the risk of long-term key exposure, encryption keys are periodically rotated.</li> <li>Old keys are securely discarded, ensuring that even if they are compromised, they cannot be used to decrypt communications.</li> </ul>"},{"location":"features/info_sec/#best-practices-for-handling-personal-and-sensitive-information","title":"Best Practices for Handling Personal and Sensitive Information","text":"<ol> <li>Data Minimization: Agents should only request and process the minimum amount of personal data necessary for the task.</li> <li>Anonymization: Whenever possible, agents should anonymize personal data, stripping away identifying details.</li> <li>Data Retention Policies: Personal data should be retained only for the period necessary to complete the task, after which it should be securely deleted.</li> <li>Access Controls: Ensure that only authorized agents have access to personal and sensitive information. Implement strict access control mechanisms.</li> <li>Regular Audits: Conduct regular security audits to ensure compliance with privacy regulations and to detect any potential vulnerabilities.</li> <li>Training: All agents should be regularly updated and trained on the latest security protocols and best practices for handling sensitive data.</li> </ol>"},{"location":"features/info_sec/#conclusion","title":"Conclusion","text":"<p>Secure communication is paramount in the Swarms Multi-Agent Framework, especially when dealing with personal and sensitive information. Adhering to these protocols and best practices ensures the safety, privacy, and trust of all stakeholders involved.</p>"},{"location":"features/promptimizer/","title":"Promptimizer Documentation","text":""},{"location":"features/promptimizer/#swarms-multi-agent-framework","title":"Swarms Multi-Agent Framework","text":"<p>The Promptimizer Tool stands as a cornerstone innovation within the Swarms Multi-Agent Framework, meticulously engineered to refine and supercharge prompts across diverse categories. Capitalizing on extensive libraries of best-practice prompting techniques, this tool ensures your prompts are razor-sharp, tailored, and primed for optimal outcomes.</p>"},{"location":"features/promptimizer/#overview","title":"Overview:","text":"<p>The Promptimizer Tool is crafted to: 1. Rigorously analyze and elevate the quality of provided prompts. 2. Furnish best-in-class recommendations rooted in proven prompting strategies. 3. Serve a spectrum of categories, from technical operations to expansive creative ventures.</p>"},{"location":"features/promptimizer/#core-features","title":"Core Features:","text":""},{"location":"features/promptimizer/#1-deep-prompt-analysis","title":"1. Deep Prompt Analysis:","text":"<ul> <li>Clarity Matrix: A proprietary algorithm assessing prompt clarity, removing ambiguities and sharpening focus.</li> <li>Efficiency Gauge: Evaluates the prompt's structure to ensure swift and precise desired results.</li> </ul>"},{"location":"features/promptimizer/#2-adaptive-recommendations","title":"2. Adaptive Recommendations:","text":"<ul> <li>Technique Engine: Suggests techniques aligned with the gold standard for the chosen category.</li> <li>Exemplar Database: Offers an extensive array of high-quality prompt examples for comparison and inspiration.</li> </ul>"},{"location":"features/promptimizer/#3-versatile-category-framework","title":"3. Versatile Category Framework:","text":"<ul> <li>Tech Suite: Optimizes prompts for technical tasks, ensuring actionable clarity.</li> <li>Narrative Craft: Hones prompts to elicit vivid and coherent stories.</li> <li>Visual Visionary: Shapes prompts for precise and dynamic visual generation.</li> <li>Sonic Sculptor: Orchestrates prompts for audio creation, tuning into desired tones and moods.</li> </ul>"},{"location":"features/promptimizer/#4-machine-learning-integration","title":"4. Machine Learning Integration:","text":"<ul> <li>Feedback Dynamo: Harnesses user feedback, continually refining the tool's recommendation capabilities.</li> <li>Live Library Updates: Periodic syncing with the latest in prompting techniques, ensuring the tool remains at the cutting edge.</li> </ul>"},{"location":"features/promptimizer/#5-collaboration-sharing","title":"5. Collaboration &amp; Sharing:","text":"<ul> <li>TeamSync: Allows teams to collaborate on prompt optimization in real-time.</li> <li>ShareSpace: Share and access a community-driven repository of optimized prompts, fostering collective growth.</li> </ul>"},{"location":"features/promptimizer/#benefits","title":"Benefits:","text":"<ol> <li>Precision Engineering: Harness the power of refined prompts, ensuring desired outcomes are achieved with surgical precision.</li> <li>Learning Hub: Immerse in a tool that not only refines but educates, enhancing the user's prompting acumen.</li> <li>Versatile Mastery: Navigate seamlessly across categories, ensuring top-tier prompt quality regardless of the domain.</li> <li>Community-driven Excellence: Dive into a world of shared knowledge, elevating the collective expertise of the Swarms community.</li> </ol>"},{"location":"features/promptimizer/#usage-workflow","title":"Usage Workflow:","text":"<ol> <li>Launch the Prompt Optimizer: Access the tool directly from the Swarms Multi-Agent Framework dashboard.</li> <li>Prompt Entry: Input the initial prompt for refinement.</li> <li>Category Selection: Pinpoint the desired category for specialized optimization.</li> <li>Receive &amp; Review: Engage with the tool's recommendations, comparing original and optimized prompts.</li> <li>Collaborate, Implement &amp; Share: Work in tandem with team members, deploy the refined prompt, and consider contributing to the community repository.</li> </ol> <p>By integrating the Promptimizer Tool into their workflow, Swarms users stand poised to redefine the boundaries of what's possible, turning each prompt into a beacon of excellence and efficiency.</p>"},{"location":"features/shorthand/","title":"Shorthand Communication System","text":""},{"location":"features/shorthand/#swarms-multi-agent-framework","title":"Swarms Multi-Agent Framework","text":"<p>The Enhanced Shorthand Communication System is designed to streamline agent-agent communication within the Swarms Multi-Agent Framework. This system employs concise alphanumeric notations to relay task-specific details to agents efficiently.</p>"},{"location":"features/shorthand/#format","title":"Format:","text":"<p>The shorthand format is structured as <code>[AgentType]-[TaskLayer].[TaskNumber]-[Priority]-[Status]</code>.</p>"},{"location":"features/shorthand/#components","title":"Components:","text":""},{"location":"features/shorthand/#1-agent-type","title":"1. Agent Type:","text":"<ul> <li>Denotes the specific agent role, such as:</li> <li><code>C</code>: Code agent</li> <li><code>D</code>: Data processing agent</li> <li><code>M</code>: Monitoring agent</li> <li><code>N</code>: Network agent</li> <li><code>R</code>: Resource management agent</li> <li><code>I</code>: Interface agent</li> <li><code>S</code>: Security agent</li> </ul>"},{"location":"features/shorthand/#2-task-layer-number","title":"2. Task Layer &amp; Number:","text":"<ul> <li>Represents the task's category.</li> <li>Example: <code>1.8</code> signifies Task layer 1, task number 8.</li> </ul>"},{"location":"features/shorthand/#3-priority","title":"3. Priority:","text":"<ul> <li>Indicates task urgency.</li> <li><code>H</code>: High</li> <li><code>M</code>: Medium</li> <li><code>L</code>: Low</li> </ul>"},{"location":"features/shorthand/#4-status","title":"4. Status:","text":"<ul> <li>Gives a snapshot of the task's progress.</li> <li><code>I</code>: Initialized</li> <li><code>P</code>: In-progress</li> <li><code>C</code>: Completed</li> <li><code>F</code>: Failed</li> <li><code>W</code>: Waiting</li> </ul>"},{"location":"features/shorthand/#extended-features","title":"Extended Features:","text":""},{"location":"features/shorthand/#1-error-codes-for-failures","title":"1. Error Codes (for failures):","text":"<ul> <li><code>E01</code>: Resource issues</li> <li><code>E02</code>: Data inconsistency</li> <li><code>E03</code>: Dependency malfunction ... and more as needed.</li> </ul>"},{"location":"features/shorthand/#2-collaboration-flag","title":"2. Collaboration Flag:","text":"<ul> <li><code>+</code>: Denotes required collaboration.</li> </ul>"},{"location":"features/shorthand/#example-codes","title":"Example Codes:","text":"<ul> <li><code>C-1.8-H-I</code>: A high-priority coding task that's initializing.</li> <li><code>D-2.3-M-P</code>: A medium-priority data task currently in-progress.</li> <li><code>M-3.5-L-P+</code>: A low-priority monitoring task in progress needing collaboration.</li> </ul> <p>By leveraging the Enhanced Shorthand Communication System, the Swarms Multi-Agent Framework can ensure swift interactions, concise communications, and effective task management.</p>"},{"location":"swarms/","title":"Swarms","text":"<p>Swarms is a modular framework that enables reliable and useful multi-agent collaboration at scale to automate real-world tasks.</p>"},{"location":"swarms/#vision","title":"Vision","text":"<p>At Swarms, we're transforming the landscape of AI from siloed AI agents to a unified 'swarm' of intelligence. Through relentless iteration and the power of collective insight from our 1500+ Agora researchers, we're developing a groundbreaking framework for AI collaboration. Our mission is to catalyze a paradigm shift, advancing Humanity with the power of unified autonomous AI agent swarms.</p>"},{"location":"swarms/#schedule-a-1-on-1-session","title":"\ud83e\udd1d Schedule a 1-on-1 Session","text":"<p>Book a 1-on-1 Session with Kye, the Creator, to discuss any issues, provide feedback, or explore how we can improve Swarms for you.</p>"},{"location":"swarms/#installation","title":"Installation","text":"<p><code>pip3 install --upgrade swarms</code></p>"},{"location":"swarms/#usage","title":"Usage","text":"<p>We have a small gallery of examples to run here, for more check out the docs to build your own agent and or swarms!</p>"},{"location":"swarms/#agent-example","title":"<code>Agent</code> Example","text":"<ul> <li>Reliable Structure that provides LLMS autonomy</li> <li>Extremely Customizeable with stopping conditions, interactivity, dynamical temperature, loop intervals, and so much more</li> <li>Enterprise Grade + Production Grade: <code>Agent</code> is designed and optimized for automating real-world tasks at scale!</li> </ul> <pre><code>from swarms.models import OpenAIChat\nfrom swarms.structs import Agent\n\napi_key = \"\"\n\n# Initialize the language model, this model can be swapped out with Anthropic, ETC, Huggingface Models like Mistral, ETC\nllm = OpenAIChat(\n    # model_name=\"gpt-4\"\n    openai_api_key=api_key,\n    temperature=0.5,\n    # max_tokens=100,\n)\n\n## Initialize the workflow\nagent = Agent(\n    llm=llm,\n    max_loops=2,\n    dashboard=True,\n    # stopping_condition=None,  # You can define a stopping condition as needed.\n    # loop_interval=1,\n    # retry_attempts=3,\n    # retry_interval=1,\n    # interactive=False,  # Set to 'True' for interactive mode.\n    # dynamic_temperature=False,  # Set to 'True' for dynamic temperature handling.\n)\n\n# out = agent.load_state(\"flow_state.json\")\n# temp = agent.dynamic_temperature()\n# filter = agent.add_response_filter(\"Trump\")\nout = agent.run(\"Generate a 10,000 word blog on health and wellness.\")\n# out = agent.validate_response(out)\n# out = agent.analyze_feedback(out)\n# out = agent.print_history_and_memory()\n# # out = agent.save_state(\"flow_state.json\")\n# print(out)\n</code></pre>"},{"location":"swarms/#sequentialworkflow","title":"<code>SequentialWorkflow</code>","text":"<ul> <li>A Sequential swarm of autonomous agents where each agent's outputs are fed into the next agent</li> <li>Save and Restore Workflow states!</li> <li>Integrate Agent's with various LLMs and Multi-Modality Models</li> </ul> <pre><code>from swarms.models import OpenAIChat\nfrom swarms.structs import Agent\nfrom swarms.structs.sequential_workflow import SequentialWorkflow\n\n# Example usage\napi_key = \"\"  # Your actual API key here\n\n# Initialize the language agent\nllm = OpenAIChat(\n    openai_api_key=api_key,\n    temperature=0.5,\n    max_tokens=3000,\n)\n\n# Initialize the Agent with the language agent\nagent1 = Agent(llm=llm, max_loops=1, dashboard=False)\n\n# Create another Agent for a different task\nagent2 = Agent(llm=llm, max_loops=1, dashboard=False)\n\nagent3 = Agent(llm=llm, max_loops=1, dashboard=False)\n\n# Create the workflow\nworkflow = SequentialWorkflow(max_loops=1)\n\n# Add tasks to the workflow\nworkflow.add(\"Generate a 10,000 word blog on health and wellness.\", agent1)\n\n# Suppose the next task takes the output of the first task as input\nworkflow.add(\"Summarize the generated blog\", agent2)\n\nworkflow.add(\"Create a references sheet of materials for the curriculm\", agent3)\n\n# Run the workflow\nworkflow.run()\n\n# Output the results\nfor task in workflow.tasks:\n    print(f\"Task: {task.description}, Result: {task.result}\")\n</code></pre>"},{"location":"swarms/#features","title":"Features \ud83e\udd16","text":"<p>The Swarms framework is designed with a strong emphasis on reliability, performance, and production-grade readiness.  Below are the key features that make Swarms an ideal choice for enterprise-level AI deployments.</p>"},{"location":"swarms/#production-grade-readiness","title":"\ud83d\ude80 Production-Grade Readiness","text":"<ul> <li>Scalable Architecture: Built to scale effortlessly with your growing business needs.</li> <li>Enterprise-Level Security: Incorporates top-notch security features to safeguard your data and operations.</li> <li>Containerization and Microservices: Easily deployable in containerized environments, supporting microservices architecture.</li> </ul>"},{"location":"swarms/#reliability-and-robustness","title":"\u2699\ufe0f Reliability and Robustness","text":"<ul> <li>Fault Tolerance: Designed to handle failures gracefully, ensuring uninterrupted operations.</li> <li>Consistent Performance: Maintains high performance even under heavy loads or complex computational demands.</li> <li>Automated Backup and Recovery: Features automatic backup and recovery processes, reducing the risk of data loss.</li> </ul>"},{"location":"swarms/#advanced-ai-capabilities","title":"\ud83d\udca1 Advanced AI Capabilities","text":"<p>The Swarms framework is equipped with a suite of advanced AI capabilities designed to cater to a wide range of applications and scenarios, ensuring versatility and cutting-edge performance.</p>"},{"location":"swarms/#multi-modal-autonomous-agents","title":"Multi-Modal Autonomous Agents","text":"<ul> <li>Versatile Model Support: Seamlessly works with various AI models, including NLP, computer vision, and more, for comprehensive multi-modal capabilities.</li> <li>Context-Aware Processing: Employs context-aware processing techniques to ensure relevant and accurate responses from agents.</li> </ul>"},{"location":"swarms/#function-calling-models-for-api-execution","title":"Function Calling Models for API Execution","text":"<ul> <li>Automated API Interactions: Function calling models that can autonomously execute API calls, enabling seamless integration with external services and data sources.</li> <li>Dynamic Response Handling: Capable of processing and adapting to responses from APIs for real-time decision making.</li> </ul>"},{"location":"swarms/#varied-architectures-of-swarms","title":"Varied Architectures of Swarms","text":"<ul> <li>Flexible Configuration: Supports multiple swarm architectures, from centralized to decentralized, for diverse application needs.</li> <li>Customizable Agent Roles: Allows customization of agent roles and behaviors within the swarm to optimize performance and efficiency.</li> </ul>"},{"location":"swarms/#generative-models","title":"Generative Models","text":"<ul> <li>Advanced Generative Capabilities: Incorporates state-of-the-art generative models to create content, simulate scenarios, or predict outcomes.</li> <li>Creative Problem Solving: Utilizes generative AI for innovative problem-solving approaches and idea generation.</li> </ul>"},{"location":"swarms/#enhanced-decision-making","title":"Enhanced Decision-Making","text":"<ul> <li>AI-Powered Decision Algorithms: Employs advanced algorithms for swift and effective decision-making in complex scenarios.</li> <li>Risk Assessment and Management: Capable of assessing risks and managing uncertain situations with AI-driven insights.</li> </ul>"},{"location":"swarms/#real-time-adaptation-and-learning","title":"Real-Time Adaptation and Learning","text":"<ul> <li>Continuous Learning: Agents can continuously learn and adapt from new data, improving their performance and accuracy over time.</li> <li>Environment Adaptability: Designed to adapt to different operational environments, enhancing robustness and reliability.</li> </ul>"},{"location":"swarms/#efficient-workflow-automation","title":"\ud83d\udd04 Efficient Workflow Automation","text":"<ul> <li>Streamlined Task Management: Simplifies complex tasks with automated workflows, reducing manual intervention.</li> <li>Customizable Workflows: Offers customizable workflow options to fit specific business needs and requirements.</li> <li>Real-Time Analytics and Reporting: Provides real-time insights into agent performance and system health.</li> </ul>"},{"location":"swarms/#wide-ranging-integration","title":"\ud83c\udf10 Wide-Ranging Integration","text":"<ul> <li>API-First Design: Easily integrates with existing systems and third-party applications via robust APIs.</li> <li>Cloud Compatibility: Fully compatible with major cloud platforms for flexible deployment options.</li> <li>Continuous Integration/Continuous Deployment (CI/CD): Supports CI/CD practices for seamless updates and deployment.</li> </ul>"},{"location":"swarms/#performance-optimization","title":"\ud83d\udcca Performance Optimization","text":"<ul> <li>Resource Management: Efficiently manages computational resources for optimal performance.</li> <li>Load Balancing: Automatically balances workloads to maintain system stability and responsiveness.</li> <li>Performance Monitoring Tools: Includes comprehensive monitoring tools for tracking and optimizing performance.</li> </ul>"},{"location":"swarms/#security-and-compliance","title":"\ud83d\udee1\ufe0f Security and Compliance","text":"<ul> <li>Data Encryption: Implements end-to-end encryption for data at rest and in transit.</li> <li>Compliance Standards Adherence: Adheres to major compliance standards ensuring legal and ethical usage.</li> <li>Regular Security Updates: Regular updates to address emerging security threats and vulnerabilities.</li> </ul>"},{"location":"swarms/#community-and-support","title":"\ud83d\udcac Community and Support","text":"<ul> <li>Extensive Documentation: Detailed documentation for easy implementation and troubleshooting.</li> <li>Active Developer Community: A vibrant community for sharing ideas, solutions, and best practices.</li> <li>Professional Support: Access to professional support for enterprise-level assistance and guidance.</li> </ul> <p>Swarms framework is not just a tool but a robust, scalable, and secure partner in your AI journey, ready to tackle the challenges of modern AI applications in a business environment.</p>"},{"location":"swarms/#documentation","title":"Documentation","text":"<ul> <li>For documentation, go here, swarms.apac.ai</li> </ul>"},{"location":"swarms/#contribute","title":"Contribute","text":"<ul> <li>We're always looking for contributors to help us improve and expand this project. If you're interested, please check out our Contributing Guidelines and our contributing board</li> </ul>"},{"location":"swarms/#community","title":"Community","text":"<ul> <li>Join the Swarms community here on Discord!</li> </ul>"},{"location":"swarms/#license","title":"License","text":"<p>MIT</p>"},{"location":"swarms/agents/abstractagent/","title":"swarms.agents","text":""},{"location":"swarms/agents/abstractagent/#1-introduction","title":"1. Introduction","text":"<p><code>AbstractAgent</code> is an abstract class that serves as a foundation for implementing AI agents. An agent is an entity that can communicate with other agents and perform actions. The <code>AbstractAgent</code> class allows for customization in the implementation of the <code>receive</code> method, enabling different agents to define unique actions for receiving and processing messages.</p> <p><code>AbstractAgent</code> provides capabilities for managing tools and accessing memory, and has methods for running, chatting, and stepping through communication with other agents.</p>"},{"location":"swarms/agents/abstractagent/#2-class-definition","title":"2. Class Definition","text":"<pre><code>class AbstractAgent:\n    \"\"\"An abstract class for AI agent.\n\n    An agent can communicate with other agents and perform actions.\n    Different agents can differ in what actions they perform in the `receive` method.\n\n    Agents are full and completed:\n\n    Agents = llm + tools + memory\n    \"\"\"\n\n    def __init__(self, name: str):\n        \"\"\"\n        Args:\n            name (str): name of the agent.\n        \"\"\"\n        self._name = name\n\n    @property\n    def name(self):\n        \"\"\"Get the name of the agent.\"\"\"\n        return self._name\n\n    def tools(self, tools):\n        \"\"\"init tools\"\"\"\n\n    def memory(self, memory_store):\n        \"\"\"init memory\"\"\"\n\n    def reset(self):\n        \"\"\"(Abstract method) Reset the agent.\"\"\"\n\n    def run(self, task: str):\n        \"\"\"Run the agent once\"\"\"\n\n    def _arun(self, taks: str):\n        \"\"\"Run Async run\"\"\"\n\n    def chat(self, messages: List[Dict]):\n        \"\"\"Chat with the agent\"\"\"\n\n    def _achat(self, messages: List[Dict]):\n        \"\"\"Asynchronous Chat\"\"\"\n\n    def step(self, message: str):\n        \"\"\"Step through the agent\"\"\"\n\n    def _astep(self, message: str):\n        \"\"\"Asynchronous step\"\"\"\n</code></pre>"},{"location":"swarms/agents/abstractagent/#3-functionality-and-usage","title":"3. Functionality and Usage","text":"<p>The <code>AbstractAgent</code> class represents a generic AI agent and provides a set of methods to interact with it.</p> <p>To create an instance of an agent, the <code>name</code> of the agent should be specified.</p>"},{"location":"swarms/agents/abstractagent/#core-methods","title":"Core Methods","text":""},{"location":"swarms/agents/abstractagent/#1-reset","title":"1. <code>reset</code>","text":"<p>The <code>reset</code> method allows the agent to be reset to its initial state.</p> <pre><code>agent.reset()\n</code></pre>"},{"location":"swarms/agents/abstractagent/#2-run","title":"2. <code>run</code>","text":"<p>The <code>run</code> method allows the agent to perform a specific task.</p> <pre><code>agent.run(\"some_task\")\n</code></pre>"},{"location":"swarms/agents/abstractagent/#3-chat","title":"3. <code>chat</code>","text":"<p>The <code>chat</code> method enables communication with the agent through a series of messages.</p> <pre><code>messages = [{\"id\": 1, \"text\": \"Hello, agent!\"}, {\"id\": 2, \"text\": \"How are you?\"}]\nagent.chat(messages)\n</code></pre>"},{"location":"swarms/agents/abstractagent/#4-step","title":"4. <code>step</code>","text":"<p>The <code>step</code> method allows the agent to process a single message.</p> <pre><code>agent.step(\"Hello, agent!\")\n</code></pre>"},{"location":"swarms/agents/abstractagent/#asynchronous-methods","title":"Asynchronous Methods","text":"<p>The class also provides asynchronous variants of the core methods.</p>"},{"location":"swarms/agents/abstractagent/#additional-functionality","title":"Additional Functionality","text":"<p>Additional functionalities for agent initialization and management of tools and memory are also provided.</p> <pre><code>agent.tools(some_tools)\nagent.memory(some_memory_store)\n</code></pre>"},{"location":"swarms/agents/abstractagent/#4-additional-information-and-tips","title":"4. Additional Information and Tips","text":"<p>When implementing a new agent using the <code>AbstractAgent</code> class, ensure that the <code>receive</code> method is overridden to define the specific behavior of the agent upon receiving messages.</p>"},{"location":"swarms/agents/abstractagent/#5-references-and-resources","title":"5. References and Resources","text":"<p>For further exploration and understanding of AI agents and agent communication, refer to the relevant literature and research on this topic.</p>"},{"location":"swarms/agents/idea_to_image/","title":"<code>Idea2Image</code> Documentation","text":""},{"location":"swarms/agents/idea_to_image/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction</li> <li>Idea2Image Class</li> <li>Initialization Parameters</li> <li>Methods and Usage</li> <li>llm_prompt Method</li> <li>generate_image Method</li> <li>Examples</li> <li>Example 1: Generating an Image</li> <li>Additional Information</li> <li>References and Resources</li> </ol>"},{"location":"swarms/agents/idea_to_image/#1-introduction","title":"1. Introduction","text":"<p>Welcome to the documentation for the Swarms library, with a focus on the <code>Idea2Image</code> class. This comprehensive guide provides in-depth information about the Swarms library and its core components. Before we dive into the details, it's crucial to understand the purpose and significance of this library.</p>"},{"location":"swarms/agents/idea_to_image/#11-purpose","title":"1.1 Purpose","text":"<p>The Swarms library aims to simplify interactions with AI models for generating images from text prompts. The <code>Idea2Image</code> class is designed to generate images from textual descriptions using the DALLE-3 model and the OpenAI GPT-4 language model.</p>"},{"location":"swarms/agents/idea_to_image/#12-key-features","title":"1.2 Key Features","text":"<ul> <li> <p>Image Generation: Swarms allows you to generate images based on natural language prompts, providing a bridge between textual descriptions and visual content.</p> </li> <li> <p>Integration with DALLE-3: The <code>Idea2Image</code> class leverages the power of DALLE-3 to create images that match the given textual descriptions.</p> </li> <li> <p>Language Model Integration: The class integrates with OpenAI's GPT-3 for prompt refinement, enhancing the specificity of image generation.</p> </li> </ul>"},{"location":"swarms/agents/idea_to_image/#2-idea2image-class","title":"2. Idea2Image Class","text":"<p>The <code>Idea2Image</code> class is a fundamental module in the Swarms library, enabling the generation of images from text prompts.</p>"},{"location":"swarms/agents/idea_to_image/#21-initialization-parameters","title":"2.1 Initialization Parameters","text":"<p>Here are the initialization parameters for the <code>Idea2Image</code> class:</p> <ul> <li> <p><code>image</code> (str): Text prompt for the image to generate.</p> </li> <li> <p><code>openai_api_key</code> (str): OpenAI API key. This key is used for prompt refinement with GPT-3. If not provided, the class will attempt to use the <code>OPENAI_API_KEY</code> environment variable.</p> </li> <li> <p><code>cookie</code> (str): Cookie value for DALLE-3. This cookie is used to interact with the DALLE-3 API. If not provided, the class will attempt to use the <code>BING_COOKIE</code> environment variable.</p> </li> <li> <p><code>output_folder</code> (str): Folder to save the generated images. The default folder is \"images/\".</p> </li> </ul>"},{"location":"swarms/agents/idea_to_image/#22-methods","title":"2.2 Methods","text":"<p>The <code>Idea2Image</code> class provides the following methods:</p> <ul> <li> <p><code>llm_prompt()</code>: Returns a prompt for refining the image generation. This method helps improve the specificity of the image generation prompt.</p> </li> <li> <p><code>generate_image()</code>: Generates and downloads the image based on the prompt. It refines the prompt, opens the website with the query, retrieves image URLs, and downloads the images to the specified folder.</p> </li> </ul>"},{"location":"swarms/agents/idea_to_image/#3-methods-and-usage","title":"3. Methods and Usage","text":"<p>Let's explore the methods provided by the <code>Idea2Image</code> class and how to use them effectively.</p>"},{"location":"swarms/agents/idea_to_image/#31-llm_prompt-method","title":"3.1 <code>llm_prompt</code> Method","text":"<p>The <code>llm_prompt</code> method returns a refined prompt for generating the image. It's a critical step in improving the specificity and accuracy of the image generation process. The method provides a guide for refining the prompt, helping users describe the desired image more precisely.</p>"},{"location":"swarms/agents/idea_to_image/#32-generate_image-method","title":"3.2 <code>generate_image</code> Method","text":"<p>The <code>generate_image</code> method combines the previous methods to execute the whole process of generating and downloading images based on the provided prompt. It's a convenient way to automate the image generation process.</p>"},{"location":"swarms/agents/idea_to_image/#4-examples","title":"4. Examples","text":"<p>Let's dive into practical examples to demonstrate the usage of the <code>Idea2Image</code> class.</p>"},{"location":"swarms/agents/idea_to_image/#41-example-1-generating-an-image","title":"4.1 Example 1: Generating an Image","text":"<p>In this example, we create an instance of the <code>Idea2Image</code> class and use it to generate an image based on a text prompt:</p> <pre><code>from swarms.agents import Idea2Image\n\n# Create an instance of the Idea2Image class with your prompt and API keys\nidea2image = Idea2Image(\n    image=\"Fish hivemind swarm in light blue avatar anime in zen garden pond concept art anime art, happy fish, anime scenery\",\n    openai_api_key=\"your_openai_api_key_here\",\n    cookie=\"your_cookie_value_here\",\n)\n\n# Generate and download the image\nidea2image.generate_image()\n</code></pre>"},{"location":"swarms/agents/idea_to_image/#5-additional-information","title":"5. Additional Information","text":"<p>Here are some additional tips and information for using the Swarms library and the <code>Idea2Image</code> class effectively:</p> <ul> <li> <p>Refining the prompt is a crucial step to influence the style, composition, and mood of the generated image. Follow the provided guide in the <code>llm_prompt</code> method to create precise prompts.</p> </li> <li> <p>Experiment with different prompts, variations, and editing techniques to create unique and interesting images.</p> </li> <li> <p>You can combine separate DALLE-3 outputs into panoramas and murals by careful positioning and editing.</p> </li> <li> <p>Consider sharing your creations and exploring resources in communities like Reddit r/dalle2 for inspiration and tools.</p> </li> <li> <p>The <code>output_folder</code> parameter allows you to specify the folder where generated images will be saved. Ensure that you have the necessary permissions to write to that folder.</p> </li> </ul>"},{"location":"swarms/agents/idea_to_image/#6-references-and-resources","title":"6. References and Resources","text":"<p>For further information and resources related to the Swarms library and DALLE-3:</p> <ul> <li> <p>DALLE-3 Unofficial API Documentation: The official documentation for the DALLE-3 Unofficial API, where you can explore additional features and capabilities.</p> </li> <li> <p>OpenAI GPT-3 Documentation: The documentation for OpenAI's GPT-3, which is used for prompt refinement.</p> </li> </ul> <p>This concludes the documentation for the Swarms library and the <code>Idea2Image</code> class. You now have a comprehensive guide on how to generate images from text prompts using DALLE-3 and GPT-3 with Swarms.</p>"},{"location":"swarms/agents/message/","title":"The Module/Class Name: Message","text":"<p>In the swarms.agents framework, the class <code>Message</code> is used to represent a message with timestamp and optional metadata.</p>"},{"location":"swarms/agents/message/#overview-and-introduction","title":"Overview and Introduction","text":"<p>The <code>Message</code> class is a fundamental component that enables the representation of messages within an agent system. Messages contain essential information such as the sender, content, timestamp, and optional metadata.</p>"},{"location":"swarms/agents/message/#class-definition","title":"Class Definition","text":""},{"location":"swarms/agents/message/#constructor-__init__","title":"Constructor: <code>__init__</code>","text":"<p>The constructor of the <code>Message</code> class takes three parameters:</p> <ol> <li><code>sender</code> (str): The sender of the message.</li> <li><code>content</code> (str): The content of the message.</li> <li><code>metadata</code> (dict or None): Optional metadata associated with the message.</li> </ol>"},{"location":"swarms/agents/message/#methods","title":"Methods","text":"<ol> <li><code>__repr__(self)</code>: Returns a string representation of the <code>Message</code> object, including the timestamp, sender, and content.</li> </ol> <pre><code>class Message:\n    \"\"\"\n    Represents a message with timestamp and optional metadata.\n\n    Usage\n    --------------\n    mes = Message(\n        sender = \"Kye\",\n        content = \"message\"\n    )\n\n    print(mes)\n    \"\"\"\n\n    def __init__(self, sender, content, metadata=None):\n        self.timestamp = datetime.datetime.now()\n        self.sender = sender\n        self.content = content\n        self.metadata = metadata or {}\n\n    def __repr__(self):\n        \"\"\"\n        __repr__ represents the string representation of the Message object.\n\n        Returns:\n        (str) A string containing the timestamp, sender, and content of the message.\n        \"\"\"\n        return f\"{self.timestamp} - {self.sender}: {self.content}\"\n</code></pre>"},{"location":"swarms/agents/message/#functionality-and-usage","title":"Functionality and Usage","text":"<p>The <code>Message</code> class represents a message in the agent system. Upon initialization, the <code>timestamp</code> is set to the current date and time, and the <code>metadata</code> is set to an empty dictionary if no metadata is provided.</p>"},{"location":"swarms/agents/message/#usage-example-1","title":"Usage Example 1","text":"<p>Creating a <code>Message</code> object and displaying its string representation.</p> <pre><code>mes = Message(sender=\"Kye\", content=\"Hello! How are you?\")\n\nprint(mes)\n</code></pre> <p>Output: <pre><code>2023-09-20 13:45:00 - Kye: Hello! How are you?\n</code></pre></p>"},{"location":"swarms/agents/message/#usage-example-2","title":"Usage Example 2","text":"<p>Creating a <code>Message</code> object with metadata.</p> <pre><code>metadata = {\"priority\": \"high\", \"category\": \"urgent\"}\nmes_with_metadata = Message(\n    sender=\"Alice\", content=\"Important update\", metadata=metadata\n)\n\nprint(mes_with_metadata)\n</code></pre> <p>Output: <pre><code>2023-09-20 13:46:00 - Alice: Important update\n</code></pre></p>"},{"location":"swarms/agents/message/#usage-example-3","title":"Usage Example 3","text":"<p>Creating a <code>Message</code> object without providing metadata.</p> <pre><code>mes_no_metadata = Message(sender=\"Bob\", content=\"Reminder: Meeting at 2PM\")\n\nprint(mes_no_metadata)\n</code></pre> <p>Output: <pre><code>2023-09-20 13:47:00 - Bob: Reminder: Meeting at 2PM\n</code></pre></p>"},{"location":"swarms/agents/message/#additional-information-and-tips","title":"Additional Information and Tips","text":"<p>When creating a new <code>Message</code> object, ensure that the required parameters <code>sender</code> and <code>content</code> are provided. The <code>timestamp</code> will automatically be assigned the current date and time. Optional <code>metadata</code> can be included to provide additional context or information associated with the message.</p>"},{"location":"swarms/agents/message/#references-and-resources","title":"References and Resources","text":"<p>For further information on the <code>Message</code> class and its usage, refer to the official swarms.agents documentation and relevant tutorials related to message handling and communication within the agent system.</p>"},{"location":"swarms/agents/omni_agent/","title":"<code>OmniModalAgent</code> Documentation","text":""},{"location":"swarms/agents/omni_agent/#overview-architectural-analysis","title":"Overview &amp; Architectural Analysis","text":"<p>The <code>OmniModalAgent</code> class is at the core of an architecture designed to facilitate dynamic interactions using various tools, through a seamless integration of planning, task execution, and response generation mechanisms. It encompasses multiple modalities including natural language processing, image processing, and more, aiming to provide comprehensive and intelligent responses.</p>"},{"location":"swarms/agents/omni_agent/#architectural-components","title":"Architectural Components:","text":"<ol> <li>LLM (Language Model): It acts as the foundation, underpinning the understanding and generation of language-based interactions.</li> <li>Chat Planner: This component drafts a blueprint for the steps necessary based on the user's input.</li> <li>Task Executor: As the name suggests, it's responsible for executing the formulated tasks.</li> <li>Tools: A collection of tools and utilities used to process different types of tasks. They span across areas like image captioning, translation, and more.</li> </ol>"},{"location":"swarms/agents/omni_agent/#structure-organization","title":"Structure &amp; Organization","text":""},{"location":"swarms/agents/omni_agent/#table-of-contents","title":"Table of Contents:","text":"<ol> <li>Class Introduction and Architecture</li> <li>Constructor (<code>__init__</code>) </li> <li>Core Methods<ul> <li><code>run</code></li> <li><code>chat</code></li> <li><code>_stream_response</code></li> </ul> </li> <li>Example Usage</li> <li>Error Messages &amp; Exception Handling</li> <li>Summary &amp; Further Reading</li> </ol>"},{"location":"swarms/agents/omni_agent/#constructor-__init__","title":"Constructor (<code>__init__</code>):","text":"<p>The agent is initialized with a language model (<code>llm</code>). During initialization, the agent loads a myriad of tools to facilitate a broad spectrum of tasks, from document querying to image transformations. </p>"},{"location":"swarms/agents/omni_agent/#core-methods","title":"Core Methods:","text":""},{"location":"swarms/agents/omni_agent/#1-runself-input-str-str","title":"1. <code>run(self, input: str) -&gt; str</code>:","text":"<p>Executes the OmniAgent. The agent plans its actions based on the user's input, executes those actions, and then uses a response generator to construct its reply. </p>"},{"location":"swarms/agents/omni_agent/#2-chatself-msg-str-streaming-bool-str","title":"2. <code>chat(self, msg: str, streaming: bool) -&gt; str</code>:","text":"<p>Facilitates an interactive chat with the agent. It processes user messages, handles exceptions, and returns a response, either in streaming format or as a whole string.</p>"},{"location":"swarms/agents/omni_agent/#3-_stream_responseself-response-str","title":"3. <code>_stream_response(self, response: str)</code>:","text":"<p>For streaming mode, this function yields the response token by token, ensuring a smooth output agent.</p>"},{"location":"swarms/agents/omni_agent/#examples-use-cases","title":"Examples &amp; Use Cases","text":"<p>Initialize the <code>OmniModalAgent</code> and communicate with it: <pre><code>import os\n\nfrom dotenv import load_dotenv\n\nfrom swarms.agents.omni_modal_agent import OmniModalAgent, OpenAIChat\nfrom swarms.models import OpenAIChat\n\n# Load the environment variables\nload_dotenv()\n\n# Get the API key from the environment\napi_key = os.environ.get(\"OPENAI_API_KEY\")\n\n# Initialize the language model\nllm = OpenAIChat(\n    temperature=0.5,\n    model_name=\"gpt-4\",\n    openai_api_key=api_key,\n)\n\n\nagent = OmniModalAgent(llm)\nresponse = agent.run(\"Translate 'Hello' to French.\")\nprint(response)\n</code></pre></p> <p>For a chat-based interaction: <pre><code>agent = OmniModalAgent(llm_instance)\nprint(agent.chat(\"How are you doing today?\"))\n</code></pre></p>"},{"location":"swarms/agents/omni_agent/#error-messages-exception-handling","title":"Error Messages &amp; Exception Handling","text":"<p>The <code>chat</code> method in <code>OmniModalAgent</code> incorporates exception handling. When an error arises during message processing, it returns a formatted error message detailing the exception. This approach ensures that users receive informative feedback in case of unexpected situations.</p> <p>For example, if there's an internal processing error, the chat function would return:  <pre><code>Error processing message: [Specific error details]\n</code></pre></p>"},{"location":"swarms/agents/omni_agent/#summary","title":"Summary","text":"<p><code>OmniModalAgent</code> epitomizes the fusion of various AI tools, planners, and executors into one cohesive unit, providing a comprehensive interface for diverse tasks and modalities. The versatility and robustness of this agent make it indispensable for applications desiring to bridge multiple AI functionalities in a unified manner.</p> <p>For more extensive documentation, API references, and advanced use-cases, users are advised to refer to the primary documentation repository associated with the parent project. Regular updates, community feedback, and patches can also be found there.</p>"},{"location":"swarms/agents/omnimodalagent/","title":"Module/Class Name: OmniModalAgent","text":"<p>The <code>OmniModalAgent</code> class is a module that operates based on the Language Model (LLM) aka Language Understanding Model, Plans, Tasks, and Tools. It is designed to be a multi-modal chatbot which uses various AI-based capabilities for fulfilling user requests. </p> <p>It has the following architecture: 1. Language Model (LLM). 2. Chat Planner - Plans 3. Task Executor - Tasks 4. Tools - Tools</p> <p></p>"},{"location":"swarms/agents/omnimodalagent/#usage","title":"Usage","text":"<pre><code>from swarms import OmniModalAgent, OpenAIChat\n\nllm = OpenAIChat()\nagent = OmniModalAgent(llm)\nresponse = agent.run(\"Hello, how are you? Create an image of how your are doing!\")\n</code></pre>"},{"location":"swarms/agents/omnimodalagent/#initialization","title":"Initialization","text":"<p>The constructor of <code>OmniModalAgent</code> class takes two main parameters: - <code>llm</code>: A <code>BaseLanguageModel</code> that represents the language model - <code>tools</code>: A List of <code>BaseTool</code> instances that are used by the agent for fulfilling different requests.</p> <pre><code>def __init__(\n    self,\n    llm: BaseLanguageModel,\n    # tools: List[BaseTool]\n):\n</code></pre>"},{"location":"swarms/agents/omnimodalagent/#methods","title":"Methods","text":"<p>The class has two main methods: 1. <code>run</code>: This method takes an input string and executes various plans and tasks using the provided tools. Ultimately, it generates a response based on the user's input and returns it.    - Parameters:      - <code>input</code>: A string representing the user's input text.    - Returns:      - A string representing the response.</p> <p>Usage:    <pre><code>response = agent.run(\"Hello, how are you? Create an image of how your are doing!\")\n</code></pre></p> <ol> <li><code>chat</code>: This method is used to simulate a chat dialog with the agent. It can take user's messages and return the response (or stream the response word-by-word if required).</li> <li>Parameters:<ul> <li><code>msg</code> (optional): A string representing the message to send to the agent.</li> <li><code>streaming</code> (optional): A boolean specifying whether to stream the response.</li> </ul> </li> <li>Returns:<ul> <li>A string representing the response from the agent.</li> </ul> </li> </ol> <p>Usage:    <pre><code>response = agent.chat(\"Hello\")\n</code></pre></p>"},{"location":"swarms/agents/omnimodalagent/#streaming-response","title":"Streaming Response","text":"<p>The class provides a method <code>_stream_response</code> that can be used to get the response token by token (i.e. word by word). It yields individual tokens from the response.</p> <p>Usage: <pre><code>for token in _stream_response(response):\n    print(token)\n</code></pre></p>"},{"location":"swarms/agents/toolagent/","title":"ToolAgent Documentation","text":""},{"location":"swarms/agents/toolagent/#overview-and-introduction","title":"Overview and Introduction","text":"<p>The <code>ToolAgent</code> class represents an intelligent agent capable of performing a specific task using a pre-trained model and tokenizer. It leverages the Transformer models of the Hugging Face <code>transformers</code> library to generate outputs that adhere to a specific JSON schema. This provides developers with a flexible tool for creating bots, text generators, and conversational AI agents. The <code>ToolAgent</code> operates based on a JSON schema provided by you, the user. Using the schema, the agent applies the provided model and tokenizer to generate structured text data that matches the specified format.</p> <p>The primary objective of the <code>ToolAgent</code> class is to amplify the efficiency of developers and AI practitioners by simplifying the process of generating meaningful outputs that navigate the complexities of the model and tokenizer.</p>"},{"location":"swarms/agents/toolagent/#class-definition","title":"Class Definition","text":"<p>The <code>ToolAgent</code> class has the following definition:</p> <pre><code>class ToolAgent(AbstractLLM):\n    def __init__(\n        self,\n        name: str,\n        description: str,\n        model: Any,\n        tokenizer: Any,\n        json_schema: Any,\n        *args,\n        **kwargs,\n    )\n    def run(self, task: str, *args, **kwargs)\n    def __call__(self, task: str, *args, **kwargs)\n</code></pre>"},{"location":"swarms/agents/toolagent/#arguments","title":"Arguments","text":"<p>The <code>ToolAgent</code> class takes the following arguments:</p> Argument Type Description name str The name of the tool agent. description str A description of the tool agent. model Any The model used by the tool agent (e.g., <code>transformers.AutoModelForCausalLM</code>). tokenizer Any The tokenizer used by the tool agent (e.g., <code>transformers.AutoTokenizer</code>). json_schema Any The JSON schema used by the tool agent. *args - Variable-length arguments. **kwargs - Keyword arguments."},{"location":"swarms/agents/toolagent/#methods","title":"Methods","text":"<p><code>ToolAgent</code> exposes the following methods:</p>"},{"location":"swarms/agents/toolagent/#runself-task-str-args-kwargs-any","title":"<code>run(self, task: str, *args, **kwargs) -&gt; Any</code>","text":"<ul> <li>Description: Runs the tool agent for a specific task.</li> <li>Parameters:</li> <li><code>task</code> (str): The task to be performed by the tool agent.</li> <li><code>*args</code>: Variable-length argument list.</li> <li><code>**kwargs</code>: Arbitrary keyword arguments.</li> <li>Returns: The output of the tool agent.</li> <li>Raises: Exception if an error occurs during the execution of the tool agent.</li> </ul>"},{"location":"swarms/agents/toolagent/#__call__self-task-str-args-kwargs-any","title":"<code>__call__(self, task: str, *args, **kwargs) -&gt; Any</code>","text":"<ul> <li>Description: Calls the tool agent to perform a specific task.</li> <li>Parameters:</li> <li><code>task</code> (str): The task to be performed by the tool agent.</li> <li><code>*args</code>: Variable-length argument list.</li> <li><code>**kwargs</code>: Arbitrary keyword arguments.</li> <li>Returns: The output of the tool agent.</li> </ul>"},{"location":"swarms/agents/toolagent/#usage-example","title":"Usage Example","text":"<pre><code>from transformers import AutoModelForCausalLM, AutoTokenizer\n\nfrom swarms import ToolAgent\n\n# Creating a model and tokenizer\nmodel = AutoModelForCausalLM.from_pretrained(\"databricks/dolly-v2-12b\")\ntokenizer = AutoTokenizer.from_pretrained(\"databricks/dolly-v2-12b\")\n\n# Defining a JSON schema\njson_schema = {\n    \"type\": \"object\",\n    \"properties\": {\n        \"name\": {\"type\": \"string\"},\n        \"age\": {\"type\": \"number\"},\n        \"is_student\": {\"type\": \"boolean\"},\n        \"courses\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n    },\n}\n\n# Defining a task\ntask = \"Generate a person's information based on the following schema:\"\n\n# Creating the ToolAgent instance\nagent = ToolAgent(model=model, tokenizer=tokenizer, json_schema=json_schema)\n\n# Running the tool agent\ngenerated_data = agent.run(task)\n\n# Accessing and printing the generated data\nprint(generated_data)\n</code></pre>"},{"location":"swarms/agents/toolagent/#additional-information-and-tips","title":"Additional Information and Tips","text":"<p>When using the <code>ToolAgent</code>, it is important to ensure compatibility between the provided model, tokenizer, and the JSON schema. Additionally, any errors encountered during the execution of the tool agent are propagated as exceptions. Handling such exceptions appropriately can improve the robustness of the tool agent usage.</p>"},{"location":"swarms/agents/toolagent/#references-and-resources","title":"References and Resources","text":"<p>For further exploration and understanding of the underlying Transformer-based models and tokenizers, refer to the Hugging Face <code>transformers</code> library documentation and examples. Additionally, for JSON schema modeling, you can refer to the official JSON Schema specification and examples.</p> <p>This documentation provides a comprehensive guide on using the <code>ToolAgent</code> class from <code>swarms</code> library, and it is recommended to refer back to this document when utilizing the <code>ToolAgent</code> for developing your custom conversational agents or text generation tools.</p>"},{"location":"swarms/agents/workeragent/","title":"WorkerClass Documentation","text":""},{"location":"swarms/agents/workeragent/#overview","title":"Overview","text":"<p>The Worker class represents an autonomous agent that can perform tasks through function calls or by running a chat. It can be used to create applications that demand effective user interactions like search engines, human-like conversational bots, or digital assistants.</p> <p>The <code>Worker</code> class is part of the <code>swarms.agents</code> codebase. This module is largely used in Natural Language Processing (NLP) projects where the agent undertakes conversations and other language-specific operations.</p>"},{"location":"swarms/agents/workeragent/#class-definition","title":"Class Definition","text":"<p>The class <code>Worker</code> has the following arguments:</p> Argument Type Default Value Description name str \"Worker\" Name of the agent. role str \"Worker in a swarm\" Role of the agent. external_tools list None List of external tools available to the agent. human_in_the_loop bool False Determines whether human interaction is required. temperature float 0.5 Temperature for the autonomous agent. llm None None Language model. openai_api_key str None OpenAI API key. tools List[Any] None List of tools available to the agent. embedding_size int 1536 Size of the word embeddings. search_kwargs dict {\"k\": 8} Search parameters. args Multiple Additional arguments that can be passed. kwargs Multiple Additional keyword arguments that can be passed. ## Usage"},{"location":"swarms/agents/workeragent/#example-1-creating-and-running-an-agent","title":"Example 1: Creating and Running an Agent","text":"<pre><code>from swarms import Worker\n\nworker = Worker(\n    name=\"My Worker\",\n    role=\"Worker\",\n    external_tools=[MyTool1(), MyTool2()],\n    human_in_the_loop=False,\n    temperature=0.5,\n    llm=some_language_model,\n    openai_api_key=\"my_key\",\n)\nworker.run(\"What's the weather in Miami?\")\n</code></pre>"},{"location":"swarms/agents/workeragent/#example-2-receiving-and-sending-messages","title":"Example 2: Receiving and Sending Messages","text":"<pre><code>worker.receieve(\"User\", \"Hello there!\")\nworker.receieve(\"User\", \"Can you tell me something about history?\")\nworker.send()\n</code></pre>"},{"location":"swarms/agents/workeragent/#example-3-setting-up-tools","title":"Example 3: Setting up Tools","text":"<pre><code>external_tools = [MyTool1(), MyTool2()]\nworker = Worker(\n    name=\"My Worker\",\n    role=\"Worker\",\n    external_tools=external_tools,\n    human_in_the_loop=False,\n    temperature=0.5,\n)\n</code></pre>"},{"location":"swarms/agents/workeragent/#additional-information-and-tips","title":"Additional Information and Tips","text":"<ul> <li>The class allows the setting up of tools for the worker to operate effectively. It provides setup facilities for essential computing infrastructure, such as the agent's memory and language model.</li> <li>By setting the <code>human_in_the_loop</code> parameter to True, interactions with the worker can be made more user-centric.</li> <li>The <code>openai_api_key</code> argument can be provided for leveraging the OpenAI infrastructure and services.</li> <li>A qualified language model can be passed as an instance of the <code>llm</code> object, which can be useful when integrating with state-of-the-art text generation engines.</li> </ul>"},{"location":"swarms/agents/workeragent/#references-and-resources","title":"References and Resources","text":"<ul> <li>OpenAI APIs</li> <li>Models and Languages at HuggingFace</li> <li>Deep Learning and Language Modeling at the Allen Institute for AI</li> </ul>"},{"location":"swarms/chunkers/basechunker/","title":"BaseChunker Documentation","text":""},{"location":"swarms/chunkers/basechunker/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction</li> <li>Overview</li> <li>Installation</li> <li>Usage</li> <li>BaseChunker Class</li> <li>Examples</li> <li>Additional Information</li> <li>Conclusion</li> </ol>"},{"location":"swarms/chunkers/basechunker/#1-introduction","title":"1. Introduction","text":"<p>The <code>BaseChunker</code> module is a tool for splitting text into smaller chunks that can be processed by a language model. It is a fundamental component in natural language processing tasks that require handling long or complex text inputs.</p> <p>This documentation provides an extensive guide on using the <code>BaseChunker</code> module, explaining its purpose, parameters, and usage.</p>"},{"location":"swarms/chunkers/basechunker/#2-overview","title":"2. Overview","text":"<p>The <code>BaseChunker</code> module is designed to address the challenge of processing lengthy text inputs that exceed the maximum token limit of language models. By breaking such text into smaller, manageable chunks, it enables efficient and accurate processing.</p> <p>Key features and parameters of the <code>BaseChunker</code> module include: - <code>separators</code>: Specifies a list of <code>ChunkSeparator</code> objects used to split the text into chunks. - <code>tokenizer</code>: Defines the tokenizer to be used for counting tokens in the text. - <code>max_tokens</code>: Sets the maximum token limit for each chunk.</p> <p>The <code>BaseChunker</code> module facilitates the chunking process and ensures that the generated chunks are within the token limit.</p>"},{"location":"swarms/chunkers/basechunker/#3-installation","title":"3. Installation","text":"<p>Before using the <code>BaseChunker</code> module, ensure you have the required dependencies installed. The module relies on <code>griptape</code> and <code>swarms</code> libraries. You can install these dependencies using pip:</p> <pre><code>pip install griptape swarms\n</code></pre>"},{"location":"swarms/chunkers/basechunker/#4-usage","title":"4. Usage","text":"<p>In this section, we'll cover how to use the <code>BaseChunker</code> module effectively. It consists of the <code>BaseChunker</code> class and provides examples to demonstrate its usage.</p>"},{"location":"swarms/chunkers/basechunker/#41-basechunker-class","title":"4.1. <code>BaseChunker</code> Class","text":"<p>The <code>BaseChunker</code> class is the core component of the <code>BaseChunker</code> module. It is used to create a <code>BaseChunker</code> instance, which can split text into chunks efficiently.</p>"},{"location":"swarms/chunkers/basechunker/#parameters","title":"Parameters:","text":"<ul> <li><code>separators</code> (list[ChunkSeparator]): Specifies a list of <code>ChunkSeparator</code> objects used to split the text into chunks.</li> <li><code>tokenizer</code> (OpenAITokenizer): Defines the tokenizer to be used for counting tokens in the text.</li> <li><code>max_tokens</code> (int): Sets the maximum token limit for each chunk.</li> </ul>"},{"location":"swarms/chunkers/basechunker/#42-examples","title":"4.2. Examples","text":"<p>Let's explore how to use the <code>BaseChunker</code> class with different scenarios and applications.</p>"},{"location":"swarms/chunkers/basechunker/#example-1-basic-chunking","title":"Example 1: Basic Chunking","text":"<pre><code>from basechunker import BaseChunker, ChunkSeparator\n\n# Initialize the BaseChunker\nchunker = BaseChunker()\n\n# Text to be chunked\ninput_text = (\n    \"This is a long text that needs to be split into smaller chunks for processing.\"\n)\n\n# Chunk the text\nchunks = chunker.chunk(input_text)\n\n# Print the generated chunks\nfor idx, chunk in enumerate(chunks, start=1):\n    print(f\"Chunk {idx}: {chunk.value}\")\n</code></pre>"},{"location":"swarms/chunkers/basechunker/#example-2-custom-separators","title":"Example 2: Custom Separators","text":"<pre><code>from basechunker import BaseChunker, ChunkSeparator\n\n# Define custom separators\ncustom_separators = [ChunkSeparator(\",\"), ChunkSeparator(\";\")]\n\n# Initialize the BaseChunker with custom separators\nchunker = BaseChunker(separators=custom_separators)\n\n# Text with custom separators\ninput_text = \"This text, separated by commas; should be split accordingly.\"\n\n# Chunk the text\nchunks = chunker.chunk(input_text)\n\n# Print the generated chunks\nfor idx, chunk in enumerate(chunks, start=1):\n    print(f\"Chunk {idx}: {chunk.value}\")\n</code></pre>"},{"location":"swarms/chunkers/basechunker/#example-3-adjusting-maximum-tokens","title":"Example 3: Adjusting Maximum Tokens","text":"<pre><code>from basechunker import BaseChunker\n\n# Initialize the BaseChunker with a custom maximum token limit\nchunker = BaseChunker(max_tokens=50)\n\n# Long text input\ninput_text = \"This is an exceptionally long text that should be broken into smaller chunks based on token count.\"\n\n# Chunk the text\nchunks = chunker.chunk(input_text)\n\n# Print the generated chunks\nfor idx, chunk in enumerate(chunks, start=1):\n    print(f\"Chunk {idx}: {chunk.value}\")\n</code></pre>"},{"location":"swarms/chunkers/basechunker/#43-additional-features","title":"4.3. Additional Features","text":"<p>The <code>BaseChunker</code> class also provides additional features:</p>"},{"location":"swarms/chunkers/basechunker/#recursive-chunking","title":"Recursive Chunking","text":"<p>The <code>_chunk_recursively</code> method handles the recursive chunking of text, ensuring that each chunk stays within the token limit.</p>"},{"location":"swarms/chunkers/basechunker/#5-additional-information","title":"5. Additional Information","text":"<ul> <li>Text Chunking: The <code>BaseChunker</code> module is a fundamental tool for text chunking, a crucial step in preprocessing text data for various natural language processing tasks.</li> <li>Custom Separators: You can customize the separators used to split the text, allowing flexibility in how text is chunked.</li> <li>Token Count: The module accurately counts tokens using the specified tokenizer, ensuring that chunks do not exceed token limits.</li> </ul>"},{"location":"swarms/chunkers/basechunker/#6-conclusion","title":"6. Conclusion","text":"<p>The <code>BaseChunker</code> module is an essential tool for text preprocessing and handling long or complex text inputs in natural language processing tasks. This documentation has provided a comprehensive guide on its usage, parameters, and examples, enabling you to efficiently manage and process text data by splitting it into manageable chunks.</p> <p>By using the <code>BaseChunker</code>, you can ensure that your text data remains within token limits and is ready for further analysis and processing.</p> <p>Please check the official <code>BaseChunker</code> repository and documentation for any updates beyond the knowledge cutoff date.</p>"},{"location":"swarms/chunkers/pdf_chunker/","title":"PdfChunker Documentation","text":""},{"location":"swarms/chunkers/pdf_chunker/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction</li> <li>Overview</li> <li>Installation</li> <li>Usage</li> <li>PdfChunker Class</li> <li>Examples</li> <li>Additional Information</li> <li>Conclusion</li> </ol>"},{"location":"swarms/chunkers/pdf_chunker/#1-introduction","title":"1. Introduction","text":"<p>The <code>PdfChunker</code> module is a specialized tool designed to split PDF text content into smaller, more manageable chunks. It is a valuable asset for processing PDF documents in natural language processing and text analysis tasks.</p> <p>This documentation provides a comprehensive guide on how to use the <code>PdfChunker</code> module. It covers its purpose, parameters, and usage, ensuring that you can effectively process PDF text content.</p>"},{"location":"swarms/chunkers/pdf_chunker/#2-overview","title":"2. Overview","text":"<p>The <code>PdfChunker</code> module serves a critical role in handling PDF text content, which is often lengthy and complex. Key features and parameters of the <code>PdfChunker</code> module include:</p> <ul> <li><code>separators</code>: Specifies a list of <code>ChunkSeparator</code> objects used to split the PDF text content into chunks.</li> <li><code>tokenizer</code>: Defines the tokenizer used for counting tokens in the text.</li> <li><code>max_tokens</code>: Sets the maximum token limit for each chunk.</li> </ul> <p>By using the <code>PdfChunker</code>, you can efficiently prepare PDF text content for further analysis and processing.</p>"},{"location":"swarms/chunkers/pdf_chunker/#3-installation","title":"3. Installation","text":"<p>Before using the <code>PdfChunker</code> module, ensure you have the required dependencies installed. The module relies on the <code>swarms</code> library. You can install this dependency using pip:</p> <pre><code>pip install swarms\n</code></pre>"},{"location":"swarms/chunkers/pdf_chunker/#4-usage","title":"4. Usage","text":"<p>In this section, we'll explore how to use the <code>PdfChunker</code> module effectively. It consists of the <code>PdfChunker</code> class and provides examples to demonstrate its usage.</p>"},{"location":"swarms/chunkers/pdf_chunker/#41-pdfchunker-class","title":"4.1. <code>PdfChunker</code> Class","text":"<p>The <code>PdfChunker</code> class is the core component of the <code>PdfChunker</code> module. It is used to create a <code>PdfChunker</code> instance, which can split PDF text content into manageable chunks.</p>"},{"location":"swarms/chunkers/pdf_chunker/#parameters","title":"Parameters:","text":"<ul> <li><code>separators</code> (list[ChunkSeparator]): Specifies a list of <code>ChunkSeparator</code> objects used to split the PDF text content into chunks.</li> <li><code>tokenizer</code> (OpenAITokenizer): Defines the tokenizer used for counting tokens in the text.</li> <li><code>max_tokens</code> (int): Sets the maximum token limit for each chunk.</li> </ul>"},{"location":"swarms/chunkers/pdf_chunker/#42-examples","title":"4.2. Examples","text":"<p>Let's explore how to use the <code>PdfChunker</code> class with different scenarios and applications.</p>"},{"location":"swarms/chunkers/pdf_chunker/#example-1-basic-chunking","title":"Example 1: Basic Chunking","text":"<pre><code>from swarms.chunkers.chunk_seperator import ChunkSeparator\nfrom swarms.chunkers.pdf_chunker import PdfChunker\n\n# Initialize the PdfChunker\npdf_chunker = PdfChunker()\n\n# PDF text content to be chunked\npdf_text = \"This is a PDF document with multiple paragraphs and sentences. It should be split into smaller chunks for analysis.\"\n\n# Chunk the PDF text content\nchunks = pdf_chunker.chunk(pdf_text)\n\n# Print the generated chunks\nfor idx, chunk in enumerate(chunks, start=1):\n    print(f\"Chunk {idx}:\\n{chunk.value}\")\n</code></pre>"},{"location":"swarms/chunkers/pdf_chunker/#example-2-custom-separators","title":"Example 2: Custom Separators","text":"<pre><code>from swarms.chunkers.chunk_seperator import ChunkSeparator\nfrom swarms.chunkers.pdf_chunker import PdfChunker\n\n# Define custom separators for PDF chunking\ncustom_separators = [ChunkSeparator(\"\\n\\n\"), ChunkSeparator(\". \")]\n\n# Initialize the PdfChunker with custom separators\npdf_chunker = PdfChunker(separators=custom_separators)\n\n# PDF text content with custom separators\npdf_text = \"This PDF document has custom paragraph separators.\\n\\nIt also uses period-based sentence separators. Split accordingly.\"\n\n# Chunk the PDF text content\nchunks = pdf_chunker.chunk(pdf_text)\n\n# Print the generated chunks\nfor idx, chunk in enumerate(chunks, start=1):\n    print(f\"Chunk {idx}:\\n{chunk.value}\")\n</code></pre>"},{"location":"swarms/chunkers/pdf_chunker/#example-3-adjusting-maximum-tokens","title":"Example 3: Adjusting Maximum Tokens","text":"<pre><code>from swarms.chunkers.pdf_chunker import PdfChunker\n\n# Initialize the PdfChunker with a custom maximum token limit\npdf_chunker = PdfChunker(max_tokens=50)\n\n# Lengthy PDF text content\npdf_text = \"This is an exceptionally long PDF document that should be broken into smaller chunks based on token count.\"\n\n# Chunk the PDF text content\nchunks = pdf_chunker.chunk(pdf_text)\n\n# Print the generated chunks\nfor idx, chunk in enumerate(chunks, start=1):\n    print(f\"Chunk {idx}:\\n{chunk.value}\")\n</code></pre>"},{"location":"swarms/chunkers/pdf_chunker/#43-additional-features","title":"4.3. Additional Features","text":"<p>The <code>PdfChunker</code> class also provides additional features:</p>"},{"location":"swarms/chunkers/pdf_chunker/#recursive-chunking","title":"Recursive Chunking","text":"<p>The <code>_chunk_recursively</code> method handles the recursive chunking of PDF text content, ensuring that each chunk stays within the token limit.</p>"},{"location":"swarms/chunkers/pdf_chunker/#5-additional-information","title":"5. Additional Information","text":"<ul> <li>PDF Text Chunking: The <code>PdfChunker</code> module is a specialized tool for splitting PDF text content into manageable chunks, making it suitable for natural language processing tasks involving PDF documents.</li> <li>Custom Separators: You can customize separators to adapt the PDF text content chunking process to specific document structures.</li> <li>Token Count: The module accurately counts tokens using the specified tokenizer, ensuring that chunks do not exceed token limits.</li> </ul>"},{"location":"swarms/chunkers/pdf_chunker/#6-conclusion","title":"6. Conclusion","text":"<p>The <code>PdfChunker</code> module is a valuable asset for processing PDF text content in various natural language processing and text analysis tasks. This documentation has provided a comprehensive guide on its usage, parameters, and examples, ensuring that you can effectively prepare PDF documents for further analysis and processing.</p> <p>By using the <code>PdfChunker</code>, you can efficiently break down lengthy and complex PDF text content into manageable chunks, making it ready for in-depth analysis.</p> <p>Please check the official <code>PdfChunker</code> repository and documentation for any updates beyond the knowledge cutoff date.</p>"},{"location":"swarms/memory/diy_memory/","title":"Building Custom Vector Memory Databases with the AbstractVectorDatabase Class","text":"<p>In the age of large language models (LLMs) and AI-powered applications, efficient memory management has become a crucial component. Vector databases, which store and retrieve data in high-dimensional vector spaces, have emerged as powerful tools for handling the vast amounts of data generated and consumed by AI systems. However, integrating vector databases into your applications can be a daunting task, requiring in-depth knowledge of their underlying architectures and APIs.</p> <p>Enter the <code>AbstractVectorDatabase</code> class, a powerful abstraction layer designed to simplify the process of creating and integrating custom vector memory databases into your AI applications. By inheriting from this class, developers can build tailored vector database solutions that seamlessly integrate with their existing systems, enabling efficient storage, retrieval, and manipulation of high-dimensional data.</p> <p>In this comprehensive guide, we'll explore the <code>AbstractVectorDatabase</code> class in detail, covering its core functionality and diving deep into the process of creating custom vector memory databases using popular solutions like PostgreSQL, Pinecone, Chroma, FAISS, and more. Whether you're a seasoned AI developer or just starting to explore the world of vector databases, this guide will provide you with the knowledge and tools necessary to build robust, scalable, and efficient memory solutions for your AI applications.</p>"},{"location":"swarms/memory/diy_memory/#understanding-the-abstractvectordatabase-class","title":"Understanding the AbstractVectorDatabase Class","text":"<p>Before we dive into the implementation details, let's take a closer look at the <code>AbstractVectorDatabase</code> class and its core functionality.</p> <p>The <code>AbstractVectorDatabase</code> class is an abstract base class that defines the interface for interacting with a vector database. It serves as a blueprint for creating concrete implementations of vector databases, ensuring a consistent and standardized approach to database operations across different systems.</p> <p>The class provides a set of abstract methods that define the essential functionality required for working with vector databases, such as connecting to the database, executing queries, and performing CRUD (Create, Read, Update, Delete) operations.</p> <p>Here's a breakdown of the abstract methods defined in the <code>AbstractVectorDatabase</code> class:</p> <p>1. <code>connect()</code>: This method establishes a connection to the vector database.</p> <p>2. <code>close()</code>: This method closes the connection to the vector database.</p> <p>3. <code>query(query: str)</code>: This method executes a given query on the vector database.</p> <p>4. <code>fetch_all()</code>: This method retrieves all rows from the result set of a query.</p> <p>5. <code>fetch_one()</code>: This method retrieves a single row from the result set of a query.</p> <p>6. <code>add(doc: str)</code>: This method adds a new record to the vector database.</p> <p>7. <code>get(query: str)</code>: This method retrieves a record from the vector database based on a given query.</p> <p>8. <code>update(doc)</code>: This method updates a record in the vector database.</p> <p>9. <code>delete(message)</code>: This method deletes a record from the vector database.</p> <p>By inheriting from the <code>AbstractVectorDatabase</code> class and implementing these abstract methods, developers can create concrete vector database implementations tailored to their specific needs and requirements.</p>"},{"location":"swarms/memory/diy_memory/#creating-a-custom-vector-memory-database","title":"Creating a Custom Vector Memory Database","text":"<p>Now that we have a solid understanding of the <code>AbstractVectorDatabase</code> class, let's dive into the process of creating a custom vector memory database by inheriting from this class. Throughout this guide, we'll explore various vector database solutions, including PostgreSQL, Pinecone, Chroma, FAISS, and more, showcasing how to integrate them seamlessly into your AI applications.</p>"},{"location":"swarms/memory/diy_memory/#step-1-inherit-from-the-abstractvectordatabase-class","title":"Step 1: Inherit from the AbstractVectorDatabase Class","text":"<p>The first step in creating a custom vector memory database is to inherit from the <code>AbstractVectorDatabase</code> class. This will provide your custom implementation with the foundational structure and interface defined by the abstract class.</p> <pre><code>from abc import ABC, abstractmethod\nfrom swarms import AbstractVectorDatabase\n\nclass MyCustomVectorDatabase(AbstractVectorDatabase):\n\n\u00a0 \u00a0 def __init__(self, *args, **kwargs):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Custom initialization logic\n\n\u00a0 \u00a0 \u00a0 \u00a0 pass\n</code></pre> <p>In the example above, we define a new class <code>MyCustomVectorDatabase</code> that inherits from the <code>AbstractVectorDatabase</code> class. Within the <code>__init__</code> method, you can add any custom initialization logic specific to your vector database implementation.</p>"},{"location":"swarms/memory/diy_memory/#step-2-implement-the-abstract-methods","title":"Step 2: Implement the Abstract Methods","text":"<p>The next step is to implement the abstract methods defined in the <code>AbstractVectorDatabase</code> class. These methods provide the core functionality for interacting with your vector database, such as connecting, querying, and performing CRUD operations.</p> <pre><code>from swarms import AbstractVectorDatabase\n\n\nclass MyCustomVectorDatabase(AbstractVectorDatabase):\n\n\u00a0 \u00a0 def __init__(self, *args, **kwargs):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Custom initialization logic\n\n\u00a0 \u00a0 \u00a0 \u00a0 pass\n\n\u00a0 \u00a0 def connect(self):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Implementation for connecting to the vector database\n\n\u00a0 \u00a0 \u00a0 \u00a0 pass\n\n\u00a0 \u00a0 def close(self):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Implementation for closing the vector database connection\n\n\u00a0 \u00a0 \u00a0 \u00a0 pass\n\n\u00a0 \u00a0 def query(self, query: str):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Implementation for executing a query on the vector database\n\n\u00a0 \u00a0 \u00a0 \u00a0 pass\n\n\u00a0 \u00a0 def fetch_all(self):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Implementation for fetching all rows from the result set\n\n\u00a0 \u00a0 \u00a0 \u00a0 pass\n\n\u00a0 \u00a0 def fetch_one(self):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Implementation for fetching a single row from the result set\n\n\u00a0 \u00a0 \u00a0 \u00a0 pass\n\n\u00a0 \u00a0 def add(self, doc: str):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Implementation for adding a new record to the vector database\n\n\u00a0 \u00a0 \u00a0 \u00a0 pass\n\n\u00a0 \u00a0 def get(self, query: str):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Implementation for retrieving a record from the vector database\n\n\u00a0 \u00a0 \u00a0 \u00a0 pass\n\n\u00a0 \u00a0 def update(self, doc):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Implementation for updating a record in the vector database\n\n\u00a0 \u00a0 \u00a0 \u00a0 pass\n\n\u00a0 \u00a0 def delete(self, message):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Implementation for deleting a record from the vector database\n\n\u00a0 \u00a0 \u00a0 \u00a0 pass\n</code></pre> <p>In this example, we define placeholders for each of the abstract methods within the <code>MyCustomVectorDatabase</code> class. These placeholders will be replaced with the actual implementation logic specific to your chosen vector database solution.</p>"},{"location":"swarms/memory/diy_memory/#step-3-choose-and-integrate-your-vector-database-solution","title":"Step 3: Choose and Integrate Your Vector Database Solution","text":"<p>With the foundational structure in place, it's time to choose a specific vector database solution and integrate it into your custom implementation. In this guide, we'll explore several popular vector database solutions, including PostgreSQL, Pinecone, Chroma, FAISS, and more, providing examples and guidance on how to integrate them seamlessly.</p>"},{"location":"swarms/memory/diy_memory/#postgresql-integration","title":"PostgreSQL Integration","text":"<p>PostgreSQL is a powerful open-source relational database management system that supports vector data types and operations, making it a viable choice for building custom vector memory databases.</p> <pre><code>import psycopg2\nfrom swarms import AbstractVectorDatabase\n\nclass PostgreSQLVectorDatabase(MyCustomVectorDatabase):\n\n\u00a0 \u00a0 def __init__(self, *args, **kwargs):\n\n\u00a0 \u00a0 \u00a0 \u00a0 super().__init__(*args, **kwargs)\n\n\u00a0 \u00a0 \u00a0 \u00a0 # PostgreSQL connection details\n\n\u00a0 \u00a0 \u00a0 \u00a0 self.conn = psycopg2.connect(\n\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 host=\"localhost\",\n\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 database=\"vector_db\",\n\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 user=\"postgres\",\n\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 password=\"your_password\"\n\n\u00a0 \u00a0 \u00a0 \u00a0 )\n\n\u00a0 \u00a0 \u00a0 \u00a0 self.cur = self.conn.cursor()\n\n\u00a0 \u00a0 def connect(self):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # PostgreSQL connection logic\n\n\u00a0 \u00a0 \u00a0 \u00a0 pass\n\n\u00a0 \u00a0 def close(self):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Close PostgreSQL connection\n\n\u00a0 \u00a0 \u00a0 \u00a0 self.cur.close()\n\n\u00a0 \u00a0 \u00a0 \u00a0 self.conn.close()\n\n\u00a0 \u00a0 def query(self, query: str):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Execute PostgreSQL query\n\n\u00a0 \u00a0 \u00a0 \u00a0 self.cur.execute(query)\n\n\u00a0 \u00a0 def fetch_all(self):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Fetch all rows from PostgreSQL result set\n\n\u00a0 \u00a0 \u00a0 \u00a0 return self.cur.fetchall()\n\n\u00a0 \u00a0 # Implement other abstract methods\n</code></pre> <p>In this example, we define a <code>PostgreSQLVectorDatabase</code> class that inherits from <code>MyCustomVectorDatabase</code>. Within the <code>__init__</code> method, we establish a connection to a PostgreSQL database using the <code>psycopg2</code> library. We then implement the <code>connect()</code>, <code>close()</code>, <code>query()</code>, and <code>fetch_all()</code> methods specific to PostgreSQL.</p>"},{"location":"swarms/memory/diy_memory/#pinecone-integration","title":"Pinecone Integration","text":"<p>Pinecone is a managed vector database service that provides efficient storage, retrieval, and manipulation of high-dimensional vector data.</p> <pre><code>import pinecone\nfrom swarms import AbstractVectorDatabase\n\n\nclass PineconeVectorDatabase(MyCustomVectorDatabase):\n\n\u00a0 \u00a0 def __init__(self, *args, **kwargs):\n\n\u00a0 \u00a0 \u00a0 \u00a0 super().__init__(*args, **kwargs)\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Pinecone initialization\n\n\u00a0 \u00a0 \u00a0 \u00a0 pinecone.init(api_key=\"your_api_key\", environment=\"your_environment\")\n\n\u00a0 \u00a0 \u00a0 \u00a0 self.index = pinecone.Index(\"your_index_name\")\n\n\u00a0 \u00a0 def connect(self):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Pinecone connection logic\n\n\u00a0 \u00a0 \u00a0 \u00a0 pass\n\n\u00a0 \u00a0 def close(self):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Close Pinecone connection\n\n\u00a0 \u00a0 \u00a0 \u00a0 pass\n\n\u00a0 \u00a0 def query(self, query: str):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Execute Pinecone query\n\n\u00a0 \u00a0 \u00a0 \u00a0 results = self.index.query(query)\n\n\u00a0 \u00a0 \u00a0 \u00a0 return results\n\n\u00a0 \u00a0 def add(self, doc: str):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Add document to Pinecone index\n\n\u00a0 \u00a0 \u00a0 \u00a0 self.index.upsert([(\"id\", doc)])\n\n\u00a0 \u00a0 # Implement other abstract methods\n</code></pre> <p>In this example, we define a <code>PineconeVectorDatabase</code> class that inherits from <code>MyCustomVectorDatabase</code>. Within the <code>__init__</code> method, we initialize the Pinecone client and create an index. We then implement the <code>query()</code> and <code>add()</code> methods specific to the Pinecone API.</p>"},{"location":"swarms/memory/diy_memory/#chroma-integration","title":"Chroma Integration","text":"<p>Chroma is an open-source vector database library that provides efficient storage, retrieval, and manipulation of vector data using various backends, including DuckDB, Chromadb, and more.</p> <pre><code>from chromadb.client import Client\nfrom swarms import AbstractVectorDatabase\n\nclass ChromaVectorDatabase(MyCustomVectorDatabase):\n\n\u00a0 \u00a0 def __init__(self, *args, **kwargs):\n\n\u00a0 \u00a0 \u00a0 \u00a0 super().__init__(*args, **kwargs)\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Chroma initialization\n\n\u00a0 \u00a0 \u00a0 \u00a0 self.client = Client()\n\n\u00a0 \u00a0 \u00a0 \u00a0 self.collection = self.client.get_or_create_collection(\"vector_collection\")\n\n\u00a0 \u00a0 def connect(self):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Chroma connection logic\n\n\u00a0 \u00a0 \u00a0 \u00a0 pass\n\n\u00a0 \u00a0 def close(self):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Close Chroma connection\n\n\u00a0 \u00a0 \u00a0 \u00a0 pass\n\n\u00a0 \u00a0 def query(self, query: str):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Execute Chroma query\n\n\u00a0 \u00a0 \u00a0 \u00a0 results = self.collection.query(query)\n\n\u00a0 \u00a0 \u00a0 \u00a0 return results\n\n\u00a0 \u00a0 def add(self, doc: str):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Add document to Chroma collection\n\n\u00a0 \u00a0 \u00a0 \u00a0 self.collection.add(doc)\n\n\u00a0 \u00a0 # Implement other abstract methods\n</code></pre> <p>In this example, we define a <code>ChromaVectorDatabase</code> class that inherits from <code>MyCustomVectorDatabase</code>. Within the <code>__init__</code> method, we create a Chroma client and get or create a collection. We then implement the <code>query()</code> and <code>add()</code> methods specific to the Chroma API.</p>"},{"location":"swarms/memory/diy_memory/#faiss-integration","title":"FAISS Integration","text":"<p>FAISS (Facebook AI Similarity Search) is a library for efficient similarity search and clustering of dense vectors, developed by Meta AI.</p> <pre><code>import faiss\n\nclass FAISSVectorDatabase(MyCustomVectorDatabase):\n\n\u00a0 \u00a0 def __init__(self, *args, **kwargs):\n\n\u00a0 \u00a0 \u00a0 \u00a0 super().__init__(*args, **kwargs)\n\n\u00a0 \u00a0 \u00a0 \u00a0 # FAISS initialization\n\n\u00a0 \u00a0 \u00a0 \u00a0 self.index = faiss.IndexFlatL2(64)\u00a0 # Assuming 64-dimensional vectors\n\n\u00a0 \u00a0 \u00a0 \u00a0 self.index_path = \"faiss_index.index\"\n\n\u00a0 \u00a0 def connect(self):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # FAISS connection logic\n\n\u00a0 \u00a0 \u00a0 \u00a0 self.index = faiss.read_index(self.index_path)\n\n\u00a0 \u00a0 def close(self):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Close FAISS connection\n\n\u00a0 \u00a0 \u00a0 \u00a0 faiss.write_index(self.index, self.index_path)\n\n\u00a0 \u00a0 def query(self, query: str):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Execute FAISS query\n\n\u00a0 \u00a0 \u00a0 \u00a0 query_vector = # Convert query to vector\n\n\u00a0 \u00a0 \u00a0 \u00a0 distances, indices = self.index.search(query_vector, k=10)\n\n\u00a0 \u00a0 \u00a0 \u00a0 return [(self.index.reconstruct(i), d) for i, d in zip(indices, distances)]\n\n\u00a0 \u00a0 def add(self, doc: str):\n\n\u00a0 \u00a0 \u00a0 \u00a0 # Add document to FAISS index\n\n\u00a0 \u00a0 \u00a0 \u00a0 doc_vector = # Convert doc to vector\n\n\u00a0 \u00a0 \u00a0 \u00a0 self.index.add(doc_vector)\n\n\u00a0 \u00a0 # Implement other abstract methods\n</code></pre> <p>In this example, we define a <code>FAISSVectorDatabase</code> class that inherits from <code>MyCustomVectorDatabase</code>. Within the <code>__init__</code> method, we create a FAISS index and set the index path. We then implement the <code>connect()</code>, <code>close()</code>, <code>query()</code>, and <code>add()</code> methods specific to the FAISS library, assuming 64-dimensional vectors for simplicity.</p> <p>These examples provide a starting point for integrating various vector database solutions into your custom implementation. Each solution has its own strengths, weaknesses, and trade-offs, so it's essential to carefully evaluate your requirements and choose the solution that best fits your needs.</p>"},{"location":"swarms/memory/diy_memory/#step-4-add-custom-functionality-and-optimizations","title":"Step 4: Add Custom Functionality and Optimizations","text":"<p>Once you've integrated your chosen vector database solution, you can further extend and optimize your custom implementation by adding custom functionality and performance optimizations.</p>"},{"location":"swarms/memory/diy_memory/#custom-functionality","title":"Custom Functionality:","text":"<ul> <li> <p>Indexing Strategies: Implement custom indexing strategies to optimize search performance and memory usage.</p> </li> <li> <p>Data Preprocessing: Add data preprocessing logic to handle different data formats, perform embedding, and prepare data for storage in the vector database.</p> </li> <li> <p>Query Optimization: Introduce query optimization techniques, such as query caching, result filtering, or query rewriting, to improve query performance.</p> </li> <li> <p>Data Partitioning: Implement data partitioning strategies to distribute data across multiple nodes or shards for better scalability and performance.</p> </li> <li> <p>Metadata Management: Introduce metadata management capabilities to store and retrieve additional information associated with the vector data.</p> </li> </ul> <p>Performance Optimizations:</p> <ul> <li> <p>Caching: Implement caching mechanisms to reduce redundant computations and improve response times.</p> </li> <li> <p>Asynchronous Operations: Utilize asynchronous programming techniques to improve concurrency and responsiveness.</p> </li> <li> <p>Multithreading and Parallelization: Leverage multithreading and parallelization to distribute computationally intensive tasks across multiple cores or processors.</p> </li> <li> <p>Load Balancing: Implement load balancing strategies to distribute workloads evenly across multiple nodes or instances.</p> </li> <li> <p>Monitoring and Profiling: Introduce monitoring and profiling tools to identify performance bottlenecks and optimize critical sections of your code.</p> </li> </ul> <p>By adding custom functionality and performance optimizations, you can tailor your custom vector memory database to meet the specific requirements of your AI applications, ensuring efficient and scalable data management.</p>"},{"location":"swarms/memory/diy_memory/#best-practices-and-considerations","title":"Best Practices and Considerations","text":"<p>Building custom vector memory databases is a powerful but complex endeavor. To ensure the success and longevity of your implementation, it's essential to follow best practices and consider potential challenges and considerations.</p> <p>1. Scalability and Performance Testing: Vector databases can quickly grow in size and complexity as your AI applications handle increasing amounts of data. Thoroughly test your implementation for scalability and performance under various load conditions, and optimize accordingly.</p> <p>2. Data Quality and Integrity: Ensure that the data stored in your vector database is accurate, consistent, and free from duplicates or errors. Implement data validation and cleansing mechanisms to maintain data quality and integrity.</p> <p>3. Security and Access Control: Vector databases may store sensitive or proprietary data. Implement robust security measures, such as encryption, access controls, and auditing mechanisms, to protect your data from unauthorized access or breaches.</p> <p>4. Distributed Architectures: As your data and workloads grow, consider implementing distributed architectures to distribute the storage and computational load across multiple nodes or clusters. This can improve scalability, fault tolerance, and overall performance.</p> <p>5. Data Versioning and Backup: Implement data versioning and backup strategies to ensure data integrity and enable recovery in case of errors or system failures.</p> <p>6. Documentation and Maintainability: Well-documented code and comprehensive documentation are essential for ensuring the long-term maintainability and extensibility of your custom vector memory database implementation.</p> <p>7. Continuous Integration and Deployment: Adopt continuous integration and deployment practices to streamline the development, testing, and deployment processes, ensuring that changes are thoroughly tested and deployed efficiently.</p> <p>8. Compliance and Regulatory Requirements: Depending on your industry and use case, ensure that your custom vector memory database implementation complies with relevant regulations and standards, such as data privacy laws or industry-specific guidelines.</p> <p>9. Community Engagement and Collaboration: Stay engaged with the vector database community, participate in discussions, and collaborate with other developers to share knowledge, best practices, and insights.</p> <p>By following these best practices and considering potential challenges, you can build robust, scalable, and efficient custom vector memory databases that meet the demanding requirements of modern AI applications.</p>"},{"location":"swarms/memory/diy_memory/#conclusion","title":"Conclusion","text":"<p>In this comprehensive guide, we've explored the <code>AbstractVectorDatabase</code> class and its role in simplifying the process of creating custom vector memory databases. We've covered the core functionality of the class, walked through the step-by-step process of inheriting and extending its functionality, and provided examples of integrating popular vector database solutions like PostgreSQL, Pinecone, Chroma, and FAISS.</p> <p>Building custom vector memory databases empowers developers to create tailored and efficient data management solutions that seamlessly integrate with their AI applications. By leveraging the power of vector databases, you can unlock new possibilities in data storage, retrieval, and manipulation, enabling your AI systems to handle vast amounts of high-dimensional data with ease.</p> <p>Remember, the journey of building custom vector memory databases is an iterative and collaborative process that requires continuous learning, adaptation, and refinement. Embrace the challenges, stay up-to-date with the latest developments in vector databases and AI, and continuously strive to optimize and enhance your implementations.</p> <p>As you embark on this journey, keep in mind the importance of scalability, performance, data quality, security, and compliance. Foster an environment of collaboration, knowledge sharing, and community engagement to ensure that your custom vector memory databases are robust, reliable, and capable of meeting the ever-evolving demands of the AI landscape.</p> <p>So, dive in, leverage the power of the <code>AbstractVectorDatabase</code> class, and create the custom vector memory databases that will drive the future of AI-powered applications.</p>"},{"location":"swarms/memory/pg/","title":"<code>PgVectorVectorStore</code> Documentation","text":""},{"location":"swarms/memory/pg/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction</li> <li>Overview</li> <li>Class Definition</li> <li>Functionality and Usage</li> <li>Setting Up the Database</li> <li>Upserting Vectors</li> <li>Loading Vector Entries</li> <li>Querying Vectors</li> <li>Additional Information</li> <li>References and Resources</li> </ol>"},{"location":"swarms/memory/pg/#1-introduction","title":"1. Introduction","text":"<p>Welcome to the documentation for the Swarms <code>PgVectorVectorStore</code> class! Swarms is a library that provides various memory and storage options for high-dimensional vectors. In this documentation, we will focus on the <code>PgVectorVectorStore</code> class, which is a vector storage driver that uses PostgreSQL with the PGVector extension as the underlying storage engine.</p>"},{"location":"swarms/memory/pg/#11-purpose","title":"1.1 Purpose","text":"<p>The <code>PgVectorVectorStore</code> class allows you to interact with a PostgreSQL database and store high-dimensional vectors efficiently. By using Swarms with PostgreSQL and PGVector, you can manage and work with vector data in your applications with ease.</p>"},{"location":"swarms/memory/pg/#12-key-features","title":"1.2 Key Features","text":"<ul> <li>Integration with PostgreSQL and PGVector for vector storage.</li> <li>Simple and convenient API for upserting vectors, querying, and loading entries.</li> <li>Support for creating and managing vector collections in PostgreSQL.</li> </ul>"},{"location":"swarms/memory/pg/#2-overview","title":"2. Overview","text":"<p>Before diving into the details of the <code>PgVectorVectorStore</code> class, let's provide an overview of its purpose and functionality.</p> <p>The <code>PgVectorVectorStore</code> class is designed to:</p> <ul> <li>Store high-dimensional vectors in a PostgreSQL database with the PGVector extension.</li> <li>Offer a seamless and efficient way to upsert vectors into the database.</li> <li>Provide methods for loading individual vector entries or all vector entries in a collection.</li> <li>Support vector queries, allowing you to find vectors similar to a given query vector.</li> </ul> <p>In the following sections, we will explore the class definition, its parameters, and how to use it effectively.</p>"},{"location":"swarms/memory/pg/#3-class-definition","title":"3. Class Definition","text":"<p>Let's start by examining the class definition of <code>PgVectorVectorStore</code>, including its attributes and parameters.</p> <pre><code>class PgVectorVectorStore(BaseVectorStore):\n    \"\"\"\n    A vector store driver to Postgres using the PGVector extension.\n\n    Attributes:\n        connection_string: An optional string describing the target Postgres database instance.\n        create_engine_params: Additional configuration params passed when creating the database connection.\n        engine: An optional sqlalchemy Postgres engine to use.\n        table_name: Optionally specify the name of the table to used to store vectors.\n    ...\n    \"\"\"\n</code></pre> <p>Attributes:</p> <ul> <li><code>connection_string</code> (Optional[str]): An optional string describing the target Postgres database instance.</li> <li><code>create_engine_params</code> (dict): Additional configuration parameters passed when creating the database connection.</li> <li><code>engine</code> (Optional[Engine]): An optional SQLAlchemy Postgres engine to use.</li> <li><code>table_name</code> (str): Optionally specify the name of the table to be used to store vectors.</li> </ul>"},{"location":"swarms/memory/pg/#31-attribute-validators","title":"3.1 Attribute Validators","text":"<p>The class includes validators for the <code>connection_string</code> and <code>engine</code> attributes to ensure their proper usage. These validators help maintain consistency in attribute values.</p>"},{"location":"swarms/memory/pg/#32-initialization","title":"3.2 Initialization","text":"<p>During initialization, the class checks if an engine is provided. If an engine is not provided, it creates a new database connection using the <code>connection_string</code> and <code>create_engine_params</code>.</p>"},{"location":"swarms/memory/pg/#4-functionality-and-usage","title":"4. Functionality and Usage","text":"<p>In this section, we will explore the functionality of the <code>PgVectorVectorStore</code> class and provide detailed instructions on how to use it effectively.</p>"},{"location":"swarms/memory/pg/#41-setting-up-the-database","title":"4.1 Setting Up the Database","text":"<p>Before using the <code>PgVectorVectorStore</code> to store and query vectors, you need to set up the database. This includes creating the necessary extensions and database schema. You can do this using the <code>setup</code> method.</p> <pre><code>def setup(\n    self,\n    create_schema: bool = True,\n    install_uuid_extension: bool = True,\n    install_vector_extension: bool = True,\n) -&gt; None:\n    \"\"\"\n    Provides a mechanism to initialize the database schema and extensions.\n\n    Parameters:\n    - create_schema (bool): If True, creates the necessary database schema for vector storage. Default: True.\n    - install_uuid_extension (bool): If True, installs the UUID extension in the database. Default: True.\n    - install_vector_extension (bool): If True, installs the PGVector extension in the database. Default: True.\n    \"\"\"\n</code></pre>"},{"location":"swarms/memory/pg/#example-1-setting-up-the-database","title":"Example 1: Setting Up the Database","text":"<pre><code># Initialize the PgVectorVectorStore instance\nvector_store = PgVectorVectorStore(\n    connection_string=\"your-db-connection-string\", table_name=\"your-table-name\"\n)\n\n# Set up the database with default settings\nvector_store.setup()\n</code></pre>"},{"location":"swarms/memory/pg/#example-2-customized-database-setup","title":"Example 2: Customized Database Setup","text":"<pre><code># Initialize the PgVectorVectorStore instance\nvector_store = PgVectorVectorStore(\n    connection_string=\"your-db-connection-string\", table_name=\"your-table-name\"\n)\n\n# Set up the database with customized settings\nvector_store.setup(\n    create_schema=False, install_uuid_extension=True, install_vector_extension=True\n)\n</code></pre>"},{"location":"swarms/memory/pg/#42-upserting-vectors","title":"4.2 Upserting Vectors","text":"<p>The <code>upsert_vector</code> method allows you to insert or update a vector in the collection. You can specify the vector, an optional vector ID, namespace, and metadata.</p> <pre><code>def upsert_vector(\n    self,\n    vector: list[float],\n    vector_id: Optional[str] = None,\n    namespace: Optional[str] = None,\n    meta: Optional[dict] = None,\n    **kwargs,\n) -&gt; str:\n    \"\"\"\n    Inserts or updates a vector in the collection.\n\n    Parameters:\n    - vector (list[float]): The vector to upsert.\n    - vector_id (Optional[str]): An optional ID for the vector. If not provided, a unique ID will be generated.\n    - namespace (Optional[str]): An optional namespace for the vector.\n    - meta (Optional[dict]): An optional metadata dictionary associated with the vector.\n    - **kwargs: Additional keyword arguments.\n\n    Returns:\n    - str: The ID of the upserted vector.\n    \"\"\"\n</code></pre>"},{"location":"swarms/memory/pg/#example-upserting-a-vector","title":"Example: Upserting a Vector","text":"<pre><code># Initialize the PgVectorVectorStore instance\nvector_store = PgVectorVectorStore(\n    connection_string=\"your-db-connection-string\", table_name=\"your-table-name\"\n)\n\n# Define a vector and upsert it\nvector = [0.1, 0.2, 0.3, 0.4]\nvector_id = \"unique-vector-id\"\nnamespace = \"your-namespace\"\nmeta = {\"key1\": \"value1\", \"key2\": \"value2\"}\n\nvector_store.upsert_vector(\n    vector=vector, vector_id=vector_id, namespace=namespace, meta=meta\n)\n</code></pre>"},{"location":"swarms/memory/pg/#43-loading-vector-entries","title":"4.3 Loading Vector Entries","text":"<p>You can load vector entries from the collection using the <code>load_entry</code> and <code>load_entries</code> methods.</p>"},{"location":"swarms/memory/pg/#4","title":"4","text":"<p>.3.1 Loading a Single Entry</p> <p>The <code>load_entry</code> method allows you to load a specific vector entry based on its identifier and optional namespace.</p> <pre><code>def load_entry(\n    self, vector_id: str, namespace: Optional[str] = None\n) -&gt; BaseVectorStore.Entry:\n    \"\"\"\n    Retrieves a specific vector entry from the collection based on its identifier and optional namespace.\n\n    Parameters:\n    - vector_id (str): The ID of the vector to retrieve.\n    - namespace (Optional[str]): An optional namespace for filtering. Default: None.\n\n    Returns:\n    - BaseVectorStore.Entry: The loaded vector entry.\n    \"\"\"\n</code></pre>"},{"location":"swarms/memory/pg/#example-loading-a-single-entry","title":"Example: Loading a Single Entry","text":"<pre><code># Initialize the PgVectorVectorStore instance\nvector_store = PgVectorVectorStore(connection_string=\"your-db-connection-string\", table_name=\"your-table-name\")\n\n# Load a specific vector entry\nloaded_entry = vector_store.load_entry(vector_id=\"unique-vector-id\", namespace=\"your-namespace\")\n\nif loaded_entry is not None:\n    loaded_vector = loaded_entry.vector\n    loaded_meta = loaded_entry.meta\n    # Use the loaded vector and metadata as needed\nelse:\n    # Vector not found\n</code></pre>"},{"location":"swarms/memory/pg/#432-loading-multiple-entries","title":"4.3.2 Loading Multiple Entries","text":"<p>The <code>load_entries</code> method allows you to load all vector entries from the collection, optionally filtering by namespace.</p> <pre><code>def load_entries(self, namespace: Optional[str] = None) -&gt; list[BaseVectorStore.Entry]:\n    \"\"\"\n    Retrieves all vector entries from the collection, optionally filtering to only those that match the provided namespace.\n\n    Parameters:\n    - namespace (Optional[str]): An optional namespace for filtering. Default: None.\n\n    Returns:\n    - list[BaseVectorStore.Entry]: A list of loaded vector entries.\n    \"\"\"\n</code></pre>"},{"location":"swarms/memory/pg/#example-loading-multiple-entries","title":"Example: Loading Multiple Entries","text":"<pre><code># Initialize the PgVectorVectorStore instance\nvector_store = PgVectorVectorStore(\n    connection_string=\"your-db-connection-string\", table_name=\"your-table-name\"\n)\n\n# Load all vector entries in the specified namespace\nentries = vector_store.load_entries(namespace=\"your-namespace\")\n\n# Process the loaded entries\nfor entry in entries:\n    vector_id = entry.id\n    vector = entry.vector\n    meta = entry.meta\n\n    # Handle the loaded entries as needed\n</code></pre>"},{"location":"swarms/memory/pg/#44-querying-vectors","title":"4.4 Querying Vectors","text":"<p>You can perform vector queries to find vectors similar to a given query vector using the <code>query</code> method. You can specify the query string, the maximum number of results to return, and other options.</p> <pre><code>def query(\n    self,\n    query: str,\n    count: Optional[int] = BaseVectorStore.DEFAULT_QUERY_COUNT,\n    namespace: Optional[str] = None,\n    include_vectors: bool = False,\n    distance_metric: str = \"cosine_distance\",\n    **kwargs,\n) -&gt; list[BaseVectorStore.QueryResult]:\n    \"\"\"\n    Performs a search on the collection to find vectors similar to the provided input vector,\n    optionally filtering to only those that match the provided namespace.\n\n    Parameters:\n    - query (str): The query string to find similar vectors.\n    - count (Optional[int]): Maximum number of results to return. Default: BaseVectorStore.DEFAULT_QUERY_COUNT.\n    - namespace (Optional[str]): An optional namespace for filtering. Default: None.\n    - include_vectors (bool): If True, includes vectors in the query results. Default: False.\n    - distance_metric (str): The distance metric to use for similarity measurement.\n      Options: \"cosine_distance\", \"l2_distance\", \"inner_product\". Default: \"cosine_distance\".\n    - **kwargs: Additional keyword arguments.\n\n    Returns:\n    - list[BaseVectorStore.QueryResult]: A list of query results, each containing vector ID, vector (if included), score, and metadata.\n    \"\"\"\n</code></pre>"},{"location":"swarms/memory/pg/#example-querying-vectors","title":"Example: Querying Vectors","text":"<pre><code># Initialize the PgVectorVectorStore instance\nvector_store = PgVectorVectorStore(\n    connection_string=\"your-db-connection-string\", table_name=\"your-table-name\"\n)\n\n# Perform a vector query\nquery_string = \"your-query-string\"\ncount = 10  # Maximum number of results to return\nnamespace = \"your-namespace\"\ninclude_vectors = False  # Set to True to include vectors in results\ndistance_metric = \"cosine_distance\"\n\nresults = vector_store.query(\n    query=query_string,\n    count=count,\n    namespace=namespace,\n    include_vectors=include_vectors,\n    distance_metric=distance_metric,\n)\n\n# Process the query results\nfor result in results:\n    vector_id = result.id\n    vector = result.vector\n    score = result.score\n    meta = result.meta\n\n    # Handle the results as needed\n</code></pre>"},{"location":"swarms/memory/pg/#5-additional-information","title":"5. Additional Information","text":"<p>Here are some additional tips and information for using the <code>PgVectorVectorStore</code> class effectively:</p> <ul> <li>When upserting vectors, you can generate a unique vector ID using a hash of the vector's content to ensure uniqueness.</li> <li>Consider using namespaces to organize and categorize vectors within your PostgreSQL database.</li> <li>You can choose from different distance metrics (cosine distance, L2 distance, inner product) for vector querying based on your application's requirements.</li> <li>Keep your database connection string secure and follow best practices for database access control.</li> </ul>"},{"location":"swarms/memory/pg/#6-references-and-resources","title":"6. References and Resources","text":"<p>Here are some references and resources for further information on Swarms and PostgreSQL with PGVector:</p> <ul> <li>Swarms GitHub Repository: Swarms library on GitHub for updates and contributions.</li> <li>PostgreSQL Official Website: Official PostgreSQL website for documentation and resources.</li> <li>PGVector GitHub Repository: PGVector extension on GitHub for detailed information.</li> </ul> <p>This concludes the documentation for the Swarms <code>PgVectorVectorStore</code> class. You now have a comprehensive understanding of how to use Swarms with PostgreSQL and PGVector for vector storage. If you have any further questions or need assistance, please refer to the provided references and resources. Happy coding!</p>"},{"location":"swarms/memory/pinecone/","title":"<code>PineconeDB</code> Documentation","text":""},{"location":"swarms/memory/pinecone/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction</li> <li>PineconeVector Class</li> <li>Installation</li> <li>Usage</li> <li>Creating a PineconeVector Instance</li> <li>Creating an Index</li> <li>Upserting Vectors</li> <li>Querying the Index</li> <li>Loading an Entry</li> <li>Loading Entries</li> <li>Additional Information</li> <li>References and Resources</li> </ol>"},{"location":"swarms/memory/pinecone/#1-introduction","title":"1. Introduction","text":"<p>Welcome to the Swarms documentation! Swarms is a library that provides various memory and storage options for high-dimensional vectors. In this documentation, we will focus on the <code>PineconeVector</code> class, which is a vector storage driver that uses Pinecone as the underlying storage engine.</p>"},{"location":"swarms/memory/pinecone/#11-purpose","title":"1.1 Purpose","text":"<p>The <code>PineconeVector</code> class allows you to interact with Pinecone, a vector database that enables the storage, search, and retrieval of high-dimensional vectors with speed and low latency. By using Swarms with Pinecone, you can easily manage and work with vector data in your applications without the need to manage infrastructure.</p>"},{"location":"swarms/memory/pinecone/#12-key-features","title":"1.2 Key Features","text":"<ul> <li>Seamless integration with Pinecone for vector storage.</li> <li>Simple and convenient API for upserting vectors, querying, and loading entries.</li> <li>Support for creating and managing indexes.</li> </ul>"},{"location":"swarms/memory/pinecone/#2-pineconevector-class","title":"2. PineconeVector Class","text":"<p>The <code>PineconeVector</code> class is the core component of Swarms that interacts with Pinecone for vector storage. Below, we will provide an in-depth overview of this class, including its purpose, parameters, and methods.</p>"},{"location":"swarms/memory/pinecone/#21-class-definition","title":"2.1 Class Definition","text":"<pre><code>class PineconeVector(BaseVector):\n</code></pre>"},{"location":"swarms/memory/pinecone/#22-parameters","title":"2.2 Parameters","text":"<p>The <code>PineconeVector</code> class accepts the following parameters during initialization:</p> <ul> <li><code>api_key</code> (str): The API key for your Pinecone account.</li> <li><code>index_name</code> (str): The name of the index to use.</li> <li><code>environment</code> (str): The environment to use. Either \"us-west1-gcp\" or \"us-east1-gcp\".</li> <li><code>project_name</code> (str, optional): The name of the project to use. Defaults to <code>None</code>.</li> <li><code>index</code> (pinecone.Index, optional): The Pinecone index to use. Defaults to <code>None</code>.</li> </ul>"},{"location":"swarms/memory/pinecone/#23-methods","title":"2.3 Methods","text":"<p>The <code>PineconeVector</code> class provides several methods for interacting with Pinecone:</p>"},{"location":"swarms/memory/pinecone/#231-upsert_vector","title":"2.3.1 <code>upsert_vector</code>","text":"<pre><code>def upsert_vector(\n    self,\n    vector: list[float],\n    vector_id: Optional[str] = None,\n    namespace: Optional[str] = None,\n    meta: Optional[dict] = None,\n    **kwargs\n) -&gt; str:\n</code></pre> <p>Upserts a vector into the index.</p> <ul> <li><code>vector</code> (list[float]): The vector to upsert.</li> <li><code>vector_id</code> (Optional[str]): An optional ID for the vector. If not provided, a unique ID will be generated.</li> <li><code>namespace</code> (Optional[str]): An optional namespace for the vector.</li> <li><code>meta</code> (Optional[dict]): An optional metadata dictionary associated with the vector.</li> <li><code>**kwargs</code>: Additional keyword arguments.</li> </ul>"},{"location":"swarms/memory/pinecone/#232-load_entry","title":"2.3.2 <code>load_entry</code>","text":"<pre><code>def load_entry(\n    self, vector_id: str, namespace: Optional[str] = None\n) -&gt; Optional[BaseVector.Entry]:\n</code></pre> <p>Loads a single vector from the index.</p> <ul> <li><code>vector_id</code> (str): The ID of the vector to load.</li> <li><code>namespace</code> (Optional[str]): An optional namespace for the vector.</li> </ul>"},{"location":"swarms/memory/pinecone/#233-load_entries","title":"2.3.3 <code>load_entries</code>","text":"<pre><code>def load_entries(self, namespace: Optional[str] = None) -&gt; list[BaseVector.Entry]:\n</code></pre> <p>Loads all vectors from the index.</p> <ul> <li><code>namespace</code> (Optional[str]): An optional namespace for the vectors.</li> </ul>"},{"location":"swarms/memory/pinecone/#234-query","title":"2.3.4 <code>query</code>","text":"<pre><code>def query(\n    self,\n    query: str,\n    count: Optional[int] = None,\n    namespace: Optional[str] = None,\n    include_vectors: bool = False,\n    include_metadata=True,\n    **kwargs\n) -&gt; list[BaseVector.QueryResult]:\n</code></pre> <p>Queries the index for vectors similar to the given query string.</p> <ul> <li><code>query</code> (str): The query string.</li> <li><code>count</code> (Optional[int]): The maximum number of results to return. If not provided, a default value is used.</li> <li><code>namespace</code> (Optional[str]): An optional namespace for the query.</li> <li><code>include_vectors</code> (bool): Whether to include vectors in the query results.</li> <li><code>include_metadata</code> (bool): Whether to include metadata in the query results.</li> <li><code>**kwargs</code>: Additional keyword arguments.</li> </ul>"},{"location":"swarms/memory/pinecone/#235-create_index","title":"2.3.5 <code>create_index</code>","text":"<pre><code>def create_index(self, name: str, **kwargs) -&gt; None:\n</code></pre> <p>Creates a new index.</p> <ul> <li><code>name</code> (str): The name of the index to create.</li> <li><code>**kwargs</code>: Additional keyword arguments.</li> </ul>"},{"location":"swarms/memory/pinecone/#3-installation","title":"3. Installation","text":"<p>To use the Swarms library and the <code>PineconeVector</code> class, you will need to install the library and its dependencies. Follow these steps to get started:</p> <ol> <li>Install Swarms:</li> </ol> <pre><code>pip install swarms\n</code></pre> <ol> <li>Install Pinecone:</li> </ol> <p>You will also need a Pinecone account and API key. Follow the instructions on the Pinecone website to create an account and obtain an API key.</p> <ol> <li>Import the necessary modules in your Python code:</li> </ol> <pre><code>from swarms.memory.vector_stores.pinecone import PineconeVector\n</code></pre> <p>Now you're ready to use the <code>PineconeVector</code> class to work with Pinecone for vector storage.</p>"},{"location":"swarms/memory/pinecone/#4-usage","title":"4. Usage","text":"<p>In this section, we will provide detailed examples of how to use the <code>PineconeVector</code> class for vector storage with Pinecone.</p>"},{"location":"swarms/memory/pinecone/#41-creating-a-pineconevector-instance","title":"4.1 Creating a PineconeVector Instance","text":"<p>To get started, you need to create an instance of the <code>PineconeVector</code> class. You will need your Pinecone API key, the name of the index you want to use, and the environment. You can also specify an optional project name if you have one.</p> <pre><code>pv = PineconeVector(\n    api_key=\"your-api-key\",\n    index_name=\"your-index-name\",\n    environment=\"us-west1-gcp\",\n    project_name=\"your-project-name\",\n)\n</code></pre>"},{"location":"swarms/memory/pinecone/#42-creating-an-index","title":"4.2 Creating an Index","text":"<p>Before you can upsert vectors, you need to create an index in Pinecone. You can use the <code>create_index</code> method for this purpose.</p> <pre><code>pv.create_index(\"your-index-name\")\n</code></pre>"},{"location":"swarms/memory/pinecone/#43-upserting-vectors","title":"4.3 Upserting Vectors","text":"<p>You can upsert vectors into the Pine</p> <p>cone index using the <code>upsert_vector</code> method. This method allows you to specify the vector, an optional vector ID, namespace, and metadata.</p> <pre><code>vector = [0.1, 0.2, 0.3, 0.4]\nvector_id = \"unique-vector-id\"\nnamespace = \"your-namespace\"\nmeta = {\"key1\": \"value1\", \"key2\": \"value2\"}\n\npv.upsert_vector(vector=vector, vector_id=vector_id, namespace=namespace, meta=meta)\n</code></pre>"},{"location":"swarms/memory/pinecone/#44-querying-the-index","title":"4.4 Querying the Index","text":"<p>You can query the Pinecone index to find vectors similar to a given query string using the <code>query</code> method. You can specify the query string, the maximum number of results to return, and other options.</p> <pre><code>query_string = \"your-query-string\"\ncount = 10  # Maximum number of results to return\nnamespace = \"your-namespace\"\ninclude_vectors = False  # Set to True to include vectors in results\ninclude_metadata = True\n\nresults = pv.query(\n    query=query_string,\n    count=count,\n    namespace=namespace,\n    include_vectors=include_vectors,\n    include_metadata=include_metadata,\n)\n\n# Process the query results\nfor result in results:\n    vector_id = result.id\n    vector = result.vector\n    score = result.score\n    meta = result.meta\n\n    # Handle the results as needed\n</code></pre>"},{"location":"swarms/memory/pinecone/#45-loading-an-entry","title":"4.5 Loading an Entry","text":"<p>You can load a single vector entry from the Pinecone index using the <code>load_entry</code> method. Provide the vector ID and an optional namespace.</p> <pre><code>vector_id = \"your-vector-id\"\nnamespace = \"your-namespace\"\n\nentry = pv.load_entry(vector_id=vector_id, namespace=namespace)\n\nif entry is not None:\n    loaded_vector = entry.vector\n    loaded_meta = entry.meta\n\n    # Use the loaded vector and metadata\nelse:\n    # Vector not found\n</code></pre>"},{"location":"swarms/memory/pinecone/#46-loading-entries","title":"4.6 Loading Entries","text":"<p>To load all vectors from the Pinecone index, you can use the <code>load_entries</code> method. You can also specify an optional namespace.</p> <pre><code>namespace = \"your-namespace\"\n\nentries = pv.load_entries(namespace=namespace)\n\n# Process the loaded entries\nfor entry in entries:\n    vector_id = entry.id\n    vector = entry.vector\n    meta = entry.meta\n\n    # Handle the loaded entries as needed\n</code></pre>"},{"location":"swarms/memory/pinecone/#5-additional-information","title":"5. Additional Information","text":"<p>In this section, we provide additional information and tips for using the <code>PineconeVector</code> class effectively.</p> <ul> <li>When upserting vectors, you can generate a unique vector ID using a hash of the vector's content to ensure uniqueness.</li> <li>Consider using namespaces to organize and categorize vectors within your Pinecone index.</li> <li>Pinecone provides powerful querying capabilities, so be sure to explore and leverage its features to retrieve relevant vectors efficiently.</li> <li>Keep your Pinecone API key secure and follow Pinecone's best practices for API key management.</li> </ul>"},{"location":"swarms/memory/pinecone/#6-references-and-resources","title":"6. References and Resources","text":"<p>Here are some references and resources for further information on Pinecone and Swarms:</p> <ul> <li>Pinecone Website: Official Pinecone website for documentation and resources.</li> <li>Pinecone Documentation: Detailed documentation for Pinecone.</li> <li>Swarms GitHub Repository: Swarms library on GitHub for updates and contributions.</li> </ul> <p>This concludes the documentation for the Swarms library and the <code>PineconeVector</code> class. You now have a deep understanding of how to use Swarms with Pinecone for vector storage. If you have any further questions or need assistance, please refer to the provided references and resources. Happy coding!</p>"},{"location":"swarms/memory/qdrant/","title":"Qdrant Client Library","text":""},{"location":"swarms/memory/qdrant/#overview","title":"Overview","text":"<p>The Qdrant Client Library is designed for interacting with the Qdrant vector database, allowing efficient storage and retrieval of high-dimensional vector data. It integrates with machine learning models for embedding and is particularly suited for search and recommendation systems.</p>"},{"location":"swarms/memory/qdrant/#installation","title":"Installation","text":"<pre><code>pip install qdrant-client sentence-transformers httpx\n</code></pre>"},{"location":"swarms/memory/qdrant/#class-definition-qdrant","title":"Class Definition: Qdrant","text":"<pre><code>class Qdrant:\n    def __init__(\n        self,\n        api_key: str,\n        host: str,\n        port: int = 6333,\n        collection_name: str = \"qdrant\",\n        model_name: str = \"BAAI/bge-small-en-v1.5\",\n        https: bool = True,\n    ):\n        ...\n</code></pre>"},{"location":"swarms/memory/qdrant/#constructor-parameters","title":"Constructor Parameters","text":"Parameter Type Description Default Value api_key str API key for authentication. - host str Host address of the Qdrant server. - port int Port number for the Qdrant server. 6333 collection_name str Name of the collection to be used or created. \"qdrant\" model_name str Name of the sentence transformer model. \"BAAI/bge-small-en-v1.5\" https bool Flag to use HTTPS for connection. True"},{"location":"swarms/memory/qdrant/#methods","title":"Methods","text":""},{"location":"swarms/memory/qdrant/#_load_embedding_modelmodel_name-str","title":"<code>_load_embedding_model(model_name: str)</code>","text":"<p>Loads the sentence embedding model.</p>"},{"location":"swarms/memory/qdrant/#_setup_collection","title":"<code>_setup_collection()</code>","text":"<p>Checks if the specified collection exists in Qdrant; if not, creates it.</p>"},{"location":"swarms/memory/qdrant/#add_vectorsdocs-listdict-operationresponse","title":"<code>add_vectors(docs: List[dict]) -&gt; OperationResponse</code>","text":"<p>Adds vectors to the Qdrant collection.</p>"},{"location":"swarms/memory/qdrant/#search_vectorsquery-str-limit-int-3-searchresult","title":"<code>search_vectors(query: str, limit: int = 3) -&gt; SearchResult</code>","text":"<p>Searches the Qdrant collection for vectors similar to the query vector.</p>"},{"location":"swarms/memory/qdrant/#usage-examples","title":"Usage Examples","text":""},{"location":"swarms/memory/qdrant/#example-1-setting-up-the-qdrant-client","title":"Example 1: Setting Up the Qdrant Client","text":"<pre><code>from qdrant_client import Qdrant\n\nqdrant_client = Qdrant(api_key=\"your_api_key\", host=\"localhost\", port=6333)\n</code></pre>"},{"location":"swarms/memory/qdrant/#example-2-adding-vectors-to-a-collection","title":"Example 2: Adding Vectors to a Collection","text":"<pre><code>documents = [{\"page_content\": \"Sample text 1\"}, {\"page_content\": \"Sample text 2\"}]\n\noperation_info = qdrant_client.add_vectors(documents)\nprint(operation_info)\n</code></pre>"},{"location":"swarms/memory/qdrant/#example-3-searching-for-vectors","title":"Example 3: Searching for Vectors","text":"<pre><code>search_result = qdrant_client.search_vectors(\"Sample search query\")\nprint(search_result)\n</code></pre>"},{"location":"swarms/memory/qdrant/#further-information","title":"Further Information","text":"<p>Refer to the Qdrant Documentation for more details on the Qdrant vector database.</p>"},{"location":"swarms/memory/short_term_memory/","title":"Short-Term Memory Module Documentation","text":""},{"location":"swarms/memory/short_term_memory/#introduction","title":"Introduction","text":"<p>The Short-Term Memory module is a component of the SWARMS framework designed for managing short-term and medium-term memory in a multi-agent system. This documentation provides a detailed explanation of the Short-Term Memory module, its purpose, functions, and usage.</p>"},{"location":"swarms/memory/short_term_memory/#purpose","title":"Purpose","text":"<p>The Short-Term Memory module serves the following purposes: 1. To store and manage messages in short-term memory. 2. To provide functions for retrieving, updating, and clearing memory. 3. To facilitate searching for specific terms within the memory. 4. To enable saving and loading memory data to/from a file.</p>"},{"location":"swarms/memory/short_term_memory/#class-definition","title":"Class Definition","text":"<pre><code>class ShortTermMemory(BaseStructure):\n    def __init__(\n        self,\n        return_str: bool = True,\n        autosave: bool = True,\n        *args,\n        **kwargs,\n    ):\n    ...\n</code></pre>"},{"location":"swarms/memory/short_term_memory/#parameters","title":"Parameters","text":"Parameter Type Default Value Description <code>return_str</code> bool True If True, returns memory as a string. <code>autosave</code> bool True If True, enables automatic saving of memory data to a file. <code>*args</code>, <code>**kwargs</code> Additional arguments and keyword arguments (not used in the constructor but allowed for flexibility)."},{"location":"swarms/memory/short_term_memory/#functions","title":"Functions","text":""},{"location":"swarms/memory/short_term_memory/#1-add","title":"1. <code>add</code>","text":"<pre><code>def add(self, role: str = None, message: str = None, *args, **kwargs):\n</code></pre> <ul> <li>Adds a message to the short-term memory.</li> <li>Parameters:</li> <li><code>role</code> (str, optional): Role associated with the message.</li> <li><code>message</code> (str, optional): The message to be added.</li> <li>Returns: The added memory.</li> </ul>"},{"location":"swarms/memory/short_term_memory/#example-1-adding-a-message-to-short-term-memory","title":"Example 1: Adding a Message to Short-Term Memory","text":"<pre><code>memory.add(role=\"Agent 1\", message=\"Received task assignment.\")\n</code></pre>"},{"location":"swarms/memory/short_term_memory/#example-2-adding-multiple-messages-to-short-term-memory","title":"Example 2: Adding Multiple Messages to Short-Term Memory","text":"<pre><code>messages = [(\"Agent 1\", \"Received task assignment.\"), (\"Agent 2\", \"Task completed.\")]\nfor role, message in messages:\n    memory.add(role=role, message=message)\n</code></pre>"},{"location":"swarms/memory/short_term_memory/#2-get_short_term","title":"2. <code>get_short_term</code>","text":"<pre><code>def get_short_term(self):\n</code></pre> <ul> <li>Retrieves the short-term memory.</li> <li>Returns: The contents of the short-term memory.</li> </ul>"},{"location":"swarms/memory/short_term_memory/#example-retrieving-short-term-memory","title":"Example: Retrieving Short-Term Memory","text":"<pre><code>short_term_memory = memory.get_short_term()\nfor entry in short_term_memory:\n    print(entry[\"role\"], \":\", entry[\"message\"])\n</code></pre>"},{"location":"swarms/memory/short_term_memory/#3-get_medium_term","title":"3. <code>get_medium_term</code>","text":"<pre><code>def get_medium_term(self):\n</code></pre> <ul> <li>Retrieves the medium-term memory.</li> <li>Returns: The contents of the medium-term memory.</li> </ul>"},{"location":"swarms/memory/short_term_memory/#example-retrieving-medium-term-memory","title":"Example: Retrieving Medium-Term Memory","text":"<pre><code>medium_term_memory = memory.get_medium_term()\nfor entry in medium_term_memory:\n    print(entry[\"role\"], \":\", entry[\"message\"])\n</code></pre>"},{"location":"swarms/memory/short_term_memory/#4-clear_medium_term","title":"4. <code>clear_medium_term</code>","text":"<pre><code>def clear_medium_term(self):\n</code></pre> <ul> <li>Clears the medium-term memory.</li> </ul>"},{"location":"swarms/memory/short_term_memory/#example-clearing-medium-term-memory","title":"Example: Clearing Medium-Term Memory","text":"<pre><code>memory.clear_medium_term()\n</code></pre>"},{"location":"swarms/memory/short_term_memory/#5-get_short_term_memory_str","title":"5. <code>get_short_term_memory_str</code>","text":"<pre><code>def get_short_term_memory_str(self, *args, **kwargs):\n</code></pre> <ul> <li>Retrieves the short-term memory as a string.</li> <li>Returns: A string representation of the short-term memory.</li> </ul>"},{"location":"swarms/memory/short_term_memory/#example-getting-short-term-memory-as-a-string","title":"Example: Getting Short-Term Memory as a String","text":"<pre><code>short_term_memory_str = memory.get_short_term_memory_str()\nprint(short_term_memory_str)\n</code></pre>"},{"location":"swarms/memory/short_term_memory/#6-update_short_term","title":"6. <code>update_short_term</code>","text":"<pre><code>def update_short_term(self, index, role: str, message: str, *args, **kwargs):\n</code></pre> <ul> <li>Updates a message in the short-term memory.</li> <li>Parameters:</li> <li><code>index</code> (int): The index of the message to update.</li> <li><code>role</code> (str): New role for the message.</li> <li><code>message</code> (str): New message content.</li> <li>Returns: None.</li> </ul>"},{"location":"swarms/memory/short_term_memory/#example-updating-a-message-in-short-term-memory","title":"Example: Updating a Message in Short-Term Memory","text":"<pre><code>memory.update_short_term(\n    index=0, role=\"Updated Role\", message=\"Updated message content.\"\n)\n</code></pre>"},{"location":"swarms/memory/short_term_memory/#7-clear","title":"7. <code>clear</code>","text":"<pre><code>def clear(self):\n</code></pre> <ul> <li>Clears the short-term memory.</li> </ul>"},{"location":"swarms/memory/short_term_memory/#example-clearing-short-term-memory","title":"Example: Clearing Short-Term Memory","text":"<pre><code>memory.clear()\n</code></pre>"},{"location":"swarms/memory/short_term_memory/#8-search_memory","title":"8. <code>search_memory</code>","text":"<pre><code>def search_memory(self, term):\n</code></pre> <ul> <li>Searches the memory for a specific term.</li> <li>Parameters:</li> <li><code>term</code> (str): The term to search for.</li> <li>Returns: A dictionary containing search results for short-term and medium-term memory.</li> </ul>"},{"location":"swarms/memory/short_term_memory/#example-searching-memory-for-a-term","title":"Example: Searching Memory for a Term","text":"<pre><code>search_results = memory.search_memory(\"task\")\nprint(\"Short-Term Memory Results:\", search_results[\"short_term\"])\nprint(\"Medium-Term Memory Results:\", search_results[\"medium_term\"])\n</code></pre>"},{"location":"swarms/memory/short_term_memory/#9-return_shortmemory_as_str","title":"9. <code>return_shortmemory_as_str</code>","text":"<pre><code>def return_shortmemory_as_str(self):\n</code></pre> <ul> <li>Returns the memory as a string.</li> </ul>"},{"location":"swarms/memory/short_term_memory/#example-returning-short-term-memory-as-a-string","title":"Example: Returning Short-Term Memory as a String","text":"<pre><code>short_term_memory_str = memory.return_shortmemory_as_str()\nprint(short_term_memory_str)\n</code></pre>"},{"location":"swarms/memory/short_term_memory/#10-move_to_medium_term","title":"10. <code>move_to_medium_term</code>","text":"<pre><code>def move_to_medium_term(self, index):\n</code></pre> <ul> <li>Moves a message from the short-term memory to the medium-term memory.</li> <li>Parameters:</li> <li><code>index</code> (int): The index of the message to move.</li> </ul>"},{"location":"swarms/memory/short_term_memory/#example-moving-a-message-to-medium-term-memory","title":"Example: Moving a Message to Medium-Term Memory","text":"<pre><code>memory.move_to_medium_term(index=0)\n</code></pre>"},{"location":"swarms/memory/short_term_memory/#11-return_medium_memory_as_str","title":"11. <code>return_medium_memory_as_str</code>","text":"<pre><code>def return_medium_memory_as_str(self):\n</code></pre> <ul> <li>Returns the medium-term memory as a string.</li> </ul>"},{"location":"swarms/memory/short_term_memory/#example-returning-medium-term-memory-as-a-string","title":"Example: Returning Medium-Term Memory as a String","text":"<pre><code>medium_term_memory_str = memory.return_medium_memory_as_str()\nprint(medium_term_memory_str)\n</code></pre>"},{"location":"swarms/memory/short_term_memory/#12-save_to_file","title":"12. <code>save_to_file</code>","text":"<pre><code>def save_to_file(self, filename: str):\n</code></pre> <ul> <li>Saves the memory data to a file.</li> <li>Parameters:</li> <li><code>filename</code> (str): The name of the file to save the data to.</li> </ul>"},{"location":"swarms/memory/short_term_memory/#example-saving-memory-data-to-a-file","title":"Example: Saving Memory Data to a File","text":"<pre><code>memory.save_to_file(\"memory_data.json\")\n</code></pre>"},{"location":"swarms/memory/short_term_memory/#13-load_from_file","title":"13. <code>load_from_file</code>","text":"<pre><code>def load_from_file(self, filename: str, *args, **kwargs):\n</code></pre> <ul> <li>Loads memory data from a file.</li> <li>Parameters:</li> <li><code>filename</code> (str): The name of the file to load data from.</li> </ul>"},{"location":"swarms/memory/short_term_memory/#example-loading-memory-data-from-a-file","title":"Example: Loading Memory Data from a File","text":"<pre><code>memory.load_from_file(\"memory_data.json\")\n</code></pre>"},{"location":"swarms/memory/short_term_memory/#additional-information-and-tips","title":"Additional Information and Tips","text":"<ul> <li>To use the Short-Term Memory module effectively, consider the following tips:</li> <li>Use the <code>add</code> function to store messages in short-term memory.   -</li> </ul> <p>Retrieve memory contents using <code>get_short_term</code> and <code>get_medium_term</code> functions.   - Clear memory as needed using <code>clear</code> and <code>clear_medium_term</code> functions.   - Search for specific terms within the memory using the <code>search_memory</code> function.   - Save and load memory data to/from files using <code>save_to_file</code> and <code>load_from_file</code> functions.</p> <ul> <li> <p>Ensure proper exception handling when using memory functions to handle potential errors gracefully.</p> </li> <li> <p>When using the <code>search_memory</code> function, iterate through the results dictionary to access search results for short-term and medium-term memory.</p> </li> </ul>"},{"location":"swarms/memory/short_term_memory/#references-and-resources","title":"References and Resources","text":"<ul> <li> <p>For more information on multi-agent systems and memory management, refer to the SWARMS framework documentation: SWARMS Documentation.</p> </li> <li> <p>For advanced memory management and customization, explore the SWARMS framework source code.</p> </li> </ul>"},{"location":"swarms/memory/weaviate/","title":"Weaviate API Client Documentation","text":""},{"location":"swarms/memory/weaviate/#overview","title":"Overview","text":"<p>The Weaviate API Client is an interface to Weaviate, a vector database with a GraphQL API. This client allows you to interact with Weaviate programmatically, making it easier to create collections, add objects, query data, update objects, and delete objects within your Weaviate instance.</p> <p>This documentation provides a comprehensive guide on how to use the Weaviate API Client, including its initialization, methods, and usage examples.</p>"},{"location":"swarms/memory/weaviate/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Installation</li> <li>Initialization</li> <li>Methods</li> <li>create_collection</li> <li>add</li> <li>query</li> <li>update</li> <li>delete</li> <li>Examples</li> </ul>"},{"location":"swarms/memory/weaviate/#installation","title":"Installation","text":"<p>Before using the Weaviate API Client, make sure to install the <code>swarms</code> library. You can install it using pip:</p> <pre><code>pip install swarms\n</code></pre>"},{"location":"swarms/memory/weaviate/#initialization","title":"Initialization","text":"<p>To use the Weaviate API Client, you need to initialize an instance of the <code>WeaviateDB</code> class. Here are the parameters you can pass to the constructor:</p> Parameter Type Description <code>http_host</code> str The HTTP host of the Weaviate server. <code>http_port</code> str The HTTP port of the Weaviate server. <code>http_secure</code> bool Whether to use HTTPS. <code>grpc_host</code> Optional[str] The gRPC host of the Weaviate server. (Optional) <code>grpc_port</code> Optional[str] The gRPC port of the Weaviate server. (Optional) <code>grpc_secure</code> Optional[bool] Whether to use gRPC over TLS. (Optional) <code>auth_client_secret</code> Optional[Any] The authentication client secret. (Optional) <code>additional_headers</code> Optional[Dict[str, str]] Additional headers to send with requests. (Optional) <code>additional_config</code> Optional[weaviate.AdditionalConfig] Additional configuration for the client. (Optional) <code>connection_params</code> Dict[str, Any] Dictionary containing connection parameters. This parameter is used internally and can be ignored in most cases. <p>Here's an example of how to initialize a WeaviateDB:</p> <pre><code>from swarms.memory import WeaviateDB\n\nweaviate_client = WeaviateDB(\n    http_host=\"YOUR_HTTP_HOST\",\n    http_port=\"YOUR_HTTP_PORT\",\n    http_secure=True,\n    grpc_host=\"YOUR_gRPC_HOST\",\n    grpc_port=\"YOUR_gRPC_PORT\",\n    grpc_secure=True,\n    auth_client_secret=\"YOUR_APIKEY\",\n    additional_headers={\"X-OpenAI-Api-Key\": \"YOUR_OPENAI_APIKEY\"},\n    additional_config=None,  # You can pass additional configuration here\n)\n</code></pre>"},{"location":"swarms/memory/weaviate/#methods","title":"Methods","text":""},{"location":"swarms/memory/weaviate/#create_collection","title":"<code>create_collection</code>","text":"<p>The <code>create_collection</code> method allows you to create a new collection in Weaviate. A collection is a container for storing objects with specific properties.</p>"},{"location":"swarms/memory/weaviate/#parameters","title":"Parameters","text":"<ul> <li><code>name</code> (str): The name of the collection.</li> <li><code>properties</code> (List[Dict[str, Any]]): A list of dictionaries specifying the properties of objects to be stored in the collection.</li> <li><code>vectorizer_config</code> (Any, optional): Additional vectorizer configuration for the collection. (Optional)</li> </ul>"},{"location":"swarms/memory/weaviate/#usage","title":"Usage","text":"<pre><code>weaviate_client.create_collection(\n    name=\"my_collection\",\n    properties=[\n        {\"name\": \"property1\", \"dataType\": [\"string\"]},\n        {\"name\": \"property2\", \"dataType\": [\"int\"]},\n    ],\n    vectorizer_config=None,  # Optional vectorizer configuration\n)\n</code></pre>"},{"location":"swarms/memory/weaviate/#add","title":"<code>add</code>","text":"<p>The <code>add</code> method allows you to add an object to a specified collection in Weaviate.</p>"},{"location":"swarms/memory/weaviate/#parameters_1","title":"Parameters","text":"<ul> <li><code>collection_name</code> (str): The name of the collection where the object will be added.</li> <li><code>properties</code> (Dict[str, Any]): A dictionary specifying the properties of the object to be added.</li> </ul>"},{"location":"swarms/memory/weaviate/#usage_1","title":"Usage","text":"<pre><code>weaviate_client.add(\n    collection_name=\"my_collection\", properties={\"property1\": \"value1\", \"property2\": 42}\n)\n</code></pre>"},{"location":"swarms/memory/weaviate/#query","title":"<code>query</code>","text":"<p>The <code>query</code> method allows you to query objects from a specified collection in Weaviate.</p>"},{"location":"swarms/memory/weaviate/#parameters_2","title":"Parameters","text":"<ul> <li><code>collection_name</code> (str): The name of the collection to query.</li> <li><code>query</code> (str): The query string specifying the search criteria.</li> <li><code>limit</code> (int, optional): The maximum number of results to return. (Default: 10)</li> </ul>"},{"location":"swarms/memory/weaviate/#usage_2","title":"Usage","text":"<pre><code>results = weaviate_client.query(\n    collection_name=\"my_collection\",\n    query=\"property1:value1\",\n    limit=20  # Optional, specify the limit\n\n if needed\n)\n</code></pre>"},{"location":"swarms/memory/weaviate/#update","title":"<code>update</code>","text":"<p>The <code>update</code> method allows you to update an object in a specified collection in Weaviate.</p>"},{"location":"swarms/memory/weaviate/#parameters_3","title":"Parameters","text":"<ul> <li><code>collection_name</code> (str): The name of the collection where the object exists.</li> <li><code>object_id</code> (str): The ID of the object to be updated.</li> <li><code>properties</code> (Dict[str, Any]): A dictionary specifying the properties to update.</li> </ul>"},{"location":"swarms/memory/weaviate/#usage_3","title":"Usage","text":"<pre><code>weaviate_client.update(\n    collection_name=\"my_collection\",\n    object_id=\"object123\",\n    properties={\"property1\": \"new_value\", \"property2\": 99},\n)\n</code></pre>"},{"location":"swarms/memory/weaviate/#delete","title":"<code>delete</code>","text":"<p>The <code>delete</code> method allows you to delete an object from a specified collection in Weaviate.</p>"},{"location":"swarms/memory/weaviate/#parameters_4","title":"Parameters","text":"<ul> <li><code>collection_name</code> (str): The name of the collection from which to delete the object.</li> <li><code>object_id</code> (str): The ID of the object to delete.</li> </ul>"},{"location":"swarms/memory/weaviate/#usage_4","title":"Usage","text":"<pre><code>weaviate_client.delete(collection_name=\"my_collection\", object_id=\"object123\")\n</code></pre>"},{"location":"swarms/memory/weaviate/#examples","title":"Examples","text":"<p>Here are three examples demonstrating how to use the Weaviate API Client for common tasks:</p>"},{"location":"swarms/memory/weaviate/#example-1-creating-a-collection","title":"Example 1: Creating a Collection","text":"<pre><code>weaviate_client.create_collection(\n    name=\"people\",\n    properties=[\n        {\"name\": \"name\", \"dataType\": [\"string\"]},\n        {\"name\": \"age\", \"dataType\": [\"int\"]},\n    ],\n)\n</code></pre>"},{"location":"swarms/memory/weaviate/#example-2-adding-an-object","title":"Example 2: Adding an Object","text":"<pre><code>weaviate_client.add(collection_name=\"people\", properties={\"name\": \"John\", \"age\": 30})\n</code></pre>"},{"location":"swarms/memory/weaviate/#example-3-querying-objects","title":"Example 3: Querying Objects","text":"<pre><code>results = weaviate_client.query(collection_name=\"people\", query=\"name:John\", limit=5)\n</code></pre> <p>These examples cover the basic operations of creating collections, adding objects, and querying objects using the Weaviate API Client.</p>"},{"location":"swarms/memory/weaviate/#additional-information-and-tips","title":"Additional Information and Tips","text":"<ul> <li>If you encounter any errors during the operations, the client will raise exceptions with informative error messages.</li> <li>You can explore more advanced features and configurations in the Weaviate documentation.</li> <li>Make sure to handle authentication and security appropriately when using the client in production environments.</li> </ul>"},{"location":"swarms/memory/weaviate/#references-and-resources","title":"References and Resources","text":"<ul> <li>Weaviate Documentation: Official documentation for Weaviate.</li> <li>Weaviate GitHub Repository: The source code and issue tracker for Weaviate.</li> </ul> <p>This documentation provides a comprehensive guide on using the Weaviate API Client to interact with Weaviate, making it easier to manage and query your data.</p>"},{"location":"swarms/models/","title":"Overview","text":""},{"location":"swarms/models/#llms-in-swarms-documentation","title":"LLMs in Swarms Documentation","text":"<p>Welcome to the documentation for the llm section of the swarms package, designed to facilitate seamless integration with various AI language models and APIs. This package empowers developers, end-users, and system administrators to interact with AI models from different providers, such as OpenAI, Hugging Face, Google PaLM, and Anthropic.</p>"},{"location":"swarms/models/#table-of-contents","title":"Table of Contents","text":"<ol> <li>OpenAI</li> <li>HuggingFace</li> <li>Google PaLM</li> <li>Anthropic</li> </ol>"},{"location":"swarms/models/#1-openai-swarmsagentsmodelsopenai","title":"1. OpenAI (swarms.agents.models.OpenAI)","text":"<p>The OpenAI class provides an interface to interact with OpenAI's language models. It allows both synchronous and asynchronous interactions.</p> <p>Constructor: <pre><code>OpenAI(api_key: str, system: str = None, console: bool = True, model: str = None, params: dict = None, save_messages: bool = True)\n</code></pre></p> <p>Attributes: - <code>api_key</code> (str): Your OpenAI API key.</p> <ul> <li> <p><code>system</code> (str, optional): A system message to be used in conversations.</p> </li> <li> <p><code>console</code> (bool, default=True): Display console logs.</p> </li> <li> <p><code>model</code> (str, optional): Name of the language model to use.</p> </li> <li> <p><code>params</code> (dict, optional): Additional parameters for model interactions.</p> </li> <li> <p><code>save_messages</code> (bool, default=True): Save conversation messages.</p> </li> </ul> <p>Methods:</p> <ul> <li> <p><code>generate(message: str, **kwargs) -&gt; str</code>: Generate a response using the OpenAI model.</p> </li> <li> <p><code>generate_async(message: str, **kwargs) -&gt; str</code>: Generate a response asynchronously.</p> </li> <li> <p><code>ask_multiple(ids: List[str], question_template: str) -&gt; List[str]</code>: Query multiple IDs simultaneously.</p> </li> <li> <p><code>stream_multiple(ids: List[str], question_template: str) -&gt; List[str]</code>: Stream multiple responses.</p> </li> </ul> <p>Usage Example: <pre><code>import asyncio\n\nfrom swarms import OpenAI\n\nchat = OpenAI(api_key=\"YOUR_OPENAI_API_KEY\")\n\nresponse = chat.generate(\"Hello, how can I assist you?\")\nprint(response)\n\nids = [\"id1\", \"id2\", \"id3\"]\nasync_responses = asyncio.run(chat.ask_multiple(ids, \"How is {id}?\"))\nprint(async_responses)\n</code></pre></p>"},{"location":"swarms/models/#2-huggingface-swarmsagentsmodelshuggingfacellm","title":"2. HuggingFace (swarms.agents.models.HuggingFaceLLM)","text":"<p>The HuggingFaceLLM class allows interaction with language models from Hugging Face.</p> <p>Constructor: <pre><code>HuggingFaceLLM(model_id: str, device: str = None, max_length: int = 20, quantize: bool = False, quantization_config: dict = None)\n</code></pre></p> <p>Attributes:</p> <ul> <li> <p><code>model_id</code> (str): ID or name of the Hugging Face model.</p> </li> <li> <p><code>device</code> (str, optional): Device to run the model on (e.g., 'cuda', 'cpu').</p> </li> <li> <p><code>max_length</code> (int, default=20): Maximum length of generated text.</p> </li> <li> <p><code>quantize</code> (bool, default=False): Apply model quantization.</p> </li> <li> <p><code>quantization_config</code> (dict, optional): Configuration for quantization.</p> </li> </ul> <p>Methods:</p> <ul> <li><code>generate(prompt_text: str, max_length: int = None) -&gt; str</code>: Generate text based on a prompt.</li> </ul> <p>Usage Example: <pre><code>from swarms import HuggingFaceLLM\n\nmodel_id = \"gpt2\"\nhugging_face_model = HuggingFaceLLM(model_id=model_id)\n\nprompt = \"Once upon a time\"\ngenerated_text = hugging_face_model.generate(prompt)\nprint(generated_text)\n</code></pre></p>"},{"location":"swarms/models/#3-google-palm-swarmsagentsmodelsgooglepalm","title":"3. Google PaLM (swarms.agents.models.GooglePalm)","text":"<p>The GooglePalm class provides an interface for Google's PaLM Chat API.</p> <p>Constructor: <pre><code>GooglePalm(model_name: str = \"models/chat-bison-001\", google_api_key: str = None, temperature: float = None, top_p: float = None, top_k: int = None, n: int = 1)\n</code></pre></p> <p>Attributes:</p> <ul> <li> <p><code>model_name</code> (str): Name of the Google PaLM model.</p> </li> <li> <p><code>google_api_key</code> (str, optional): Google API key.</p> </li> <li> <p><code>temperature</code> (float, optional): Temperature for text generation.</p> </li> <li> <p><code>top_p</code> (float, optional): Top-p sampling value.</p> </li> <li> <p><code>top_k</code> (int, optional): Top-k sampling value.</p> </li> <li> <p><code>n</code> (int, default=1): Number of candidate completions.</p> </li> </ul> <p>Methods:</p> <ul> <li> <p><code>generate(messages: List[Dict[str, Any]], stop: List[str] = None, **kwargs) -&gt; Dict[str, Any]</code>: Generate text based on a list of messages.</p> </li> <li> <p><code>__call__(messages: List[Dict[str, Any]], stop: List[str] = None, **kwargs) -&gt; Dict[str, Any]</code>: Generate text using the call syntax.</p> </li> </ul> <p>Usage Example: <pre><code>from swarms import GooglePalm\n\ngoogle_palm = GooglePalm()\nmessages = [\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n    {\"role\": \"user\", \"content\": \"Tell me a joke\"},\n]\n\nresponse = google_palm.generate(messages)\nprint(response[\"choices\"][0][\"text\"])\n</code></pre></p>"},{"location":"swarms/models/#4-anthropic-swarmsagentsmodelsanthropic","title":"4. Anthropic (swarms.agents.models.Anthropic)","text":"<p>The Anthropic class enables interaction with Anthropic's large language models.</p> <p>Constructor: <pre><code>Anthropic(model: str = \"claude-2\", max_tokens_to_sample: int = 256, temperature: float = None, top_k: int = None, top_p: float = None, streaming: bool = False, default_request_timeout: int = None)\n</code></pre></p> <p>Attributes:</p> <ul> <li> <p><code>model</code> (str): Name of the Anthropic model.</p> </li> <li> <p><code>max_tokens_to_sample</code> (int, default=256): Maximum tokens to sample.</p> </li> <li> <p><code>temperature</code> (float, optional): Temperature for text generation.</p> </li> <li> <p><code>top_k</code> (int, optional): Top-k sampling value.</p> </li> <li> <p><code>top_p</code> (float, optional): Top-p sampling value.</p> </li> <li> <p><code>streaming</code> (bool, default=False): Enable streaming mode.</p> </li> <li> <p><code>default_request_timeout</code> (int, optional): Default request timeout.</p> </li> </ul> <p>Methods:</p> <ul> <li><code>generate(prompt: str, stop: List[str] = None) -&gt; str</code>: Generate text based on a prompt.</li> </ul> <p>Usage Example: <pre><code>from swarms import Anthropic\n\nanthropic = Anthropic()\nprompt = \"Once upon a time\"\ngenerated_text = anthropic.generate(prompt)\nprint(generated_text)\n</code></pre></p> <p>This concludes the documentation for the \"models\" folder, providing you with tools to seamlessly integrate with various language models and APIs. Happy coding!</p>"},{"location":"swarms/models/anthropic/","title":"Documentation for the <code>Anthropic</code> Class","text":""},{"location":"swarms/models/anthropic/#overview-and-introduction","title":"Overview and Introduction","text":"<p>The <code>Anthropic</code> class provides an interface to interact with the Anthropic large language models. This class encapsulates the necessary functionality to request completions from the Anthropic API based on a provided prompt and other configurable parameters.</p>"},{"location":"swarms/models/anthropic/#key-concepts-and-terminology","title":"Key Concepts and Terminology","text":"<ul> <li>Anthropic: A large language model, akin to GPT-3 and its successors.</li> <li>Prompt: A piece of text that serves as the starting point for model completions.</li> <li>Stop Sequences: Specific tokens or sequences to indicate when the model should stop generating.</li> <li>Tokens: Discrete pieces of information in a text. For example, in English, a token can be as short as one character or as long as one word.</li> </ul>"},{"location":"swarms/models/anthropic/#class-definition","title":"Class Definition","text":""},{"location":"swarms/models/anthropic/#anthropic","title":"<code>Anthropic</code>","text":"<pre><code>class Anthropic:\n    \"\"\"Anthropic large language models.\"\"\"\n</code></pre>"},{"location":"swarms/models/anthropic/#parameters","title":"Parameters:","text":"<ul> <li> <p><code>model (str)</code>: The name of the model to use for completions. Default is \"claude-2\".</p> </li> <li> <p><code>max_tokens_to_sample (int)</code>: Maximum number of tokens to generate in the output. Default is 256.</p> </li> <li> <p><code>temperature (float, optional)</code>: Sampling temperature. A higher value will make the output more random, while a lower value will make it more deterministic.</p> </li> <li> <p><code>top_k (int, optional)</code>: Sample from the top-k most probable next tokens. Setting this parameter can reduce randomness in the output.</p> </li> <li> <p><code>top_p (float, optional)</code>: Sample from the smallest set of tokens such that their cumulative probability exceeds the specified value. Used in nucleus sampling to provide a balance between randomness and determinism.</p> </li> <li> <p><code>streaming (bool)</code>: Whether to stream the output or not. Default is False.</p> </li> <li> <p><code>default_request_timeout (int, optional)</code>: Default timeout in seconds for API requests. Default is 600.</p> </li> </ul>"},{"location":"swarms/models/anthropic/#methods-and-their-functionality","title":"Methods and their Functionality","text":""},{"location":"swarms/models/anthropic/#_default_paramsself-dict","title":"<code>_default_params(self) -&gt; dict</code>","text":"<ul> <li> <p>Provides the default parameters for calling the Anthropic API.</p> </li> <li> <p>Returns: A dictionary containing the default parameters.</p> </li> </ul>"},{"location":"swarms/models/anthropic/#generateself-prompt-str-stop-liststr-none-str","title":"<code>generate(self, prompt: str, stop: list[str] = None) -&gt; str</code>","text":"<ul> <li> <p>Calls out to Anthropic's completion endpoint to generate text based on the given prompt.</p> </li> <li> <p>Parameters:</p> <ul> <li> <p><code>prompt (str)</code>: The input text to provide context for the generated text.</p> </li> <li> <p><code>stop (list[str], optional)</code>: Sequences to indicate when the model should stop generating.</p> </li> </ul> </li> <li> <p>Returns: A string containing the model's generated completion based on the prompt.</p> </li> </ul>"},{"location":"swarms/models/anthropic/#__call__self-prompt-str-stop-liststr-none-str","title":"<code>__call__(self, prompt: str, stop: list[str] = None) -&gt; str</code>","text":"<ul> <li> <p>An alternative to the <code>generate</code> method that allows calling the class instance directly.</p> </li> <li> <p>Parameters:</p> <ul> <li> <p><code>prompt (str)</code>: The input text to provide context for the generated text.</p> </li> <li> <p><code>stop (list[str], optional)</code>: Sequences to indicate when the model should stop generating.</p> </li> </ul> </li> <li> <p>Returns: A string containing the model's generated completion based on the prompt.</p> </li> </ul>"},{"location":"swarms/models/anthropic/#usage-examples","title":"Usage Examples","text":"<pre><code># Import necessary modules and classes\nfrom swarms.models import Anthropic\n\n# Initialize an instance of the Anthropic class\nmodel = Anthropic(anthropic_api_key=\"\")\n\n# Using the run method\ncompletion_1 = model.run(\"What is the capital of France?\")\nprint(completion_1)\n\n# Using the __call__ method\ncompletion_2 = model(\"How far is the moon from the earth?\", stop=[\"miles\", \"km\"])\nprint(completion_2)\n</code></pre>"},{"location":"swarms/models/anthropic/#mathematical-formula","title":"Mathematical Formula","text":"<p>The underlying operations of the <code>Anthropic</code> class involve probabilistic sampling based on token logits from the Anthropic model. Mathematically, the process of generating a token ( t ) from the given logits ( l ) can be described by the softmax function:</p> <p>[ P(t) = \\frac{e^{l_t}}{\\sum_{i} e^{l_i}} ]</p> <p>Where: - ( P(t) ) is the probability of token ( t ). - ( l_t ) is the logit corresponding to token ( t ). - The summation runs over all possible tokens.</p> <p>The temperature, top-k, and top-p parameters are further used to modulate the probabilities.</p>"},{"location":"swarms/models/anthropic/#additional-information-and-tips","title":"Additional Information and Tips","text":"<ul> <li> <p>Ensure you have a valid <code>ANTHROPIC_API_KEY</code> set as an environment variable or passed during class instantiation.</p> </li> <li> <p>Always handle exceptions that may arise from API timeouts or invalid prompts.</p> </li> </ul>"},{"location":"swarms/models/anthropic/#references-and-resources","title":"References and Resources","text":"<ul> <li> <p>Anthropic's official documentation</p> </li> <li> <p>Token-based sampling in Language Models for a deeper understanding of token sampling.</p> </li> </ul>"},{"location":"swarms/models/base_llm/","title":"Language Model Interface Documentation","text":""},{"location":"swarms/models/base_llm/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction</li> <li>Abstract Language Model</li> <li>Initialization</li> <li>Attributes</li> <li>Methods</li> <li>Implementation</li> <li>Usage Examples</li> <li>Additional Features</li> <li>Performance Metrics</li> <li>Logging and Checkpoints</li> <li>Resource Utilization Tracking</li> <li>Conclusion</li> </ol>"},{"location":"swarms/models/base_llm/#1-introduction","title":"1. Introduction","text":"<p>The Language Model Interface (<code>AbstractLLM</code>) is a flexible and extensible framework for working with various language models. This documentation provides a comprehensive guide to the interface, its attributes, methods, and usage examples. Whether you're using a pre-trained language model or building your own, this interface can help streamline the process of text generation, chatbots, summarization, and more.</p>"},{"location":"swarms/models/base_llm/#2-abstract-language-model","title":"2. Abstract Language Model","text":""},{"location":"swarms/models/base_llm/#initialization","title":"Initialization","text":"<p>The <code>AbstractLLM</code> class provides a common interface for language models. It can be initialized with various parameters to customize model behavior. Here are the initialization parameters:</p> Parameter Description Default Value <code>model_name</code> The name of the language model to use. None <code>max_tokens</code> The maximum number of tokens in the generated text. None <code>temperature</code> The temperature parameter for controlling randomness in text generation. None <code>top_k</code> The top-k parameter for filtering words in text generation. None <code>top_p</code> The top-p parameter for filtering words in text generation. None <code>system_prompt</code> A system-level prompt to set context for generation. None <code>beam_width</code> The beam width for beam search. None <code>num_return_sequences</code> The number of sequences to return in the output. None <code>seed</code> The random seed for reproducibility. None <code>frequency_penalty</code> The frequency penalty parameter for promoting word diversity. None <code>presence_penalty</code> The presence penalty parameter for discouraging repetitions. None <code>stop_token</code> A stop token to indicate the end of generated text. None <code>length_penalty</code> The length penalty parameter for controlling the output length. None <code>role</code> The role of the language model (e.g., assistant, user, etc.). None <code>max_length</code> The maximum length of generated sequences. None <code>do_sample</code> Whether to use sampling during text generation. None <code>early_stopping</code> Whether to use early stopping during text generation. None <code>num_beams</code> The number of beams to use in beam search. None <code>repition_penalty</code> The repetition penalty parameter for discouraging repeated tokens. None <code>pad_token_id</code> The token ID for padding. None <code>eos_token_id</code> The token ID for the end of a sequence. None <code>bos_token_id</code> The token ID for the beginning of a sequence. None <code>device</code> The device to run the model on (e.g., 'cpu' or 'cuda'). None"},{"location":"swarms/models/base_llm/#attributes","title":"Attributes","text":"<ul> <li><code>model_name</code>: The name of the language model being used.</li> <li><code>max_tokens</code>: The maximum number of tokens in generated text.</li> <li><code>temperature</code>: The temperature parameter controlling randomness.</li> <li><code>top_k</code>: The top-k parameter for word filtering.</li> <li><code>top_p</code>: The top-p parameter for word filtering.</li> <li><code>system_prompt</code>: A system-level prompt for context.</li> <li><code>beam_width</code>: The beam width for beam search.</li> <li><code>num_return_sequences</code>: The number of output sequences.</li> <li><code>seed</code>: The random seed for reproducibility.</li> <li><code>frequency_penalty</code>: The frequency penalty parameter.</li> <li><code>presence_penalty</code>: The presence penalty parameter.</li> <li><code>stop_token</code>: The stop token to indicate text end.</li> <li><code>length_penalty</code>: The length penalty parameter.</li> <li><code>role</code>: The role of the language model.</li> <li><code>max_length</code>: The maximum length of generated sequences.</li> <li><code>do_sample</code>: Whether to use sampling during generation.</li> <li><code>early_stopping</code>: Whether to use early stopping.</li> <li><code>num_beams</code>: The number of beams in beam search.</li> <li><code>repition_penalty</code>: The repetition penalty parameter.</li> <li><code>pad_token_id</code>: The token ID for padding.</li> <li><code>eos_token_id</code>: The token ID for the end of a sequence.</li> <li><code>bos_token_id</code>: The token ID for the beginning of a sequence.</li> <li><code>device</code>: The device used for model execution.</li> <li><code>history</code>: A list of conversation history.</li> </ul>"},{"location":"swarms/models/base_llm/#methods","title":"Methods","text":"<p>The <code>AbstractLLM</code> class defines several methods for working with language models:</p> <ul> <li> <p><code>run(task: Optional[str] = None, *args, **kwargs) -&gt; str</code>: Generate text using the language model. This method is abstract and must be implemented by subclasses.</p> </li> <li> <p><code>arun(task: Optional[str] = None, *args, **kwargs)</code>: An asynchronous version of <code>run</code> for concurrent text generation.</p> </li> <li> <p><code>batch_run(tasks: List[str], *args, **kwargs)</code>: Generate text for a batch of tasks.</p> </li> <li> <p><code>abatch_run(tasks: List[str], *args, **kwargs)</code>: An asynchronous version of <code>batch_run</code> for concurrent batch generation.</p> </li> <li> <p><code>chat(task: str, history: str = \"\") -&gt; str</code>: Conduct a chat with the model, providing a conversation history.</p> </li> <li> <p><code>__call__(task: str) -&gt; str</code>: Call the model to generate text.</p> </li> <li> <p><code>_tokens_per_second() -&gt; float</code>: Calculate tokens generated per second.</p> </li> <li> <p><code>_num_tokens(text: str) -&gt; int</code>: Calculate the number of tokens in a text.</p> </li> <li> <p><code>_time_for_generation(task: str) -&gt; float</code>: Measure the time taken for text generation.</p> </li> <li> <p><code>generate_summary(text: str) -&gt; str</code>: Generate a summary of the provided text.</p> </li> <li> <p><code>set_temperature(value: float)</code>: Set the temperature parameter.</p> </li> <li> <p><code>set_max_tokens(value: int)</code>: Set the maximum number of tokens.</p> </li> <li> <p><code>clear_history()</code>: Clear the conversation history.</p> </li> <li> <p><code>enable_logging(log_file: str = \"model.log\")</code>: Initialize logging for the model.</p> </li> <li> <p><code>log_event(message: str)</code>: Log an event.</p> </li> <li> <p><code>save_checkpoint(checkpoint_dir: str = \"checkpoints\")</code>: Save the model state as a checkpoint.</p> </li> <li> <p><code>load_checkpoint(checkpoint_path: str)</code>: Load the model state from a checkpoint.</p> </li> <li> <p><code>toggle_creative_mode(enable: bool)</code>: Toggle creative mode for the model.</p> </li> <li> <p><code>track_resource_utilization()</code>: Track and report resource utilization.</p> </li> <li> <p>`</p> </li> </ul> <p>get_generation_time() -&gt; float`: Get the time taken for text generation.</p> <ul> <li> <p><code>set_max_length(max_length: int)</code>: Set the maximum length of generated sequences.</p> </li> <li> <p><code>set_model_name(model_name: str)</code>: Set the model name.</p> </li> <li> <p><code>set_frequency_penalty(frequency_penalty: float)</code>: Set the frequency penalty parameter.</p> </li> <li> <p><code>set_presence_penalty(presence_penalty: float)</code>: Set the presence penalty parameter.</p> </li> <li> <p><code>set_stop_token(stop_token: str)</code>: Set the stop token.</p> </li> <li> <p><code>set_length_penalty(length_penalty: float)</code>: Set the length penalty parameter.</p> </li> <li> <p><code>set_role(role: str)</code>: Set the role of the model.</p> </li> <li> <p><code>set_top_k(top_k: int)</code>: Set the top-k parameter.</p> </li> <li> <p><code>set_top_p(top_p: float)</code>: Set the top-p parameter.</p> </li> <li> <p><code>set_num_beams(num_beams: int)</code>: Set the number of beams.</p> </li> <li> <p><code>set_do_sample(do_sample: bool)</code>: Set whether to use sampling.</p> </li> <li> <p><code>set_early_stopping(early_stopping: bool)</code>: Set whether to use early stopping.</p> </li> <li> <p><code>set_seed(seed: int)</code>: Set the random seed.</p> </li> <li> <p><code>set_device(device: str)</code>: Set the device for model execution.</p> </li> </ul>"},{"location":"swarms/models/base_llm/#3-implementation","title":"3. Implementation","text":"<p>The <code>AbstractLLM</code> class serves as the base for implementing specific language models. Subclasses of <code>AbstractLLM</code> should implement the <code>run</code> method to define how text is generated for a given task. This design allows flexibility in integrating different language models while maintaining a common interface.</p>"},{"location":"swarms/models/base_llm/#4-usage-examples","title":"4. Usage Examples","text":"<p>To demonstrate how to use the <code>AbstractLLM</code> interface, let's create an example using a hypothetical language model. We'll initialize an instance of the model and generate text for a simple task.</p> <pre><code># Import the AbstractLLM class\nfrom swarms.models import AbstractLLM\n\n# Create an instance of the language model\nlanguage_model = AbstractLLM(\n    model_name=\"my_language_model\",\n    max_tokens=50,\n    temperature=0.7,\n    top_k=50,\n    top_p=0.9,\n    device=\"cuda\",\n)\n\n# Generate text for a task\ntask = \"Translate the following English text to French: 'Hello, world.'\"\ngenerated_text = language_model.run(task)\n\n# Print the generated text\nprint(generated_text)\n</code></pre> <p>In this example, we've created an instance of our hypothetical language model, configured its parameters, and used the <code>run</code> method to generate text for a translation task.</p>"},{"location":"swarms/models/base_llm/#5-additional-features","title":"5. Additional Features","text":"<p>The <code>AbstractLLM</code> interface provides additional features for customization and control:</p> <ul> <li><code>batch_run</code>: Generate text for a batch of tasks efficiently.</li> <li><code>arun</code> and <code>abatch_run</code>: Asynchronous versions of <code>run</code> and <code>batch_run</code> for concurrent text generation.</li> <li><code>chat</code>: Conduct a conversation with the model by providing a history of the conversation.</li> <li><code>__call__</code>: Allow the model to be called directly to generate text.</li> </ul> <p>These features enhance the flexibility and utility of the interface in various applications, including chatbots, language translation, and content generation.</p>"},{"location":"swarms/models/base_llm/#6-performance-metrics","title":"6. Performance Metrics","text":"<p>The <code>AbstractLLM</code> class offers methods for tracking performance metrics:</p> <ul> <li><code>_tokens_per_second</code>: Calculate tokens generated per second.</li> <li><code>_num_tokens</code>: Calculate the number of tokens in a text.</li> <li><code>_time_for_generation</code>: Measure the time taken for text generation.</li> </ul> <p>These metrics help assess the efficiency and speed of text generation, enabling optimizations as needed.</p>"},{"location":"swarms/models/base_llm/#7-logging-and-checkpoints","title":"7. Logging and Checkpoints","text":"<p>Logging and checkpointing are crucial for tracking model behavior and ensuring reproducibility:</p> <ul> <li><code>enable_logging</code>: Initialize logging for the model.</li> <li><code>log_event</code>: Log events and activities.</li> <li><code>save_checkpoint</code>: Save the model state as a checkpoint.</li> <li><code>load_checkpoint</code>: Load the model state from a checkpoint.</li> </ul> <p>These capabilities aid in debugging, monitoring, and resuming model experiments.</p>"},{"location":"swarms/models/base_llm/#8-resource-utilization-tracking","title":"8. Resource Utilization Tracking","text":"<p>The <code>track_resource_utilization</code> method is a placeholder for tracking and reporting resource utilization, such as CPU and memory usage. It can be customized to suit specific monitoring needs.</p>"},{"location":"swarms/models/base_llm/#9-conclusion","title":"9. Conclusion","text":"<p>The Language Model Interface (<code>AbstractLLM</code>) is a versatile framework for working with language models. Whether you're using pre-trained models or developing your own, this interface provides a consistent and extensible foundation. By following the provided guidelines and examples, you can integrate and customize language models for various natural language processing tasks.</p>"},{"location":"swarms/models/base_multimodal_model/","title":"<code>BaseMultiModalModel</code> Documentation","text":"<p>Swarms is a Python library that provides a framework for running multimodal AI models. It allows you to combine text and image inputs and generate coherent and context-aware responses. This library is designed to be extensible, allowing you to integrate various multimodal models.</p>"},{"location":"swarms/models/base_multimodal_model/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction</li> <li>Installation</li> <li>Getting Started</li> <li>BaseMultiModalModel Class<ul> <li>Initialization</li> <li>Methods</li> </ul> </li> <li>Usage Examples</li> <li>Additional Tips</li> <li>References and Resources</li> </ol>"},{"location":"swarms/models/base_multimodal_model/#1-introduction","title":"1. Introduction","text":"<p>Swarms is designed to simplify the process of working with multimodal AI models. These models are capable of understanding and generating content based on both textual and image inputs. With this library, you can run such models and receive context-aware responses.</p>"},{"location":"swarms/models/base_multimodal_model/#2-installation","title":"2. Installation","text":"<p>To install swarms, you can use pip:</p> <pre><code>pip install swarms\n</code></pre>"},{"location":"swarms/models/base_multimodal_model/#3-getting-started","title":"3. Getting Started","text":"<p>To get started with Swarms, you'll need to import the library and create an instance of the <code>BaseMultiModalModel</code> class. This class serves as the foundation for running multimodal models.</p> <pre><code>from swarms.models import BaseMultiModalModel\n\nmodel = BaseMultiModalModel(\n    model_name=\"your_model_name\",\n    temperature=0.5,\n    max_tokens=500,\n    max_workers=10,\n    top_p=1,\n    top_k=50,\n    beautify=False,\n    device=\"cuda\",\n    max_new_tokens=500,\n    retries=3,\n)\n</code></pre> <p>You can customize the initialization parameters based on your model's requirements.</p>"},{"location":"swarms/models/base_multimodal_model/#4-basemultimodalmodel-class","title":"4. BaseMultiModalModel Class","text":""},{"location":"swarms/models/base_multimodal_model/#initialization","title":"Initialization","text":"<p>The <code>BaseMultiModalModel</code> class is initialized with several parameters that control its behavior. Here's a breakdown of the initialization parameters:</p> Parameter Description Default Value <code>model_name</code> The name of the multimodal model to use. None <code>temperature</code> The temperature parameter for controlling randomness in text generation. 0.5 <code>max_tokens</code> The maximum number of tokens in the generated text. 500 <code>max_workers</code> The maximum number of concurrent workers for running tasks. 10 <code>top_p</code> The top-p parameter for filtering words in text generation. 1 <code>top_k</code> The top-k parameter for filtering words in text generation. 50 <code>beautify</code> Whether to beautify the output text. False <code>device</code> The device to run the model on (e.g., 'cuda' or 'cpu'). 'cuda' <code>max_new_tokens</code> The maximum number of new tokens allowed in generated responses. 500 <code>retries</code> The number of retries in case of an error during text generation. 3 <code>system_prompt</code> A system-level prompt to set context for generation. None <code>meta_prompt</code> A meta prompt to provide guidance for including image labels in responses. None"},{"location":"swarms/models/base_multimodal_model/#methods","title":"Methods","text":"<p>The <code>BaseMultiModalModel</code> class defines various methods for running multimodal models and managing interactions:</p> <ul> <li> <p><code>run(task: str, img: str) -&gt; str</code>: Run the multimodal model with a text task and an image URL to generate a response.</p> </li> <li> <p><code>arun(task: str, img: str) -&gt; str</code>: Run the multimodal model asynchronously with a text task and an image URL to generate a response.</p> </li> <li> <p><code>get_img_from_web(img: str) -&gt; Image</code>: Fetch an image from a URL and return it as a PIL Image.</p> </li> <li> <p><code>encode_img(img: str) -&gt; str</code>: Encode an image to base64 format.</p> </li> <li> <p><code>get_img(img: str) -&gt; Image</code>: Load an image from the local file system and return it as a PIL Image.</p> </li> <li> <p><code>clear_chat_history()</code>: Clear the chat history maintained by the model.</p> </li> <li> <p><code>run_many(tasks: List[str], imgs: List[str]) -&gt; List[str]</code>: Run the model on multiple text tasks and image URLs concurrently and return a list of responses.</p> </li> <li> <p><code>run_batch(tasks_images: List[Tuple[str, str]]) -&gt; List[str]</code>: Process a batch of text tasks and image URLs and return a list of responses.</p> </li> <li> <p><code>run_batch_async(tasks_images: List[Tuple[str, str]]) -&gt; List[str]</code>: Process a batch of text tasks and image URLs asynchronously and return a list of responses.</p> </li> <li> <p><code>run_batch_async_with_retries(tasks_images: List[Tuple[str, str]]) -&gt; List[str]</code>: Process a batch of text tasks and image URLs asynchronously with retries in case of errors and return a list of responses.</p> </li> <li> <p><code>unique_chat_history() -&gt; List[str]</code>: Get the unique chat history stored by the model.</p> </li> <li> <p><code>run_with_retries(task: str, img: str) -&gt; str</code>: Run the model with retries in case of an error.</p> </li> <li> <p><code>run_batch_with_retries(tasks_images: List[Tuple[str, str]]) -&gt; List[str]</code>: Run a batch of tasks with retries in case of errors and return a list of responses.</p> </li> <li> <p><code>_tokens_per_second() -&gt; float</code>: Calculate the tokens generated per second during text generation.</p> </li> <li> <p><code>_time_for_generation(task: str) -&gt; float</code>: Measure the time taken for text generation for a specific task.</p> </li> <li> <p><code>generate_summary(text: str) -&gt; str</code>: Generate a summary of the provided text.</p> </li> <li> <p><code>set_temperature(value: float)</code>: Set the temperature parameter for controlling randomness in text generation.</p> </li> <li> <p><code>set_max_tokens(value: int)</code>: Set the maximum number of tokens allowed in generated responses.</p> </li> <li> <p><code>get_generation_time() -&gt; float</code>: Get the time taken for text generation for the last task.</p> </li> <li> <p><code>get_chat_history() -&gt; List[str]</code>: Get the chat history, including all interactions.</p> </li> <li> <p><code>get_unique_chat_history() -&gt; List[str]</code>: Get the unique chat history, removing duplicate interactions.</p> </li> <li> <p><code>get_chat_history_length() -&gt; int</code>: Get the length of the chat history.</p> </li> <li> <p><code>get_unique_chat_history_length() -&gt; int</code>: Get the length of the unique chat history.</p> </li> <li> <p><code>get_chat_history_tokens() -&gt; int</code>: Get the total number of tokens in the chat history.</p> </li> <li> <p><code>print_beautiful(content: str, color: str = 'cyan')</code>: Print content beautifully using colored text.</p> </li> <li> <p><code>stream(content: str)</code>: Stream the content, printing it character by character.</p> </li> <li> <p><code>meta_prompt() -&gt; str</code>: Get the meta prompt that provides guidance for including image labels in responses.</p> </li> </ul>"},{"location":"swarms/models/base_multimodal_model/#5-usage-examples","title":"5. Usage Examples","text":"<p>Let's explore some usage examples of the MultiModalAI library:</p>"},{"location":"swarms/models/base_multimodal_model/#example-1-running","title":"Example 1: Running","text":"<p>the Model</p> <pre><code># Import the library\nfrom swarms.models import BaseMultiModalModel\n\n# Create an instance of the model\nmodel = BaseMultiModalModel(\n    model_name=\"your_model_name\",\n    temperature=0.5,\n    max_tokens=500,\n    device=\"cuda\",\n)\n\n# Run the model with a text task and an image URL\nresponse = model.run(\n    \"Generate a summary of this text\", \"https://www.example.com/image.jpg\"\n)\nprint(response)\n</code></pre>"},{"location":"swarms/models/base_multimodal_model/#example-2-running-multiple-tasks-concurrently","title":"Example 2: Running Multiple Tasks Concurrently","text":"<pre><code># Import the library\nfrom swarms.models import BaseMultiModalModel\n\n# Create an instance of the model\nmodel = BaseMultiModalModel(\n    model_name=\"your_model_name\",\n    temperature=0.5,\n    max_tokens=500,\n    max_workers=4,\n    device=\"cuda\",\n)\n\n# Define a list of tasks and image URLs\ntasks = [\"Task 1\", \"Task 2\", \"Task 3\"]\nimages = [\"https://image1.jpg\", \"https://image2.jpg\", \"https://image3.jpg\"]\n\n# Run the model on multiple tasks concurrently\nresponses = model.run_many(tasks, images)\nfor response in responses:\n    print(response)\n</code></pre>"},{"location":"swarms/models/base_multimodal_model/#example-3-running-the-model-asynchronously","title":"Example 3: Running the Model Asynchronously","text":"<pre><code># Import the library\nfrom swarms.models import BaseMultiModalModel\n\n# Create an instance of the model\nmodel = BaseMultiModalModel(\n    model_name=\"your_model_name\",\n    temperature=0.5,\n    max_tokens=500,\n    device=\"cuda\",\n)\n\n# Define a list of tasks and image URLs\ntasks_images = [\n    (\"Task 1\", \"https://image1.jpg\"),\n    (\"Task 2\", \"https://image2.jpg\"),\n    (\"Task 3\", \"https://image3.jpg\"),\n]\n\n# Run the model on multiple tasks asynchronously\nresponses = model.run_batch_async(tasks_images)\nfor response in responses:\n    print(response)\n</code></pre>"},{"location":"swarms/models/base_multimodal_model/#example-4-inheriting-basemultimodalmodel-for-its-prebuilt-classes","title":"Example 4: Inheriting <code>BaseMultiModalModel</code> for it's prebuilt classes","text":"<pre><code>from swarms.models import BaseMultiModalModel\n\n\nclass CustomMultiModalModel(BaseMultiModalModel):\n    def __init__(self, model_name, custom_parameter, *args, **kwargs):\n        # Call the parent class constructor\n        super().__init__(model_name=model_name, *args, **kwargs)\n        # Initialize custom parameters specific to your model\n        self.custom_parameter = custom_parameter\n\n    def __call__(self, text, img):\n        # Implement the multimodal model logic here\n        # You can use self.custom_parameter and other inherited attributes\n        pass\n\n    def generate_summary(self, text):\n        # Implement the summary generation logic using your model\n        # You can use self.custom_parameter and other inherited attributes\n        pass\n\n\n# Create an instance of your custom multimodal model\ncustom_model = CustomMultiModalModel(\n    model_name=\"your_custom_model_name\",\n    custom_parameter=\"your_custom_value\",\n    temperature=0.5,\n    max_tokens=500,\n    device=\"cuda\",\n)\n\n# Run your custom model\nresponse = custom_model.run(\n    \"Generate a summary of this text\", \"https://www.example.com/image.jpg\"\n)\nprint(response)\n\n# Generate a summary using your custom model\nsummary = custom_model.generate_summary(\"This is a sample text to summarize.\")\nprint(summary)\n</code></pre> <p>In the code above:</p> <ol> <li> <p>We define a <code>CustomMultiModalModel</code> class that inherits from <code>BaseMultiModalModel</code>.</p> </li> <li> <p>In the constructor of our custom class, we call the parent class constructor using <code>super()</code> and initialize any custom parameters specific to our model. In this example, we introduced a <code>custom_parameter</code>.</p> </li> <li> <p>We override the <code>__call__</code> method, which is responsible for running the multimodal model logic. Here, you can implement the specific behavior of your model, considering both text and image inputs.</p> </li> <li> <p>We override the <code>generate_summary</code> method, which is used to generate a summary of text input. You can implement your custom summarization logic here.</p> </li> <li> <p>We create an instance of our custom model, passing the required parameters, including the custom parameter.</p> </li> <li> <p>We demonstrate how to run the custom model and generate a summary using it.</p> </li> </ol> <p>By inheriting from <code>BaseMultiModalModel</code>, you can leverage the prebuilt features and methods provided by the library while customizing the behavior of your multimodal model. This allows you to create powerful and specialized models for various multimodal tasks.</p> <p>These examples demonstrate how to use MultiModalAI to run multimodal models with text and image inputs. You can adjust the parameters and methods to suit your specific use cases.</p>"},{"location":"swarms/models/base_multimodal_model/#6-additional-tips","title":"6. Additional Tips","text":"<p>Here are some additional tips and considerations for using MultiModalAI effectively:</p> <ul> <li> <p>Custom Models: You can create your own multimodal models and inherit from the <code>BaseMultiModalModel</code> class to integrate them with this library.</p> </li> <li> <p>Retries: In cases where text generation might fail due to various reasons (e.g., server issues), using methods with retries can be helpful.</p> </li> <li> <p>Monitoring: You can monitor the performance of your model using methods like <code>_tokens_per_second()</code> and <code>_time_for_generation()</code>.</p> </li> <li> <p>Chat History: The library maintains a chat history, allowing you to keep track of interactions.</p> </li> <li> <p>Streaming: The <code>stream()</code> method can be useful for displaying output character by character, which can be helpful for certain applications.</p> </li> </ul>"},{"location":"swarms/models/base_multimodal_model/#7-references-and-resources","title":"7. References and Resources","text":"<p>Here are some references and resources that you may find useful for working with multimodal models:</p> <ul> <li> <p>Hugging Face Transformers Library: A library for working with various transformer-based models.</p> </li> <li> <p>PIL (Python Imaging Library): Documentation for working with images in Python using the Pillow library.</p> </li> <li> <p>Concurrent Programming in Python: Official Python documentation for concurrent programming.</p> </li> <li> <p>Requests Library Documentation: Documentation for the Requests library, which is used for making HTTP requests.</p> </li> <li> <p>Base64 Encoding in Python: Official Python documentation for base64 encoding and decoding.</p> </li> </ul> <p>This concludes the documentation for the MultiModalAI library. You can now explore the library further and integrate it with your multimodal AI projects.</p>"},{"location":"swarms/models/bingchat/","title":"BingChat Documentation","text":""},{"location":"swarms/models/bingchat/#introduction","title":"Introduction","text":"<p>Welcome to the documentation for BingChat, a powerful chatbot and image generation tool based on OpenAI's GPT model. This documentation provides a comprehensive understanding of BingChat, its architecture, usage, and how it can be integrated into your projects.</p>"},{"location":"swarms/models/bingchat/#overview","title":"Overview","text":"<p>BingChat is designed to provide text responses and generate images based on user prompts. It utilizes the capabilities of the GPT model to generate creative and contextually relevant responses. In addition, it can create images based on text prompts, making it a versatile tool for various applications.</p>"},{"location":"swarms/models/bingchat/#class-definition","title":"Class Definition","text":"<pre><code>class BingChat:\n    def __init__(self, cookies_path: str):\n</code></pre>"},{"location":"swarms/models/bingchat/#usage","title":"Usage","text":"<p>To use BingChat, follow these steps:</p> <ol> <li>Initialize the BingChat instance:</li> </ol> <pre><code>from swarms.models.bing_chat import BingChat\n\nedgegpt = BingChat(cookies_path=\"./path/to/cookies.json\")\n</code></pre> <ol> <li>Get a text response:</li> </ol> <pre><code>response = edgegpt(\"Hello, my name is ChatGPT\")\nprint(response)\n</code></pre>"},{"location":"swarms/models/bingchat/#example-1-text-response","title":"Example 1 - Text Response","text":"<pre><code>from swarms.models.bing_chat import BingChat\n\nedgegpt = BingChat(cookies_path=\"./path/to/cookies.json\")\nresponse = edgegpt(\"Hello, my name is ChatGPT\")\nprint(response)\n</code></pre> <ol> <li>Generate an image based on a text prompt:</li> </ol> <pre><code>image_path = edgegpt.create_img(\n    \"Sunset over mountains\", output_dir=\"./output\", auth_cookie=\"your_auth_cookie\"\n)\nprint(f\"Generated image saved at {image_path}\")\n</code></pre>"},{"location":"swarms/models/bingchat/#example-2-image-generation","title":"Example 2 - Image Generation","text":"<pre><code>from swarms.models.bing_chat import BingChat\n\nedgegpt = BingChat(cookies_path=\"./path/to/cookies.json\")\n\nimage_path = edgegpt.create_img(\n    \"Sunset over mountains\", output_dir=\"./output\", auth_cookie=\"your_auth_cookie\"\n)\n\nprint(f\"Generated image saved at {image_path}\")\n</code></pre> <ol> <li>Set the directory path for managing cookies:</li> </ol> <pre><code>BingChat.set_cookie_dir_path(\"./cookie_directory\")\n</code></pre>"},{"location":"swarms/models/bingchat/#example-3-set-cookie-directory-path","title":"Example 3 - Set Cookie Directory Path","text":"<pre><code>BingChat.set_cookie_dir_path(\"./cookie_directory\")\n</code></pre>"},{"location":"swarms/models/bingchat/#how-bingchat-works","title":"How BingChat Works","text":"<p>BingChat works by utilizing cookies for authentication and interacting with OpenAI's GPT model. Here's how it works:</p> <ol> <li> <p>Initialization: When you create a BingChat instance, it loads the necessary cookies for authentication with BingChat.</p> </li> <li> <p>Text Response: You can use the <code>__call__</code> method to get a text response from the GPT model based on the provided prompt. You can specify the conversation style for different response types.</p> </li> <li> <p>Image Generation: The <code>create_img</code> method allows you to generate images based on text prompts. It requires an authentication cookie and saves the generated images to the specified output directory.</p> </li> <li> <p>Cookie Directory: You can set the directory path for managing cookies using the <code>set_cookie_dir_path</code> method.</p> </li> </ol>"},{"location":"swarms/models/bingchat/#parameters","title":"Parameters","text":"<ul> <li><code>cookies_path</code>: The path to the cookies.json file necessary for authenticating with BingChat.</li> </ul>"},{"location":"swarms/models/bingchat/#additional-information","title":"Additional Information","text":"<ul> <li>BingChat provides both text-based and image-based responses, making it versatile for various use cases.</li> <li>Cookies are used for authentication, so make sure to provide the correct path to the cookies.json file.</li> <li>Image generation requires an authentication cookie, and the generated images can be saved to a specified directory.</li> </ul> <p>That concludes the documentation for BingChat. We hope you find this tool valuable for your text generation and image generation tasks. If you have any questions or encounter any issues, please refer to the BingChat documentation for further assistance. Enjoy working with BingChat!</p>"},{"location":"swarms/models/biogpt/","title":"<code>BioGPT</code> Documentation","text":""},{"location":"swarms/models/biogpt/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction</li> <li>Overview</li> <li>Installation</li> <li>Usage</li> <li>BioGPT Class</li> <li>Examples</li> <li>Additional Information</li> <li>Conclusion</li> </ol>"},{"location":"swarms/models/biogpt/#1-introduction","title":"1. Introduction","text":"<p>The <code>BioGPT</code> module is a domain-specific generative language model designed for the biomedical domain. It is built upon the powerful Transformer architecture and pretrained on a large corpus of biomedical literature. This documentation provides an extensive guide on using the <code>BioGPT</code> module, explaining its purpose, parameters, and usage.</p>"},{"location":"swarms/models/biogpt/#2-overview","title":"2. Overview","text":"<p>The <code>BioGPT</code> module addresses the need for a language model specialized in the biomedical domain. Unlike general-purpose language models, <code>BioGPT</code> excels in generating coherent and contextually relevant text specific to biomedical terms and concepts. It has been evaluated on various biomedical natural language processing tasks and has demonstrated superior performance.</p> <p>Key features and parameters of the <code>BioGPT</code> module include: - <code>model_name</code>: Name of the pretrained model. - <code>max_length</code>: Maximum length of generated text. - <code>num_return_sequences</code>: Number of sequences to return. - <code>do_sample</code>: Whether to use sampling in generation. - <code>min_length</code>: Minimum length of generated text.</p> <p>The <code>BioGPT</code> module is equipped with features for generating text, extracting features, and more.</p>"},{"location":"swarms/models/biogpt/#3-installation","title":"3. Installation","text":"<p>Before using the <code>BioGPT</code> module, ensure you have the required dependencies installed, including the Transformers library and Torch. You can install these dependencies using pip:</p> <pre><code>pip install transformers\npip install torch\n</code></pre>"},{"location":"swarms/models/biogpt/#4-usage","title":"4. Usage","text":"<p>In this section, we'll cover how to use the <code>BioGPT</code> module effectively. It consists of the <code>BioGPT</code> class and provides examples to demonstrate its usage.</p>"},{"location":"swarms/models/biogpt/#41-biogpt-class","title":"4.1. <code>BioGPT</code> Class","text":"<p>The <code>BioGPT</code> class is the core component of the <code>BioGPT</code> module. It is used to create a <code>BioGPT</code> instance, which can generate text, extract features, and more.</p>"},{"location":"swarms/models/biogpt/#parameters","title":"Parameters:","text":"<ul> <li><code>model_name</code> (str): Name of the pretrained model.</li> <li><code>max_length</code> (int): Maximum length of generated text.</li> <li><code>num_return_sequences</code> (int): Number of sequences to return.</li> <li><code>do_sample</code> (bool): Whether or not to use sampling in generation.</li> <li><code>min_length</code> (int): Minimum length of generated text.</li> </ul>"},{"location":"swarms/models/biogpt/#42-examples","title":"4.2. Examples","text":"<p>Let's explore how to use the <code>BioGPT</code> class with different scenarios and applications.</p>"},{"location":"swarms/models/biogpt/#example-1-generating-biomedical-text","title":"Example 1: Generating Biomedical Text","text":"<pre><code>from swarms.models import BioGPT\n\n# Initialize the BioGPT model\nbiogpt = BioGPT()\n\n# Generate biomedical text\ninput_text = \"The patient has a fever\"\ngenerated_text = biogpt(input_text)\n\nprint(generated_text)\n</code></pre>"},{"location":"swarms/models/biogpt/#example-2-extracting-features","title":"Example 2: Extracting Features","text":"<pre><code>from swarms.models import BioGPT\n\n# Initialize the BioGPT model\nbiogpt = BioGPT()\n\n# Extract features from a biomedical text\ninput_text = \"The patient has a fever\"\nfeatures = biogpt.get_features(input_text)\n\nprint(features)\n</code></pre>"},{"location":"swarms/models/biogpt/#example-3-using-beam-search-decoding","title":"Example 3: Using Beam Search Decoding","text":"<pre><code>from swarms.models import BioGPT\n\n# Initialize the BioGPT model\nbiogpt = BioGPT()\n\n# Generate biomedical text using beam search decoding\ninput_text = \"The patient has a fever\"\ngenerated_text = biogpt.beam_search_decoding(input_text)\n\nprint(generated_text)\n</code></pre>"},{"location":"swarms/models/biogpt/#43-additional-features","title":"4.3. Additional Features","text":"<p>The <code>BioGPT</code> class also provides additional features:</p>"},{"location":"swarms/models/biogpt/#set-a-new-pretrained-model","title":"Set a New Pretrained Model","text":"<pre><code>biogpt.set_pretrained_model(\"new_pretrained_model\")\n</code></pre>"},{"location":"swarms/models/biogpt/#get-the-models-configuration","title":"Get the Model's Configuration","text":"<pre><code>config = biogpt.get_config()\nprint(config)\n</code></pre>"},{"location":"swarms/models/biogpt/#save-and-load-the-model","title":"Save and Load the Model","text":"<pre><code># Save the model and tokenizer to a directory\nbiogpt.save_model(\"saved_model\")\n\n# Load a model and tokenizer from a directory\nbiogpt.load_from_path(\"saved_model\")\n</code></pre>"},{"location":"swarms/models/biogpt/#print-the-models-architecture","title":"Print the Model's Architecture","text":"<pre><code>biogpt.print_model()\n</code></pre>"},{"location":"swarms/models/biogpt/#5-additional-information","title":"5. Additional Information","text":"<ul> <li>Biomedical Text Generation: The <code>BioGPT</code> module is designed specifically for generating biomedical text, making it a valuable tool for various biomedical natural language processing tasks.</li> <li>Feature Extraction: It also provides the capability to extract features from biomedical text.</li> <li>Beam Search Decoding: Beam search decoding is available for generating text with improved quality.</li> <li>Customization: You can set a new pretrained model and save/load models for customization.</li> </ul>"},{"location":"swarms/models/biogpt/#6-conclusion","title":"6. Conclusion","text":"<p>The <code>BioGPT</code> module is a powerful and specialized tool for generating and working with biomedical text. This documentation has provided a comprehensive guide on its usage, parameters, and examples, enabling you to effectively leverage it for various biomedical natural language processing tasks.</p> <p>By using <code>BioGPT</code>, you can enhance your biomedical text generation and analysis tasks with contextually relevant and coherent text.</p> <p>Please check the official <code>BioGPT</code> repository and documentation for any updates beyond the knowledge cutoff date.</p>"},{"location":"swarms/models/dalle3/","title":"<code>Dalle3</code> Documentation","text":""},{"location":"swarms/models/dalle3/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction</li> <li>Installation</li> <li>Quick Start</li> <li>Dalle3 Class<ul> <li>Attributes</li> <li>Methods</li> </ul> </li> <li>Usage Examples</li> <li>Error Handling</li> <li>Advanced Usage</li> <li>References</li> </ol>"},{"location":"swarms/models/dalle3/#introduction","title":"Introduction","text":"<p>The Dalle3 library is a Python module that provides an easy-to-use interface for generating images from text descriptions using the DALL\u00b7E 3 model by OpenAI. DALL\u00b7E 3 is a powerful language model capable of converting textual prompts into images. This documentation will guide you through the installation, setup, and usage of the Dalle3 library.</p>"},{"location":"swarms/models/dalle3/#installation","title":"Installation","text":"<p>To use the Dalle3 model, you must first install swarms:</p> <pre><code>pip install swarms\n</code></pre>"},{"location":"swarms/models/dalle3/#quick-start","title":"Quick Start","text":"<p>Let's get started with a quick example of using the Dalle3 library to generate an image from a text prompt:</p> <pre><code>from swarms.models.dalle3 import Dalle3\n\n# Create an instance of the Dalle3 class\ndalle = Dalle3()\n\n# Define a text prompt\ntask = \"A painting of a dog\"\n\n# Generate an image from the text prompt\nimage_url = dalle3(task)\n\n# Print the generated image URL\nprint(image_url)\n</code></pre> <p>This example demonstrates the basic usage of the Dalle3 library to convert a text prompt into an image. The generated image URL will be printed to the console.</p>"},{"location":"swarms/models/dalle3/#dalle3-class","title":"Dalle3 Class","text":"<p>The Dalle3 library provides a <code>Dalle3</code> class that allows you to interact with the DALL\u00b7E 3 model. This class has several attributes and methods for generating images from text prompts.</p>"},{"location":"swarms/models/dalle3/#attributes","title":"Attributes","text":"<ul> <li><code>model</code> (str): The name of the DALL\u00b7E 3 model. Default: \"dall-e-3\".</li> <li><code>img</code> (str): The image URL generated by the Dalle3 API.</li> <li><code>size</code> (str): The size of the generated image. Default: \"1024x1024\".</li> <li><code>max_retries</code> (int): The maximum number of API request retries. Default: 3.</li> <li><code>quality</code> (str): The quality of the generated image. Default: \"standard\".</li> <li><code>n</code> (int): The number of variations to create. Default: 4.</li> </ul>"},{"location":"swarms/models/dalle3/#methods","title":"Methods","text":""},{"location":"swarms/models/dalle3/#__call__self-task-str-dalle3","title":"<code>__call__(self, task: str) -&gt; Dalle3</code>","text":"<p>This method makes a call to the Dalle3 API and returns the image URL generated from the provided text prompt.</p> <p>Parameters: - <code>task</code> (str): The text prompt to be converted to an image.</p> <p>Returns: - <code>Dalle3</code>: An instance of the Dalle3 class with the image URL generated by the Dalle3 API.</p>"},{"location":"swarms/models/dalle3/#create_variationsself-img-str","title":"<code>create_variations(self, img: str)</code>","text":"<p>This method creates variations of an image using the Dalle3 API.</p> <p>Parameters: - <code>img</code> (str): The image to be used for the API request.</p> <p>Returns: - <code>img</code> (str): The image URL of the generated variations.</p>"},{"location":"swarms/models/dalle3/#usage-examples","title":"Usage Examples","text":""},{"location":"swarms/models/dalle3/#example-1-basic-image-generation","title":"Example 1: Basic Image Generation","text":"<pre><code>from swarms.models.dalle3 import Dalle3\n\n# Create an instance of the Dalle3 class\ndalle3 = Dalle3()\n\n# Define a text prompt\ntask = \"A painting of a dog\"\n\n# Generate an image from the text prompt\nimage_url = dalle3(task)\n\n# Print the generated image URL\nprint(image_url)\n</code></pre>"},{"location":"swarms/models/dalle3/#example-2-creating-image-variations","title":"Example 2: Creating Image Variations","text":"<pre><code>from swarms.models.dalle3 import Dalle3\n\n# Create an instance of the Dalle3 class\ndalle3 = Dalle3()\n\n# Define the URL of an existing image\nimg_url = \"https://images.unsplash.com/photo-1694734479898-6ac4633158ac?q=80&amp;w=1287&amp;auto=format&amp;fit=crop&amp;ixlib=rb-4.0.3&amp;ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D\n\n# Create variations of the image\nvariations_url = dalle3.create_variations(img_url)\n\n# Print the URLs of the generated variations\nprint(variations_url)\n</code></pre> <p>Certainly! Here are additional examples that cover various edge cases and methods of the <code>Dalle3</code> class in the Dalle3 library:</p>"},{"location":"swarms/models/dalle3/#example-3-customizing-image-size","title":"Example 3: Customizing Image Size","text":"<p>You can customize the size of the generated image by specifying the <code>size</code> parameter when creating an instance of the <code>Dalle3</code> class. Here's how to generate a smaller image:</p> <pre><code>from swarms.models.dalle3 import Dalle3\n\n# Create an instance of the Dalle3 class with a custom image size\ndalle3 = Dalle3(size=\"512x512\")\n\n# Define a text prompt\ntask = \"A small painting of a cat\"\n\n# Generate a smaller image from the text prompt\nimage_url = dalle3(task)\n\n# Print the generated image URL\nprint(image_url)\n</code></pre>"},{"location":"swarms/models/dalle3/#example-4-adjusting-retry-limit","title":"Example 4: Adjusting Retry Limit","text":"<p>You can adjust the maximum number of API request retries using the <code>max_retries</code> parameter. Here's how to increase the retry limit:</p> <pre><code>from swarms.models.dalle3 import Dalle3\n\n# Create an instance of the Dalle3 class with a higher retry limit\ndalle3 = Dalle3(max_retries=5)\n\n# Define a text prompt\ntask = \"An image of a landscape\"\n\n# Generate an image with a higher retry limit\nimage_url = dalle3(task)\n\n# Print the generated image URL\nprint(image_url)\n</code></pre>"},{"location":"swarms/models/dalle3/#example-5-generating-image-variations","title":"Example 5: Generating Image Variations","text":"<p>To create variations of an existing image, you can use the <code>create_variations</code> method. Here's an example:</p> <pre><code>from swarms.models.dalle3 import Dalle3\n\n# Create an instance of the Dalle3 class\ndalle3 = Dalle3()\n\n# Define the URL of an existing image\nimg_url = \"https://images.unsplash.com/photo-1677290043066-12eccd944004?q=80&amp;w=1287&amp;auto=format&amp;fit=crop&amp;ixlib=rb-4.0.3&amp;ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D\"\n\n# Create variations of the image\nvariations_url = dalle3.create_variations(img_url)\n\n# Print the URLs of the generated variations\nprint(variations_url)\n</code></pre>"},{"location":"swarms/models/dalle3/#example-6-handling-api-errors","title":"Example 6: Handling API Errors","text":"<p>The Dalle3 library provides error handling for API-related issues. Here's how to handle and display API errors:</p> <pre><code>from swarms.models.dalle3 import Dalle3\n\n# Create an instance of the Dalle3 class\ndalle3 = Dalle3()\n\n# Define a text prompt\ntask = \"Invalid prompt that may cause an API error\"\n\ntry:\n    # Attempt to generate an image with an invalid prompt\n    image_url = dalle3(task)\n    print(image_url)\nexcept Exception as e:\n    print(f\"Error occurred: {str(e)}\")\n</code></pre>"},{"location":"swarms/models/dalle3/#example-7-customizing-image-quality","title":"Example 7: Customizing Image Quality","text":"<p>You can customize the quality of the generated image by specifying the <code>quality</code> parameter. Here's how to generate a high-quality image:</p> <pre><code>from swarms.models.dalle3 import Dalle3\n\n# Create an instance of the Dalle3 class with high quality\ndalle3 = Dalle3(quality=\"high\")\n\n# Define a text prompt\ntask = \"A high-quality image of a sunset\"\n\n# Generate a high-quality image from the text prompt\nimage_url = dalle3(task)\n\n# Print the generated image URL\nprint(image_url)\n</code></pre>"},{"location":"swarms/models/dalle3/#error-handling","title":"Error Handling","text":"<p>The Dalle3 library provides error handling for API-related issues. If an error occurs during API communication, the library will handle it and provide detailed error messages. Make sure to handle exceptions appropriately in your code.</p>"},{"location":"swarms/models/dalle3/#advanced-usage","title":"Advanced Usage","text":"<p>For advanced usage and customization of the Dalle3 library, you can explore the attributes and methods of the <code>Dalle3</code> class. Adjusting parameters such as <code>size</code>, <code>max_retries</code>, and <code>quality</code> allows you to fine-tune the image generation process to your specific needs.</p>"},{"location":"swarms/models/dalle3/#references","title":"References","text":"<p>For more information about the DALL\u00b7E 3 model and the Dalle3 library, you can refer to the official OpenAI documentation and resources.</p> <ul> <li>OpenAI API Documentation</li> <li>DALL\u00b7E 3 Model Information</li> <li>Dalle3 GitHub Repository</li> </ul> <p>This concludes the documentation for the Dalle3 library. You can now use the library to generate images from text prompts and explore its advanced features for various applications.</p>"},{"location":"swarms/models/distilled_whisperx/","title":"DistilWhisperModel Documentation","text":""},{"location":"swarms/models/distilled_whisperx/#overview","title":"Overview","text":"<p>The <code>DistilWhisperModel</code> is a Python class designed to handle English speech recognition tasks. It leverages the capabilities of the Whisper model, which is fine-tuned for speech-to-text processes. It is designed for both synchronous and asynchronous transcription of audio inputs, offering flexibility for real-time applications or batch processing.</p>"},{"location":"swarms/models/distilled_whisperx/#installation","title":"Installation","text":"<p>Before you can use <code>DistilWhisperModel</code>, ensure you have the required libraries installed:</p> <pre><code>pip3 install --upgrade swarms\n</code></pre>"},{"location":"swarms/models/distilled_whisperx/#initialization","title":"Initialization","text":"<p>The <code>DistilWhisperModel</code> class is initialized with the following parameters:</p> Parameter Type Description Default <code>model_id</code> <code>str</code> The identifier for the pre-trained Whisper model <code>\"distil-whisper/distil-large-v2\"</code> <p>Example of initialization:</p> <pre><code>from swarms.models import DistilWhisperModel\n\n# Initialize with default model\nmodel_wrapper = DistilWhisperModel()\n\n# Initialize with a specific model ID\nmodel_wrapper = DistilWhisperModel(model_id=\"distil-whisper/distil-large-v2\")\n</code></pre>"},{"location":"swarms/models/distilled_whisperx/#attributes","title":"Attributes","text":"<p>After initialization, the <code>DistilWhisperModel</code> has several attributes:</p> Attribute Type Description <code>device</code> <code>str</code> The device used for computation (<code>\"cuda:0\"</code> for GPU or <code>\"cpu\"</code>). <code>torch_dtype</code> <code>torch.dtype</code> The data type used for the Torch tensors. <code>model_id</code> <code>str</code> The model identifier string. <code>model</code> <code>torch.nn.Module</code> The actual Whisper model loaded from the identifier. <code>processor</code> <code>transformers.AutoProcessor</code> The processor for handling input data."},{"location":"swarms/models/distilled_whisperx/#methods","title":"Methods","text":""},{"location":"swarms/models/distilled_whisperx/#transcribe","title":"<code>transcribe</code>","text":"<p>Transcribes audio input synchronously.</p> <p>Arguments:</p> Argument Type Description <code>inputs</code> <code>Union[str, dict]</code> File path or audio data dictionary. <p>Returns: <code>str</code> - The transcribed text.</p> <p>Usage Example:</p> <pre><code># Synchronous transcription\ntranscription = model_wrapper.transcribe(\"path/to/audio.mp3\")\nprint(transcription)\n</code></pre>"},{"location":"swarms/models/distilled_whisperx/#async_transcribe","title":"<code>async_transcribe</code>","text":"<p>Transcribes audio input asynchronously.</p> <p>Arguments:</p> Argument Type Description <code>inputs</code> <code>Union[str, dict]</code> File path or audio data dictionary. <p>Returns: <code>Coroutine</code> - A coroutine that when awaited, returns the transcribed text.</p> <p>Usage Example:</p> <pre><code>import asyncio\n\n# Asynchronous transcription\ntranscription = asyncio.run(model_wrapper.async_transcribe(\"path/to/audio.mp3\"))\nprint(transcription)\n</code></pre>"},{"location":"swarms/models/distilled_whisperx/#real_time_transcribe","title":"<code>real_time_transcribe</code>","text":"<p>Simulates real-time transcription of an audio file.</p> <p>Arguments:</p> Argument Type Description <code>audio_file_path</code> <code>str</code> Path to the audio file. <code>chunk_duration</code> <code>int</code> Duration of audio chunks in seconds. <p>Usage Example:</p> <pre><code># Real-time transcription simulation\nmodel_wrapper.real_time_transcribe(\"path/to/audio.mp3\", chunk_duration=5)\n</code></pre>"},{"location":"swarms/models/distilled_whisperx/#error-handling","title":"Error Handling","text":"<p>The <code>DistilWhisperModel</code> class incorporates error handling for file not found errors and generic exceptions during the transcription process. If a non-recoverable exception is raised, it is printed to the console in red to indicate failure.</p>"},{"location":"swarms/models/distilled_whisperx/#conclusion","title":"Conclusion","text":"<p>The <code>DistilWhisperModel</code> offers a convenient interface to the powerful Whisper model for speech recognition. Its design supports both batch and real-time transcription, catering to different application needs. The class's error handling and retry logic make it robust for real-world applications.</p>"},{"location":"swarms/models/distilled_whisperx/#additional-notes","title":"Additional Notes","text":"<ul> <li>Ensure you have appropriate permissions to read audio files when using file paths.</li> <li>Transcription quality depends on the audio quality and the Whisper model's performance on your dataset.</li> <li>Adjust <code>chunk_duration</code> according to the processing power of your system for real-time transcription.</li> </ul> <p>For a full list of models supported by <code>transformers.AutoModelForSpeechSeq2Seq</code>, visit the Hugging Face Model Hub.</p>"},{"location":"swarms/models/elevenlabs/","title":"ElevenLabsText2SpeechTool Documentation","text":""},{"location":"swarms/models/elevenlabs/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction</li> <li>Class Overview</li> <li>Attributes</li> <li>Installation</li> <li>Usage</li> <li>Initialization</li> <li>Converting Text to Speech</li> <li>Playing and Streaming Speech</li> <li>Exception Handling</li> <li>Advanced Usage</li> <li>Contributing</li> <li>References</li> </ol>"},{"location":"swarms/models/elevenlabs/#1-introduction","title":"1. Introduction","text":"<p>The <code>ElevenLabsText2SpeechTool</code> is a Python class designed to simplify the process of converting text to speech using the Eleven Labs Text2Speech API. This tool is a wrapper around the API and provides a convenient interface for generating speech from text. It supports multiple languages, making it suitable for a wide range of applications, including voice assistants, audio content generation, and more.</p>"},{"location":"swarms/models/elevenlabs/#2-class-overview","title":"2. Class Overview","text":""},{"location":"swarms/models/elevenlabs/#attributes","title":"Attributes","text":"<ul> <li><code>model</code> (Union[ElevenLabsModel, str]): The model to use for text to speech. Defaults to <code>ElevenLabsModel.MULTI_LINGUAL</code>.</li> <li><code>name</code> (str): The name of the tool. Defaults to <code>\"eleven_labs_text2speech\"</code>.</li> <li><code>description</code> (str): A brief description of the tool. Defaults to a detailed explanation of its functionality.</li> </ul>"},{"location":"swarms/models/elevenlabs/#3-installation","title":"3. Installation","text":"<p>To use the <code>ElevenLabsText2SpeechTool</code>, you need to install the required dependencies and have access to the Eleven Labs Text2Speech API. Follow these steps:</p> <ol> <li> <p>Install the <code>elevenlabs</code> library:    <pre><code>pip install elevenlabs\n</code></pre></p> </li> <li> <p>Install the <code>swarms</code> library     <code>pip install swarms</code></p> </li> <li> <p>Set up your API key by following the instructions at Eleven Labs Documentation.</p> </li> </ol>"},{"location":"swarms/models/elevenlabs/#4-usage","title":"4. Usage","text":""},{"location":"swarms/models/elevenlabs/#initialization","title":"Initialization","text":"<p>To get started, create an instance of the <code>ElevenLabsText2SpeechTool</code>. You can customize the <code>model</code> attribute if needed.</p> <pre><code>from swarms.models import ElevenLabsText2SpeechTool\n\nstt = ElevenLabsText2SpeechTool(model=ElevenLabsModel.MONO_LINGUAL)\n</code></pre>"},{"location":"swarms/models/elevenlabs/#converting-text-to-speech","title":"Converting Text to Speech","text":"<p>You can use the <code>run</code> method to convert text to speech. It returns the path to the generated speech file.</p> <pre><code>speech_file = stt.run(\"Hello, this is a test.\")\n</code></pre>"},{"location":"swarms/models/elevenlabs/#playing-and-streaming-speech","title":"Playing and Streaming Speech","text":"<ul> <li>Use the <code>play</code> method to play the generated speech file.</li> </ul> <pre><code>stt.play(speech_file)\n</code></pre> <ul> <li>Use the <code>stream_speech</code> method to stream the text as speech. It plays the speech in real-time.</li> </ul> <pre><code>stt.stream_speech(\"Hello world!\")\n</code></pre>"},{"location":"swarms/models/elevenlabs/#5-exception-handling","title":"5. Exception Handling","text":"<p>The <code>ElevenLabsText2SpeechTool</code> handles exceptions gracefully. If an error occurs during the conversion process, it raises a <code>RuntimeError</code> with an informative error message.</p>"},{"location":"swarms/models/elevenlabs/#6-advanced-usage","title":"6. Advanced Usage","text":"<ul> <li>You can implement custom error handling and logging to further enhance the functionality of this tool.</li> <li>For advanced users, extending the class to support additional features or customization is possible.</li> </ul>"},{"location":"swarms/models/elevenlabs/#7-contributing","title":"7. Contributing","text":"<p>Contributions to this tool are welcome. Feel free to open issues, submit pull requests, or provide feedback to improve its functionality and documentation.</p>"},{"location":"swarms/models/elevenlabs/#8-references","title":"8. References","text":"<ul> <li>Eleven Labs Text2Speech API Documentation</li> </ul> <p>This documentation provides a comprehensive guide to using the <code>ElevenLabsText2SpeechTool</code>. It covers installation, basic usage, advanced features, and contribution guidelines. Refer to the References section for additional resources.</p>"},{"location":"swarms/models/fuyu/","title":"Fuyu Documentation","text":""},{"location":"swarms/models/fuyu/#introduction","title":"Introduction","text":"<p>Welcome to the documentation for Fuyu, a versatile model for generating text conditioned on both textual prompts and images. Fuyu is based on the Adept's Fuyu model and offers a convenient way to create text that is influenced by the content of an image. In this documentation, you will find comprehensive information on the Fuyu class, its architecture, usage, and examples.</p>"},{"location":"swarms/models/fuyu/#overview","title":"Overview","text":"<p>Fuyu is a text generation model that leverages both text and images to generate coherent and contextually relevant text. It combines state-of-the-art language modeling techniques with image processing capabilities to produce text that is semantically connected to the content of an image. Whether you need to create captions for images or generate text that describes visual content, Fuyu can assist you.</p>"},{"location":"swarms/models/fuyu/#class-definition","title":"Class Definition","text":"<pre><code>class Fuyu:\n    def __init__(\n        self,\n        pretrained_path: str = \"adept/fuyu-8b\",\n        device_map: str = \"cuda:0\",\n        max_new_tokens: int = 7,\n    ):\n</code></pre>"},{"location":"swarms/models/fuyu/#purpose","title":"Purpose","text":"<p>The Fuyu class serves as a convenient interface for using the Adept's Fuyu model. It allows you to generate text based on a textual prompt and an image. The primary purpose of Fuyu is to provide a user-friendly way to create text that is influenced by visual content, making it suitable for various applications, including image captioning, storytelling, and creative text generation.</p>"},{"location":"swarms/models/fuyu/#parameters","title":"Parameters","text":"<ul> <li><code>pretrained_path</code> (str): The path to the pretrained Fuyu model. By default, it uses the \"adept/fuyu-8b\" model.</li> <li><code>device_map</code> (str): The device to use for model inference (e.g., \"cuda:0\" for GPU or \"cpu\" for CPU). Default: \"cuda:0\".</li> <li><code>max_new_tokens</code> (int): The maximum number of tokens to generate in the output text. Default: 7.</li> </ul>"},{"location":"swarms/models/fuyu/#usage","title":"Usage","text":"<p>To use Fuyu, follow these steps:</p> <ol> <li>Initialize the Fuyu instance:</li> </ol> <pre><code>from swarms.models.fuyu import Fuyu\n\nfuyu = Fuyu()\n</code></pre> <ol> <li>Generate Text with Fuyu:</li> </ol> <pre><code>text = \"Hello, my name is\"\nimg_path = \"path/to/image.png\"\noutput_text = fuyu(text, img_path)\n</code></pre>"},{"location":"swarms/models/fuyu/#example-2-text-generation","title":"Example 2 - Text Generation","text":"<pre><code>from swarms.models.fuyu import Fuyu\n\nfuyu = Fuyu()\n\ntext = \"Hello, my name is\"\n\nimg_path = \"path/to/image.png\"\n\noutput_text = fuyu(text, img_path)\nprint(output_text)\n</code></pre>"},{"location":"swarms/models/fuyu/#how-fuyu-works","title":"How Fuyu Works","text":"<p>Fuyu combines text and image processing to generate meaningful text outputs. Here's how it works:</p> <ol> <li> <p>Initialization: When you create a Fuyu instance, you specify the pretrained model path, the device for inference, and the maximum number of tokens to generate.</p> </li> <li> <p>Processing Text and Images: Fuyu can process both textual prompts and images. You provide a text prompt and the path to an image as input.</p> </li> <li> <p>Tokenization: Fuyu tokenizes the input text and encodes the image using its tokenizer.</p> </li> <li> <p>Model Inference: The model takes the tokenized inputs and generates text that is conditioned on both the text and the image.</p> </li> <li> <p>Output Text: Fuyu returns the generated text as the output.</p> </li> </ol>"},{"location":"swarms/models/fuyu/#additional-information","title":"Additional Information","text":"<ul> <li>Fuyu uses the Adept's Fuyu model, which is pretrained on a large corpus of text and images, making it capable of generating coherent and contextually relevant text.</li> <li>You can specify the device for inference to utilize GPU acceleration if available.</li> <li>The <code>max_new_tokens</code> parameter allows you to control the length of the generated text.</li> </ul> <p>That concludes the documentation for Fuyu. We hope you find this model useful for your text generation tasks that involve images. If you have any questions or encounter any issues, please refer to the Fuyu documentation for further assistance. Enjoy working with Fuyu!</p>"},{"location":"swarms/models/gemini/","title":"Gemini","text":""},{"location":"swarms/models/gemini/#gemini-documentation","title":"<code>Gemini</code> Documentation","text":""},{"location":"swarms/models/gemini/#introduction","title":"Introduction","text":"<p>The Gemini module is a versatile tool for leveraging the power of multimodal AI models to generate content. It allows users to combine textual and image inputs to generate creative and informative outputs. In this documentation, we will explore the Gemini module in detail, covering its purpose, architecture, methods, and usage examples.</p>"},{"location":"swarms/models/gemini/#purpose","title":"Purpose","text":"<p>The Gemini module is designed to bridge the gap between text and image data, enabling users to harness the capabilities of multimodal AI models effectively. By providing both a textual task and an image as input, Gemini generates content that aligns with the specified task and incorporates the visual information from the image.</p>"},{"location":"swarms/models/gemini/#installation","title":"Installation","text":"<p>Before using Gemini, ensure that you have the required dependencies installed. You can install them using the following commands:</p> <pre><code>pip install swarms\npip install google-generativeai\npip install python-dotenv\n</code></pre>"},{"location":"swarms/models/gemini/#class-gemini","title":"Class: Gemini","text":""},{"location":"swarms/models/gemini/#overview","title":"Overview","text":"<p>The <code>Gemini</code> class is the central component of the Gemini module. It inherits from the <code>BaseMultiModalModel</code> class and provides methods to interact with the Gemini AI model. Let's dive into its architecture and functionality.</p>"},{"location":"swarms/models/gemini/#class-constructor","title":"Class Constructor","text":"<pre><code>class Gemini(BaseMultiModalModel):\n    def __init__(\n        self,\n        model_name: str = \"gemini-pro\",\n        gemini_api_key: str = get_gemini_api_key_env,\n        *args,\n        **kwargs,\n    ):\n</code></pre> Parameter Type Description Default Value <code>model_name</code> str The name of the Gemini model. \"gemini-pro\" <code>gemini_api_key</code> str The Gemini API key. If not provided, it is fetched from the environment. (None) <ul> <li> <p><code>model_name</code>: Specifies the name of the Gemini model to use. By default, it is set to \"gemini-pro,\" but you can specify a different model if needed.</p> </li> <li> <p><code>gemini_api_key</code>: This parameter allows you to provide your Gemini API key directly. If not provided, the constructor attempts to fetch it from the environment using the <code>get_gemini_api_key_env</code> helper function.</p> </li> </ul>"},{"location":"swarms/models/gemini/#methods","title":"Methods","text":"<ol> <li>run()</li> </ol> <pre><code>def run(\n    self,\n    task: str = None,\n    img: str = None,\n    *args,\n    **kwargs,\n) -&gt; str:\n</code></pre> Parameter Type Description <code>task</code> str The textual task for content generation. <code>img</code> str The path to the image to be processed. <code>*args</code> Variable Additional positional arguments. <code>**kwargs</code> Variable Additional keyword arguments. <ul> <li> <p><code>task</code>: Specifies the textual task for content generation. It can be a sentence or a phrase that describes the desired content.</p> </li> <li> <p><code>img</code>: Provides the path to the image that will be processed along with the textual task. Gemini combines the visual information from the image with the textual task to generate content.</p> </li> <li> <p><code>*args</code> and <code>**kwargs</code>: Allow for additional, flexible arguments that can be passed to the underlying Gemini model. These arguments can vary based on the specific Gemini model being used.</p> </li> </ul> <p>Returns: A string containing the generated content.</p> <p>Examples:</p> <pre><code>from swarms.models import Gemini\n\n# Initialize the Gemini model\ngemini = Gemini()\n\n# Generate content for a textual task with an image\ngenerated_content = gemini.run(\n    task=\"Describe this image\",\n    img=\"image.jpg\",\n)\n\n# Print the generated content\nprint(generated_content)\n</code></pre> <p>In this example, we initialize the Gemini model, provide a textual task, and specify an image for processing. The <code>run()</code> method generates content based on the input and returns the result.</p> <ol> <li>process_img()</li> </ol> <pre><code>def process_img(\n    self,\n    img: str = None,\n    type: str = \"image/png\",\n    *args,\n    **kwargs,\n):\n</code></pre> Parameter Type Description Default Value <code>img</code> str The path to the image to be processed. (None) <code>type</code> str The MIME type of the image (e.g., \"image/png\"). \"image/png\" <code>*args</code> Variable Additional positional arguments. <code>**kwargs</code> Variable Additional keyword arguments. <ul> <li> <p><code>img</code>: Specifies the path to the image that will be processed. It's essential to provide a valid image path for image-based content generation.</p> </li> <li> <p><code>type</code>: Indicates the MIME type of the image. By default, it is set to \"image/png,\" but you can change it based on the image format you're using.</p> </li> <li> <p><code>*args</code> and <code>**kwargs</code>: Allow for additional, flexible arguments that can be passed to the underlying Gemini model. These arguments can vary based on the specific Gemini model being used.</p> </li> </ul> <p>Raises: ValueError if any of the following conditions are met:    - No image is provided.    - The image type is not specified.    - The Gemini API key is missing.</p> <p>Examples:</p> <pre><code>from swarms.models.gemini import Gemini\n\n# Initialize the Gemini model\ngemini = Gemini()\n\n# Process an image\nprocessed_image = gemini.process_img(\n    img=\"image.jpg\",\n    type=\"image/jpeg\",\n)\n\n# Further use the processed image in content generation\ngenerated_content = gemini.run(\n    task=\"Describe this image\",\n    img=processed_image,\n)\n\n# Print the generated content\nprint(generated_content)\n</code></pre> <p>In this example, we demonstrate how to process an image using the <code>process_img()</code> method and then use the processed image in content generation.</p>"},{"location":"swarms/models/gemini/#additional-information","title":"Additional Information","text":"<ul> <li> <p>Gemini is designed to work seamlessly with various multimodal AI models, making it a powerful tool for content generation tasks.</p> </li> <li> <p>The module uses the <code>google.generativeai</code> package to access the underlying AI models. Ensure that you have this package installed to leverage the full capabilities of Gemini.</p> </li> <li> <p>It's essential to provide a valid Gemini API key for authentication. You can either pass it directly during initialization or store it in the environment variable \"GEMINI_API_KEY.\"</p> </li> <li> <p>Gemini's flexibility allows you to experiment with different Gemini models and tailor the content generation process to your specific needs.</p> </li> <li> <p>Keep in mind that Gemini is designed to handle both textual and image inputs, making it a valuable asset for various applications, including natural language processing and computer vision tasks.</p> </li> <li> <p>If you encounter any issues or have specific requirements, refer to the Gemini documentation for more details and advanced usage.</p> </li> </ul>"},{"location":"swarms/models/gemini/#references-and-resources","title":"References and Resources","text":"<ul> <li> <p>Gemini GitHub Repository: Explore the Gemini repository for additional information, updates, and examples.</p> </li> <li> <p>Google GenerativeAI Documentation: Dive deeper into the capabilities of the Google GenerativeAI package used by Gemini.</p> </li> <li> <p>Gemini API Documentation: Access the official documentation for the Gemini API to explore advanced features and integrations.</p> </li> </ul>"},{"location":"swarms/models/gemini/#conclusion","title":"Conclusion","text":"<p>In this comprehensive documentation, we've explored the Gemini module, its purpose, architecture, methods, and usage examples. Gemini empowers developers to generate content by combining textual tasks and images, making it a valuable asset for multimodal AI applications. Whether you're working on natural language processing or computer vision projects, Gemini can help you achieve impressive results.</p>"},{"location":"swarms/models/gpt4v/","title":"<code>GPT4VisionAPI</code> Documentation","text":"<p>Table of Contents - Introduction - Installation - Module Overview - Class: GPT4VisionAPI   - Initialization   - Methods     - encode_image     - run     - call - Examples   - Example 1: Basic Usage   - Example 2: Custom API Key   - Example 3: Adjusting Maximum Tokens - Additional Information - References</p>"},{"location":"swarms/models/gpt4v/#introduction","title":"Introduction","text":"<p>Welcome to the documentation for the <code>GPT4VisionAPI</code> module! This module is a powerful wrapper for the OpenAI GPT-4 Vision model. It allows you to interact with the model to generate descriptions or answers related to images. This documentation will provide you with comprehensive information on how to use this module effectively.</p>"},{"location":"swarms/models/gpt4v/#installation","title":"Installation","text":"<p>Before you start using the <code>GPT4VisionAPI</code> module, make sure you have the required dependencies installed. You can install them using the following commands:</p> <pre><code>pip3 install --upgrade swarms\n</code></pre>"},{"location":"swarms/models/gpt4v/#module-overview","title":"Module Overview","text":"<p>The <code>GPT4VisionAPI</code> module serves as a bridge between your application and the OpenAI GPT-4 Vision model. It allows you to send requests to the model and retrieve responses related to images. Here are some key features and functionality provided by this module:</p> <ul> <li>Encoding images to base64 format.</li> <li>Running the GPT-4 Vision model with specified tasks and images.</li> <li>Customization options such as setting the OpenAI API key and maximum token limit.</li> </ul>"},{"location":"swarms/models/gpt4v/#class-gpt4visionapi","title":"Class: GPT4VisionAPI","text":"<p>The <code>GPT4VisionAPI</code> class is the core component of this module. It encapsulates the functionality required to interact with the GPT-4 Vision model. Below, we'll dive into the class in detail.</p>"},{"location":"swarms/models/gpt4v/#initialization","title":"Initialization","text":"<p>When initializing the <code>GPT4VisionAPI</code> class, you have the option to provide the OpenAI API key and set the maximum token limit. Here are the parameters and their descriptions:</p> Parameter Type Default Value Description openai_api_key str <code>OPENAI_API_KEY</code> environment variable (if available) The OpenAI API key. If not provided, it defaults to the <code>OPENAI_API_KEY</code> environment variable. max_tokens int 300 The maximum number of tokens to generate in the model's response. <p>Here's how you can initialize the <code>GPT4VisionAPI</code> class:</p> <pre><code>from swarms.models import GPT4VisionAPI\n\n# Initialize with default API key and max_tokens\napi = GPT4VisionAPI()\n\n# Initialize with custom API key and max_tokens\ncustom_api_key = \"your_custom_api_key\"\napi = GPT4VisionAPI(openai_api_key=custom_api_key, max_tokens=500)\n</code></pre>"},{"location":"swarms/models/gpt4v/#methods","title":"Methods","text":""},{"location":"swarms/models/gpt4v/#encode_image","title":"encode_image","text":"<p>This method allows you to encode an image from a URL to base64 format. It's a utility function used internally by the module.</p> <pre><code>def encode_image(img: str) -&gt; str:\n    \"\"\"\n    Encode image to base64.\n\n    Parameters:\n    - img (str): URL of the image to encode.\n\n    Returns:\n    str: Base64 encoded image.\n    \"\"\"\n</code></pre>"},{"location":"swarms/models/gpt4v/#run","title":"run","text":"<p>The <code>run</code> method is the primary way to interact with the GPT-4 Vision model. It sends a request to the model with a task and an image URL, and it returns the model's response.</p> <pre><code>def run(task: str, img: str) -&gt; str:\n    \"\"\"\n    Run the GPT-4 Vision model.\n\n    Parameters:\n    - task (str): The task or question related to the image.\n    - img (str): URL of the image to analyze.\n\n    Returns:\n    str: The model's response.\n    \"\"\"\n</code></pre>"},{"location":"swarms/models/gpt4v/#call","title":"call","text":"<p>The <code>__call__</code> method is a convenient way to run the GPT-4 Vision model. It has the same functionality as the <code>run</code> method.</p> <pre><code>def __call__(task: str, img: str) -&gt; str:\n    \"\"\"\n       Run the GPT-4 Vision model (callable).\n\n       Parameters:\n       - task (str): The task or question related to the image.\n       - img\n\n    (str): URL of the image to analyze.\n\n       Returns:\n       str: The model's response.\n    \"\"\"\n</code></pre>"},{"location":"swarms/models/gpt4v/#examples","title":"Examples","text":"<p>Let's explore some usage examples of the <code>GPT4VisionAPI</code> module to better understand how to use it effectively.</p>"},{"location":"swarms/models/gpt4v/#example-1-basic-usage","title":"Example 1: Basic Usage","text":"<p>In this example, we'll use the module with the default API key and maximum tokens to analyze an image.</p> <pre><code>from swarms.models import GPT4VisionAPI\n\n# Initialize with default API key and max_tokens\napi = GPT4VisionAPI()\n\n# Define the task and image URL\ntask = \"What is the color of the object?\"\nimg = \"https://i.imgur.com/2M2ZGwC.jpeg\"\n\n# Run the GPT-4 Vision model\nresponse = api.run(task, img)\n\n# Print the model's response\nprint(response)\n</code></pre>"},{"location":"swarms/models/gpt4v/#example-2-custom-api-key","title":"Example 2: Custom API Key","text":"<p>If you have a custom API key, you can initialize the module with it as shown in this example.</p> <pre><code>from swarms.models import GPT4VisionAPI\n\n# Initialize with custom API key and max_tokens\ncustom_api_key = \"your_custom_api_key\"\napi = GPT4VisionAPI(openai_api_key=custom_api_key, max_tokens=500)\n\n# Define the task and image URL\ntask = \"What is the object in the image?\"\nimg = \"https://i.imgur.com/3T3ZHwD.jpeg\"\n\n# Run the GPT-4 Vision model\nresponse = api.run(task, img)\n\n# Print the model's response\nprint(response)\n</code></pre>"},{"location":"swarms/models/gpt4v/#example-3-adjusting-maximum-tokens","title":"Example 3: Adjusting Maximum Tokens","text":"<p>You can also customize the maximum token limit when initializing the module. In this example, we set it to 1000 tokens.</p> <pre><code>from swarms.models import GPT4VisionAPI\n\n# Initialize with default API key and custom max_tokens\napi = GPT4VisionAPI(max_tokens=1000)\n\n# Define the task and image URL\ntask = \"Describe the scene in the image.\"\nimg = \"https://i.imgur.com/4P4ZRxU.jpeg\"\n\n# Run the GPT-4 Vision model\nresponse = api.run(task, img)\n\n# Print the model's response\nprint(response)\n</code></pre>"},{"location":"swarms/models/gpt4v/#additional-information","title":"Additional Information","text":"<ul> <li>If you encounter any errors or issues with the module, make sure to check your API key and internet connectivity.</li> <li>It's recommended to handle exceptions when using the module to gracefully handle errors.</li> <li>You can further customize the module to fit your specific use case by modifying the code as needed.</li> </ul>"},{"location":"swarms/models/gpt4v/#references","title":"References","text":"<ul> <li>OpenAI API Documentation</li> </ul> <p>This documentation provides a comprehensive guide on how to use the <code>GPT4VisionAPI</code> module effectively. It covers initialization, methods, usage examples, and additional information to ensure a smooth experience when working with the GPT-4 Vision model.</p>"},{"location":"swarms/models/hf/","title":"HuggingFaceLLM","text":""},{"location":"swarms/models/hf/#overview-introduction","title":"Overview &amp; Introduction","text":"<p>The <code>HuggingFaceLLM</code> class in the Zeta library provides a simple and easy-to-use interface to harness the power of Hugging Face's transformer-based language models, specifically for causal language modeling. This enables developers to generate coherent and contextually relevant sentences or paragraphs given a prompt, without delving deep into the intricate details of the underlying model or the tokenization process.</p> <p>Causal Language Modeling (CLM) is a task where given a series of tokens (or words), the model predicts the next token in the sequence. This functionality is central to many natural language processing tasks, including chatbots, story generation, and code autocompletion.</p>"},{"location":"swarms/models/hf/#class-definition","title":"Class Definition","text":"<pre><code>class HuggingFaceLLM:\n</code></pre>"},{"location":"swarms/models/hf/#parameters","title":"Parameters:","text":"<ul> <li> <p><code>model_id (str)</code>: Identifier for the pre-trained model on the Hugging Face model hub. Examples include \"gpt2-medium\", \"openai-gpt\", etc.</p> </li> <li> <p><code>device (str, optional)</code>: The device on which to load and run the model. Defaults to 'cuda' if GPU is available, else 'cpu'.</p> </li> <li> <p><code>max_length (int, optional)</code>: Maximum length of the generated sequence. Defaults to 20.</p> </li> <li> <p><code>quantization_config (dict, optional)</code>: Configuration dictionary for model quantization (if applicable). Default is <code>None</code>.</p> </li> </ul>"},{"location":"swarms/models/hf/#functionality-usage","title":"Functionality &amp; Usage","text":""},{"location":"swarms/models/hf/#initialization","title":"Initialization:","text":"<pre><code>llm = HuggingFaceLLM(model_id=\"gpt2-medium\")\n</code></pre> <p>Upon initialization, the specified pre-trained model and tokenizer are loaded from Hugging Face's model hub. The model is then moved to the designated device. If there's an issue loading either the model or the tokenizer, an error will be logged.</p>"},{"location":"swarms/models/hf/#generation","title":"Generation:","text":"<p>The main functionality of this class is text generation. The class provides two methods for this: <code>__call__</code> and <code>generate</code>. Both methods take in a prompt text and an optional <code>max_length</code> parameter and return the generated text.</p> <p>Usage: <pre><code>from swarms import HuggingFaceLLM\n\n# Initialize\nllm = HuggingFaceLLM(model_id=\"gpt2-medium\")\n\n# Generate text using __call__ method\nresult = llm(\"Once upon a time,\")\nprint(result)\n\n# Alternatively, using the generate method\nresult = llm.generate(\"The future of AI is\")\nprint(result)\n</code></pre></p>"},{"location":"swarms/models/hf/#mathematical-explanation","title":"Mathematical Explanation:","text":"<p>Given a sequence of tokens ( x_1, x_2, ..., x_n ), a causal language model aims to maximize the likelihood of the next token ( x_{n+1} ) in the sequence. Formally, it tries to optimize:</p> <p>[ P(x_{n+1} | x_1, x_2, ..., x_n) ]</p> <p>Where ( P ) is the probability distribution over all possible tokens in the vocabulary.</p> <p>The model takes the tokenized input sequence, feeds it through several transformer blocks, and finally through a linear layer to produce logits for each token in the vocabulary. The token with the highest logit value is typically chosen as the next token in the sequence.</p>"},{"location":"swarms/models/hf/#additional-information-tips","title":"Additional Information &amp; Tips:","text":"<ul> <li> <p>Ensure you have an active internet connection when initializing the class for the first time, as the models and tokenizers are fetched from Hugging Face's servers.</p> </li> <li> <p>Although the default <code>max_length</code> is set to 20, it's advisable to adjust this parameter based on the context of the problem.</p> </li> <li> <p>Keep an eye on GPU memory when using large models or generating long sequences.</p> </li> </ul>"},{"location":"swarms/models/hf/#references-resources","title":"References &amp; Resources:","text":"<ul> <li> <p>Hugging Face Model Hub: https://huggingface.co/models</p> </li> <li> <p>Introduction to Transformers: https://huggingface.co/transformers/introduction.html</p> </li> <li> <p>Causal Language Modeling: Vaswani, A., et al. (2017). Attention is All You Need. arXiv:1706.03762</p> </li> </ul> <p>Note: This documentation template provides a comprehensive overview of the <code>HuggingFaceLLM</code> class. Developers can follow similar structures when documenting other classes or functionalities.</p>"},{"location":"swarms/models/huggingface/","title":"HuggingFaceLLM","text":""},{"location":"swarms/models/huggingface/#huggingfacellm-documentation","title":"<code>HuggingfaceLLM</code> Documentation","text":""},{"location":"swarms/models/huggingface/#introduction","title":"Introduction","text":"<p>The <code>HuggingfaceLLM</code> class is designed for running inference using models from the Hugging Face Transformers library. This documentation provides an in-depth understanding of the class, its purpose, attributes, methods, and usage examples.</p>"},{"location":"swarms/models/huggingface/#purpose","title":"Purpose","text":"<p>The <code>HuggingfaceLLM</code> class serves the following purposes:</p> <ol> <li>Load pre-trained Hugging Face models and tokenizers.</li> <li>Generate text-based responses from the loaded model using a given prompt.</li> <li>Provide flexibility in device selection, quantization, and other configuration options.</li> </ol>"},{"location":"swarms/models/huggingface/#class-definition","title":"Class Definition","text":"<p>The <code>HuggingfaceLLM</code> class is defined as follows:</p> <pre><code>class HuggingfaceLLM:\n    def __init__(\n        self,\n        model_id: str,\n        device: str = None,\n        max_length: int = 20,\n        quantize: bool = False,\n        quantization_config: dict = None,\n        verbose=False,\n        distributed=False,\n        decoding=False,\n    ):\n        # Attributes and initialization logic explained below\n        pass\n\n    def load_model(self):\n        # Method to load the pre-trained model and tokenizer\n        pass\n\n    def run(self, prompt_text: str, max_length: int = None):\n        # Method to generate text-based responses\n        pass\n\n    def __call__(self, prompt_text: str, max_length: int = None):\n        # Alternate method for generating text-based responses\n        pass\n</code></pre>"},{"location":"swarms/models/huggingface/#attributes","title":"Attributes","text":"Attribute Description <code>model_id</code> The ID of the pre-trained model to be used. <code>device</code> The device on which the model runs (<code>'cuda'</code> for GPU or <code>'cpu'</code> for CPU). <code>max_length</code> The maximum length of the generated text. <code>quantize</code> A boolean indicating whether quantization should be used. <code>quantization_config</code> A dictionary with configuration options for quantization. <code>verbose</code> A boolean indicating whether verbose logs should be printed. <code>logger</code> An optional logger for logging messages (defaults to a basic logger). <code>distributed</code> A boolean indicating whether distributed processing should be used. <code>decoding</code> A boolean indicating whether to perform decoding during text generation."},{"location":"swarms/models/huggingface/#class-methods","title":"Class Methods","text":""},{"location":"swarms/models/huggingface/#__init__-method","title":"<code>__init__</code> Method","text":"<p>The <code>__init__</code> method initializes an instance of the <code>HuggingfaceLLM</code> class with the specified parameters. It also loads the pre-trained model and tokenizer.</p> <ul> <li><code>model_id</code> (str): The ID of the pre-trained model to use.</li> <li><code>device</code> (str, optional): The device to run the model on ('cuda' or 'cpu').</li> <li><code>max_length</code> (int, optional): The maximum length of the generated text.</li> <li><code>quantize</code> (bool, optional): Whether to use quantization.</li> <li><code>quantization_config</code> (dict, optional): Configuration for quantization.</li> <li><code>verbose</code> (bool, optional): Whether to print verbose logs.</li> <li><code>logger</code> (logging.Logger, optional): The logger to use.</li> <li><code>distributed</code> (bool, optional): Whether to use distributed processing.</li> <li><code>decoding</code> (bool, optional): Whether to perform decoding during text generation.</li> </ul>"},{"location":"swarms/models/huggingface/#load_model-method","title":"<code>load_model</code> Method","text":"<p>The <code>load_model</code> method loads the pre-trained model and tokenizer specified by <code>model_id</code>.</p>"},{"location":"swarms/models/huggingface/#run-and-__call__-methods","title":"<code>run</code> and <code>__call__</code> Methods","text":"<p>Both <code>run</code> and <code>__call__</code> methods generate text-based responses based on a given prompt. They accept the following parameters:</p> <ul> <li><code>prompt_text</code> (str): The text prompt to initiate text generation.</li> <li><code>max_length</code> (int, optional): The maximum length of the generated text.</li> </ul>"},{"location":"swarms/models/huggingface/#usage-examples","title":"Usage Examples","text":"<p>Here are three ways to use the <code>HuggingfaceLLM</code> class:</p>"},{"location":"swarms/models/huggingface/#example-1-basic-usage","title":"Example 1: Basic Usage","text":"<pre><code>from swarms.models import HuggingfaceLLM\n\n# Initialize the HuggingfaceLLM instance with a model ID\nmodel_id = \"NousResearch/Nous-Hermes-2-Vision-Alpha\"\ninference = HuggingfaceLLM(model_id=model_id)\n\n# Generate text based on a prompt\nprompt_text = \"Once upon a time\"\ngenerated_text = inference(prompt_text)\nprint(generated_text)\n</code></pre>"},{"location":"swarms/models/huggingface/#example-2-custom-configuration","title":"Example 2: Custom Configuration","text":"<pre><code>from swarms.models import HuggingfaceLLM\n\n# Initialize with custom configuration\ncustom_config = {\n    \"quantize\": True,\n    \"quantization_config\": {\"load_in_4bit\": True},\n    \"verbose\": True,\n}\ninference = HuggingfaceLLM(\n    model_id=\"NousResearch/Nous-Hermes-2-Vision-Alpha\", **custom_config\n)\n\n# Generate text based on a prompt\nprompt_text = \"Tell me a joke\"\ngenerated_text = inference(prompt_text)\nprint(generated_text)\n</code></pre>"},{"location":"swarms/models/huggingface/#example-3-distributed-processing","title":"Example 3: Distributed Processing","text":"<pre><code>from swarms.models import HuggingfaceLLM\n\n# Initialize for distributed processing\ninference = HuggingfaceLLM(model_id=\"gpt2-medium\", distributed=True)\n\n# Generate text based on a prompt\nprompt_text = \"Translate the following sentence to French\"\ngenerated_text = inference(prompt_text)\nprint(generated_text)\n</code></pre>"},{"location":"swarms/models/huggingface/#additional-information","title":"Additional Information","text":"<ul> <li>The <code>HuggingfaceLLM</code> class provides the flexibility to load and use pre-trained models from the Hugging Face Transformers library.</li> <li>Quantization can be enabled to reduce model size and inference time.</li> <li>Distributed processing can be used for parallelized inference.</li> <li>Verbose logging can help in debugging and understanding the text generation process.</li> </ul>"},{"location":"swarms/models/huggingface/#references","title":"References","text":"<ul> <li>Hugging Face Transformers Documentation</li> <li>PyTorch Documentation</li> </ul> <p>This documentation provides a comprehensive understanding of the <code>HuggingfaceLLM</code> class, its attributes, methods, and usage examples. Developers can use this class to perform text generation tasks efficiently using pre-trained models from the Hugging Face Transformers library.</p>"},{"location":"swarms/models/idefics/","title":"<code>Idefics</code> Documentation","text":""},{"location":"swarms/models/idefics/#introduction","title":"Introduction","text":"<p>Welcome to the documentation for Idefics, a versatile multimodal inference tool using pre-trained models from the Hugging Face Hub. Idefics is designed to facilitate the generation of text from various prompts, including text and images. This documentation provides a comprehensive understanding of Idefics, its architecture, usage, and how it can be integrated into your projects.</p>"},{"location":"swarms/models/idefics/#overview","title":"Overview","text":"<p>Idefics leverages the power of pre-trained models to generate textual responses based on a wide range of prompts. It is capable of handling both text and images, making it suitable for various multimodal tasks, including text generation from images.</p>"},{"location":"swarms/models/idefics/#class-definition","title":"Class Definition","text":"<pre><code>class Idefics:\n    def __init__(\n        self,\n        checkpoint=\"HuggingFaceM4/idefics-9b-instruct\",\n        device=None,\n        torch_dtype=torch.bfloat16,\n        max_length=100,\n    ):\n</code></pre>"},{"location":"swarms/models/idefics/#usage","title":"Usage","text":"<p>To use Idefics, follow these steps:</p> <ol> <li>Initialize the Idefics instance:</li> </ol> <pre><code>from swarms.models import Idefics\n\nmodel = Idefics()\n</code></pre> <ol> <li>Generate text based on prompts:</li> </ol> <pre><code>prompts = [\n    \"User: What is in this image? https://upload.wikimedia.org/wikipedia/commons/8/86/Id%C3%A9fix.JPG\"\n]\nresponse = model(prompts)\nprint(response)\n</code></pre>"},{"location":"swarms/models/idefics/#example-1-image-questioning","title":"Example 1 - Image Questioning","text":"<pre><code>from swarms.models import Idefics\n\nmodel = Idefics()\nprompts = [\n    \"User: What is in this image? https://upload.wikimedia.org/wikipedia/commons/8/86/Id%C3%A9fix.JPG\"\n]\nresponse = model(prompts)\nprint(response)\n</code></pre>"},{"location":"swarms/models/idefics/#example-2-bidirectional-conversation","title":"Example 2 - Bidirectional Conversation","text":"<pre><code>from swarms.models import Idefics\n\nmodel = Idefics()\nuser_input = \"User: What is in this image? https://upload.wikimedia.org/wikipedia/commons/8/86/Id%C3%A9fix.JPG\"\nresponse = model.chat(user_input)\nprint(response)\n\nuser_input = \"User: Who is that? https://static.wikia.nocookie.net/asterix/images/2/25/R22b.gif/revision/latest?cb=20110815073052\"\nresponse = model.chat(user_input)\nprint(response)\n</code></pre>"},{"location":"swarms/models/idefics/#example-3-configuration-changes","title":"Example 3 - Configuration Changes","text":"<pre><code>model.set_checkpoint(\"new_checkpoint\")\nmodel.set_device(\"cpu\")\nmodel.set_max_length(200)\nmodel.clear_chat_history()\n</code></pre>"},{"location":"swarms/models/idefics/#how-idefics-works","title":"How Idefics Works","text":"<p>Idefics operates by leveraging pre-trained models from the Hugging Face Hub. Here's how it works:</p> <ol> <li> <p>Initialization: When you create an Idefics instance, it initializes the model using a specified checkpoint, sets the device for inference, and configures other parameters like data type and maximum text length.</p> </li> <li> <p>Prompt-Based Inference: You can use the <code>infer</code> method to generate text based on prompts. It processes prompts in batched or non-batched mode, depending on your preference. It uses a pre-trained processor to handle text and images.</p> </li> <li> <p>Bidirectional Conversation: The <code>chat</code> method enables bidirectional conversations. You provide user input, and the model responds accordingly. The chat history is maintained for context.</p> </li> <li> <p>Configuration Changes: You can change the model checkpoint, device, maximum text length, or clear the chat history as needed during runtime.</p> </li> </ol>"},{"location":"swarms/models/idefics/#parameters","title":"Parameters","text":"<ul> <li><code>checkpoint</code>: The name of the pre-trained model checkpoint (default is \"HuggingFaceM4/idefics-9b-instruct\").</li> <li><code>device</code>: The device to use for inference. By default, it uses CUDA if available; otherwise, it uses CPU.</li> <li><code>torch_dtype</code>: The data type to use for inference. By default, it uses torch.bfloat16.</li> <li><code>max_length</code>: The maximum length of the generated text (default is 100).</li> </ul>"},{"location":"swarms/models/idefics/#additional-information","title":"Additional Information","text":"<ul> <li>Idefics provides a convenient way to engage in bidirectional conversations with pre-trained models.</li> <li>You can easily change the model checkpoint, device, and other settings to adapt to your specific use case.</li> </ul> <p>That concludes the documentation for Idefics. We hope you find this tool valuable for your multimodal text generation tasks. If you have any questions or encounter any issues, please refer to the Hugging Face Transformers documentation for further assistance. Enjoy working with Idefics!</p>"},{"location":"swarms/models/kosmos/","title":"<code>Kosmos</code> Documentation","text":""},{"location":"swarms/models/kosmos/#introduction","title":"Introduction","text":"<p>Welcome to the documentation for Kosmos, a powerful multimodal AI model that can perform various tasks, including multimodal grounding, referring expression comprehension, referring expression generation, grounded visual question answering (VQA), and grounded image captioning. Kosmos is based on the ydshieh/kosmos-2-patch14-224 model and is designed to process both text and images to provide meaningful outputs. In this documentation, you will find a detailed explanation of the Kosmos class, its functions, parameters, and usage examples.</p>"},{"location":"swarms/models/kosmos/#overview","title":"Overview","text":"<p>Kosmos is a state-of-the-art multimodal AI model that combines the power of natural language understanding with image analysis. It can perform several tasks that involve processing both textual prompts and images to provide informative responses. Whether you need to find objects in an image, understand referring expressions, generate descriptions, answer questions, or create captions, Kosmos has you covered.</p>"},{"location":"swarms/models/kosmos/#class-definition","title":"Class Definition","text":"<pre><code>class Kosmos:\n    def __init__(self, model_name=\"ydshieh/kosmos-2-patch14-224\"):\n</code></pre>"},{"location":"swarms/models/kosmos/#usage","title":"Usage","text":"<p>To use Kosmos, follow these steps:</p> <ol> <li>Initialize the Kosmos instance:</li> </ol> <pre><code>from swarms.models.kosmos_two import Kosmos\n\nkosmos = Kosmos()\n</code></pre> <ol> <li>Perform Multimodal Grounding:</li> </ol> <pre><code>kosmos.multimodal_grounding(\n    \"Find the red apple in the image.\", \"https://example.com/apple.jpg\"\n)\n</code></pre>"},{"location":"swarms/models/kosmos/#example-1-multimodal-grounding","title":"Example 1 - Multimodal Grounding","text":"<pre><code>from swarms.models.kosmos_two import Kosmos\n\nkosmos = Kosmos()\n\nkosmos.multimodal_grounding(\n    \"Find the red apple in the image.\", \"https://example.com/apple.jpg\"\n)\n</code></pre> <ol> <li>Perform Referring Expression Comprehension:</li> </ol> <pre><code>kosmos.referring_expression_comprehension(\n    \"Show me the green bottle.\", \"https://example.com/bottle.jpg\"\n)\n</code></pre>"},{"location":"swarms/models/kosmos/#example-2-referring-expression-comprehension","title":"Example 2 - Referring Expression Comprehension","text":"<pre><code>from swarms.models.kosmos_two import Kosmos\n\nkosmos = Kosmos()\n\nkosmos.referring_expression_comprehension(\n    \"Show me the green bottle.\", \"https://example.com/bottle.jpg\"\n)\n</code></pre> <ol> <li>Generate Referring Expressions:</li> </ol> <pre><code>kosmos.referring_expression_generation(\n    \"It is on the table.\", \"https://example.com/table.jpg\"\n)\n</code></pre>"},{"location":"swarms/models/kosmos/#example-3-referring-expression-generation","title":"Example 3 - Referring Expression Generation","text":"<pre><code>from swarms.models.kosmos_two import Kosmos\n\nkosmos = Kosmos()\n\nkosmos.referring_expression_generation(\n    \"It is on the table.\", \"https://example.com/table.jpg\"\n)\n</code></pre> <ol> <li>Perform Grounded Visual Question Answering (VQA):</li> </ol> <pre><code>kosmos.grounded_vqa(\"What is the color of the car?\", \"https://example.com/car.jpg\")\n</code></pre>"},{"location":"swarms/models/kosmos/#example-4-grounded-visual-question-answering","title":"Example 4 - Grounded Visual Question Answering","text":"<pre><code>from swarms.models.kosmos_two import Kosmos\n\nkosmos = Kosmos()\n\nkosmos.grounded_vqa(\"What is the color of the car?\", \"https://example.com/car.jpg\")\n</code></pre> <ol> <li>Generate Grounded Image Captions:</li> </ol> <pre><code>kosmos.grounded_image_captioning(\"https://example.com/beach.jpg\")\n</code></pre>"},{"location":"swarms/models/kosmos/#example-5-grounded-image-captioning","title":"Example 5 - Grounded Image Captioning","text":"<pre><code>from swarms.models.kosmos_two import Kosmos\n\nkosmos = Kosmos()\n\nkosmos.grounded_image_captioning(\"https://example.com/beach.jpg\")\n</code></pre> <ol> <li>Generate Detailed Grounded Image Captions:</li> </ol> <pre><code>kosmos.grounded_image_captioning_detailed(\"https://example.com/beach.jpg\")\n</code></pre>"},{"location":"swarms/models/kosmos/#example-6-detailed-grounded-image-captioning","title":"Example 6 - Detailed Grounded Image Captioning","text":"<pre><code>from swarms.models.kosmos_two import Kosmos\n\nkosmos = Kosmos()\n\nkosmos.grounded_image_captioning_detailed(\"https://example.com/beach.jpg\")\n</code></pre> <ol> <li>Draw Entity Boxes on Image:</li> </ol> <pre><code>image = kosmos.get_image(\"https://example.com/image.jpg\")\nentities = [\n    (\"apple\", (0, 3), [(0.2, 0.3, 0.4, 0.5)]),\n    (\"banana\", (4, 9), [(0.6, 0.2, 0.8, 0.4)]),\n]\nkosmos.draw_entity_boxes_on_image(image, entities, show=True)\n</code></pre>"},{"location":"swarms/models/kosmos/#example-7-drawing-entity-boxes-on-image","title":"Example 7 - Drawing Entity Boxes on Image","text":"<pre><code>from swarms.models.kosmos_two import Kosmos\n\nkosmos = Kosmos()\n\nimage = kosmos.get_image(\"https://example.com/image.jpg\")\nentities = [\n    (\"apple\", (0, 3), [(0.2, 0.3, 0.4, 0.5)]),\n    (\"banana\", (4, 9), [(0.6, 0.2, 0.8, 0.4)]),\n]\nkosmos.draw_entity_boxes_on_image(image, entities, show=True)\n</code></pre> <ol> <li>Generate Boxes for Entities:</li> </ol> <pre><code>entities = [\n    (\"apple\", (0, 3), [(0.2, 0.3, 0.4, 0.5)]),\n    (\"banana\", (4, 9), [(0.6, 0.2, 0.8, 0.4)]),\n]\nimage = kosmos.generate_boxes(\n    \"Find the apple and the banana in the image.\", \"https://example.com/image.jpg\"\n)\n</code></pre>"},{"location":"swarms/models/kosmos/#example-8-generating-boxes-for-entities","title":"Example 8 - Generating Boxes for Entities","text":"<pre><code>from swarms.models.kosmos_two import Kosmos\n\nkosmos = Kosmos()\nentities = [\n    (\"apple\", (0, 3), [(0.2, 0.3, 0.4, 0.5)]),\n    (\"banana\", (4, 9), [(0.6, 0.2, 0.8, 0.4)]),\n]\nimage = kosmos.generate_boxes(\n    \"Find the apple and the banana in the image.\", \"https://example.com/image.jpg\"\n)\n</code></pre>"},{"location":"swarms/models/kosmos/#how-kosmos-works","title":"How Kosmos Works","text":"<p>Kosmos is a multimodal AI model that combines text and image processing. It uses the ydshieh/kosmos-2-patch14-224 model for understanding and generating responses. Here's how it works:</p> <ol> <li> <p>Initialization: When you create a Kosmos instance, it loads the ydshieh/kosmos-2-patch14-224 model for multimodal tasks.</p> </li> <li> <p>Processing Text and Images: Kosmos can process both text prompts and images. It takes a textual prompt and an image URL as input.</p> </li> <li> <p>Task Execution: Based on the task you specify, Kosmos generates informative responses by combining natural language understanding with image analysis.</p> </li> <li> <p>Drawing Entity Boxes: You can use the <code>draw_entity_boxes_on_image</code> method to draw bounding boxes around entities in an image.</p> </li> <li> <p>Generating Boxes for Entities: The <code>generate_boxes</code> method allows you to generate bounding boxes for entities mentioned in a prompt.</p> </li> </ol>"},{"location":"swarms/models/kosmos/#parameters","title":"Parameters","text":"<ul> <li><code>model_name</code>: The name or path of the Kosmos model to be used. By default, it uses the ydshieh/kosmos-2-patch14-224 model.</li> </ul>"},{"location":"swarms/models/kosmos/#additional-information","title":"Additional Information","text":"<ul> <li>Kosmos can handle various multimodal tasks, making it a versatile tool for understanding and generating content.</li> <li>You can provide image URLs for image-based tasks, and Kosmos will automatically retrieve and process the images.</li> <li>The <code>draw_entity_boxes_on_image</code> method is useful for visualizing the results of multimodal grounding tasks.</li> <li>The <code>generate_boxes</code> method is handy for generating bounding boxes around entities mentioned in a textual prompt.</li> </ul> <p>That concludes the documentation for Kosmos. We hope you find this multimodal AI model valuable for your projects. If you have any questions or encounter any issues, please refer to the Kosmos documentation for further assistance. Enjoy working with Kosmos!</p>"},{"location":"swarms/models/layoutlm_document_qa/","title":"<code>LayoutLMDocumentQA</code> Documentation","text":""},{"location":"swarms/models/layoutlm_document_qa/#introduction","title":"Introduction","text":"<p>Welcome to the documentation for LayoutLMDocumentQA, a multimodal model designed for visual question answering (QA) on real-world documents, such as invoices, PDFs, and more. This comprehensive documentation will provide you with a deep understanding of the LayoutLMDocumentQA class, its architecture, usage, and examples.</p>"},{"location":"swarms/models/layoutlm_document_qa/#overview","title":"Overview","text":"<p>LayoutLMDocumentQA is a versatile model that combines layout-based understanding of documents with natural language processing to answer questions about the content of documents. It is particularly useful for automating tasks like invoice processing, extracting information from PDFs, and handling various document-based QA scenarios.</p>"},{"location":"swarms/models/layoutlm_document_qa/#class-definition","title":"Class Definition","text":"<pre><code>class LayoutLMDocumentQA(AbstractModel):\n    def __init__(\n        self, \n        model_name: str = \"impira/layoutlm-document-qa\",\n        task: str = \"document-question-answering\",\n    ):\n</code></pre>"},{"location":"swarms/models/layoutlm_document_qa/#purpose","title":"Purpose","text":"<p>The LayoutLMDocumentQA class serves the following primary purposes:</p> <ol> <li> <p>Document QA: LayoutLMDocumentQA is specifically designed for document-based question answering. It can process both the textual content and the layout of a document to answer questions.</p> </li> <li> <p>Multimodal Understanding: It combines natural language understanding with document layout analysis, making it suitable for documents with complex structures.</p> </li> </ol>"},{"location":"swarms/models/layoutlm_document_qa/#parameters","title":"Parameters","text":"<ul> <li><code>model_name</code> (str): The name or path of the pretrained LayoutLMDocumentQA model. Default: \"impira/layoutlm-document-qa\".</li> <li><code>task</code> (str): The specific task for which the model will be used. Default: \"document-question-answering\".</li> </ul>"},{"location":"swarms/models/layoutlm_document_qa/#usage","title":"Usage","text":"<p>To use LayoutLMDocumentQA, follow these steps:</p> <ol> <li>Initialize the LayoutLMDocumentQA instance:</li> </ol> <pre><code>from swarms.models import LayoutLMDocumentQA\n\nlayout_lm_doc_qa = LayoutLMDocumentQA()\n</code></pre>"},{"location":"swarms/models/layoutlm_document_qa/#example-1-initialization","title":"Example 1 - Initialization","text":"<pre><code>layout_lm_doc_qa = LayoutLMDocumentQA()\n</code></pre> <ol> <li>Ask a question about a document and provide the document's image path:</li> </ol> <pre><code>question = \"What is the total amount?\"\nimage_path = \"path/to/document_image.png\"\nanswer = layout_lm_doc_qa(question, image_path)\n</code></pre>"},{"location":"swarms/models/layoutlm_document_qa/#example-2-document-qa","title":"Example 2 - Document QA","text":"<pre><code>layout_lm_doc_qa = LayoutLMDocumentQA()\nquestion = \"What is the total amount?\"\nimage_path = \"path/to/document_image.png\"\nanswer = layout_lm_doc_qa(question, image_path)\n</code></pre>"},{"location":"swarms/models/layoutlm_document_qa/#how-layoutlmdocumentqa-works","title":"How LayoutLMDocumentQA Works","text":"<p>LayoutLMDocumentQA employs a multimodal approach to document QA. Here's how it works:</p> <ol> <li> <p>Initialization: When you create a LayoutLMDocumentQA instance, you can specify the model to use and the task, which is \"document-question-answering\" by default.</p> </li> <li> <p>Question and Document: You provide a question about the document and the image path of the document to the LayoutLMDocumentQA instance.</p> </li> <li> <p>Multimodal Processing: LayoutLMDocumentQA processes both the question and the document image. It combines layout-based analysis with natural language understanding.</p> </li> <li> <p>Answer Generation: The model generates an answer to the question based on its analysis of the document layout and content.</p> </li> </ol>"},{"location":"swarms/models/layoutlm_document_qa/#additional-information","title":"Additional Information","text":"<ul> <li>LayoutLMDocumentQA uses the \"impira/layoutlm-document-qa\" pretrained model, which is specifically designed for document-based question answering.</li> <li>You can adapt this model to various document QA scenarios by changing the task and providing relevant questions and documents.</li> <li>This model is particularly useful for automating document-based tasks and extracting valuable information from structured documents.</li> </ul> <p>That concludes the documentation for LayoutLMDocumentQA. We hope you find this tool valuable for your document-based question answering needs. If you have any questions or encounter any issues, please refer to the LayoutLMDocumentQA documentation for further assistance. Enjoy using LayoutLMDocumentQA!</p>"},{"location":"swarms/models/mistral/","title":"<code>Mistral</code> Documentation","text":""},{"location":"swarms/models/mistral/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction</li> <li>Overview</li> <li>Class Definition</li> <li>Mistral Class</li> <li>Initialization Parameters</li> <li>Functionality and Usage</li> <li>Loading the Model</li> <li>Running the Model</li> <li>Chatting with the Agent</li> <li>Additional Information</li> <li>Examples</li> <li>Example 1: Initializing Mistral</li> <li>Example 2: Running a Task</li> <li>Example 3: Chatting with the Agent</li> <li>References and Resources</li> </ol>"},{"location":"swarms/models/mistral/#1-introduction","title":"1. Introduction","text":"<p>Welcome to the documentation for Mistral, a powerful language model-based AI agent. Mistral leverages the capabilities of large language models to generate text-based responses to queries and tasks. This documentation provides a comprehensive guide to understanding and using the Mistral AI agent.</p>"},{"location":"swarms/models/mistral/#11-purpose","title":"1.1 Purpose","text":"<p>Mistral is designed to assist users by generating coherent and contextually relevant text based on user inputs or tasks. It can be used for various natural language understanding and generation tasks, such as chatbots, text completion, question answering, and content generation.</p>"},{"location":"swarms/models/mistral/#12-key-features","title":"1.2 Key Features","text":"<ul> <li>Utilizes large pre-trained language models.</li> <li>Supports GPU acceleration for faster processing.</li> <li>Provides an easy-to-use interface for running tasks and engaging in chat-based conversations.</li> <li>Offers fine-grained control over response generation through temperature and maximum length settings.</li> </ul>"},{"location":"swarms/models/mistral/#2-overview","title":"2. Overview","text":"<p>Before diving into the details of the Mistral AI agent, let's provide an overview of its purpose and functionality.</p> <p>Mistral is built on top of powerful language models, such as GPT-3. It allows you to:</p> <ul> <li>Generate text-based responses to tasks and queries.</li> <li>Control the temperature of response generation for creativity.</li> <li>Set a maximum length for generated responses.</li> <li>Engage in chat-based conversations with the AI agent.</li> <li>Utilize GPU acceleration for faster inference.</li> </ul> <p>In the following sections, we will explore the class definition, its initialization parameters, and how to use Mistral effectively.</p>"},{"location":"swarms/models/mistral/#3-class-definition","title":"3. Class Definition","text":"<p>Mistral consists of a single class, the <code>Mistral</code> class. This class provides methods for initializing the agent, loading the pre-trained model, and running tasks.</p>"},{"location":"swarms/models/mistral/#31-mistral-class","title":"3.1 Mistral Class","text":"<pre><code>class Mistral:\n    \"\"\"\n    Mistral\n\n    model = Mistral(device=\"cuda\", use_flash_attention=True, temperature=0.7, max_length=200)\n    task = \"My favorite condiment is\"\n    result = model.run(task)\n    print(result)\n    \"\"\"\n\n    def __init__(\n        self,\n        ai_name: str = \"Node Model Agent\",\n        system_prompt: str = None,\n        model_name: str = \"mistralai/Mistral-7B-v0.1\",\n        device: str = \"cuda\",\n        use_flash_attention: bool = False,\n        temperature: float = 1.0,\n        max_length: int = 100,\n        do_sample: bool = True,\n    ):\n        \"\"\"\n        Initializes the Mistral AI agent.\n\n        Parameters:\n        - ai_name (str): The name or identifier of the AI agent. Default: \"Node Model Agent\".\n        - system_prompt (str): A system-level prompt for context (e.g., conversation history). Default: None.\n        - model_name (str): The name of the pre-trained language model to use. Default: \"mistralai/Mistral-7B-v0.1\".\n        - device (str): The device for model inference, such as \"cuda\" or \"cpu\". Default: \"cuda\".\n        - use_flash_attention (bool): If True, enables flash attention for faster inference. Default: False.\n        - temperature (float): A value controlling the creativity of generated text. Default: 1.0.\n        - max_length (int): The maximum length of generated text. Default: 100.\n        - do_sample (bool): If True, uses sampling for text generation. Default: True.\n        \"\"\"\n</code></pre>"},{"location":"swarms/models/mistral/#32-initialization-parameters","title":"3.2 Initialization Parameters","text":"<ul> <li> <p><code>ai_name</code> (str): The name or identifier of the AI agent. This name can be used to distinguish between different agents if multiple instances are used. The default value is \"Node Model Agent\".</p> </li> <li> <p><code>system_prompt</code> (str): A system-level prompt that provides context for the AI agent. This can be useful for maintaining a conversation history or providing context for the current task. By default, it is set to <code>None</code>.</p> </li> <li> <p><code>model_name</code> (str): The name of the pre-trained language model to use. The default value is \"mistralai/Mistral-7B-v0.1\", which points to a specific version of the Mistral model.</p> </li> <li> <p><code>device</code> (str): The device on which the model should perform inference. You can specify \"cuda\" for GPU acceleration or \"cpu\" for CPU-only inference. The default is \"cuda\", assuming GPU availability.</p> </li> <li> <p><code>use_flash_attention</code> (bool): If set to <code>True</code>, Mistral uses flash attention for faster inference. This is beneficial when low-latency responses are required. The default is <code>False</code>.</p> </li> <li> <p><code>temperature</code> (float): The temperature parameter controls the creativity of the generated text. Higher values (e.g., 1.0) produce more random output, while lower values (e.g., 0.7) make the output more focused and deterministic. The default value is 1.0.</p> </li> <li> <p><code>max_length</code> (int): This parameter sets the maximum length of the generated text. It helps control the length of responses. The default value is 100.</p> </li> <li> <p><code>do_sample</code> (bool): If set to <code>True</code>, Mistral uses sampling during text generation. Sampling introduces randomness into the generated text. The default is <code>True</code>.</p> </li> </ul>"},{"location":"swarms/models/mistral/#4-functionality-and-usage","title":"4. Functionality and Usage","text":"<p>Now that we've introduced the Mistral class and its parameters, let's explore how to use Mistral for various tasks.</p>"},{"location":"swarms/models/mistral/#41-loading-the-model","title":"4.1 Loading the Model","text":"<p>The <code>Mistral</code> class handles the loading of the pre-trained language model during initialization. You do not need to explicitly load the model. Simply create an instance of <code>Mistral</code>, and it will take care of loading the model into memory.</p>"},{"location":"swarms/models/mistral/#42-running-the-model","title":"4.2 Running the Model","text":"<p>Mistral provides two methods for running the model:</p>"},{"location":"swarms/models/mistral/#421-run-method","title":"4.2.1 <code>run</code> Method","text":"<p>The <code>run</code> method is used to generate text-based responses to a given task or input. It takes a single string parameter, <code>task</code>, and returns the generated text as a string.</p> <pre><code>def run(self, task: str) -&gt; str:\n    \"\"\"\n    Run the model on a given task.\n\n    Parameters:\n    - task (str): The task or query for which to generate a response.\n\n    Returns:\n    - str: The generated text response.\n    \"\"\"\n</code></pre> <p>Example:</p> <pre><code>from swarms.models import Mistral\n\nmodel = Mistral()\ntask = \"Translate the following English text to French: 'Hello, how are you?'\"\nresult = model.run(task)\nprint(result)\n</code></pre>"},{"location":"swarms/models/mistral/#422-__call__-method","title":"4.2.2 <code>__call__</code> Method","text":"<p>The <code>__call__</code> method provides a more concise way to run the model on a given task. You can use it by simply calling the <code>Mistral</code> instance with a task string.</p> <p>Example:</p> <pre><code>model = Mistral()\ntask = \"Generate a summary of the latest research paper on AI ethics.\"\nresult = model(task)\nprint(result)\n</code></pre>"},{"location":"swarms/models/mistral/#43-chatting-with-the-agent","title":"4.3 Chatting with the Agent","text":"<p>Mistral supports chat-based interactions with the AI agent. You can send a series of messages to the agent, and it will respond accordingly. The <code>chat</code> method handles these interactions.</p>"},{"location":"swarms/models/mistral/#chat-method","title":"<code>chat</code> Method","text":"<p>The <code>chat</code> method allows you to engage in chat-based conversations with the AI agent. You can send messages to the agent, and it will respond with text-based messages.</p> <pre><code>def chat(self, msg: str = None, streaming: bool = False) -&gt; str:\n    \"\"\"\n    Run a chat conversation with the agent.\n\n    Parameters:\n    - msg (str, optional): The message to send to the agent. Defaults to None.\n    - streaming (bool, optional): Whether to stream the response token by token. Defaults to False.\n\n    Returns:\n    - str: The response from the agent.\n    \"\"\"\n</code></pre> <p>Example:</p> <pre><code>model = Mistral()\nconversation = [\n    \"Tell me a joke.\",\n    \"What's the weather like today?\",\n    \"Translate 'apple' to Spanish.\",\n]\nfor user_message in conversation:\n    response = model.chat(user_message)\n    print(f\"User: {user_message}\")\n    print(f\"Agent: {response}\")\n</code></pre>"},{"location":"swarms/models/mistral/#5-additional-information","title":"5. Additional Information","text":"<p>Here are some additional tips and information for using Mistral effectively:</p> <ul> <li> <p>Mistral uses a specific pre-trained model (\"mistralai/Mistral-7B-v0.1\" by default). You can explore other available models and choose one that best suits your task.</p> </li> <li> <p>The <code>temperature</code> parameter controls the randomness of generated text. Experiment with different values to achieve the desired level of creativity in responses.</p> </li> <li> <p>Be cautious with <code>max_length</code>, especially if you set it to a very high value, as it may lead to excessively long responses.</p> </li> <li> <p>Ensure that you have the required libraries, such as <code>torch</code> and <code>transformers</code>, installed to use Mistral successfully.</p> </li> <li> <p>Consider providing a system-level prompt when engaging in chat-based conversations to provide context for the agent.</p> </li> </ul>"},{"location":"swarms/models/mistral/#6-examples","title":"6. Examples","text":"<p>In this section, we provide practical examples to illustrate how to use Mistral for various tasks.</p>"},{"location":"swarms/models/mistral/#61-example-1-initializing-mistral","title":"6.1 Example 1: Initializing Mistral","text":"<p>In this example, we initialize the Mistral AI agent with custom settings:</p> <pre><code>from swarms.models import Mistral\n\nmodel = Mistral(\n    ai_name=\"My AI Assistant\",\n    device=\"cpu\",\n    temperature=0.8,\n    max_length=150,\n)\n</code></pre>"},{"location":"swarms/models/mistral/#62-example-2-running-a-task","title":"6.2 Example 2: Running a Task","text":"<p>Here, we run a text generation task using Mistral:</p> <pre><code>model = Mistral()\ntask = \"Summarize the main findings of the recent climate change report.\"\nresult = model.run(task)\nprint(result)\n</code></pre>"},{"location":"swarms/models/mistral/#63-example-3-chatting-with-the-agent","title":"6.3 Example 3: Chatting with the Agent","text":"<p>Engage in a chat-based conversation with Mistral:</p> <pre><code>model = Mistral()\nconversation = [\n    \"Tell me a joke.\",\n    \"What's the latest news?\",\n    \"Translate 'cat' to French.\",\n]\nfor user_message in conversation:\n    response = model.chat(user_message)\n    print(f\"User: {user_message}\")\n    print(f\"Agent: {response}\")\n</code></pre>"},{"location":"swarms/models/mistral/#7-references-and-resources","title":"7. References and Resources","text":"<p>Here are some references and resources for further information on Mistral and related topics:</p> <ul> <li>Mistral GitHub Repository: Official Mistral repository for updates and contributions.</li> <li>Hugging Face Transformers: Documentation and models for various transformers, including Mistral's parent models.</li> <li>PyTorch Official Website: Official website for PyTorch, the deep learning framework used in Mistral.</li> </ul> <p>This concludes the documentation for the Mistral AI agent. You now have a comprehensive understanding of how to use Mistral for text generation and chat-based interactions. If you have any further questions or need assistance, please refer to the provided references and resources. Happy AI modeling!</p>"},{"location":"swarms/models/mixtral/","title":"Module Name: Mixtral","text":""},{"location":"swarms/models/mixtral/#introduction","title":"Introduction","text":"<p>The Mixtral module is a powerful language model designed for text generation tasks. It leverages the MistralAI Mixtral-8x7B pre-trained model to generate high-quality text based on user-defined tasks or prompts. In this documentation, we will provide a comprehensive overview of the Mixtral module, including its architecture, purpose, arguments, and detailed usage examples.</p>"},{"location":"swarms/models/mixtral/#purpose","title":"Purpose","text":"<p>The Mixtral module is designed to facilitate text generation tasks using state-of-the-art language models. Whether you need to generate creative content, draft text for various applications, or simply explore the capabilities of Mixtral, this module serves as a versatile and efficient solution. With its easy-to-use interface, you can quickly generate text for a wide range of applications.</p>"},{"location":"swarms/models/mixtral/#architecture","title":"Architecture","text":"<p>The Mixtral module is built on top of the MistralAI Mixtral-8x7B pre-trained model. It utilizes a deep neural network architecture with 8 layers and 7 attention heads to generate coherent and contextually relevant text. The model is capable of handling a variety of text generation tasks, from simple prompts to more complex content generation.</p>"},{"location":"swarms/models/mixtral/#class-definition","title":"Class Definition","text":""},{"location":"swarms/models/mixtral/#mixtralmodel_name-str-mistralaimixtral-8x7b-v01-max_new_tokens-int-500","title":"<code>Mixtral(model_name: str = \"mistralai/Mixtral-8x7B-v0.1\", max_new_tokens: int = 500)</code>","text":""},{"location":"swarms/models/mixtral/#parameters","title":"Parameters","text":"<ul> <li><code>model_name</code> (str, optional): The name or path of the pre-trained Mixtral model. Default is \"mistralai/Mixtral-8x7B-v0.1\".</li> <li><code>max_new_tokens</code> (int, optional): The maximum number of new tokens to generate. Default is 500.</li> </ul>"},{"location":"swarms/models/mixtral/#functionality-and-usage","title":"Functionality and Usage","text":"<p>The Mixtral module offers a straightforward interface for text generation. It accepts a task or prompt as input and returns generated text based on the provided input.</p>"},{"location":"swarms/models/mixtral/#runtask-optionalstr-none-kwargs-str","title":"<code>run(task: Optional[str] = None, **kwargs) -&gt; str</code>","text":""},{"location":"swarms/models/mixtral/#parameters_1","title":"Parameters","text":"<ul> <li><code>task</code> (str, optional): The task or prompt for text generation.</li> </ul>"},{"location":"swarms/models/mixtral/#returns","title":"Returns","text":"<ul> <li><code>str</code>: The generated text.</li> </ul>"},{"location":"swarms/models/mixtral/#usage-examples","title":"Usage Examples","text":""},{"location":"swarms/models/mixtral/#example-1-basic-usage","title":"Example 1: Basic Usage","text":"<pre><code>from swarms.models import Mixtral\n\n# Initialize the Mixtral model\nmixtral = Mixtral()\n\n# Generate text for a simple task\ngenerated_text = mixtral.run(\"Generate a creative story.\")\nprint(generated_text)\n</code></pre>"},{"location":"swarms/models/mixtral/#example-2-custom-model","title":"Example 2: Custom Model","text":"<p>You can specify a custom pre-trained model by providing the <code>model_name</code> parameter.</p> <pre><code>custom_model_name = \"model_name\"\nmixtral_custom = Mixtral(model_name=custom_model_name)\n\ngenerated_text = mixtral_custom.run(\"Generate text with a custom model.\")\nprint(generated_text)\n</code></pre>"},{"location":"swarms/models/mixtral/#example-3-controlling-output-length","title":"Example 3: Controlling Output Length","text":"<p>You can control the length of the generated text by adjusting the <code>max_new_tokens</code> parameter.</p> <pre><code>mixtral_length = Mixtral(max_new_tokens=100)\n\ngenerated_text = mixtral_length.run(\"Generate a short text.\")\nprint(generated_text)\n</code></pre>"},{"location":"swarms/models/mixtral/#additional-information-and-tips","title":"Additional Information and Tips","text":"<ul> <li>It's recommended to use a descriptive task or prompt to guide the text generation process.</li> <li>Experiment with different prompt styles and lengths to achieve the desired output.</li> <li>You can fine-tune Mixtral on specific tasks if needed, although pre-trained models often work well out of the box.</li> <li>Monitor the <code>max_new_tokens</code> parameter to control the length of the generated text.</li> </ul>"},{"location":"swarms/models/mixtral/#conclusion","title":"Conclusion","text":"<p>The Mixtral module is a versatile tool for text generation tasks, powered by the MistralAI Mixtral-8x7B pre-trained model. Whether you need creative writing, content generation, or assistance with text-based tasks, Mixtral can help you achieve your goals. With a simple interface and flexible parameters, it's a valuable addition to your text generation toolkit.</p> <p>If you encounter any issues or have questions about using Mixtral, please refer to the MistralAI documentation or reach out to their support team for further assistance. Happy text generation with Mixtral!</p>"},{"location":"swarms/models/mpt/","title":"<code>MPT7B</code>","text":"<p>==============================================</p> <p>The\u00a0<code>MPT7B</code>\u00a0class is a powerful tool for generating text using pre-trained models. It leverages the\u00a0<code>transformers</code>\u00a0library from Hugging Face to load models and tokenizers, and to perform the text generation. The class is designed to be flexible and easy to use, with a variety of methods for generating text both synchronously and asynchronously.</p>"},{"location":"swarms/models/mpt/#class-definition","title":"Class Definition","text":"<pre><code>class MPT7B:\n    def __init__(self, model_name: str, tokenizer_name: str, max_tokens: int = 100)\n    def run(self, task: str, *args, **kwargs) -&gt; str\n    async def run_async(self, task: str, *args, **kwargs) -&gt; str\n    def generate(self, prompt: str) -&gt; str\n    async def generate_async(self, prompt: str) -&gt; str\n    def __call__(self, task: str, *args, **kwargs) -&gt; str\n    async def __call_async__(self, task: str, *args, **kwargs) -&gt; str\n    def batch_generate(self, prompts: list, temperature: float = 1.0) -&gt; list\n    def unfreeze_model(self)\n</code></pre>"},{"location":"swarms/models/mpt/#class-parameters","title":"Class Parameters","text":"Parameter Type Description <code>model_name</code> str Name of the pre-trained model to use. <code>tokenizer_name</code> str Name of the tokenizer to use. <code>max_tokens</code> int Maximum number of tokens to generate. Default is 100."},{"location":"swarms/models/mpt/#class-methods","title":"Class Methods","text":"Method Returns Description <code>run(task: str, *args, **kwargs)</code> str Run the model with the specified task and arguments. <code>run_async(task: str, *args, **kwargs)</code> str Run the model asynchronously with the specified task and arguments. <code>generate(prompt: str)</code> str Generate text from the given prompt. <code>generate_async(prompt: str)</code> str Generate text asynchronously from the given prompt. <code>__call__(task: str, *args, **kwargs)</code> str Call the model with the specified task and arguments. <code>__call_async__(task: str, *args, **kwargs)</code> str Call the model asynchronously with the specified task and arguments. <code>batch_generate(prompts: list, temperature: float = 1.0)</code> list Generate text for a batch of prompts. <code>unfreeze_model()</code> None Unfreeze the model for fine-tuning."},{"location":"swarms/models/mpt/#usage-examples","title":"Usage Examples","text":""},{"location":"swarms/models/mpt/#example-1-basic-text-generation","title":"Example 1: Basic Text Generation","text":"<pre><code>from swarms.models import MPT7B\n\n# Initialize the MPT7B class\nmpt = MPT7B(\"mosaicml/mpt-7b-storywriter\", \"EleutherAI/gpt-neox-20b\", max_tokens=150)\n\n# Generate text\noutput = mpt.run(\"generate\", \"Once upon a time in a land far, far away...\")\nprint(output)\n</code></pre>"},{"location":"swarms/models/mpt/#example-2-batch-text-generation","title":"Example 2: Batch Text Generation","text":"<pre><code>from swarms.models import MPT7B\n\n# Initialize the MPT7B class\nmpt = MPT7B('mosaicml/mpt-7b-storywriter', 'EleutherAI/gpt-neox-20b', max_tokens=150)\n\n# Generate text for a batch of prompts\nprompts = ['In the deep jungles,', 'At the heart of the city,']\noutputs = mpt.batch_generate(prompts, temperature=0.7)\nprint(outputs)\n</code></pre>"},{"location":"swarms/models/mpt/#example-3-asynchronous-text-generation","title":"Example 3: Asynchronous Text Generation","text":"<pre><code>import asyncio\n\nfrom swarms.models import MPT7B\n\n# Initialize the MPT7B class\nmpt = MPT7B(\"mosaicml/mpt-7b-storywriter\", \"EleutherAI/gpt-neox-20b\", max_tokens=150)\n\n# Generate text asynchronously\noutput = asyncio.run(\n    mpt.run_async(\"generate\", \"Once upon a time in a land far, far away...\")\n)\nprint(output)\n</code></pre>"},{"location":"swarms/models/mpt/#additional-information","title":"Additional Information","text":"<p>The\u00a0<code>batch_generate</code>\u00a0method allows for generating text for multiple prompts at once. This can be more efficient than generating text for each prompt individually, especially when working with a large number of prompts.</p> <p>The\u00a0<code>unfreeze_model</code>\u00a0method is used to unfreeze the model for fine-tuning. By default, the model parameters are frozen to prevent them from being updated during training. Unfreezing the model allows the parameters to be updated, which can be useful for fine-tuning the model on a specific task.</p> <p>The\u00a0<code>__call__</code>\u00a0and\u00a0<code>__call_async__</code>\u00a0methods are convenience methods that allow the class instance to be called like a function. They simply call the\u00a0<code>run</code>\u00a0and\u00a0<code>run_async</code>\u00a0methods, respectively.</p>"},{"location":"swarms/models/mpt/#architecture-and-working","title":"Architecture and Working","text":"<p>The\u00a0<code>MPT7B</code>\u00a0class is designed to be a simple and flexible interface for text generation with pre-trained models. It encapsulates the complexity of loading models and tokenizers, setting up the text generation pipeline, and generating text.</p> <p>The class uses the\u00a0<code>AutoModelForCausalLM</code>\u00a0and\u00a0<code>AutoTokenizer</code>\u00a0classes from the\u00a0<code>transformers</code>\u00a0library to load the pre-trained model and tokenizer. The\u00a0<code>pipeline</code>\u00a0function is used to create a text generation pipeline with the loaded model and tokenizer. This pipeline is used to generate text from prompts.</p> <p>The\u00a0<code>run</code>\u00a0and\u00a0<code>run_async</code>\u00a0methods are the main entry points for using the class. They accept a task name and arbitrary arguments, and call the appropriate method based on the task name. The\u00a0<code>generate</code>\u00a0and\u00a0<code>generate_async</code>\u00a0methods perform the actual text generation.</p> <p>The\u00a0<code>batch_generate</code>\u00a0method allows for generating text for multiple prompts at once. This can be more efficient than generating text for each prompt individually, especially when working with a large number of prompts.</p> <p>The\u00a0<code>unfreeze_model</code>\u00a0method is used to unfreeze the model for fine-tuning. By default, the model parameters are frozen to prevent them from being updated during training. Unfreezing the model allows the parameters to be updated, which can be useful for fine-tuning the model on a specific task.</p> <p>The\u00a0<code>__call__</code>\u00a0and\u00a0<code>__call_async__</code>\u00a0methods are convenience methods that allow the class instance to be called like a function. They simply call the\u00a0<code>run</code>\u00a0and\u00a0<code>run_async</code>\u00a0methods, respectively.</p>"},{"location":"swarms/models/mpt/#conclusion","title":"Conclusion","text":"<p>The\u00a0<code>MPT7B</code>\u00a0class provides a powerful and flexible interface for text generation with pre-trained models. It encapsulates the complexity of loading models and tokenizers, setting up the text generation pipeline, and generating text, making it easy to generate high-quality text with just a few lines of code. Whether you're generating text for a single prompt, a batch of prompts, or fine-tuning the model on a specific task, the\u00a0<code>MPT7B</code>\u00a0class has you covered.</p>"},{"location":"swarms/models/nougat/","title":"<code>Nougat</code> Documentation","text":""},{"location":"swarms/models/nougat/#introduction","title":"Introduction","text":"<p>Welcome to the documentation for Nougat, a versatile model designed by Meta for transcribing scientific PDFs into user-friendly Markdown format, extracting information from PDFs, and extracting metadata from PDF documents. This documentation will provide you with a deep understanding of the Nougat class, its architecture, usage, and examples.</p>"},{"location":"swarms/models/nougat/#overview","title":"Overview","text":"<p>Nougat is a powerful tool that combines language modeling and image processing capabilities to convert scientific PDF documents into Markdown format. It is particularly useful for researchers, students, and professionals who need to extract valuable information from PDFs quickly. With Nougat, you can simplify complex PDFs, making their content more accessible and easy to work with.</p>"},{"location":"swarms/models/nougat/#class-definition","title":"Class Definition","text":"<pre><code>class Nougat:\n    def __init__(\n        self,\n        model_name_or_path=\"facebook/nougat-base\",\n        min_length: int = 1,\n        max_new_tokens: int = 30,\n    ):\n</code></pre>"},{"location":"swarms/models/nougat/#purpose","title":"Purpose","text":"<p>The Nougat class serves the following primary purposes:</p> <ol> <li> <p>PDF Transcription: Nougat is designed to transcribe scientific PDFs into Markdown format. It helps convert complex PDF documents into a more readable and structured format, making it easier to extract information.</p> </li> <li> <p>Information Extraction: It allows users to extract valuable information and content from PDFs efficiently. This can be particularly useful for researchers and professionals who need to extract data, figures, or text from scientific papers.</p> </li> <li> <p>Metadata Extraction: Nougat can also extract metadata from PDF documents, providing essential details about the document, such as title, author, and publication date.</p> </li> </ol>"},{"location":"swarms/models/nougat/#parameters","title":"Parameters","text":"<ul> <li><code>model_name_or_path</code> (str): The name or path of the pretrained Nougat model. Default: \"facebook/nougat-base\".</li> <li><code>min_length</code> (int): The minimum length of the generated transcription. Default: 1.</li> <li><code>max_new_tokens</code> (int): The maximum number of new tokens to generate in the Markdown transcription. Default: 30.</li> </ul>"},{"location":"swarms/models/nougat/#usage","title":"Usage","text":"<p>To use Nougat, follow these steps:</p> <ol> <li>Initialize the Nougat instance:</li> </ol> <pre><code>from swarms.models import Nougat\n\nnougat = Nougat()\n</code></pre>"},{"location":"swarms/models/nougat/#example-1-initialization","title":"Example 1 - Initialization","text":"<pre><code>nougat = Nougat()\n</code></pre> <ol> <li>Transcribe a PDF image using Nougat:</li> </ol> <pre><code>markdown_transcription = nougat(\"path/to/pdf_file.png\")\n</code></pre>"},{"location":"swarms/models/nougat/#example-2-pdf-transcription","title":"Example 2 - PDF Transcription","text":"<pre><code>nougat = Nougat()\nmarkdown_transcription = nougat(\"path/to/pdf_file.png\")\n</code></pre> <ol> <li>Extract information from a PDF:</li> </ol> <pre><code>information = nougat.extract_information(\"path/to/pdf_file.png\")\n</code></pre>"},{"location":"swarms/models/nougat/#example-3-information-extraction","title":"Example 3 - Information Extraction","text":"<pre><code>nougat = Nougat()\ninformation = nougat.extract_information(\"path/to/pdf_file.png\")\n</code></pre> <ol> <li>Extract metadata from a PDF:</li> </ol> <pre><code>metadata = nougat.extract_metadata(\"path/to/pdf_file.png\")\n</code></pre>"},{"location":"swarms/models/nougat/#example-4-metadata-extraction","title":"Example 4 - Metadata Extraction","text":"<pre><code>nougat = Nougat()\nmetadata = nougat.extract_metadata(\"path/to/pdf_file.png\")\n</code></pre>"},{"location":"swarms/models/nougat/#how-nougat-works","title":"How Nougat Works","text":"<p>Nougat employs a vision encoder-decoder model, along with a dedicated processor, to transcribe PDFs into Markdown format and perform information and metadata extraction. Here's how it works:</p> <ol> <li> <p>Initialization: When you create a Nougat instance, you can specify the model to use, the minimum transcription length, and the maximum number of new tokens to generate.</p> </li> <li> <p>Processing PDFs: Nougat can process PDFs as input. You can provide the path to a PDF document.</p> </li> <li> <p>Image Processing: The processor converts PDF pages into images, which are then encoded by the model.</p> </li> <li> <p>Transcription: Nougat generates Markdown transcriptions of PDF content, ensuring a minimum length and respecting the token limit.</p> </li> <li> <p>Information Extraction: Information extraction involves parsing the Markdown transcription to identify key details or content of interest.</p> </li> <li> <p>Metadata Extraction: Metadata extraction involves identifying and extracting document metadata, such as title, author, and publication date.</p> </li> </ol>"},{"location":"swarms/models/nougat/#additional-information","title":"Additional Information","text":"<ul> <li>Nougat leverages the \"facebook/nougat-base\" pretrained model, which is specifically designed for document transcription and extraction tasks.</li> <li>You can adjust the minimum transcription length and the maximum number of new tokens to control the output's length and quality.</li> <li>Nougat can be run on both CPU and GPU devices.</li> </ul> <p>That concludes the documentation for Nougat. We hope you find this tool valuable for your PDF transcription, information extraction, and metadata extraction needs. If you have any questions or encounter any issues, please refer to the Nougat documentation for further assistance. Enjoy using Nougat!</p>"},{"location":"swarms/models/openai/","title":"<code>BaseOpenAI</code> and <code>OpenAI</code> Documentation","text":""},{"location":"swarms/models/openai/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Overview</li> <li>Class Architecture</li> <li>Purpose</li> <li>Class Attributes</li> <li>Methods</li> <li>Construction</li> <li>Configuration</li> <li>Tokenization</li> <li>Generation</li> <li>Asynchronous Generation</li> <li>Usage Examples</li> <li>Creating an OpenAI Object</li> <li>Generating Text</li> <li>Advanced Configuration</li> </ol>"},{"location":"swarms/models/openai/#1-overview","title":"1. Overview","text":"<p>The <code>BaseOpenAI</code> and <code>OpenAI</code> classes are part of the LangChain library, designed to interact with OpenAI's large language models (LLMs). These classes provide a seamless interface for utilizing OpenAI's API to generate natural language text.</p>"},{"location":"swarms/models/openai/#2-class-architecture","title":"2. Class Architecture","text":"<p>Both <code>BaseOpenAI</code> and <code>OpenAI</code> classes inherit from <code>BaseLLM</code>, demonstrating an inheritance-based architecture. This architecture allows for easy extensibility and customization while adhering to the principles of object-oriented programming.</p>"},{"location":"swarms/models/openai/#3-purpose","title":"3. Purpose","text":"<p>The purpose of these classes is to simplify the interaction with OpenAI's LLMs. They encapsulate API calls, handle tokenization, and provide a high-level interface for generating text. By instantiating an object of the <code>OpenAI</code> class, developers can quickly leverage the power of OpenAI's models to generate text for various applications, such as chatbots, content generation, and more.</p>"},{"location":"swarms/models/openai/#4-class-attributes","title":"4. Class Attributes","text":"<p>Here are the key attributes and their descriptions for the <code>BaseOpenAI</code> and <code>OpenAI</code> classes:</p> Attribute Description <code>lc_secrets</code> A dictionary of secrets required for LangChain, including the OpenAI API key. <code>lc_attributes</code> A dictionary of attributes relevant to LangChain. <code>is_lc_serializable()</code> A method indicating if the class is serializable for LangChain. <code>model_name</code> The name of the language model to use. <code>temperature</code> The sampling temperature for text generation. <code>max_tokens</code> The maximum number of tokens to generate in a completion. <code>top_p</code> The total probability mass of tokens to consider at each step. <code>frequency_penalty</code> Penalizes repeated tokens according to frequency. <code>presence_penalty</code> Penalizes repeated tokens. <code>n</code> How many completions to generate for each prompt. <code>best_of</code> Generates <code>best_of</code> completions server-side and returns the \"best.\" <code>model_kwargs</code> Holds any model parameters valid for <code>create</code> calls not explicitly specified. <code>openai_api_key</code> The OpenAI API key used for authentication. <code>openai_api_base</code> The base URL for the OpenAI API. <code>openai_organization</code> The OpenAI organization name, if applicable. <code>openai_proxy</code> An explicit proxy URL for OpenAI requests. <code>batch_size</code> The batch size to use when passing multiple documents for generation. <code>request_timeout</code> The timeout for requests to the OpenAI completion API. <code>logit_bias</code> Adjustment to the probability of specific tokens being generated. <code>max_retries</code> The maximum number of retries to make when generating. <code>streaming</code> Whether to stream the results or not. <code>allowed_special</code> A set of special tokens that are allowed. <code>disallowed_special</code> A collection of special tokens that are not allowed. <code>tiktoken_model_name</code> The model name to pass to <code>tiktoken</code> for token counting."},{"location":"swarms/models/openai/#5-methods","title":"5. Methods","text":""},{"location":"swarms/models/openai/#51-construction","title":"5.1 Construction","text":""},{"location":"swarms/models/openai/#511-__new__cls-data-any-unionopenaichat-baseopenai","title":"5.1.1 <code>__new__(cls, **data: Any) -&gt; Union[OpenAIChat, BaseOpenAI]</code>","text":"<ul> <li>Description: Initializes the OpenAI object.</li> <li>Arguments:</li> <li><code>cls</code> (class): The class instance.</li> <li><code>data</code> (dict): Additional data for initialization.</li> <li>Returns:</li> <li>Union[OpenAIChat, BaseOpenAI]: An instance of the OpenAI class.</li> </ul>"},{"location":"swarms/models/openai/#52-configuration","title":"5.2 Configuration","text":""},{"location":"swarms/models/openai/#521-build_extracls-values-dictstr-any-dictstr-any","title":"5.2.1 <code>build_extra(cls, values: Dict[str, Any]) -&gt; Dict[str, Any]</code>","text":"<ul> <li>Description: Builds extra kwargs from additional params passed in.</li> <li>Arguments:</li> <li><code>cls</code> (class): The class instance.</li> <li><code>values</code> (dict): Values and parameters to build extra kwargs.</li> <li>Returns:</li> <li>Dict[str, Any]: A dictionary of built extra kwargs.</li> </ul>"},{"location":"swarms/models/openai/#522-validate_environmentcls-values-dict-dict","title":"5.2.2 <code>validate_environment(cls, values: Dict) -&gt; Dict</code>","text":"<ul> <li>Description: Validates that the API key and python package exist in the environment.</li> <li>Arguments:</li> <li><code>values</code> (dict): The class values and parameters.</li> <li>Returns:</li> <li>Dict: A dictionary of validated values.</li> </ul>"},{"location":"swarms/models/openai/#53-tokenization","title":"5.3 Tokenization","text":""},{"location":"swarms/models/openai/#531-get_sub_promptsself-params-dictstr-any-prompts-liststr-stop-optionalliststr-none-listliststr","title":"5.3.1 <code>get_sub_prompts(self, params: Dict[str, Any], prompts: List[str], stop: Optional[List[str]] = None) -&gt; List[List[str]]</code>","text":"<ul> <li>Description: Gets sub-prompts for LLM call.</li> <li>Arguments:</li> <li><code>params</code> (dict): Parameters for LLM call.</li> <li><code>prompts</code> (list): List of prompts.</li> <li><code>stop</code> (list, optional): List of stop words.</li> <li>Returns:</li> <li>List[List[str]]: List of sub-prompts.</li> </ul>"},{"location":"swarms/models/openai/#532-get_token_idsself-text-str-listint","title":"5.3.2 <code>get_token_ids(self, text: str) -&gt; List[int]</code>","text":"<ul> <li>Description: Gets token IDs using the <code>tiktoken</code> package.</li> <li>Arguments:</li> <li><code>text</code> (str): The text for which to calculate token IDs.</li> <li>Returns:</li> <li>List[int]: A list of token IDs.</li> </ul>"},{"location":"swarms/models/openai/#533-modelname_to_contextsizemodelname-str-int","title":"5.3.3 <code>modelname_to_contextsize(modelname: str) -&gt; int</code>","text":"<ul> <li>Description: Calculates the maximum number of tokens possible to generate for a model.</li> <li>Arguments:</li> <li><code>modelname</code> (str): The model name to determine the context size for.</li> <li>Returns:</li> <li>int: The maximum context size.</li> </ul>"},{"location":"swarms/models/openai/#534-max_tokens_for_promptself-prompt-str-int","title":"5.3.4 <code>max_tokens_for_prompt(self, prompt: str) -&gt; int</code>","text":"<ul> <li>Description: Calculates the maximum number of tokens possible to generate for a prompt.</li> <li>Arguments:</li> <li><code>prompt</code> (str): The prompt for which to</li> </ul> <p>determine the maximum token limit. - Returns:   - int: The maximum token limit.</p>"},{"location":"swarms/models/openai/#54-generation","title":"5.4 Generation","text":""},{"location":"swarms/models/openai/#541-generateself-text-unionstr-liststr-kwargs-unionstr-liststr","title":"5.4.1 <code>generate(self, text: Union[str, List[str]], **kwargs) -&gt; Union[str, List[str]]</code>","text":"<ul> <li>Description: Generates text using the OpenAI API.</li> <li>Arguments:</li> <li><code>text</code> (str or list): The input text or list of inputs.</li> <li><code>**kwargs</code> (dict): Additional parameters for the generation process.</li> <li>Returns:</li> <li>Union[str, List[str]]: The generated text or list of generated texts.</li> </ul>"},{"location":"swarms/models/openai/#55-asynchronous-generation","title":"5.5 Asynchronous Generation","text":""},{"location":"swarms/models/openai/#551-generate_asyncself-text-unionstr-liststr-kwargs-unionstr-liststr","title":"5.5.1 <code>generate_async(self, text: Union[str, List[str]], **kwargs) -&gt; Union[str, List[str]]</code>","text":"<ul> <li>Description: Generates text asynchronously using the OpenAI API.</li> <li>Arguments:</li> <li><code>text</code> (str or list): The input text or list of inputs.</li> <li><code>**kwargs</code> (dict): Additional parameters for the asynchronous generation process.</li> <li>Returns:</li> <li>Union[str, List[str]]: The generated text or list of generated texts.</li> </ul>"},{"location":"swarms/models/openai/#6-usage-examples","title":"6. Usage Examples","text":""},{"location":"swarms/models/openai/#61-creating-an-openai-object","title":"6.1 Creating an OpenAI Object","text":"<pre><code># Import the OpenAI class\nfrom swarms.models import OpenAI\n\n# Set your OpenAI API key\napi_key = \"YOUR_API_KEY\"\n\n# Create an OpenAI object\nopenai = OpenAI(api_key)\n</code></pre>"},{"location":"swarms/models/openai/#62-generating-text","title":"6.2 Generating Text","text":"<pre><code># Generate text from a single prompt\nprompt = \"Translate the following English text to French: 'Hello, how are you?'\"\ngenerated_text = openai.generate(prompt, max_tokens=50)\n\n# Generate text from multiple prompts\nprompts = [\n    \"Translate this: 'Good morning' to Spanish.\",\n    \"Summarize the following article:\",\n    article_text,\n]\ngenerated_texts = openai.generate(prompts, max_tokens=100)\n\n# Generate text asynchronously\nasync_prompt = \"Translate 'Thank you' into German.\"\nasync_result = openai.generate_async(async_prompt, max_tokens=30)\n\n# Access the result of an asynchronous generation\nasync_result_text = async_result.get()\n</code></pre>"},{"location":"swarms/models/openai/#63-advanced-configuration","title":"6.3 Advanced Configuration","text":"<pre><code># Configure generation with advanced options\ncustom_options = {\n    \"temperature\": 0.7,\n    \"max_tokens\": 100,\n    \"top_p\": 0.9,\n    \"frequency_penalty\": 0.2,\n    \"presence_penalty\": 0.4,\n}\ngenerated_text = openai.generate(prompt, **custom_options)\n</code></pre> <p>This documentation provides a comprehensive understanding of the <code>BaseOpenAI</code> and <code>OpenAI</code> classes, their attributes, methods, and usage examples. Developers can utilize these classes to interact with OpenAI's language models efficiently, enabling various natural language generation tasks.</p>"},{"location":"swarms/models/openai_chat/","title":"<code>OpenAIChat</code> Documentation","text":""},{"location":"swarms/models/openai_chat/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction</li> <li>Class Overview</li> <li>Class Architecture</li> <li>Class Attributes</li> <li>Methods<ul> <li>Construction</li> <li>Configuration</li> <li>Message Handling</li> <li>Generation</li> <li>Tokenization</li> </ul> </li> <li>Usage Examples</li> <li>Additional Information</li> </ol>"},{"location":"swarms/models/openai_chat/#1-introduction","title":"1. Introduction","text":"<p>The <code>OpenAIChat</code> class is part of the LangChain library and serves as an interface to interact with OpenAI's Chat large language models. This documentation provides an in-depth understanding of the class, its attributes, methods, and usage examples.</p>"},{"location":"swarms/models/openai_chat/#2-class-overview","title":"2. Class Overview","text":"<p>The <code>OpenAIChat</code> class is designed for conducting chat-like conversations with OpenAI's language models, such as GPT-3.5 Turbo. It allows you to create interactive conversations by sending messages and receiving model-generated responses. This class simplifies the process of integrating OpenAI's models into chatbot applications and other natural language processing tasks.</p>"},{"location":"swarms/models/openai_chat/#3-class-architecture","title":"3. Class Architecture","text":"<p>The <code>OpenAIChat</code> class is built on top of the <code>BaseLLM</code> class, which provides a foundation for working with large language models. This inheritance-based architecture allows for customization and extension while adhering to object-oriented programming principles.</p>"},{"location":"swarms/models/openai_chat/#4-class-attributes","title":"4. Class Attributes","text":"<p>Here are the key attributes and their descriptions for the <code>OpenAIChat</code> class:</p> Attribute Description <code>client</code> An internal client for making API calls to OpenAI. <code>model_name</code> The name of the language model to use (default: \"gpt-3.5-turbo\"). <code>model_kwargs</code> Additional model parameters valid for <code>create</code> calls not explicitly specified. <code>openai_api_key</code> The OpenAI API key used for authentication. <code>openai_api_base</code> The base URL for the OpenAI API. <code>openai_proxy</code> An explicit proxy URL for OpenAI requests. <code>max_retries</code> The maximum number of retries to make when generating (default: 6). <code>prefix_messages</code> A list of messages to set the initial conversation state (default: []). <code>streaming</code> Whether to stream the results or not (default: False). <code>allowed_special</code> A set of special tokens that are allowed (default: an empty set). <code>disallowed_special</code> A collection of special tokens that are not allowed (default: \"all\")."},{"location":"swarms/models/openai_chat/#5-methods","title":"5. Methods","text":""},{"location":"swarms/models/openai_chat/#51-construction","title":"5.1 Construction","text":""},{"location":"swarms/models/openai_chat/#511-__init__self-model_name-str-gpt-35-turbo-openai_api_key-optionalstr-none-openai_api_base-optionalstr-none-openai_proxy-optionalstr-none-max_retries-int-6-prefix_messages-list","title":"5.1.1 <code>__init__(self, model_name: str = \"gpt-3.5-turbo\", openai_api_key: Optional[str] = None, openai_api_base: Optional[str] = None, openai_proxy: Optional[str] = None, max_retries: int = 6, prefix_messages: List = [])</code>","text":"<ul> <li>Description: Initializes an OpenAIChat object.</li> <li>Arguments:</li> <li><code>model_name</code> (str): The name of the language model to use (default: \"gpt-3.5-turbo\").</li> <li><code>openai_api_key</code> (str, optional): The OpenAI API key used for authentication.</li> <li><code>openai_api_base</code> (str, optional): The base URL for the OpenAI API.</li> <li><code>openai_proxy</code> (str, optional): An explicit proxy URL for OpenAI requests.</li> <li><code>max_retries</code> (int): The maximum number of retries to make when generating (default: 6).</li> <li><code>prefix_messages</code> (List): A list of messages to set the initial conversation state (default: []).</li> </ul>"},{"location":"swarms/models/openai_chat/#52-configuration","title":"5.2 Configuration","text":""},{"location":"swarms/models/openai_chat/#521-build_extraself-values-dictstr-any-dictstr-any","title":"5.2.1 <code>build_extra(self, values: Dict[str, Any]) -&gt; Dict[str, Any]</code>","text":"<ul> <li>Description: Builds extra kwargs from additional parameters passed in.</li> <li>Arguments:</li> <li><code>values</code> (dict): Values and parameters to build extra kwargs.</li> <li>Returns:</li> <li>Dict[str, Any]: A dictionary of built extra kwargs.</li> </ul>"},{"location":"swarms/models/openai_chat/#522-validate_environmentself-values-dict-dict","title":"5.2.2 <code>validate_environment(self, values: Dict) -&gt; Dict</code>","text":"<ul> <li>Description: Validates that the API key and Python package exist in the environment.</li> <li>Arguments:</li> <li><code>values</code> (dict): The class values and parameters.</li> <li>Returns:</li> <li>Dict: A dictionary of validated values.</li> </ul>"},{"location":"swarms/models/openai_chat/#53-message-handling","title":"5.3 Message Handling","text":""},{"location":"swarms/models/openai_chat/#531-_get_chat_paramsself-prompts-liststr-stop-optionalliststr-none-tuple","title":"5.3.1 <code>_get_chat_params(self, prompts: List[str], stop: Optional[List[str]] = None) -&gt; Tuple</code>","text":"<ul> <li>Description: Gets chat-related parameters for generating responses.</li> <li>Arguments:</li> <li><code>prompts</code> (list): List of user messages.</li> <li><code>stop</code> (list, optional): List of stop words.</li> <li>Returns:</li> <li>Tuple: Messages and parameters.</li> </ul>"},{"location":"swarms/models/openai_chat/#54-generation","title":"5.4 Generation","text":""},{"location":"swarms/models/openai_chat/#541-_streamself-prompt-str-stop-optionalliststr-none-run_manager-optionalcallbackmanagerforllmrun-none-kwargs-any-iteratorgenerationchunk","title":"5.4.1 <code>_stream(self, prompt: str, stop: Optional[List[str]] = None, run_manager: Optional[CallbackManagerForLLMRun] = None, **kwargs: Any) -&gt; Iterator[GenerationChunk]</code>","text":"<ul> <li>Description: Generates text asynchronously using the OpenAI API.</li> <li>Arguments:</li> <li><code>prompt</code> (str): The user's message.</li> <li><code>stop</code> (list, optional): List of stop words.</li> <li><code>run_manager</code> (optional): Callback manager for asynchronous generation.</li> <li><code>**kwargs</code> (dict): Additional parameters for asynchronous generation.</li> <li>Returns:</li> <li>Iterator[GenerationChunk]: An iterator of generated text chunks.</li> </ul>"},{"location":"swarms/models/openai_chat/#542-_agenerateself-prompts-liststr-stop-optionalliststr-none-run_manager-optionalasynccallbackmanagerforllmrun-none-kwargs-any-llmresult","title":"5.4.2 <code>_agenerate(self, prompts: List[str], stop: Optional[List[str]] = None, run_manager: Optional[AsyncCallbackManagerForLLMRun] = None, **kwargs: Any) -&gt; LLMResult</code>","text":"<ul> <li>Description: Generates text asynchronously using the OpenAI API (async version).</li> <li>Arguments:</li> <li><code>prompts</code> (list): List of user messages.</li> <li><code>stop</code> (list, optional): List of stop words.</li> <li><code>run_manager</code> (optional): Callback manager for asynchronous generation.</li> <li><code>**kwargs</code> (dict): Additional parameters for asynchronous generation.</li> <li>Returns:</li> <li>LLMResult: A result object containing the generated text.</li> </ul>"},{"location":"swarms/models/openai_chat/#55-tokenization","title":"5.5 Tokenization","text":""},{"location":"swarms/models/openai_chat/#551-get_token_idsself-text-str-listint","title":"5.5.1 <code>get_token_ids(self, text: str) -&gt; List[int]</code>","text":"<ul> <li>Description: Gets token IDs using the tiktoken package.</li> <li>Arguments:</li> <li><code>text</code> (str): The text for which to calculate token IDs.</li> <li>Returns:</li> <li>List[int]: A list of</li> </ul> <p>token IDs.</p>"},{"location":"swarms/models/openai_chat/#6-usage-examples","title":"6. Usage Examples","text":""},{"location":"swarms/models/openai_chat/#example-1-initializing-openaichat","title":"Example 1: Initializing <code>OpenAIChat</code>","text":"<pre><code>from swarms.models import OpenAIChat\n\n# Initialize OpenAIChat with model name and API key\nopenai_chat = OpenAIChat(model_name=\"gpt-3.5-turbo\", openai_api_key=\"YOUR_API_KEY\")\n</code></pre>"},{"location":"swarms/models/openai_chat/#example-2-sending-messages-and-generating-responses","title":"Example 2: Sending Messages and Generating Responses","text":"<pre><code># Define a conversation\nconversation = [\n    \"User: Tell me a joke.\",\n    \"Assistant: Why did the chicken cross the road?\",\n    \"User: I don't know. Why?\",\n    \"Assistant: To get to the other side!\",\n]\n\n# Set the conversation as the prefix messages\nopenai_chat.prefix_messages = conversation\n\n# Generate a response\nuser_message = \"User: Tell me another joke.\"\nresponse = openai_chat.generate([user_message])\n\n# Print the generated response\nprint(\n    response[0][0].text\n)  # Output: \"Assistant: Why don't scientists trust atoms? Because they make up everything!\"\n</code></pre>"},{"location":"swarms/models/openai_chat/#example-3-asynchronous-generation","title":"Example 3: Asynchronous Generation","text":"<pre><code>import asyncio\n\n\n# Define an asynchronous function for generating responses\nasync def generate_responses():\n    user_message = \"User: Tell me a fun fact.\"\n    async for chunk in openai_chat.stream([user_message]):\n        print(chunk.text)\n\n\n# Run the asynchronous generation function\nasyncio.run(generate_responses())\n</code></pre>"},{"location":"swarms/models/openai_chat/#7-additional-information","title":"7. Additional Information","text":"<ul> <li>To use the <code>OpenAIChat</code> class, you should have the <code>openai</code> Python package installed, and the environment variable <code>OPENAI_API_KEY</code> set with your API key.</li> <li>Any parameters that are valid to be passed to the <code>openai.create</code> call can be passed to the <code>OpenAIChat</code> constructor.</li> <li>You can customize the behavior of the class by setting various attributes, such as <code>model_name</code>, <code>openai_api_key</code>, <code>prefix_messages</code>, and more.</li> <li>For asynchronous generation, you can use the <code>_stream</code> and <code>_agenerate</code> methods to interactively receive model-generated text chunks.</li> <li>To calculate token IDs, you can use the <code>get_token_ids</code> method, which utilizes the <code>tiktoken</code> package. Make sure to install the <code>tiktoken</code> package with <code>pip install tiktoken</code> if needed.</li> </ul> <p>This documentation provides a comprehensive overview of the <code>OpenAIChat</code> class, its attributes, methods, and usage examples. You can use this class to create chatbot applications, conduct conversations with language models, and explore the capabilities of OpenAI's GPT-3.5 Turbo model.</p>"},{"location":"swarms/models/openai_tts/","title":"<code>OpenAITTS</code> Documentation","text":""},{"location":"swarms/models/openai_tts/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Overview</li> <li>Installation</li> <li>Usage</li> <li>Initialization</li> <li>Running TTS</li> <li>Running TTS and Saving</li> <li>Examples</li> <li>Basic Usage</li> <li>Saving the Output</li> <li>Advanced Options</li> <li>Troubleshooting</li> <li>References</li> </ol>"},{"location":"swarms/models/openai_tts/#1-overview","title":"1. Overview","text":"<p>The <code>OpenAITTS</code> module is a Python library that provides an interface for converting text to speech (TTS) using the OpenAI TTS API. It allows you to generate high-quality speech from text input, making it suitable for various applications such as voice assistants, speech synthesis, and more.</p>"},{"location":"swarms/models/openai_tts/#features","title":"Features:","text":"<ul> <li>Convert text to speech using OpenAI's TTS model.</li> <li>Supports specifying the model name, voice, and other parameters.</li> <li>Option to save the generated speech to a WAV file.</li> </ul>"},{"location":"swarms/models/openai_tts/#2-installation","title":"2. Installation","text":"<p>To use the <code>OpenAITTS</code> model, you need to install the necessary dependencies. You can do this using <code>pip</code>:</p> <pre><code>pip install swarms requests wave\n</code></pre>"},{"location":"swarms/models/openai_tts/#3-usage","title":"3. Usage","text":""},{"location":"swarms/models/openai_tts/#initialization","title":"Initialization","text":"<p>To use the <code>OpenAITTS</code> module, you need to initialize an instance of the <code>OpenAITTS</code> class. Here's how you can do it:</p> <pre><code>from swarms.models.openai_tts import OpenAITTS\n\n# Initialize the OpenAITTS instance\ntts = OpenAITTS(\n    model_name=\"tts-1-1106\",\n    proxy_url=\"https://api.openai.com/v1/audio/speech\",\n    openai_api_key=openai_api_key_env,\n    voice=\"onyx\",\n)\n</code></pre>"},{"location":"swarms/models/openai_tts/#parameters","title":"Parameters:","text":"<ul> <li><code>model_name</code> (str): The name of the TTS model to use (default is \"tts-1-1106\").</li> <li><code>proxy_url</code> (str): The URL for the OpenAI TTS API (default is \"https://api.openai.com/v1/audio/speech\").</li> <li><code>openai_api_key</code> (str): Your OpenAI API key. It can be obtained from the OpenAI website.</li> <li><code>voice</code> (str): The voice to use for generating speech (default is \"onyx\").</li> <li><code>chunk_size</code> (int): The size of data chunks when fetching audio (default is 1024 * 1024 bytes).</li> <li><code>autosave</code> (bool): Whether to automatically save the generated speech to a file (default is False).</li> <li><code>saved_filepath</code> (str): The path to the file where the speech will be saved (default is \"runs/tts_speech.wav\").</li> </ul>"},{"location":"swarms/models/openai_tts/#running-tts","title":"Running TTS","text":"<p>Once the <code>OpenAITTS</code> instance is initialized, you can use it to convert text to speech using the <code>run</code> method:</p> <pre><code># Generate speech from text\nspeech_data = tts.run(\"Hello, world!\")\n</code></pre>"},{"location":"swarms/models/openai_tts/#parameters_1","title":"Parameters:","text":"<ul> <li><code>task</code> (str): The text you want to convert to speech.</li> </ul>"},{"location":"swarms/models/openai_tts/#returns","title":"Returns:","text":"<ul> <li><code>speech_data</code> (bytes): The generated speech data.</li> </ul>"},{"location":"swarms/models/openai_tts/#running-tts-and-saving","title":"Running TTS and Saving","text":"<p>You can also use the <code>run_and_save</code> method to generate speech from text and save it to a file:</p> <pre><code># Generate speech from text and save it to a file\nspeech_data = tts.run_and_save(\"Hello, world!\")\n</code></pre>"},{"location":"swarms/models/openai_tts/#parameters_2","title":"Parameters:","text":"<ul> <li><code>task</code> (str): The text you want to convert to speech.</li> </ul>"},{"location":"swarms/models/openai_tts/#returns_1","title":"Returns:","text":"<ul> <li><code>speech_data</code> (bytes): The generated speech data.</li> </ul>"},{"location":"swarms/models/openai_tts/#4-examples","title":"4. Examples","text":""},{"location":"swarms/models/openai_tts/#basic-usage","title":"Basic Usage","text":"<p>Here's a basic example of how to use the <code>OpenAITTS</code> module to generate speech from text:</p> <pre><code>from swarms.models.openai_tts import OpenAITTS\n\n# Initialize the OpenAITTS instance\ntts = OpenAITTS(\n    model_name=\"tts-1-1106\",\n    proxy_url=\"https://api.openai.com/v1/audio/speech\",\n    openai_api_key=openai_api_key_env,\n    voice=\"onyx\",\n)\n\n# Generate speech from text\nspeech_data = tts.run(\"Hello, world!\")\n</code></pre>"},{"location":"swarms/models/openai_tts/#saving-the-output","title":"Saving the Output","text":"<p>You can save the generated speech to a WAV file using the <code>run_and_save</code> method:</p> <pre><code># Generate speech from text and save it to a file\nspeech_data = tts.run_and_save(\"Hello, world!\")\n</code></pre>"},{"location":"swarms/models/openai_tts/#5-advanced-options","title":"5. Advanced Options","text":"<p>The <code>OpenAITTS</code> module supports various advanced options for customizing the TTS generation process. You can specify the model name, voice, and other parameters during initialization. Additionally, you can configure the chunk size for audio data fetching and choose whether to automatically save the generated speech to a file.</p>"},{"location":"swarms/models/openai_tts/#6-troubleshooting","title":"6. Troubleshooting","text":"<p>If you encounter any issues while using the <code>OpenAITTS</code> module, please make sure you have installed all the required dependencies and that your OpenAI API key is correctly configured. If you still face problems, refer to the OpenAI documentation or contact their support for assistance.</p>"},{"location":"swarms/models/openai_tts/#7-references","title":"7. References","text":"<ul> <li>OpenAI API Documentation</li> <li>Python Requests Library</li> <li>Python Wave Library</li> </ul> <p>This documentation provides a comprehensive guide on how to use the <code>OpenAITTS</code> module to convert text to speech using OpenAI's TTS model. It covers initialization, basic usage, advanced options, troubleshooting, and references for further exploration.</p>"},{"location":"swarms/models/vilt/","title":"<code>Vilt</code> Documentation","text":""},{"location":"swarms/models/vilt/#introduction","title":"Introduction","text":"<p>Welcome to the documentation for Vilt, a Vision-and-Language Transformer (ViLT) model fine-tuned on the VQAv2 dataset. Vilt is a powerful model capable of answering questions about images. This documentation will provide a comprehensive understanding of Vilt, its architecture, usage, and how it can be integrated into your projects.</p>"},{"location":"swarms/models/vilt/#overview","title":"Overview","text":"<p>Vilt is based on the Vision-and-Language Transformer (ViLT) architecture, designed for tasks that involve understanding both text and images. It has been fine-tuned on the VQAv2 dataset, making it adept at answering questions about images. This model is particularly useful for tasks where textual and visual information needs to be combined to provide meaningful answers.</p>"},{"location":"swarms/models/vilt/#class-definition","title":"Class Definition","text":"<pre><code>class Vilt:\n    def __init__(self):\n        \"\"\"\n        Initialize the Vilt model.\n        \"\"\"\n</code></pre>"},{"location":"swarms/models/vilt/#usage","title":"Usage","text":"<p>To use the Vilt model, follow these steps:</p> <ol> <li>Initialize the Vilt model:</li> </ol> <pre><code>from swarms.models import Vilt\n\nmodel = Vilt()\n</code></pre> <ol> <li>Call the model with a text question and an image URL:</li> </ol> <pre><code>output = model(\n    \"What is this image?\", \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n)\n</code></pre>"},{"location":"swarms/models/vilt/#example-1-image-questioning","title":"Example 1 - Image Questioning","text":"<pre><code>model = Vilt()\noutput = model(\n    \"What are the objects in this image?\",\n    \"http://images.cocodataset.org/val2017/000000039769.jpg\",\n)\nprint(output)\n</code></pre>"},{"location":"swarms/models/vilt/#example-2-image-analysis","title":"Example 2 - Image Analysis","text":"<pre><code>model = Vilt()\noutput = model(\n    \"Describe the scene in this image.\",\n    \"http://images.cocodataset.org/val2017/000000039769.jpg\",\n)\nprint(output)\n</code></pre>"},{"location":"swarms/models/vilt/#example-3-visual-knowledge-retrieval","title":"Example 3 - Visual Knowledge Retrieval","text":"<pre><code>model = Vilt()\noutput = model(\n    \"Tell me more about the landmark in this image.\",\n    \"http://images.cocodataset.org/val2017/000000039769.jpg\",\n)\nprint(output)\n</code></pre>"},{"location":"swarms/models/vilt/#how-vilt-works","title":"How Vilt Works","text":"<p>Vilt operates by combining text and image information to generate meaningful answers to questions about the provided image. Here's how it works:</p> <ol> <li> <p>Initialization: When you create a Vilt instance, it initializes the processor and the model. The processor is responsible for handling the image and text input, while the model is the fine-tuned ViLT model.</p> </li> <li> <p>Processing Input: When you call the Vilt model with a text question and an image URL, it downloads the image and processes it along with the text question. This processing step involves tokenization and encoding of the input.</p> </li> <li> <p>Forward Pass: The encoded input is then passed through the ViLT model. It calculates the logits, and the answer with the highest probability is selected.</p> </li> <li> <p>Output: The predicted answer is returned as the output of the model.</p> </li> </ol>"},{"location":"swarms/models/vilt/#parameters","title":"Parameters","text":"<p>Vilt does not require any specific parameters during initialization. It is pre-configured to work with the \"dandelin/vilt-b32-finetuned-vqa\" model.</p>"},{"location":"swarms/models/vilt/#additional-information","title":"Additional Information","text":"<ul> <li>Vilt is fine-tuned on the VQAv2 dataset, making it proficient at answering questions about a wide range of images.</li> <li>You can use Vilt for various applications, including image question-answering, image analysis, and visual knowledge retrieval.</li> </ul> <p>That concludes the documentation for Vilt. We hope you find this model useful for your vision-and-language tasks. If you have any questions or encounter any issues, please refer to the Hugging Face Transformers documentation for further assistance. Enjoy working with Vilt!</p>"},{"location":"swarms/models/vllm/","title":"<code>vLLM</code> Documentation","text":""},{"location":"swarms/models/vllm/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Overview</li> <li>Installation</li> <li>vLLM Class</li> <li>Initialization</li> <li>Methods<ul> <li>run</li> </ul> </li> <li>Usage Examples</li> <li>Common Issues and Troubleshooting</li> <li>References and Resources</li> </ul>"},{"location":"swarms/models/vllm/#overview","title":"Overview","text":"<p>Welcome to the documentation for the vLLM (Variable-Length Language Model) library. vLLM is a powerful tool for generating text using pre-trained language models. This documentation will provide a comprehensive guide on how to use vLLM effectively.</p>"},{"location":"swarms/models/vllm/#purpose","title":"Purpose","text":"<p>vLLM is designed to simplify the process of generating text using language models, specifically the Facebook <code>opt-13b</code> model. It allows you to fine-tune various parameters to achieve the desired text generation outcomes.</p>"},{"location":"swarms/models/vllm/#key-features","title":"Key Features","text":"<ul> <li>Seamless integration with the Facebook <code>opt-13b</code> language model.</li> <li>Flexible configuration options for model parameters.</li> <li>Support for generating text for various natural language processing tasks.</li> </ul>"},{"location":"swarms/models/vllm/#installation","title":"Installation","text":"<p>Before using vLLM, you need to install swarms. You can install vLLM using <code>pip</code>:</p> <pre><code>pip install swarms vllm\n</code></pre>"},{"location":"swarms/models/vllm/#vllm-class","title":"vLLM Class","text":"<p>The vLLM class is the core component of the vLLM library. It provides a high-level interface for generating text using the Facebook <code>opt-13b</code> language model.</p>"},{"location":"swarms/models/vllm/#initialization","title":"Initialization","text":"<p>To initialize the vLLM class, you can use the following parameters:</p> <ul> <li><code>model_name</code> (str, optional): The name of the language model to use. Defaults to \"facebook/opt-13b\".</li> <li><code>tensor_parallel_size</code> (int, optional): The size of the tensor parallelism. Defaults to 4.</li> <li><code>trust_remote_code</code> (bool, optional): Whether to trust remote code. Defaults to False.</li> <li><code>revision</code> (str, optional): The revision of the language model. Defaults to None.</li> <li><code>temperature</code> (float, optional): The temperature parameter for text generation. Defaults to 0.5.</li> <li><code>top_p</code> (float, optional): The top-p parameter for text generation. Defaults to 0.95.</li> </ul> <pre><code>from swarms.models import vLLM\n\n# Initialize vLLM with default parameters\nvllm = vLLM()\n\n# Initialize vLLM with custom parameters\ncustom_vllm = vLLM(\n    model_name=\"custom/model\",\n    tensor_parallel_size=8,\n    trust_remote_code=True,\n    revision=\"abc123\",\n    temperature=0.7,\n    top_p=0.8,\n)\n</code></pre>"},{"location":"swarms/models/vllm/#methods","title":"Methods","text":""},{"location":"swarms/models/vllm/#run","title":"run","text":"<p>The <code>run</code> method is used to generate text using the vLLM model. It takes a <code>task</code> parameter, which is a text prompt or description of the task you want the model to perform. It returns the generated text as a string.</p> <pre><code># Generate text using vLLM\nresult = vllm.run(\"Generate a creative story about a dragon.\")\nprint(result)\n</code></pre>"},{"location":"swarms/models/vllm/#usage-examples","title":"Usage Examples","text":"<p>Here are three usage examples demonstrating different ways to use vLLM:</p> <p>Example 1: Basic Text Generation</p> <pre><code>from swarms.models import vLLM\n\n# Initialize vLLM\nvllm = vLLM()\n\n# Generate text for a given task\ngenerated_text = vllm.run(\"Generate a summary of a scientific paper.\")\nprint(generated_text)\n</code></pre> <p>Example 2: Custom Model and Parameters</p> <pre><code>from swarms.models import vLLM\n\n# Initialize vLLM with custom model and parameters\ncustom_vllm = vLLM(\n    model_name=\"custom/model\",\n    tensor_parallel_size=8,\n    trust_remote_code=True,\n    revision=\"abc123\",\n    temperature=0.7,\n    top_p=0.8,\n)\n\n# Generate text with custom configuration\ngenerated_text = custom_vllm.run(\"Create a poem about nature.\")\nprint(generated_text)\n</code></pre> <p>Example 3: Batch Processing</p> <pre><code>from swarms.models import vLLM\n\n# Initialize vLLM\nvllm = vLLM()\n\n# Generate multiple texts in batch\ntasks = [\n    \"Translate the following sentence to French: 'Hello, world!'\",\n    \"Write a short story set in a futuristic world.\",\n    \"Summarize the main points of a news article about climate change.\",\n]\n\nfor task in tasks:\n    generated_text = vllm.run(task)\n    print(generated_text)\n</code></pre>"},{"location":"swarms/models/vllm/#common-issues-and-troubleshooting","title":"Common Issues and Troubleshooting","text":"<ul> <li> <p>ImportError: If you encounter an <code>ImportError</code> related to vLLM, make sure you have installed it using <code>pip install vllm</code>.</p> </li> <li> <p>Model Configuration: Ensure that you provide valid model names and configurations when initializing vLLM. Invalid model names or parameters can lead to errors.</p> </li> <li> <p>Text Generation: Be cautious with text generation parameters like <code>temperature</code> and <code>top_p</code>. Experiment with different values to achieve the desired text quality.</p> </li> </ul>"},{"location":"swarms/models/vllm/#references-and-resources","title":"References and Resources","text":"<p>For more information and resources related to vLLM and language models, refer to the following:</p> <ul> <li>vLLM GitHub Repository</li> <li>Hugging Face Transformers Documentation</li> <li>Facebook <code>opt-13b</code> Model Documentation</li> </ul> <p>This concludes the documentation for the vLLM library. We hope this guide helps you effectively use vLLM for text generation tasks. If you have any questions or encounter issues, please refer to the troubleshooting section or seek assistance from the vLLM community. Happy text generation!</p>"},{"location":"swarms/models/zephyr/","title":"<code>Zephyr</code> Documentation","text":""},{"location":"swarms/models/zephyr/#introduction","title":"Introduction","text":"<p>Welcome to the documentation for Zephyr, a language model by Hugging Face designed for text generation tasks. Zephyr is capable of generating text in response to prompts and is highly customizable using various parameters. This document will provide you with a detailed understanding of Zephyr, its purpose, and how to effectively use it in your projects.</p>"},{"location":"swarms/models/zephyr/#overview","title":"Overview","text":"<p>Zephyr is a text generation model that can be used to generate human-like text based on a given prompt. It utilizes the power of transformers and fine-tuning to create coherent and contextually relevant text. Users can control the generated text's characteristics through parameters such as <code>temperature</code>, <code>top_k</code>, <code>top_p</code>, and <code>max_new_tokens</code>.</p>"},{"location":"swarms/models/zephyr/#class-definition","title":"Class Definition","text":"<pre><code>class Zephyr:\n    def __init__(\n        self,\n        max_new_tokens: int = 300,\n        temperature: float = 0.5,\n        top_k: float = 50,\n        top_p: float = 0.95,\n    ):\n        \"\"\"\n        Initialize the Zephyr model.\n\n        Args:\n            max_new_tokens (int): The maximum number of tokens in the generated text.\n            temperature (float): The temperature parameter, controlling the randomness of the output.\n            top_k (float): The top-k parameter, limiting the vocabulary used in generation.\n            top_p (float): The top-p parameter, controlling the diversity of the output.\n        \"\"\"\n</code></pre>"},{"location":"swarms/models/zephyr/#parameters","title":"Parameters","text":"<ul> <li><code>max_new_tokens</code> (int): The maximum number of tokens in the generated text.</li> <li><code>temperature</code> (float): The temperature parameter, controlling the randomness of the output.</li> <li><code>top_k</code> (float): The top-k parameter, limiting the vocabulary used in generation.</li> <li><code>top_p</code> (float): The top-p parameter, controlling the diversity of the output.</li> </ul>"},{"location":"swarms/models/zephyr/#usage","title":"Usage","text":"<p>To use the Zephyr model, follow these steps:</p> <ol> <li>Initialize the Zephyr model with your desired parameters:</li> </ol> <pre><code>from swarms.models import Zephyr\n\nmodel = Zephyr(max_new_tokens=300, temperature=0.7, top_k=50, top_p=0.95)\n</code></pre> <ol> <li>Generate text by providing a prompt:</li> </ol> <pre><code>output = model(\"Generate a funny joke about cats\")\nprint(output)\n</code></pre>"},{"location":"swarms/models/zephyr/#example-1-generating-a-joke","title":"Example 1 - Generating a Joke","text":"<pre><code>model = Zephyr(max_new_tokens=100)\noutput = model(\"Tell me a joke about programmers\")\nprint(output)\n</code></pre>"},{"location":"swarms/models/zephyr/#example-2-writing-poetry","title":"Example 2 - Writing Poetry","text":"<pre><code>model = Zephyr(temperature=0.2, top_k=30)\noutput = model(\"Write a short poem about the moon\")\nprint(output)\n</code></pre>"},{"location":"swarms/models/zephyr/#example-3-asking-for-advice","title":"Example 3 - Asking for Advice","text":"<pre><code>model = Zephyr(temperature=0.8, top_p=0.9)\noutput = model(\"Give me advice on starting a healthy lifestyle\")\nprint(output)\n</code></pre>"},{"location":"swarms/models/zephyr/#additional-information","title":"Additional Information","text":"<ul> <li>Zephyr is based on the Hugging Face Transformers library and uses the \"HuggingFaceH4/zephyr-7b-alpha\" model.</li> <li>The generated text can vary based on the values of <code>temperature</code>, <code>top_k</code>, and <code>top_p</code>. Experiment with these parameters to achieve the desired output.</li> <li>The <code>max_new_tokens</code> parameter can be adjusted to control the length of the generated text.</li> <li>You can integrate Zephyr into chat applications, creative writing projects, or any task that involves generating human-like text.</li> </ul> <p>That concludes the documentation for Zephyr. We hope you find this model useful for your text generation needs! If you have any questions or encounter any issues, please refer to the Hugging Face Transformers documentation for further assistance. Happy text generation!</p>"},{"location":"swarms/models/zeroscope/","title":"Module Name: ZeroscopeTTV","text":""},{"location":"swarms/models/zeroscope/#introduction","title":"Introduction","text":"<p>The ZeroscopeTTV module is a versatile zero-shot video generation model designed to create videos based on textual descriptions. This comprehensive documentation will provide you with an in-depth understanding of the ZeroscopeTTV module, its architecture, purpose, arguments, and detailed usage examples.</p>"},{"location":"swarms/models/zeroscope/#purpose","title":"Purpose","text":"<p>The ZeroscopeTTV module serves as a powerful tool for generating videos from text descriptions. Whether you need to create video content for various applications, visualize textual data, or explore the capabilities of ZeroscopeTTV, this module offers a flexible and efficient solution. With its easy-to-use interface, you can quickly generate videos based on your textual input.</p>"},{"location":"swarms/models/zeroscope/#architecture","title":"Architecture","text":"<p>The ZeroscopeTTV module is built on top of the Diffusers library, leveraging the power of diffusion models for video generation. It allows you to specify various parameters such as model name, data type, chunk size, dimensions, and more to customize the video generation process. The model performs multiple inference steps and utilizes a diffusion pipeline to generate high-quality videos.</p>"},{"location":"swarms/models/zeroscope/#class-definition","title":"Class Definition","text":""},{"location":"swarms/models/zeroscope/#zeroscopettvmodel_name-str-cerspensezeroscope_v2_576w-torch_dtypetorchfloat16-chunk_size-int-1-dim-int-1-num_inference_steps-int-40-height-int-320-width-int-576-num_frames-int-36","title":"<code>ZeroscopeTTV(model_name: str = \"cerspense/zeroscope_v2_576w\", torch_dtype=torch.float16, chunk_size: int = 1, dim: int = 1, num_inference_steps: int = 40, height: int = 320, width: int = 576, num_frames: int = 36)</code>","text":""},{"location":"swarms/models/zeroscope/#parameters","title":"Parameters","text":"<ul> <li><code>model_name</code> (str, optional): The name of the pre-trained model to use. Default is \"cerspense/zeroscope_v2_576w\".</li> <li><code>torch_dtype</code> (torch.dtype, optional): The torch data type to use for computations. Default is torch.float16.</li> <li><code>chunk_size</code> (int, optional): The size of chunks for forward chunking. Default is 1.</li> <li><code>dim</code> (int, optional): The dimension along which the input is split for forward chunking. Default is 1.</li> <li><code>num_inference_steps</code> (int, optional): The number of inference steps to perform. Default is 40.</li> <li><code>height</code> (int, optional): The height of the video frames. Default is 320.</li> <li><code>width</code> (int, optional): The width of the video frames. Default is 576.</li> <li><code>num_frames</code> (int, optional): The number of frames in the video. Default is 36.</li> </ul>"},{"location":"swarms/models/zeroscope/#functionality-and-usage","title":"Functionality and Usage","text":"<p>The ZeroscopeTTV module offers a straightforward interface for video generation. It accepts a textual task or description as input and returns the path to the generated video.</p>"},{"location":"swarms/models/zeroscope/#runtask-str-none-args-kwargs-str","title":"<code>run(task: str = None, *args, **kwargs) -&gt; str</code>","text":""},{"location":"swarms/models/zeroscope/#parameters_1","title":"Parameters","text":"<ul> <li><code>task</code> (str, optional): The input task or description for video generation.</li> </ul>"},{"location":"swarms/models/zeroscope/#returns","title":"Returns","text":"<ul> <li><code>str</code>: The path to the generated video.</li> </ul>"},{"location":"swarms/models/zeroscope/#usage-examples","title":"Usage Examples","text":""},{"location":"swarms/models/zeroscope/#example-1-basic-usage","title":"Example 1: Basic Usage","text":"<pre><code>from swarms.models import ZeroscopeTTV\n\n# Initialize the ZeroscopeTTV model\nzeroscope = ZeroscopeTTV()\n\n# Generate a video based on a textual description\ntask = \"A bird flying in the sky.\"\nvideo_path = zeroscope.run(task)\nprint(f\"Generated video path: {video_path}\")\n</code></pre>"},{"location":"swarms/models/zeroscope/#example-2-custom-model-and-parameters","title":"Example 2: Custom Model and Parameters","text":"<p>You can specify a custom pre-trained model and adjust various parameters for video generation.</p> <pre><code>custom_model_name = \"your_custom_model_path\"\ncustom_dtype = torch.float32\ncustom_chunk_size = 2\ncustom_dim = 2\ncustom_num_inference_steps = 50\ncustom_height = 480\ncustom_width = 720\ncustom_num_frames = 48\n\ncustom_zeroscope = ZeroscopeTTV(\n    model_name=custom_model_name,\n    torch_dtype=custom_dtype,\n    chunk_size=custom_chunk_size,\n    dim=custom_dim,\n    num_inference_steps=custom_num_inference_steps,\n    height=custom_height,\n    width=custom_width,\n    num_frames=custom_num_frames,\n)\n\ntask = \"A car driving on the road.\"\nvideo_path = custom_zeroscope.run(task)\nprint(f\"Generated video path: {video_path}\")\n</code></pre>"},{"location":"swarms/models/zeroscope/#example-3-exporting-video-frames","title":"Example 3: Exporting Video Frames","text":"<p>You can also export individual video frames if needed.</p> <pre><code>from swarms.models import export_to_video\n\n# Generate video frames\nvideo_frames = zeroscope.run(\"A boat sailing on the water.\")\n\n# Export video frames to a video file\nvideo_path = export_to_video(video_frames)\nprint(f\"Generated video path: {video_path}\")\n</code></pre>"},{"location":"swarms/models/zeroscope/#additional-information-and-tips","title":"Additional Information and Tips","text":"<ul> <li>Ensure that the input textual task or description is clear and descriptive to achieve the desired video output.</li> <li>Experiment with different parameter settings to control video resolution, frame count, and inference steps.</li> <li>Use the <code>export_to_video</code> function to export individual video frames as needed.</li> <li>Monitor the progress and output paths to access the generated videos.</li> </ul>"},{"location":"swarms/models/zeroscope/#conclusion","title":"Conclusion","text":"<p>The ZeroscopeTTV module is a powerful solution for zero-shot video generation based on textual descriptions. Whether you are creating videos for storytelling, data visualization, or other applications, ZeroscopeTTV offers a versatile and efficient way to bring your text to life. With a flexible interface and customizable parameters, it empowers you to generate high-quality videos with ease.</p> <p>If you encounter any issues or have questions about using ZeroscopeTTV, please refer to the Diffusers library documentation or reach out to their support team for further assistance. Enjoy creating videos with ZeroscopeTTV!</p>"},{"location":"swarms/structs/abstractswarm/","title":"<code>AbstractSwarm</code> Documentation","text":""},{"location":"swarms/structs/abstractswarm/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction</li> <li>Class Definition</li> <li>Methods<ul> <li>communicate()</li> <li>run()</li> <li>arun()</li> <li>add_worker(worker)</li> <li>remove_worker(worker)</li> <li>broadcast(message, sender)</li> <li>reset()</li> <li>plan(task)</li> <li>direct_message(message, sender, recipient)</li> <li>autoscaler(num_workers, worker)</li> <li>get_worker_by_id(id)</li> <li>get_worker_by_name(name)</li> <li>assign_task(worker, task)</li> <li>get_all_tasks(worker, task)</li> <li>get_finished_tasks()</li> <li>get_pending_tasks()</li> <li>pause_worker(worker, worker_id)</li> <li>resume_worker(worker, worker_id)</li> <li>stop_worker(worker, worker_id)</li> <li>restart_worker(worker)</li> <li>scale_up(num_worker)</li> <li>scale_down(num_worker)</li> <li>scale_to(num_worker)</li> <li>get_all_workers()</li> <li>get_swarm_size()</li> <li>get_swarm_status()</li> <li>save_swarm_state()</li> </ul> </li> </ol>"},{"location":"swarms/structs/abstractswarm/#1-introduction","title":"1. Introduction","text":"<p>The Swarms library is designed to provide a framework for swarm simulation architectures. Swarms are collections of autonomous agents or workers that collaborate to perform tasks and achieve common goals. This documentation will guide you through the functionality and usage of the Swarms library, explaining the purpose and implementation details of the provided classes and methods.</p>"},{"location":"swarms/structs/abstractswarm/#2-class-definition","title":"2. Class Definition","text":""},{"location":"swarms/structs/abstractswarm/#abstractswarm-class","title":"<code>AbstractSwarm</code> Class","text":"<p>The <code>AbstractSwarm</code> class is an abstract base class that serves as the foundation for swarm simulation architectures. It defines the core functionality and methods required to manage and interact with a swarm of workers.</p> <pre><code>from abc import ABC, abstractmethod\nfrom typing import List\n\nfrom swarms.swarms.base import AbstractWorker\n\n\nclass AbstractSwarm(ABC):\n    \"\"\"\n    Abstract class for swarm simulation architectures\n\n    Methods:\n    ---------\n    ...\n    \"\"\"\n\n    # The class definition and constructor are provided here.\n\n    @abstractmethod\n    def __init__(self, workers: List[\"AbstractWorker\"]):\n        \"\"\"Initialize the swarm with workers\"\"\"\n\n    # Other abstract methods are listed here.\n</code></pre>"},{"location":"swarms/structs/abstractswarm/#3-methods","title":"3. Methods","text":""},{"location":"swarms/structs/abstractswarm/#communicate","title":"<code>communicate()</code>","text":"<p>The <code>communicate()</code> method allows the swarm to exchange information through the orchestrator, protocols, and the universal communication layer.</p> <p>Usage Example 1:</p> <pre><code>swarm = YourSwarmClass(workers)\nswarm.communicate()\n</code></pre> <p>Usage Example 2:</p> <pre><code># Another example of using the communicate method\nswarm = YourSwarmClass(workers)\nswarm.communicate()\n</code></pre>"},{"location":"swarms/structs/abstractswarm/#run","title":"<code>run()</code>","text":"<p>The <code>run()</code> method executes the swarm, initiating its activities.</p> <p>Usage Example 1:</p> <pre><code>swarm = YourSwarmClass(workers)\nswarm.run()\n</code></pre> <p>Usage Example 2:</p> <pre><code># Another example of running the swarm\nswarm = YourSwarmClass(workers)\nswarm.run()\n</code></pre>"},{"location":"swarms/structs/abstractswarm/#arun","title":"<code>arun()</code>","text":"<p>The <code>arun()</code> method runs the swarm asynchronously, allowing for parallel execution of tasks.</p> <p>Usage Example 1:</p> <pre><code>swarm = YourSwarmClass(workers)\nswarm.arun()\n</code></pre> <p>Usage Example 2:</p> <pre><code># Another example of running the swarm asynchronously\nswarm = YourSwarmClass(workers)\nswarm.arun()\n</code></pre>"},{"location":"swarms/structs/abstractswarm/#add_workerworker-abstractworker","title":"<code>add_worker(worker: \"AbstractWorker\")</code>","text":"<p>The <code>add_worker()</code> method adds a worker to the swarm.</p> <p>Parameters: - <code>worker</code> (AbstractWorker): The worker to be added to the swarm.</p> <p>Usage Example:</p> <pre><code>swarm = YourSwarmClass([])\nworker = YourWorkerClass()\nswarm.add_worker(worker)\n</code></pre>"},{"location":"swarms/structs/abstractswarm/#remove_workerworker-abstractworker","title":"<code>remove_worker(worker: \"AbstractWorker\")</code>","text":"<p>The <code>remove_worker()</code> method removes a worker from the swarm.</p> <p>Parameters: - <code>worker</code> (AbstractWorker): The worker to be removed from the swarm.</p> <p>Usage Example:</p> <pre><code>swarm = YourSwarmClass(workers)\nworker = swarm.get_worker_by_id(\"worker_id\")\nswarm.remove_worker(worker)\n</code></pre>"},{"location":"swarms/structs/abstractswarm/#broadcastmessage-str-sender-optionalabstractworker-none","title":"<code>broadcast(message: str, sender: Optional[\"AbstractWorker\"] = None)</code>","text":"<p>The <code>broadcast()</code> method sends a message to all workers in the swarm.</p> <p>Parameters: - <code>message</code> (str): The message to be broadcasted. - <code>sender</code> (Optional[AbstractWorker]): The sender of the message (optional).</p> <p>Usage Example 1:</p> <pre><code>swarm = YourSwarmClass(workers)\nmessage = \"Hello, everyone!\"\nswarm.broadcast(message)\n</code></pre> <p>Usage Example 2:</p> <pre><code># Another example of broadcasting a message\nswarm = YourSwarmClass(workers)\nmessage = \"Important announcement!\"\nsender = swarm.get_worker_by_name(\"Supervisor\")\nswarm.broadcast(message, sender)\n</code></pre>"},{"location":"swarms/structs/abstractswarm/#reset","title":"<code>reset()</code>","text":"<p>The <code>reset()</code> method resets the swarm to its initial state.</p> <p>Usage Example:</p> <pre><code>swarm = YourSwarmClass(workers)\nswarm.reset()\n</code></pre>"},{"location":"swarms/structs/abstractswarm/#plantask-str","title":"<code>plan(task: str)</code>","text":"<p>The <code>plan()</code> method instructs workers to individually plan using a workflow or pipeline for a specified task.</p> <p>Parameters: - <code>task</code> (str): The task for which workers should plan.</p> <p>Usage Example:</p> <pre><code>swarm = YourSwarmClass(workers)\ntask = \"Perform data analysis\"\nswarm.plan(task)\n</code></pre>"},{"location":"swarms/structs/abstractswarm/#direct_messagemessage-str-sender-abstractworker-recipient-abstractworker","title":"<code>direct_message(message: str, sender: \"AbstractWorker\", recipient: \"AbstractWorker\")</code>","text":"<p>The <code>direct_message()</code> method sends a direct message from one worker to another.</p> <p>Parameters: - <code>message</code> (str): The message to be sent. - <code>sender</code> (AbstractWorker): The sender of the message. - <code>recipient</code> (AbstractWorker): The recipient of the message.</p> <p>Usage Example:</p> <pre><code>swarm = YourSwarmClass(workers)\nsender = swarm.get_worker_by_name(\"Worker1\")\nrecipient = swarm.get_worker_by_name(\"Worker2\")\nmessage = \"Hello\n\n, Worker2!\"\nswarm.direct_message(message, sender, recipient)\n</code></pre>"},{"location":"swarms/structs/abstractswarm/#autoscalernum_workers-int-worker-listabstractworker","title":"<code>autoscaler(num_workers: int, worker: List[\"AbstractWorker\"])</code>","text":"<p>The <code>autoscaler()</code> method acts as an autoscaler, dynamically adjusting the number of workers based on system load or other criteria.</p> <p>Parameters: - <code>num_workers</code> (int): The desired number of workers. - <code>worker</code> (List[AbstractWorker]): A list of workers to be managed by the autoscaler.</p> <p>Usage Example:</p> <pre><code>swarm = YourSwarmClass([])\nworkers = [YourWorkerClass() for _ in range(10)]\nswarm.autoscaler(5, workers)\n</code></pre>"},{"location":"swarms/structs/abstractswarm/#get_worker_by_idid-str-abstractworker","title":"<code>get_worker_by_id(id: str) -&gt; \"AbstractWorker\"</code>","text":"<p>The <code>get_worker_by_id()</code> method locates a worker in the swarm by their ID.</p> <p>Parameters: - <code>id</code> (str): The ID of the worker to locate.</p> <p>Returns: - <code>AbstractWorker</code>: The worker with the specified ID.</p> <p>Usage Example:</p> <pre><code>swarm = YourSwarmClass(workers)\nworker_id = \"worker_123\"\nworker = swarm.get_worker_by_id(worker_id)\n</code></pre>"},{"location":"swarms/structs/abstractswarm/#get_worker_by_namename-str-abstractworker","title":"<code>get_worker_by_name(name: str) -&gt; \"AbstractWorker\"</code>","text":"<p>The <code>get_worker_by_name()</code> method locates a worker in the swarm by their name.</p> <p>Parameters: - <code>name</code> (str): The name of the worker to locate.</p> <p>Returns: - <code>AbstractWorker</code>: The worker with the specified name.</p> <p>Usage Example:</p> <pre><code>swarm = YourSwarmClass(workers)\nworker_name = \"Alice\"\nworker = swarm.get_worker_by_name(worker_name)\n</code></pre>"},{"location":"swarms/structs/abstractswarm/#assign_taskworker-abstractworker-task-any-dict","title":"<code>assign_task(worker: \"AbstractWorker\", task: Any) -&gt; Dict</code>","text":"<p>The <code>assign_task()</code> method assigns a task to a specific worker.</p> <p>Parameters: - <code>worker</code> (AbstractWorker): The worker to whom the task should be assigned. - <code>task</code> (Any): The task to be assigned.</p> <p>Returns: - <code>Dict</code>: A dictionary indicating the status of the task assignment.</p> <p>Usage Example:</p> <pre><code>swarm = YourSwarmClass(workers)\nworker = swarm.get_worker_by_name(\"Worker1\")\ntask = \"Perform data analysis\"\nresult = swarm.assign_task(worker, task)\n</code></pre>"},{"location":"swarms/structs/abstractswarm/#get_all_tasksworker-abstractworker-task-any","title":"<code>get_all_tasks(worker: \"AbstractWorker\", task: Any)</code>","text":"<p>The <code>get_all_tasks()</code> method retrieves all tasks assigned to a specific worker.</p> <p>Parameters: - <code>worker</code> (AbstractWorker): The worker for whom tasks should be retrieved. - <code>task</code> (Any): The task to be retrieved.</p> <p>Usage Example:</p> <pre><code>swarm = YourSwarmClass(workers)\nworker = swarm.get_worker_by_name(\"Worker1\")\ntasks = swarm.get_all_tasks(worker, \"data analysis\")\n</code></pre>"},{"location":"swarms/structs/abstractswarm/#get_finished_tasks-listdict","title":"<code>get_finished_tasks() -&gt; List[Dict]</code>","text":"<p>The <code>get_finished_tasks()</code> method retrieves all tasks that have been completed by the workers in the swarm.</p> <p>Returns: - <code>List[Dict]</code>: A list of dictionaries representing finished tasks.</p> <p>Usage Example:</p> <pre><code>swarm = YourSwarmClass(workers)\nfinished_tasks = swarm.get_finished_tasks()\n</code></pre>"},{"location":"swarms/structs/abstractswarm/#get_pending_tasks-listdict","title":"<code>get_pending_tasks() -&gt; List[Dict]</code>","text":"<p>The <code>get_pending_tasks()</code> method retrieves all tasks that are pending or yet to be completed by the workers in the swarm.</p> <p>Returns: - <code>List[Dict]</code>: A list of dictionaries representing pending tasks.</p> <p>Usage Example:</p> <pre><code>swarm = YourSwarmClass(workers)\npending_tasks = swarm.get_pending_tasks()\n</code></pre>"},{"location":"swarms/structs/abstractswarm/#pause_workerworker-abstractworker-worker_id-str","title":"<code>pause_worker(worker: \"AbstractWorker\", worker_id: str)</code>","text":"<p>The <code>pause_worker()</code> method pauses a specific worker, temporarily suspending their activities.</p> <p>Parameters: - <code>worker</code> (AbstractWorker): The worker to be paused. - <code>worker_id</code> (str): The ID of the worker to be paused.</p> <p>Usage Example:</p> <pre><code>swarm = YourSwarmClass(workers)\nworker = swarm.get_worker_by_name(\"Worker1\")\nworker_id = \"worker_123\"\nswarm.pause_worker(worker, worker_id)\n</code></pre>"},{"location":"swarms/structs/abstractswarm/#resume_workerworker-abstractworker-worker_id-str","title":"<code>resume_worker(worker: \"AbstractWorker\", worker_id: str)</code>","text":"<p>The <code>resume_worker()</code> method resumes a paused worker, allowing them to continue their activities.</p> <p>Parameters: - <code>worker</code> (AbstractWorker): The worker to be resumed. - <code>worker_id</code> (str): The ID of the worker to be resumed.</p> <p>Usage Example:</p> <pre><code>swarm = YourSwarmClass(workers)\nworker = swarm.get_worker_by_name(\"Worker1\")\nworker_id = \"worker_123\"\nswarm.resume_worker(worker, worker_id)\n</code></pre>"},{"location":"swarms/structs/abstractswarm/#stop_workerworker-abstractworker-worker_id-str","title":"<code>stop_worker(worker: \"AbstractWorker\", worker_id: str)</code>","text":"<p>The <code>stop_worker()</code> method stops a specific worker, terminating their activities.</p> <p>Parameters: - <code>worker</code> (AbstractWorker): The worker to be stopped. - <code>worker_id</code> (str): The ID of the worker to be stopped.</p> <p>Usage Example:</p> <pre><code>swarm = YourSwarmClass(workers)\nworker = swarm.get_worker_by_name(\"Worker1\")\nworker_id = \"worker_123\"\nswarm.stop_worker(worker, worker_id)\n</code></pre>"},{"location":"swarms/structs/abstractswarm/#restart_workerworker-abstractworker","title":"<code>restart_worker(worker: \"AbstractWorker\")</code>","text":"<p>The <code>restart_worker()</code> method restarts a worker, resetting them to their initial state.</p> <p>Parameters: - <code>worker</code> (AbstractWorker): The worker to be restarted.</p> <p>Usage Example:</p> <pre><code>swarm = YourSwarmClass(workers)\nworker = swarm.get_worker_by_name(\"Worker1\")\nswarm.restart_worker(worker)\n</code></pre>"},{"location":"swarms/structs/abstractswarm/#scale_upnum_worker-int","title":"<code>scale_up(num_worker: int)</code>","text":"<p>The <code>scale_up()</code> method increases the number of workers in the swarm.</p> <p>Parameters: - <code>num_worker</code> (int): The number of workers to add to the swarm.</p> <p>Usage Example:</p> <pre><code>swarm = YourSwarmClass(workers)\nswarm.scale_up(5)\n</code></pre>"},{"location":"swarms/structs/abstractswarm/#scale_downnum_worker-int","title":"<code>scale_down(num_worker: int)</code>","text":"<p>The <code>scale_down()</code> method decreases the number of workers in the swarm.</p> <p>Parameters: - <code>num_worker</code> (int): The number of workers to remove from the swarm.</p> <p>Usage Example:</p> <pre><code>swarm = YourSwarmClass(workers)\nswarm.scale_down(3)\n</code></pre>"},{"location":"swarms/structs/abstractswarm/#scale_tonum_worker-int","title":"<code>scale_to(num_worker: int)</code>","text":"<p>The <code>scale_to()</code> method scales the swarm to a specific number of workers.</p> <p>Parameters: - <code>num_worker</code> (int): The desired number of workers.</p> <p>Usage Example:</p> <pre><code>swarm = YourSwarmClass(workers)\nswarm.scale_to(10)\n</code></pre>"},{"location":"swarms/structs/abstractswarm/#get","title":"`get","text":"<p>_all_workers() -&gt; List[\"AbstractWorker\"]` </p> <p>The <code>get_all_workers()</code> method retrieves a list of all workers in the swarm.</p> <p>Returns: - <code>List[AbstractWorker]</code>: A list of all workers in the swarm.</p> <p>Usage Example:</p> <pre><code>swarm = YourSwarmClass(workers)\nall_workers = swarm.get_all_workers()\n</code></pre>"},{"location":"swarms/structs/abstractswarm/#get_swarm_size-int","title":"<code>get_swarm_size() -&gt; int</code>","text":"<p>The <code>get_swarm_size()</code> method returns the size of the swarm, which is the total number of workers.</p> <p>Returns: - <code>int</code>: The size of the swarm.</p> <p>Usage Example:</p> <pre><code>swarm = YourSwarmClass(workers)\nswarm_size = swarm.get_swarm_size()\n</code></pre>"},{"location":"swarms/structs/abstractswarm/#get_swarm_status-dict","title":"<code>get_swarm_status() -&gt; Dict</code>","text":"<p>The <code>get_swarm_status()</code> method provides information about the current status of the swarm.</p> <p>Returns: - <code>Dict</code>: A dictionary containing various status indicators for the swarm.</p> <p>Usage Example:</p> <pre><code>swarm = YourSwarmClass(workers)\nswarm_status = swarm.get_swarm_status()\n</code></pre>"},{"location":"swarms/structs/abstractswarm/#save_swarm_state","title":"<code>save_swarm_state()</code>","text":"<p>The <code>save_swarm_state()</code> method allows you to save the current state of the swarm, including worker configurations and task assignments.</p> <p>Usage Example:</p> <pre><code>swarm = YourSwarmClass(workers)\nswarm.save_swarm_state()\n</code></pre> <p>This comprehensive documentation covers the Swarms library, including the <code>AbstractSwarm</code> class and its methods. You can use this documentation as a guide to understanding and effectively utilizing the Swarms framework for swarm simulation architectures. Feel free to explore further and adapt the library to your specific use cases.</p>"},{"location":"swarms/structs/agent/","title":"<code>Agent</code> Documentation","text":""},{"location":"swarms/structs/agent/#overview","title":"Overview","text":"<p>The <code>Agent</code> class is a Python module designed to facilitate interactions with a language model, particularly one that operates as an autonomous agent. This class is part of a larger framework aimed at creating conversational agents using advanced language models like GPT-3. It enables you to establish a conversational loop with the model, generate responses, collect feedback, and control the agent of the conversation.</p> <p>In this documentation, you will learn how to use the <code>Agent</code> class effectively, its purpose, and how it can be integrated into your projects.</p>"},{"location":"swarms/structs/agent/#purpose","title":"Purpose","text":"<p>The <code>Agent</code> class serves several key purposes:</p> <ol> <li> <p>Conversational Loop: It establishes a conversational loop with a language model. This means it allows you to interact with the model in a back-and-forth manner, taking turns in the conversation.</p> </li> <li> <p>Feedback Collection: The class allows users to provide feedback on the responses generated by the model. This feedback can be valuable for training and improving the model's responses over time.</p> </li> <li> <p>Stoppable Conversation: You can define custom stopping conditions for the conversation, allowing you to stop the interaction based on specific criteria. For example, you can stop the conversation if a certain keyword is detected in the responses.</p> </li> <li> <p>Retry Mechanism: The class includes a retry mechanism that can be helpful if there are issues generating responses from the model. It attempts to generate a response multiple times before raising an error.</p> </li> </ol>"},{"location":"swarms/structs/agent/#class-definition","title":"Class Definition","text":"<p>The <code>Agent</code> class has the following constructor:</p> <pre><code>class Agent:\n    def __init__(\n        self,\n        llm: Any,\n        max_loops: int = 5,\n        stopping_condition: Optional[Callable[[str], bool]] = None,\n        loop_interval: int = 1,\n        retry_attempts: int = 3,\n        retry_interval: int = 1,\n        interactive: bool = False,\n        **kwargs: Any,\n    ):\n</code></pre>"},{"location":"swarms/structs/agent/#parameters","title":"Parameters","text":"<ul> <li><code>llm</code> (Any): The language model with which you want to interact.</li> <li><code>max_loops</code> (int): The maximum number of conversation loops. Default is 5.</li> <li><code>stopping_condition</code> (Optional[Callable[[str], bool]]): A custom stopping condition function. Default is <code>None</code>.</li> <li><code>loop_interval</code> (int): The time interval (in seconds) between conversation loops. Default is 1 second.</li> <li><code>retry_attempts</code> (int): The number of retry attempts if response generation fails. Default is 3.</li> <li><code>retry_interval</code> (int): The time interval (in seconds) between retry attempts. Default is 1 second.</li> <li><code>interactive</code> (bool): Set to <code>True</code> if the conversation is interactive, meaning the user is involved. Default is <code>False</code>.</li> </ul>"},{"location":"swarms/structs/agent/#usage","title":"Usage","text":"<p>The <code>Agent</code> class can be used to create a conversational loop with the language model. Here's how you can use it:</p> <pre><code>from swarms.structs import Agent\n\nagent = Agent(llm=my_language_model, max_loops=5)\n\n# Define a starting task or message\ninitial_task = \"Generate a 10,000 word blog on health and wellness.\"\n\n# Run the conversation loop\nfinal_response = agent.run(initial_task)\n</code></pre>"},{"location":"swarms/structs/agent/#feedback","title":"Feedback","text":"<p>You can collect feedback during the conversation using the <code>provide_feedback</code> method:</p> <pre><code>agent.provide_feedback(\n    \"Generate an SOP for new sales employees on the best cold sales practices\"\n)\n</code></pre>"},{"location":"swarms/structs/agent/#stopping-condition","title":"Stopping Condition","text":"<p>You can define a custom stopping condition using a function. For example, you can stop the conversation if the response contains the word \"Stop\":</p> <pre><code>from swarms.structs import Agent\n\n\ndef stop_when_repeats(response: str) -&gt; bool:\n    return \"Stop\" in response.lower()\n\n\nagent = Agent(llm=my_language_model, max_loops=5, stopping_condition=stop_when_repeats)\n</code></pre>"},{"location":"swarms/structs/agent/#retry-mechanism","title":"Retry Mechanism","text":"<p>If the response generation fails, the class will retry up to the specified number of attempts:</p> <pre><code>agent = Agent(llm=my_language_model, max_loops=5, retry_attempts=3)\n</code></pre>"},{"location":"swarms/structs/agent/#additional-information","title":"Additional Information","text":"<ul> <li> <p>To save the conversation history to a file, you can use the <code>save</code> method.</p> </li> <li> <p>To load a previously saved conversation history, you can use the <code>load</code> method.</p> </li> <li> <p>The class includes methods for bulk running conversations with multiple input sets.</p> </li> </ul>"},{"location":"swarms/structs/agent/#examples","title":"Examples","text":"<p>Here are three usage examples:</p>"},{"location":"swarms/structs/agent/#example-1-simple-conversation","title":"Example 1: Simple Conversation","text":"<pre><code># Select any Language model from the models folder\nfrom swarms.models import Mistral, OpenAIChat\nfrom swarms.structs import Agent\n\nllm = Mistral()\n# llm = OpenAIChat()\n\nagent = Agent(llm=llm, max_loops=5)\n\n# Define a starting task or message\ninitial_task = \"Generate an long form analysis on the transformer model architecture.\"\n\n# Run the conversation loop\nfinal_response = agent.run(initial_task)\n</code></pre>"},{"location":"swarms/structs/agent/#example-2-custom-stopping-condition","title":"Example 2: Custom Stopping Condition","text":"<pre><code>from swarms.structs import Agent\n\n\ndef stop_when_repeats(response: str) -&gt; bool:\n    return \"Stop\" in response.lower()\n\n\nagent = Agent(llm=llm, max_loops=5, stopping_condition=stop_when_repeats)\n</code></pre>"},{"location":"swarms/structs/agent/#example-3-interactive-conversation","title":"Example 3: Interactive Conversation","text":"<pre><code>from swarms.structs import Agent\n\nagent = Agent(llm=llm, max_loops=5, interactive=True)\n\n# Provide initial task\ninitial_task = \"Rank and prioritize the following financial documents and cut out 30% of our expenses\"\n\n# Run the conversation loop\nfinal_response = agent.run(initial_task)\n</code></pre>"},{"location":"swarms/structs/agent/#references-and-resources","title":"References and Resources","text":"<ul> <li>GitHub Repository</li> </ul>"},{"location":"swarms/structs/agent/#conclusion","title":"Conclusion","text":"<p>The <code>Agent</code> class provides a powerful way to interact with language models in a conversational manner. By defining custom stopping conditions, collecting feedback, and controlling the agent of the conversation, you can create engaging and interactive applications that make use of advanced language models.</p>"},{"location":"swarms/structs/artifact/","title":"swarms.structs Documentation","text":""},{"location":"swarms/structs/artifact/#introduction","title":"Introduction","text":"<p>The swarms.structs library provides a collection of classes for representing artifacts and their attributes. This documentation will provide an overview of the <code>Artifact</code> class, its attributes, functionality, and usage examples.</p>"},{"location":"swarms/structs/artifact/#artifact-class","title":"Artifact Class","text":"<p>The <code>Artifact</code> class represents an artifact and its attributes. It inherits from the <code>BaseModel</code> class and includes the following attributes:</p>"},{"location":"swarms/structs/artifact/#attributes","title":"Attributes","text":"<ol> <li><code>artifact_id (str)</code>: Id of the artifact.</li> <li><code>file_name (str)</code>: Filename of the artifact.</li> <li><code>relative_path (str, optional)</code>: Relative path of the artifact in the agent's workspace.</li> </ol> <p>These attributes are crucial for identifying and managing different artifacts within a given context.</p>"},{"location":"swarms/structs/artifact/#class-definition","title":"Class Definition","text":"<p>The <code>Artifact</code> class can be defined as follows:</p> <pre><code>class Artifact(BaseModel):\n    \"\"\"\n    Represents an artifact.\n\n    Attributes:\n        artifact_id (str): Id of the artifact.\n        file_name (str): Filename of the artifact.\n        relative_path (str, optional): Relative path of the artifact in the agent's workspace.\n    \"\"\"\n\n    artifact_id: str = Field(\n        ...,\n        description=\"Id of the artifact\",\n        example=\"b225e278-8b4c-4f99-a696-8facf19f0e56\",\n    )\n    file_name: str = Field(\n        ..., description=\"Filename of the artifact\", example=\"main.py\"\n    )\n    relative_path: Optional[str] = Field(\n        None,\n        description=(\"Relative path of the artifact in the agent's workspace\"),\n        example=\"python/code/\",\n    )\n</code></pre> <p>The <code>Artifact</code> class defines the mandatory and optional attributes and provides corresponding descriptions along with example values.</p>"},{"location":"swarms/structs/artifact/#functionality-and-usage","title":"Functionality and Usage","text":"<p>The <code>Artifact</code> class encapsulates the information and attributes representing an artifact. It provides a structured and organized way to manage artifacts within a given context.</p>"},{"location":"swarms/structs/artifact/#example-1-creating-an-artifact-instance","title":"Example 1: Creating an Artifact instance","text":"<p>To create an instance of the <code>Artifact</code> class, you can simply initialize it with the required attributes. Here's an example:</p> <pre><code>from swarms.structs import Artifact\n\nartifact_instance = Artifact(\n    artifact_id=\"b225e278-8b4c-4f99-a696-8facf19f0e56\",\n    file_name=\"main.py\",\n    relative_path=\"python/code/\",\n)\n</code></pre> <p>In this example, we create an instance of the <code>Artifact</code> class with the specified artifact details.</p>"},{"location":"swarms/structs/artifact/#example-2-accessing-artifact-attributes","title":"Example 2: Accessing Artifact attributes","text":"<p>You can access the attributes of the <code>Artifact</code> instance using dot notation. Here's how you can access the file name of the artifact:</p> <pre><code>print(artifact_instance.file_name)\n# Output: \"main.py\"\n</code></pre>"},{"location":"swarms/structs/artifact/#example-3-handling-optional-attributes","title":"Example 3: Handling optional attributes","text":"<p>If the <code>relative_path</code> attribute is not provided during artifact creation, it will default to <code>None</code>. Here's an example:</p> <pre><code>artifact_instance_no_path = Artifact(\n    artifact_id=\"c280s347-9b7d-3c68-m337-7abvf50j23k\", file_name=\"script.js\"\n)\n\nprint(artifact_instance_no_path.relative_path)\n# Output: None\n</code></pre> <p>By providing default values for optional attributes, the <code>Artifact</code> class allows flexibility in defining artifact instances.</p>"},{"location":"swarms/structs/artifact/#additional-information-and-tips","title":"Additional Information and Tips","text":"<p>The <code>Artifact</code> class represents a powerful and flexible means of handling various artifacts with different attributes. By utilizing this class, users can organize, manage, and streamline their artifacts with ease.</p>"},{"location":"swarms/structs/artifact/#references-and-resources","title":"References and Resources","text":"<p>For further details and references related to the swarms.structs library and the <code>Artifact</code> class, refer to the official documentation.</p> <p>This comprehensive documentation provides an in-depth understanding of the <code>Artifact</code> class, its attributes, functionality, and usage examples. By following the detailed examples and explanations, developers can effectively leverage the capabilities of the <code>Artifact</code> class within their projects.</p>"},{"location":"swarms/structs/artifactupload/","title":"swarms.structs","text":""},{"location":"swarms/structs/artifactupload/#overview","title":"Overview","text":"<p>Swarms is a library that provides tools for managing a distributed system of agents working together to achieve a common goal. The structs module within Swarms provides a set of data structures and classes that are used to represent artifacts, tasks, and other entities within the system. The <code>ArtifactUpload</code> class is one such data structure that represents the process of uploading an artifact to an agent's workspace.</p>"},{"location":"swarms/structs/artifactupload/#artifactupload","title":"ArtifactUpload","text":"<p>The <code>ArtifactUpload</code> class inherits from the <code>BaseModel</code> class. It has two attributes: <code>file</code> and <code>relative_path</code>. The <code>file</code> attribute represents the bytes of the file to be uploaded, while the <code>relative_path</code> attribute represents the relative path of the artifact in the agent's workspace.</p>"},{"location":"swarms/structs/artifactupload/#class-definition","title":"Class Definition","text":"<pre><code>class ArtifactUpload(BaseModel):\n    file: bytes = Field(..., description=\"File to upload\")\n    relative_path: Optional[str] = Field(\n        None,\n        description=(\"Relative path of the artifact in the agent's workspace\"),\n        example=\"python/code/\",\n    )\n</code></pre> <p>The <code>ArtifactUpload</code> class requires the <code>file</code> attribute to be passed as an argument. It is of type <code>bytes</code> and represents the file to be uploaded. The <code>relative_path</code> attribute is optional and is of type <code>str</code>. It represents the relative path of the artifact in the agent's workspace. If not provided, it defaults to <code>None</code>.</p>"},{"location":"swarms/structs/artifactupload/#functionality-and-usage","title":"Functionality and Usage","text":"<p>The <code>ArtifactUpload</code> class is used to create an instance of an artifact upload. It can be instantiated with or without a <code>relative_path</code>. Here is an example of how the class can be used:</p> <pre><code>from swarms.structs import ArtifactUpload\n\n# Uploading a file with no relative path\nupload_no_path = ArtifactUpload(file=b\"example_file_contents\")\n\n# Uploading a file with a relative path\nupload_with_path = ArtifactUpload(\n    file=b\"example_file_contents\", relative_path=\"python/code/\"\n)\n</code></pre> <p>In the above example, <code>upload_no_path</code> is an instance of <code>ArtifactUpload</code> with no specified <code>relative_path</code>, whereas <code>upload_with_path</code> is an instance of <code>ArtifactUpload</code> with the <code>relative_path</code> set to \"python/code/\".</p>"},{"location":"swarms/structs/artifactupload/#additional-information","title":"Additional Information","text":"<p>When passing the <code>file</code> and <code>relative_path</code> parameters to the <code>ArtifactUpload</code> class, ensure that the <code>file</code> parameter is provided exactly as the file that needs to be uploaded, represented as a <code>bytes</code> object. If a <code>relative_path</code> is provided, ensure that it is a valid path within the agent's workspace.</p>"},{"location":"swarms/structs/artifactupload/#conclusion","title":"Conclusion","text":"<p>The <code>ArtifactUpload</code> class is an essential data structure within the Swarms library that represents the process of uploading an artifact to an agent's workspace. By using this class, users can easily manage and represent artifact uploads within the Swarms distributed system.</p>"},{"location":"swarms/structs/autoscaler/","title":"Autoscaler","text":""},{"location":"swarms/structs/autoscaler/#enterprise-grade-documentation","title":"Enterprise Grade Documentation","text":""},{"location":"swarms/structs/autoscaler/#autoscaler-class-from-swarms-package","title":"AutoScaler Class from <code>swarms</code> Package","text":"<p>The <code>AutoScaler</code> class, part of the <code>swarms</code> package, provides a dynamic mechanism to handle agents depending on the workload. This document outlines how to use it, complete with import statements and examples.</p>"},{"location":"swarms/structs/autoscaler/#importing-the-autoscaler-class","title":"Importing the AutoScaler Class","text":"<p>Before you can use the <code>AutoScaler</code> class, you must import it from the <code>swarms</code> package:</p> <pre><code>from swarms import AutoScaler\n</code></pre>"},{"location":"swarms/structs/autoscaler/#constructor-autoscaler__init__","title":"Constructor: <code>AutoScaler.__init__()</code>","text":"<p>Description: Initializes the <code>AutoScaler</code> with a predefined number of agents and sets up configurations for scaling.</p> <p>Parameters: - <code>initial_agents (int)</code>: Initial number of agents. Default is 10. - <code>scale_up_factor (int)</code>: Multiplicative factor to scale up the number of agents. Default is 2. - <code>idle_threshold (float)</code>: Threshold below which agents are considered idle. Expressed as a ratio (0-1). Default is 0.2. - <code>busy_threshold (float)</code>: Threshold above which agents are considered busy. Expressed as a ratio (0-1). Default is 0.7.</p> <p>Returns: - None</p> <p>Example Usage: <pre><code>from swarms import AutoScaler\n\nscaler = AutoScaler(\n    initial_agents=5, scale_up_factor=3, idle_threshold=0.1, busy_threshold=0.8\n)\n</code></pre></p>"},{"location":"swarms/structs/autoscaler/#method-autoscaleradd_tasktask","title":"Method: <code>AutoScaler.add_task(task)</code>","text":"<p>Description: Enqueues the specified task into the task queue.</p> <p>Parameters: - <code>task</code>: The task to be added to the queue.</p> <p>Returns: - None</p> <p>Example Usage: <pre><code>task_data = \"Process dataset X\"\nscaler.add_task(task_data)\n</code></pre></p>"},{"location":"swarms/structs/autoscaler/#method-autoscalerscale_up","title":"Method: <code>AutoScaler.scale_up()</code>","text":"<p>Description: Scales up the number of agents based on the specified scale-up factor.</p> <p>Parameters: - None</p> <p>Returns: - None</p> <p>Example Usage: <pre><code># Called internally but can be manually invoked if necessary\nscaler.scale_up()\n</code></pre></p>"},{"location":"swarms/structs/autoscaler/#method-autoscalerscale_down","title":"Method: <code>AutoScaler.scale_down()</code>","text":"<p>Description: Scales down the number of agents, ensuring a minimum is always present.</p> <p>Parameters: - None</p> <p>Returns: - None</p> <p>Example Usage: <pre><code># Called internally but can be manually invoked if necessary\nscaler.scale_down()\n</code></pre></p>"},{"location":"swarms/structs/autoscaler/#method-autoscalermonitor_and_scale","title":"Method: <code>AutoScaler.monitor_and_scale()</code>","text":"<p>Description: Continuously monitors the task queue and agent utilization to decide on scaling.</p> <p>Parameters: - None</p> <p>Returns: - None</p> <p>Example Usage: <pre><code># This method is internally used as a thread and does not require manual invocation in most scenarios.\n</code></pre></p>"},{"location":"swarms/structs/autoscaler/#method-autoscalerstart","title":"Method: <code>AutoScaler.start()</code>","text":"<p>Description: Initiates the monitoring process and starts processing tasks from the queue.</p> <p>Parameters: - None</p> <p>Returns: - None</p> <p>Example Usage: <pre><code>scaler.start()\n</code></pre></p>"},{"location":"swarms/structs/autoscaler/#full-usage","title":"Full Usage","text":"<pre><code>from swarms import AutoScaler\n\n# Initialize the scaler\nauto_scaler = AutoScaler(\n    initial_agents=15, scale_up_factor=2, idle_threshold=0.2, busy_threshold=0.7\n)\n\n# Start the monitoring and task processing\nauto_scaler.start()\n\n# Simulate the addition of tasks\nfor i in range(100):\n    auto_scaler.add_task(f\"Task {i}\")\n</code></pre>"},{"location":"swarms/structs/autoscaler/#pass-in-custom-agent","title":"Pass in Custom Agent","text":"<p>You can pass any agent class that adheres to the required interface (like having a run() method). If no class is passed, it defaults to using AutoBot. This makes the AutoScaler more flexible and able to handle a wider range of agent implementations.</p> <pre><code>from swarms import AutoScaler\n\nauto_scaler = AutoScaler(agent=YourCustomAgent)\nauto_scaler.start()\n\nfor i in range(100):  # Adding tasks\n    auto_scaler.add_task(f\"Task {i}\")\n</code></pre> <p>Notes: 1. Adjust the thresholds and scaling factors as per your specific requirements and nature of the tasks. 2. The provided implementation is a baseline. Depending on your production environment, you may need additional features, error-handling, and optimizations. 3. Ensure that the <code>swarms</code> package and its dependencies are installed in your environment.</p>"},{"location":"swarms/structs/basestructure/","title":"Module/Function Name: BaseStructure","text":""},{"location":"swarms/structs/basestructure/#introduction","title":"Introduction:","text":"<p>The <code>BaseStructure</code> module contains the basic structure and attributes required for running machine learning models and associated metadata, error logging, artifact saving/loading, and relevant event logging. </p> <p>The module provides the flexibility to save and load the model metadata, log errors, save artifacts, and maintain a log for multiple events associated with multiple threads and batched operations. The key attributes of the module include name, description, save_metadata_path, and save_error_path.</p>"},{"location":"swarms/structs/basestructure/#class-definition","title":"Class Definition:","text":""},{"location":"swarms/structs/basestructure/#arguments","title":"Arguments:","text":"Argument Type Description name str (Optional) The name of the structure. description str (Optional) A description of the structure. save_metadata bool A boolean flag to enable or disable metadata saving. save_artifact_path str (Optional) The path to save artifacts. save_metadata_path str (Optional) The path to save metadata. save_error_path str (Optional) The path to save errors."},{"location":"swarms/structs/basestructure/#methods","title":"Methods:","text":""},{"location":"swarms/structs/basestructure/#1-run","title":"1. run","text":"<p>Runs the structure.</p>"},{"location":"swarms/structs/basestructure/#2-save_to_file","title":"2. save_to_file","text":"<p>Saves data to a file. * data: Value to be saved. * file_path: Path where the data is to be saved.</p>"},{"location":"swarms/structs/basestructure/#3-load_from_file","title":"3. load_from_file","text":"<p>Loads data from a file. * file_path: Path from where the data is to be loaded.</p>"},{"location":"swarms/structs/basestructure/#4-save_metadata","title":"4. save_metadata","text":"<p>Saves metadata to a file. * metadata: Data to be saved as metadata.</p>"},{"location":"swarms/structs/basestructure/#5-load_metadata","title":"5. load_metadata","text":"<p>Loads metadata from a file.</p>"},{"location":"swarms/structs/basestructure/#6-log_error","title":"6. log_error","text":"<p>Logs error to a file.</p>"},{"location":"swarms/structs/basestructure/#7-save_artifact","title":"7. save_artifact","text":"<p>Saves artifact to a file. * artifact: The artifact to be saved. * artifact_name: Name of the artifact.</p>"},{"location":"swarms/structs/basestructure/#8-load_artifact","title":"8. load_artifact","text":"<p>Loads artifact from a file. * artifact_name: Name of the artifact.</p>"},{"location":"swarms/structs/basestructure/#9-log_event","title":"9. log_event","text":"<p>Logs an event to a file. * event: The event to be logged. * event_type: Type of the event (optional, defaults to \"INFO\").</p>"},{"location":"swarms/structs/basestructure/#10-run_async","title":"10. run_async","text":"<p>Runs the structure asynchronously.</p>"},{"location":"swarms/structs/basestructure/#11-save_metadata_async","title":"11. save_metadata_async","text":"<p>Saves metadata to a file asynchronously.</p>"},{"location":"swarms/structs/basestructure/#12-load_metadata_async","title":"12. load_metadata_async","text":"<p>Loads metadata from a file asynchronously.</p>"},{"location":"swarms/structs/basestructure/#13-log_error_async","title":"13. log_error_async","text":"<p>Logs error to a file asynchronously.</p>"},{"location":"swarms/structs/basestructure/#14-save_artifact_async","title":"14. save_artifact_async","text":"<p>Saves artifact to a file asynchronously.</p>"},{"location":"swarms/structs/basestructure/#15-load_artifact_async","title":"15. load_artifact_async","text":"<p>Loads artifact from a file asynchronously.</p>"},{"location":"swarms/structs/basestructure/#16-log_event_async","title":"16. log_event_async","text":"<p>Logs an event to a file asynchronously.</p>"},{"location":"swarms/structs/basestructure/#17-asave_to_file","title":"17. asave_to_file","text":"<p>Saves data to a file asynchronously.</p>"},{"location":"swarms/structs/basestructure/#18-aload_from_file","title":"18. aload_from_file","text":"<p>Loads data from a file asynchronously.</p>"},{"location":"swarms/structs/basestructure/#19-run_concurrent","title":"19. run_concurrent","text":"<p>Runs the structure concurrently.</p>"},{"location":"swarms/structs/basestructure/#20-compress_data","title":"20. compress_data","text":"<p>Compresses data.</p>"},{"location":"swarms/structs/basestructure/#21-decompres_data","title":"21. decompres_data","text":"<p>Decompresses data.</p>"},{"location":"swarms/structs/basestructure/#22-run_batched","title":"22. run_batched","text":"<p>Runs batched data. </p>"},{"location":"swarms/structs/basestructure/#examples","title":"Examples:","text":""},{"location":"swarms/structs/basestructure/#example-1-saving-metadata","title":"Example 1: Saving Metadata","text":"<pre><code>base_structure = BaseStructure(name=\"ExampleStructure\")\nmetadata = {\"key1\": \"value1\", \"key2\": \"value2\"}\nbase_structure.save_metadata(metadata)\n</code></pre>"},{"location":"swarms/structs/basestructure/#example-2-loading-artifact","title":"Example 2: Loading Artifact","text":"<pre><code>artifact_name = \"example_artifact\"\nartifact_data = base_structure.load_artifact(artifact_name)\n</code></pre>"},{"location":"swarms/structs/basestructure/#example-3-running-concurrently","title":"Example 3: Running Concurrently","text":"<pre><code>concurrent_data = [data1, data2, data3]\nresults = base_structure.run_concurrent(batched_data=concurrent_data)\n</code></pre>"},{"location":"swarms/structs/basestructure/#note","title":"Note:","text":"<p>The <code>BaseStructure</code> class is designed to provide a modular and extensible structure for managing metadata, logs, errors, and batched operations while running machine learning models. The class's methods offer asynchronous and concurrent execution capabilities, thus optimizing the performance of the associated applications and models. The module's attributes and methods cater to a wide range of use cases, making it an essential foundational component for machine learning and data-based applications.</p>"},{"location":"swarms/structs/basestructure/#conclusion","title":"Conclusion:","text":"<p>The <code>BaseStructure</code> module offers a robust and flexible foundation for managing machine learning model metadata, error logs, and event tracking, including asynchronous, concurrent, and batched operations. By leveraging the inherent capabilities of this class, developers can enhance the reliability, scalability, and performance of machine learning-based applications.</p>"},{"location":"swarms/structs/basestructure/#references","title":"References:","text":"<ul> <li>Python Concurrent Programming with <code>asyncio</code></li> <li>Understanding Thread Pool Executor in Python</li> <li>Documentation on <code>gzip</code> Module for Data Compression</li> </ul> <p>The above documentation provides detailed information about the <code>BaseStructure</code> module, including its functionality, attributes, methods, usage examples, and references to relevant resources for further exploration. This comprehensive documentation aims to deepen the users' understanding of the module's purpose and how it can be effectively utilized in practice.</p> <p>Please let me know if you need further elaboration on any specific aspect or functionality of the <code>BaseStructure</code> module.</p>"},{"location":"swarms/structs/baseworkflow/","title":"baseworkflow","text":""},{"location":"swarms/structs/baseworkflow/#swarmsmodulesstructs","title":"swarms.modules.structs","text":"<p><code>Class Name: BaseWorkflow</code></p> <p>Base class for workflows.</p> <p><code>Attributes</code> - Task_pool (list): A list to store tasks.</p> <p><code>Methods</code> - Add(task: Task = None, tasks: List[Task] = None, args, *kwargs): Adds a task or a list of tasks to the task pool. - Run(): Abstract method to run the workflow.</p> <p>Source Code: <pre><code>class BaseWorkflow(BaseStructure):\n\"\"\"\nBase class for workflows.\n\n Attributes:\n     task_pool (list): A list to store tasks.\n\n Methods:\n     add(task: Task = None, tasks: List[Task] = None, *args, **kwargs):\n         Adds a task or a list of tasks to the task pool.\n     run():\n         Abstract method to run the workflow.\n\"\"\"\n</code></pre></p> <p>For the usage examples and additional in-depth documentation please visit BaseWorkflow</p> <p>Explanation:</p> <p>Initially, the <code>BaseWorkflow</code> class is a class designed to handle workflows. It contains a list within the task pool to handle various tasks and run methods. In the current structure, there are a few in-built methods such as <code>add</code>, <code>run</code>, <code>__sequential_loop</code>, <code>__log</code>, <code>reset</code>, <code>get_task_results</code>, <code>remove_task</code>, <code>update_task</code>, <code>delete_task</code>, <code>save_workflow_state</code>, <code>add_objective_to_workflow</code>, and <code>load_workflow_state</code>, each serving a unique purpose.</p> <p>The <code>add</code> method functions to add tasks or a list of tasks to the task pool while the <code>run</code> method is left as an abstract method for initializing the workflow. Considering the need to run the workflow, <code>__sequential_loop</code> is another abstract method. In cases where the user desires to log messages, <code>__log</code> can be utilized. For resetting the workflow, there is a <code>reset</code> method, complemented by <code>get_task_results</code> that returns the results of each task in the workflow. To remove a task from the workflow, <code>remove_task</code> can be employed.</p> <p>In cases where an update is required for the tasks in the workflow, <code>update_task</code> comes in handy. Deleting a task from the workflow can be achieved using the <code>delete_task</code> method. The method saves the workflow\u2019s state to a JSON file, and the user can fix the path where the file resides. For adding objectives to the workflow, <code>add_objective_to_workflow</code> can be employed, and there is an abstract method of <code>load_workflow_state</code> for loading the workflow state from a JSON file providing the freedom to revert the workflow to a specific state.</p> <p>The class also has a method <code>__str__</code> and <code>__repr__</code> to represent the text and instantiate an object of the class, respectively. The object can be reset, task results obtained, tasks removed, tasks updated, tasks deleted, or workflow state saved. The structure provides detailed methods for altering the workflow at every level. </p>"},{"location":"swarms/structs/concurrentworkflow/","title":"concurrentworkflow","text":"<p>```     # Module/Function Name: ConcurrentWorkflow</p> <pre><code>class swarms.structs.ConcurrentWorkflow(max_workers, autosave, saved_state_filepath):\n    \"\"\"\n    ConcurrentWorkflow class for running a set of tasks concurrently using N autonomous agents.\n\n    Args:\n        - max_workers (int): The maximum number of workers to use for concurrent execution.\n        - autosave (bool): Whether to autosave the workflow state.\n        - saved_state_filepath (Optional[str]): The file path to save the workflow state.\n\n    \"\"\"\n\n    def add(self, task, tasks=None):\n        \"\"\"Adds a task to the workflow.\n\n        Args:\n            - task (Task): Task to add to the workflow.\n            - tasks (List[Task]): List of tasks to add to the workflow (optional).\n\n        \"\"\"\n        try:\n            # Implementation of the function goes here\n        except Exception as error:\n            print(f\"[ERROR][ConcurrentWorkflow] {error}\")\n            raise error\n\n    def run(self, print_results=False, return_results=False):\n        \"\"\"\n        Executes the tasks in parallel using a ThreadPoolExecutor.\n\n        Args:\n            - print_results (bool): Whether to print the results of each task. Default is False.\n            - return_results (bool): Whether to return the results of each task. Default is False.\n\n        Returns:\n            - (List[Any]): A list of the results of each task, if return_results is True. Otherwise, returns None.\n\n        \"\"\"\n        try:\n            # Implementation of the function goes here\n        except Exception as e:\n            print(f\"Task {task} generated an exception: {e}\")\n\n        return results if self.return_results else None\n\n    def _execute_task(self, task):\n        \"\"\"Executes a task.\n\n        Args:\n            - task (Task): Task to execute.\n\n        Returns:\n            - result: The result of executing the task.\n\n        \"\"\"\n        try:\n            # Implementation of the function goes here\n        except Exception as error:\n            print(f\"[ERROR][ConcurrentWorkflow] {error}\")\n            raise error\n\n# Usage example:\n\nfrom swarms.models import OpenAIChat\nfrom swarms.structs import ConcurrentWorkflow\n\nllm = OpenAIChat(openai_api_key=\"\")\nworkflow = ConcurrentWorkflow(max_workers=5)\nworkflow.add(\"What's the weather in miami\", llm)\nworkflow.add(\"Create a report on these metrics\", llm)\nworkflow.run()\nworkflow.tasks\n\n\"\"\"\n```\n</code></pre>"},{"location":"swarms/structs/conversation/","title":"Module/Class Name: Conversation","text":""},{"location":"swarms/structs/conversation/#introduction","title":"Introduction","text":"<p>The <code>Conversation</code> class is a powerful tool for managing and structuring conversation data in a Python program. It enables you to create, manipulate, and analyze conversations easily. This documentation will provide you with a comprehensive understanding of the <code>Conversation</code> class, its attributes, methods, and how to effectively use it.</p>"},{"location":"swarms/structs/conversation/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Class Definition</li> <li>Overview</li> <li> <p>Attributes</p> </li> <li> <p>Methods</p> </li> <li><code>__init__(self, time_enabled: bool = False, *args, **kwargs)</code></li> <li><code>add(self, role: str, content: str, *args, **kwargs)</code></li> <li><code>delete(self, index: str)</code></li> <li><code>update(self, index: str, role, content)</code></li> <li><code>query(self, index: str)</code></li> <li><code>search(self, keyword: str)</code></li> <li><code>display_conversation(self, detailed: bool = False)</code></li> <li><code>export_conversation(self, filename: str)</code></li> <li><code>import_conversation(self, filename: str)</code></li> <li><code>count_messages_by_role(self)</code></li> <li><code>return_history_as_string(self)</code></li> <li><code>save_as_json(self, filename: str)</code></li> <li><code>load_from_json(self, filename: str)</code></li> <li><code>search_keyword_in_conversation(self, keyword: str)</code></li> <li><code>pretty_print_conversation(self, messages)</code></li> </ol>"},{"location":"swarms/structs/conversation/#1-class-definition","title":"1. Class Definition","text":""},{"location":"swarms/structs/conversation/#overview","title":"Overview","text":"<p>The <code>Conversation</code> class is designed to manage conversations by keeping track of messages and their attributes. It offers methods for adding, deleting, updating, querying, and displaying messages within the conversation. Additionally, it supports exporting and importing conversations, searching for specific keywords, and more.</p>"},{"location":"swarms/structs/conversation/#attributes","title":"Attributes","text":"<ul> <li><code>time_enabled (bool)</code>: A flag indicating whether to enable timestamp recording for messages.</li> <li><code>conversation_history (list)</code>: A list that stores messages in the conversation.</li> </ul>"},{"location":"swarms/structs/conversation/#2-methods","title":"2. Methods","text":""},{"location":"swarms/structs/conversation/#__init__self-time_enabled-bool-false-args-kwargs","title":"<code>__init__(self, time_enabled: bool = False, *args, **kwargs)</code>","text":"<ul> <li>Description: Initializes a new Conversation object.</li> <li>Parameters:</li> <li><code>time_enabled (bool)</code>: If <code>True</code>, timestamps will be recorded for each message. Default is <code>False</code>.</li> </ul>"},{"location":"swarms/structs/conversation/#addself-role-str-content-str-args-kwargs","title":"<code>add(self, role: str, content: str, *args, **kwargs)</code>","text":"<ul> <li>Description: Adds a message to the conversation history.</li> <li>Parameters:</li> <li><code>role (str)</code>: The role of the speaker (e.g., \"user,\" \"assistant\").</li> <li><code>content (str)</code>: The content of the message.</li> </ul>"},{"location":"swarms/structs/conversation/#deleteself-index-str","title":"<code>delete(self, index: str)</code>","text":"<ul> <li>Description: Deletes a message from the conversation history.</li> <li>Parameters:</li> <li><code>index (str)</code>: The index of the message to delete.</li> </ul>"},{"location":"swarms/structs/conversation/#updateself-index-str-role-content","title":"<code>update(self, index: str, role, content)</code>","text":"<ul> <li>Description: Updates a message in the conversation history.</li> <li>Parameters:</li> <li><code>index (str)</code>: The index of the message to update.</li> <li><code>role (_type_)</code>: The new role of the speaker.</li> <li><code>content (_type_)</code>: The new content of the message.</li> </ul>"},{"location":"swarms/structs/conversation/#queryself-index-str","title":"<code>query(self, index: str)</code>","text":"<ul> <li>Description: Retrieves a message from the conversation history.</li> <li>Parameters:</li> <li><code>index (str)</code>: The index of the message to query.</li> <li>Returns: The message as a string.</li> </ul>"},{"location":"swarms/structs/conversation/#searchself-keyword-str","title":"<code>search(self, keyword: str)</code>","text":"<ul> <li>Description: Searches for messages containing a specific keyword in the conversation history.</li> <li>Parameters:</li> <li><code>keyword (str)</code>: The keyword to search for.</li> <li>Returns: A list of messages that contain the keyword.</li> </ul>"},{"location":"swarms/structs/conversation/#display_conversationself-detailed-bool-false","title":"<code>display_conversation(self, detailed: bool = False)</code>","text":"<ul> <li>Description: Displays the conversation history.</li> <li>Parameters:</li> <li><code>detailed (bool, optional)</code>: If <code>True</code>, provides detailed information about each message. Default is <code>False</code>.</li> </ul>"},{"location":"swarms/structs/conversation/#export_conversationself-filename-str","title":"<code>export_conversation(self, filename: str)</code>","text":"<ul> <li>Description: Exports the conversation history to a text file.</li> <li>Parameters:</li> <li><code>filename (str)</code>: The name of the file to export to.</li> </ul>"},{"location":"swarms/structs/conversation/#import_conversationself-filename-str","title":"<code>import_conversation(self, filename: str)</code>","text":"<ul> <li>Description: Imports a conversation history from a text file.</li> <li>Parameters:</li> <li><code>filename (str)</code>: The name of the file to import from.</li> </ul>"},{"location":"swarms/structs/conversation/#count_messages_by_roleself","title":"<code>count_messages_by_role(self)</code>","text":"<ul> <li>Description: Counts the number of messages by role in the conversation.</li> <li>Returns: A dictionary containing the count of messages for each role.</li> </ul>"},{"location":"swarms/structs/conversation/#return_history_as_stringself","title":"<code>return_history_as_string(self)</code>","text":"<ul> <li>Description: Returns the entire conversation history as a single string.</li> <li>Returns: The conversation history as a string.</li> </ul>"},{"location":"swarms/structs/conversation/#save_as_jsonself-filename-str","title":"<code>save_as_json(self, filename: str)</code>","text":"<ul> <li>Description: Saves the conversation history as a JSON file.</li> <li>Parameters:</li> <li><code>filename (str)</code>: The name of the JSON file to save.</li> </ul>"},{"location":"swarms/structs/conversation/#load_from_jsonself-filename-str","title":"<code>load_from_json(self, filename: str)</code>","text":"<ul> <li>Description: Loads a conversation history from a JSON file.</li> <li>Parameters:</li> <li><code>filename (str)</code>: The name of the JSON file to load.</li> </ul>"},{"location":"swarms/structs/conversation/#search_keyword_in_conversationself-keyword-str","title":"<code>search_keyword_in_conversation(self, keyword: str)</code>","text":"<ul> <li>Description: Searches for a keyword in the conversation history and returns matching messages.</li> <li>Parameters:</li> <li><code>keyword (str)</code>: The keyword to search for.</li> <li>Returns: A list of messages containing the keyword.</li> </ul>"},{"location":"swarms/structs/conversation/#pretty_print_conversationself-messages","title":"<code>pretty_print_conversation(self, messages)</code>","text":"<ul> <li>Description: Pretty prints a list of messages with colored role indicators.</li> <li>Parameters:</li> <li><code>messages (list)</code>: A list of messages to print.</li> </ul>"},{"location":"swarms/structs/conversation/#examples","title":"Examples","text":"<p>Here are some usage examples of the <code>Conversation</code> class:</p>"},{"location":"swarms/structs/conversation/#creating-a-conversation","title":"Creating a Conversation","text":"<pre><code>from swarms.structs import Conversation\n\nconv = Conversation()\n</code></pre>"},{"location":"swarms/structs/conversation/#adding-messages","title":"Adding Messages","text":"<pre><code>conv.add(\"user\", \"Hello, world!\")\nconv.add(\"assistant\", \"Hello, user!\")\n</code></pre>"},{"location":"swarms/structs/conversation/#displaying-the-conversation","title":"Displaying the Conversation","text":"<pre><code>conv.display_conversation()\n</code></pre>"},{"location":"swarms/structs/conversation/#searching-for-messages","title":"Searching for Messages","text":"<pre><code>result = conv.search(\"Hello\")\n</code></pre>"},{"location":"swarms/structs/conversation/#exporting-and-importing-conversations","title":"Exporting and Importing Conversations","text":"<pre><code>conv.export_conversation(\"conversation.txt\")\nconv.import_conversation(\"conversation.txt\")\n</code></pre>"},{"location":"swarms/structs/conversation/#counting-messages-by-role","title":"Counting Messages by Role","text":"<pre><code>counts = conv.count_messages_by_role()\n</code></pre>"},{"location":"swarms/structs/conversation/#loading-and-saving-as-json","title":"Loading and Saving as JSON","text":"<pre><code>conv.save_as_json(\"conversation.json\")\nconv.load_from_json(\"conversation.json\")\n</code></pre> <p>Certainly! Let's continue with more examples and additional information about the <code>Conversation</code> class.</p>"},{"location":"swarms/structs/conversation/#querying-a-specific-message","title":"Querying a Specific Message","text":"<p>You can retrieve a specific message from the conversation by its index:</p> <pre><code>message = conv.query(0)  # Retrieves the first message\n</code></pre>"},{"location":"swarms/structs/conversation/#updating-a-message","title":"Updating a Message","text":"<p>You can update a message's content or role within the conversation:</p> <pre><code>conv.update(0, \"user\", \"Hi there!\")  # Updates the first message\n</code></pre>"},{"location":"swarms/structs/conversation/#deleting-a-message","title":"Deleting a Message","text":"<p>If you want to remove a message from the conversation, you can use the <code>delete</code> method:</p> <pre><code>conv.delete(0)  # Deletes the first message\n</code></pre>"},{"location":"swarms/structs/conversation/#counting-messages-by-role_1","title":"Counting Messages by Role","text":"<p>You can count the number of messages by role in the conversation:</p> <pre><code>counts = conv.count_messages_by_role()\n# Example result: {'user': 2, 'assistant': 2}\n</code></pre>"},{"location":"swarms/structs/conversation/#exporting-and-importing-as-text","title":"Exporting and Importing as Text","text":"<p>You can export the conversation to a text file and later import it:</p> <pre><code>conv.export_conversation(\"conversation.txt\")  # Export\nconv.import_conversation(\"conversation.txt\")  # Import\n</code></pre>"},{"location":"swarms/structs/conversation/#exporting-and-importing-as-json","title":"Exporting and Importing as JSON","text":"<p>Conversations can also be saved and loaded as JSON files:</p> <pre><code>conv.save_as_json(\"conversation.json\")  # Save as JSON\nconv.load_from_json(\"conversation.json\")  # Load from JSON\n</code></pre>"},{"location":"swarms/structs/conversation/#searching-for-a-keyword","title":"Searching for a Keyword","text":"<p>You can search for messages containing a specific keyword within the conversation:</p> <pre><code>results = conv.search_keyword_in_conversation(\"Hello\")\n</code></pre>"},{"location":"swarms/structs/conversation/#pretty-printing","title":"Pretty Printing","text":"<p>The <code>pretty_print_conversation</code> method provides a visually appealing way to display messages with colored role indicators:</p> <pre><code>conv.pretty_print_conversation(conv.conversation_history)\n</code></pre> <p>These examples demonstrate the versatility of the <code>Conversation</code> class in managing and interacting with conversation data. Whether you're building a chatbot, conducting analysis, or simply organizing dialogues, this class offers a robust set of tools to help you accomplish your goals.</p>"},{"location":"swarms/structs/conversation/#conclusion","title":"Conclusion","text":"<p>The <code>Conversation</code> class is a valuable utility for handling conversation data in Python. With its ability to add, update, delete, search, export, and import messages, you have the flexibility to work with conversations in various ways. Feel free to explore its features and adapt them to your specific projects and applications.</p> <p>If you have any further questions or need additional assistance, please don't hesitate to ask!</p>"},{"location":"swarms/structs/groupchat/","title":"Module Name: Group Chat","text":"<p>The <code>GroupChat</code> class is used to create a group chat containing a list of agents. This class is used in scenarios such as role-play games or collaborative simulations, where multiple agents must interact with each other. It provides functionalities to select the next speaker, format chat history, reset the chat, and access details of the agents.</p>"},{"location":"swarms/structs/groupchat/#class-definition","title":"Class Definition","text":"<p>The <code>GroupChat</code> class is defined as follows:</p> <pre><code>@dataclass\nclass GroupChat:\n    \"\"\"\n    A group chat class that contains a list of agents and the maximum number of rounds.\n\n    Args:\n        agents: List[Agent]\n        messages: List[Dict]\n        max_round: int\n        admin_name: str\n\n    Usage:\n    &gt;&gt;&gt; from swarms import GroupChat\n    &gt;&gt;&gt; from swarms.structs.agent import Agent\n    &gt;&gt;&gt; agents = Agent()\n    \"\"\"\n\n    agents: List[Agent]\n    messages: List[Dict]\n    max_round: int = 10\n    admin_name: str = \"Admin\"  # the name of the admin agent\n</code></pre>"},{"location":"swarms/structs/groupchat/#arguments","title":"Arguments","text":"<p>The <code>GroupChat</code> class takes the following arguments: | Argument    | Type          | Description                                       | Default Value   | |-------------|---------------|---------------------------------------------------|-----------------| | agents      | List[Agent]   | List of agents participating in the group chat.   |                 | | messages    | List[Dict]    | List of messages exchanged in the group chat.     |                 | | max_round   | int           | Maximum number of rounds for the group chat.      | 10              | | admin_name  | str           | Name of the admin agent.                          | \"Admin\"         |</p>"},{"location":"swarms/structs/groupchat/#methods","title":"Methods","text":"<ol> <li> <p>agent_names</p> <ul> <li>Returns the names of the agents in the group chat.</li> <li>Returns: List of strings.</li> </ul> </li> <li> <p>reset</p> <ul> <li>Resets the group chat, clears all the messages.</li> </ul> </li> <li> <p>agent_by_name</p> <ul> <li>Finds an agent in the group chat by their name.</li> <li>Arguments: name (str) - Name of the agent to search for.</li> <li>Returns: Agent - The agent with the matching name.</li> <li>Raises: ValueError if no matching agent is found.</li> </ul> </li> <li> <p>next_agent</p> <ul> <li>Returns the next agent in the list based on the order of agents.</li> <li>Arguments: agent (Agent) - The current agent.</li> <li>Returns: Agent - The next agent in the list.</li> </ul> </li> <li> <p>select_speaker_msg</p> <ul> <li>Returns the message for selecting the next speaker.</li> </ul> </li> <li> <p>select_speaker</p> <ul> <li>Selects the next speaker based on the system message and history of conversations.</li> <li>Arguments: last_speaker (Agent) - The speaker in the last round, selector (Agent) - The agent responsible for selecting the next speaker.</li> <li>Returns: Agent - The agent selected as the next speaker.</li> </ul> </li> <li> <p>_participant_roles</p> <ul> <li>Formats and returns a string containing the roles of the participants.</li> <li>(Internal method, not intended for direct usage)</li> </ul> </li> <li> <p>format_history</p> <ul> <li>Formats the history of messages exchanged in the group chat.</li> <li>Arguments: messages (List[Dict]) - List of messages.</li> <li>Returns: str - Formatted history of messages.</li> </ul> </li> </ol>"},{"location":"swarms/structs/groupchat/#additional-information","title":"Additional Information","text":"<ul> <li>For operations involving roles and conversations, the system messages and agent names are used.</li> <li>The <code>select_speaker</code> method warns when the number of agents is less than 3, indicating that direct communication might be more efficient.</li> </ul>"},{"location":"swarms/structs/groupchat/#usage-example-1","title":"Usage Example 1","text":"<pre><code>from swarms import GroupChat\nfrom swarms.structs.agent import Agent\n\nagents = [Agent(name=\"Alice\"), Agent(name=\"Bob\"), Agent(name=\"Charlie\")]\ngroup_chat = GroupChat(agents, [], max_round=5)\n\nprint(group_chat.agent_names)  # Output: [\"Alice\", \"Bob\", \"Charlie\"]\n\nselector = agents[1]\nnext_speaker = group_chat.select_speaker(last_speaker=agents[0], selector=selector)\nprint(next_speaker.name)  # Output: \"Bob\"\n</code></pre>"},{"location":"swarms/structs/groupchat/#usage-example-2","title":"Usage Example 2","text":"<pre><code>from swarms import GroupChat\nfrom swarms.structs.agent import Agent\n\nagents = [Agent(name=\"X\"), Agent(name=\"Y\")]\ngroup_chat = GroupChat(agents, [], max_round=10)\n\ngroup_chat.messages.append({\"role\": \"X\", \"content\": \"Hello Y!\"})\ngroup_chat.messages.append({\"role\": \"Y\", \"content\": \"Hi X!\"})\n\nformatted_history = group_chat.format_history(group_chat.messages)\nprint(formatted_history)\n\"\"\"\nOutput:\n'X: Hello Y!\nY: Hi X!'\n\"\"\"\n\nagent_charlie = Agent(name=\"Charlie\")\ngroup_chat.agents.append(agent_charlie)\n\nprint(group_chat.agent_names)  # Output: [\"X\", \"Y\", \"Charlie\"]\n</code></pre>"},{"location":"swarms/structs/groupchat/#usage-example-3","title":"Usage Example 3","text":"<pre><code>from swarms import GroupChat\nfrom swarms.structs.agent import Agent\n\nagents = [Agent(name=\"A1\"), Agent(name=\"A2\"), Agent(name=\"A3\")]\ngroup_chat = GroupChat(agents, [], max_round=3, admin_name=\"A1\")\n\ngroup_chat.reset()\nprint(group_chat.messages)  # Output: []\n</code></pre>"},{"location":"swarms/structs/groupchat/#references","title":"References","text":"<ol> <li>Swarms Documentation</li> <li>Role-Based Conversations in Multi-Agent Systems</li> </ol> <p>This detailed documentation has provided a comprehensive understanding of the <code>GroupChat</code> class in the <code>swarms.structs</code> module of the <code>swarms</code> library. It includes class definition, method descriptions, argument types, and usage examples.</p> <p>(Sample Documentation - 950 words)</p>"},{"location":"swarms/structs/groupchatmanager/","title":"GroupChatManager","text":"<p>Documentation:</p> <p>The <code>GroupChatManager</code> class is designed for managing group chat interactions between agents. It allows you to create and manage group chats among multiple agents. The <code>GroupChatManager</code> requires two main arguments - the <code>groupchat</code> of type <code>GroupChat</code> which indicates the actual group chat object and <code>selector</code> of type <code>Agent</code> which specifies the agent who is the selector or the initiator of the chat.</p> <p>This class provides a variety of features and functions such as maintaining and appending messages, managing the communication rounds, interacting between different agents and extracting replies.</p> <p>Args:</p> Parameter Type Description groupchat <code>GroupChat</code> The group chat object where the conversation occurs. selector <code>Agent</code> The agent who is the selector or the initiator of the chat. Usage: <pre><code>from swarms import GroupChatManager\nfrom swarms.structs.agent import Agent\n\n# Create an instance of Agent\nagents = Agent()\n\n# Initialize GroupChatManager with an existing GroupChat instance and an agent\nmanager = GroupChatManager(groupchat, selector)\n\n# Call the group chat manager passing a specific chat task\nresult = manager(\"Discuss the agenda for the upcoming meeting\")\n</code></pre> <p>Explanation:</p> <ol> <li> <p>First, you import the <code>GroupChatManager</code> class and the <code>Agent</code> class from the <code>swarms</code> library.</p> </li> <li> <p>Then, you create an instance of the <code>Agent</code>.</p> </li> <li> <p>After that, you initialize the <code>GroupChatManager</code> with an existing <code>GroupChat</code> instance and an agent.</p> </li> <li> <p>Finally, you call the group chat manager, passing a specific chat task and receive the response.</p> </li> </ol> <p>Source Code:</p> <pre><code>class GroupChatManager:\n    \"\"\"\n    GroupChatManager\n\n    Args:\n        groupchat: GroupChat\n        selector: Agent\n\n    Usage:\n    &gt;&gt;&gt; from swarms import GroupChatManager\n    &gt;&gt;&gt; from swarms.structs.agent import Agent\n    &gt;&gt;&gt; agents = Agent()\n    \"\"\"\n\n    def __init__(self, groupchat: GroupChat, selector: Agent):\n        self.groupchat = groupchat\n        self.selector = selector\n\n    def __call__(self, task: str):\n        \"\"\"Call 'GroupChatManager' instance as a function.\n\n        Args:\n            task (str): The task to be performed during the group chat.\n\n        Returns:\n            str: The response from the group chat.\n        \"\"\"\n        self.groupchat.messages.append({\"role\": self.selector.name, \"content\": task})\n        for i in range(self.groupchat.max_round):\n            speaker = self.groupchat.select_speaker(\n                last_speaker=self.selector, selector=self.selector\n            )\n            reply = speaker.generate_reply(\n                self.groupchat.format_history(self.groupchat.messages)\n            )\n            self.groupchat.messages.append(reply)\n            print(reply)\n            if i == self.groupchat.max_round - 1:\n                break\n\n        return reply\n</code></pre> <p>The <code>GroupChatManager</code> class has an <code>__init__</code> method which takes <code>groupchat</code> and <code>selector</code> as arguments to initialize the class properties. It also has a <code>__call__</code> method to perform the group chat task and provide the appropriate response.</p> <p>In the <code>__call__</code> method, it appends the message with the speaker\u2019s role and their content. It then iterates over the communication rounds, selects speakers, generates replies and appends messages to the group chat. Finally, it returns the response.</p> <p>The above example demonstrates how to use the <code>GroupChatManager</code> class to manage group chat interactions. You can further customize this class based on specific requirements and extend its functionality as needed.</p>"},{"location":"swarms/structs/json/","title":"Documentation for <code>swarms.structs.JSON</code> Class","text":"<p>The <code>swarms.structs.JSON</code> class is a helper class that provides a templated framework for creating new classes that deal with JSON objects and need to validate these objects against a JSON Schema. Being an abstract base class (ABC), the <code>JSON</code> class allows for the creation of subclasses that implement specific behavior while ensuring that they all adhere to a common interface, particularly the <code>validate</code> method.</p> <p>Given that documenting the entire code provided in full detail would exceed our platform's limitations, below is a generated documentation for the <code>JSON</code> class following the steps you provided. This is an outline and would need to be expanded upon to reach the desired word count and thoroughness in a full, professional documentation.</p>"},{"location":"swarms/structs/json/#introduction","title":"Introduction","text":"<p>JSON (JavaScript Object Notation) is a lightweight data interchange format that is easy for humans to read and write and easy for machines to parse and generate. <code>swarms.structs.JSON</code> class aims to provide a basic structure for utilizing JSON and validating it against a pre-defined schema. This is essential for applications where data integrity and structure are crucial, such as configurations for applications, communications over networks, and data storage.</p>"},{"location":"swarms/structs/json/#class-definition","title":"Class Definition","text":"Parameter Type Description <code>schema_path</code> <code>str</code> The path to the JSON schema file."},{"location":"swarms/structs/json/#json__init__self-schema_path","title":"<code>JSON.__init__(self, schema_path)</code>","text":"<p>Class constructor that initializes a <code>JSON</code> object with the specified JSON schema path. <pre><code>def __init__(self, schema_path):\n    self.schema_path = schema_path\n    self.schema = self.load_schema()\n</code></pre></p>"},{"location":"swarms/structs/json/#jsonload_schemaself","title":"<code>JSON.load_schema(self)</code>","text":"<p>Private method that loads and returns the JSON schema from the file specified at the <code>schema_path</code>.</p>"},{"location":"swarms/structs/json/#jsonvalidateself-data","title":"<code>JSON.validate(self, data)</code>","text":"<p>Abstract method that needs to be implemented by subclasses to validate input <code>data</code> against the JSON schema.</p>"},{"location":"swarms/structs/json/#functionality-and-usage","title":"Functionality and Usage","text":""},{"location":"swarms/structs/json/#why-use-json-class","title":"Why use <code>JSON</code> Class","text":"<p>The <code>JSON</code> class abstracts away the details of loading and validating JSON data, allowing for easy implementation in any subclass that needs to handle JSON input. It sets up a standard for all subclasses to follow, ensuring consistency across different parts of code or different projects.</p> <p>By enforcing a JSON schema, the <code>JSON</code> class helps maintain the integrity of the data, catching errors early in the process of reading and writing JSON.</p>"},{"location":"swarms/structs/json/#step-by-step-guide","title":"Step-by-step Guide","text":"<ol> <li>Subclass the <code>JSON</code> class.</li> <li>Provide an implementation for the <code>validate</code> method.</li> <li>Use the provided schema to enforce required fields and types within your JSON data.</li> </ol>"},{"location":"swarms/structs/json/#example-usage","title":"Example Usage","text":""},{"location":"swarms/structs/json/#implementing-a-subclass","title":"Implementing a Subclass","text":"<p>Suppose we have a JSON Schema in <code>config_schema.json</code> for application configuration.</p> <pre><code>{\n    \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n    \"type\": \"object\",\n    \"properties\": {\n        \"debug\": {\n            \"type\": \"boolean\"\n        },\n        \"window_size\": {\n            \"type\": \"array\",\n            \"items\": {\n                \"type\": \"number\"\n            },\n            \"minItems\": 2,\n            \"maxItems\": 2\n        }\n    },\n    \"required\": [\"debug\", \"window_size\"]\n}\n</code></pre> <p>Now we'll create a subclass <code>AppConfig</code> that uses this schema.</p> <pre><code>from swarms.structs import JSON\n\n\nclass AppConfig(JSON):\n    def __init__(self, schema_path):\n        super().__init__(schema_path)\n\n    def validate(self, config_data):\n        # Here we'll use a JSON Schema validation library like jsonschema\n        from jsonschema import ValidationError, validate\n\n        try:\n            validate(instance=config_data, schema=self.schema)\n        except ValidationError as e:\n            print(f\"Invalid configuration: {e}\")\n            return False\n        return True\n\n\n# Main Example Usage\n\nif __name__ == \"__main__\":\n    config = {\"debug\": True, \"window_size\": [800, 600]}\n\n    app_config = AppConfig(\"config_schema.json\")\n\n    if app_config.validate(config):\n        print(\"Config is valid!\")\n    else:\n        print(\"Config is invalid.\")\n</code></pre> <p>In this example, an <code>AppConfig</code> class that inherits from <code>JSON</code> is created. The <code>validate</code> method is implemented to check whether a configuration dictionary is valid against the provided schema.</p>"},{"location":"swarms/structs/json/#note","title":"Note","text":"<ul> <li>Validate real JSON data using this class in a production environment.</li> <li>Catch and handle any exceptions as necessary to avoid application crashes.</li> <li>Extend functionality within subclasses as required for your application.</li> </ul>"},{"location":"swarms/structs/json/#additional-information-and-tips","title":"Additional Information and Tips","text":"<ul> <li>Use detailed JSON Schemas for complex data validation.</li> <li>Use the jsonschema library for advanced validation features.</li> </ul>"},{"location":"swarms/structs/json/#references-and-resources","title":"References and Resources","text":"<ul> <li>Official Python Documentation for ABCs: https://docs.python.org/3/library/abc.html</li> <li>JSON Schema: https://json-schema.org/</li> <li>jsonschema Python package: https://pypi.org/project/jsonschema/</li> </ul> <p>This generated documentation serves as a template and starting point intended for creating in-depth, practical documentation. Expanding upon each section, in practice, would involve deeper code examples, common patterns and pitfalls, and more thorough explanations of the <code>JSON</code> class internals and how to best utilize them in various real-world scenarios.</p>"},{"location":"swarms/structs/majorityvoting/","title":"<code>MajorityVoting</code> Documentation","text":""},{"location":"swarms/structs/majorityvoting/#overview","title":"Overview","text":"<p>The <code>swarms.structs</code> library provides a flexible architecture for creating and managing swarms of agents capable of performing tasks and making decisions based on majority voting. This documentation will guide you through the <code>MajorityVoting</code> class, explaining its purpose, architecture, and usage with examples.</p>"},{"location":"swarms/structs/majorityvoting/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Introduction</li> <li>Installation</li> <li>The <code>MajorityVoting</code> Class</li> <li>Class Definition</li> <li>Parameters</li> <li>Methods<ul> <li><code>__init__</code></li> <li><code>run</code></li> </ul> </li> <li>Usage Examples</li> <li>Basic Usage</li> <li>Concurrent Execution</li> <li>Asynchronous Execution</li> <li>Advanced Features</li> <li>Troubleshooting and FAQ</li> <li>Conclusion</li> <li>References</li> </ul>"},{"location":"swarms/structs/majorityvoting/#introduction","title":"Introduction","text":"<p>The <code>swarms.structs</code> library introduces a mode of distributed computation through \"agents\" that collaborate to determine the outcome of tasks using a majority voting system. It becomes crucial in scenarios where collective decision-making is preferred over individual agent accuracy.</p>"},{"location":"swarms/structs/majorityvoting/#installation","title":"Installation","text":"<p>To install the <code>swarms.structs</code> library, run the following command:</p> <pre><code>pip install swarms-structs\n</code></pre>"},{"location":"swarms/structs/majorityvoting/#the-majorityvoting-class","title":"The <code>MajorityVoting</code> Class","text":"<p>The <code>MajorityVoting</code> class is a high-level abstraction used to coordinate a group of agents that perform tasks and return results. These results are then aggregated to form a majority vote, determining the final output.</p>"},{"location":"swarms/structs/majorityvoting/#class-definition","title":"Class Definition","text":""},{"location":"swarms/structs/majorityvoting/#parameters","title":"Parameters","text":"Parameter Type Default Description agents List[Agent] Required A list of agent instances to participate in the voting process. concurrent bool False Enables concurrent execution using threading if set to <code>True</code>. multithreaded bool False Enables execution using multiple threads if set to <code>True</code>. multiprocess bool False Enables execution using multiple processes if set to <code>True</code>. asynchronous bool False Enables asynchronous execution if set to <code>True</code>. output_parser callable None A function to parse the output from the majority voting function. autosave bool False Enables automatic saving of the process state if set to <code>True</code>. (currently not used in source code) verbose bool False Enables verbose logging if set to <code>True</code>."},{"location":"swarms/structs/majorityvoting/#methods","title":"Methods","text":""},{"location":"swarms/structs/majorityvoting/#__init__","title":"<code>__init__</code>","text":"<p>The constructor for the <code>MajorityVoting</code> class. Initializes a new majority voting system with the given configuration.</p> <p>This method doesn't return any value.</p>"},{"location":"swarms/structs/majorityvoting/#run","title":"<code>run</code>","text":"<p>Executes the given task by all participating agents and aggregates the results through majority voting.</p> Parameter Type Description task str The task to be performed. *args list Additional positional arguments. **kwargs dict Additional keyword arguments. <p>Returns: List[Any] - The result based on the majority vote.</p>"},{"location":"swarms/structs/majorityvoting/#usage-examples","title":"Usage Examples","text":""},{"location":"swarms/structs/majorityvoting/#basic-usage","title":"Basic Usage","text":"<pre><code>from swarms.structs.agent import Agent\nfrom swarms.structs.majority_voting import MajorityVoting\n\n\ndef create_agent(name):\n    return Agent(name)\n\n\nagents = [create_agent(name) for name in [\"GPT-3\", \"Codex\", \"Tabnine\"]]\nmajority_voting = MajorityVoting(agents)\nresult = majority_voting.run(\"What is the capital of France?\")\nprint(result)  # Output: Paris\n</code></pre>"},{"location":"swarms/structs/majorityvoting/#concurrent-execution","title":"Concurrent Execution","text":"<pre><code>majority_voting = MajorityVoting(agents, concurrent=True)\nresult = majority_voting.run(\"What is the largest continent?\")\nprint(result)  # Example Output: Asia\n</code></pre>"},{"location":"swarms/structs/majorityvoting/#asynchronous-execution","title":"Asynchronous Execution","text":"<pre><code>majority_voting = MajorityVoting(agents, asynchronous=True)\nresult = majority_voting.run(\"What is the square root of 16?\")\nprint(result)  # Output: 4\n</code></pre>"},{"location":"swarms/structs/nonlinearworkflow/","title":"nonlinearworkflow","text":""},{"location":"swarms/structs/nonlinearworkflow/#class-name-nonlinearworkflow","title":"Class Name: NonlinearWorkflow","text":"<p>This class represents a Directed Acyclic Graph (DAG) workflow used to store tasks and their dependencies in a workflow. The structures can validate, execute and store the order of tasks present in the workflow. It has the following attributes and methods:</p>"},{"location":"swarms/structs/nonlinearworkflow/#attributes","title":"Attributes:","text":"<ul> <li><code>tasks</code> (dict): A dictionary mapping task names to Task objects.</li> <li><code>edges</code> (dict): A dictionary mapping task names to a list of dependencies.</li> <li><code>stopping_token</code> (str): The token which denotes the end condition for the workflow execution. Default: <code>&lt;DONE&gt;</code></li> </ul>"},{"location":"swarms/structs/nonlinearworkflow/#methods","title":"Methods:","text":"<ol> <li><code>__init__(self, stopping_token: str = \"&lt;DONE&gt;\")</code>: The initialization method that sets up the NonlinearWorkflow object with an optional stopping token. This token marks the end of the workflow. </li> <li> <p>Args:</p> <ul> <li><code>stopping_token</code> (str): The token to denote the end condition for the workflow execution.</li> </ul> </li> <li> <p><code>add(task: Task, *dependencies: str)</code>: Adds a task to the workflow along with its dependencies. This method is used to add a new task to the workflow with an optional list of dependency tasks.</p> </li> <li>Args:<ul> <li><code>task</code> (Task): The task to be added.</li> <li><code>dependencies</code> (varargs): Variable number of dependency task names.</li> </ul> </li> <li> <p>Returns: None</p> </li> <li> <p><code>run()</code>: This method runs the workflow by executing tasks in topological order. It runs the tasks according to the sequence of dependencies.</p> </li> <li>Raises:<ul> <li><code>Exception</code>: If a circular dependency is detected.</li> </ul> </li> <li>Returns: None</li> </ol>"},{"location":"swarms/structs/nonlinearworkflow/#examples","title":"Examples:","text":"<p>Usage Example 1:</p> <pre><code>from swarms.models import OpenAIChat\nfrom swarms.structs import NonlinearWorkflow, Task\n\n# Initialize the OpenAIChat model\nllm = OpenAIChat(openai_api_key=\"\")\n# Create a new Task\ntask = Task(llm, \"What's the weather in Miami\")\n# Initialize the NonlinearWorkflow\nworkflow = NonlinearWorkflow()\n# Add task to the workflow\nworkflow.add(task)\n# Execute the workflow\nworkflow.run()\n</code></pre> <p>Usage Example 2:</p> <pre><code>from swarms.models import OpenAIChat\nfrom swarms.structs import NonlinearWorkflow, Task\n\n# Initialize the OpenAIChat model\nllm = OpenAIChat(openai_api_key=\"\")\n# Create new Tasks\ntask1 = Task(llm, \"What's the weather in Miami\")\ntask2 = Task(llm, \"Book a flight to New York\")\ntask3 = Task(llm, \"Find a hotel in Paris\")\n# Initialize the NonlinearWorkflow\nworkflow = NonlinearWorkflow()\n# Add tasks to the workflow with dependencies\nworkflow.add(task1, task2.name)\nworkflow.add(task2, task3.name)\nworkflow.add(task3, \"OpenAIChat Initialization\")\n# Execute the workflow\nworkflow.run()\n</code></pre> <p>Usage Example 3:</p> <pre><code>from swarms.models import OpenAIChat\nfrom swarms.structs import NonlinearWorkflow, Task\n\n# Initialize the OpenAIChat model\nllm = OpenAIChat(openai_api_key=\"\")\n# Create new Tasks\ntask1 = Task(llm, \"What's the weather in Miami\")\ntask2 = Task(llm, \"Book a flight to New York\")\ntask3 = Task(llm, \"Find a hotel in Paris\")\n# Initialize the NonlinearWorkflow\nworkflow = NonlinearWorkflow()\n# Add tasks to the workflow with dependencies\nworkflow.add(task1)\nworkflow.add(task2, task1.name)\nworkflow.add(task3, task1.name, task2.name)\n# Execute the workflow\nworkflow.run()\n</code></pre> <p>These examples illustrate the three main types of usage for the NonlinearWorkflow class and how it can be used to represent a directed acyclic graph (DAG) workflow with tasks and their dependencies.</p> <p>The explanatory documentation details the architectural aspects, methods, attributes, examples, and usage patterns for the <code>NonlinearWorkflow</code> class. By following the module and function definition structure, the documentation provides clear and comprehensive descriptions of the class and its functionalities.</p>"},{"location":"swarms/structs/recursiveworkflow/","title":"recursiveworkflow","text":"<p>Module/Function Name: RecursiveWorkflow</p> <p><code>class</code> RecursiveWorkflow(BaseStructure):</p> <p>Creates a recursive workflow structure for executing a task until a stated stopping condition is reached. </p>"},{"location":"swarms/structs/recursiveworkflow/#parameters","title":"Parameters","text":"<ul> <li>task (<code>Task</code>): The task to execute.</li> <li>stop_token (<code>Any</code>): The token that signals the termination of the workflow.</li> </ul>"},{"location":"swarms/structs/recursiveworkflow/#examples","title":"Examples:","text":"<pre><code>from swarms.models import OpenAIChat\nfrom swarms.structs import RecursiveWorkflow, Task\n\nllm = OpenAIChat(openai_api_key=\"YourKey\")\ntask = Task(llm, \"What's the weather in miami\")\nworkflow = RecursiveWorkflow(stop_token=\"&lt;DONE&gt;\")\nworkflow.add(task)\nworkflow.run()\n</code></pre> <p>In summary, the <code>RecursiveWorkflow</code> class is designed to automate tasks by adding and executing these tasks recursively until a stopping condition is reached. This can be achieved by utilizing the <code>add</code> and <code>run</code> methods provided. A general format for adding and utilizing the <code>RecursiveWorkflow</code> class has been provided under the \"Examples\" section. If you require any further information, view other sections, like Args and Source Code for specifics on using the class effectively.</p>"},{"location":"swarms/structs/sequential_workflow/","title":"<code>SequentialWorkflow</code> Documentation","text":"<p>The SequentialWorkflow class is a Python module designed to facilitate the execution of a sequence of tasks in a sequential manner. It is a part of the <code>swarms.structs</code> package and is particularly useful for orchestrating the execution of various callable objects, such as functions or models, in a predefined order. This documentation will provide an in-depth understanding of the SequentialWorkflow class, including its purpose, architecture, usage, and examples.</p>"},{"location":"swarms/structs/sequential_workflow/#purpose-and-relevance","title":"Purpose and Relevance","text":"<p>The SequentialWorkflow class is essential for managing and executing a series of tasks or processes, where each task may depend on the outcome of the previous one. It is commonly used in various application scenarios, including but not limited to:</p> <ol> <li> <p>Natural Language Processing (NLP) Workflows: In NLP workflows, multiple language models are employed sequentially to process and generate text. Each model may depend on the results of the previous one, making sequential execution crucial.</p> </li> <li> <p>Data Analysis Pipelines: Data analysis often involves a series of tasks such as data preprocessing, transformation, and modeling steps. These tasks must be performed sequentially to ensure data consistency and accuracy.</p> </li> <li> <p>Task Automation: In task automation scenarios, there is a need to execute a series of automated tasks in a specific order. Sequential execution ensures that each task is performed in a predefined sequence, maintaining the workflow's integrity.</p> </li> </ol> <p>By providing a structured approach to managing these tasks, the SequentialWorkflow class helps developers streamline their workflow execution and improve code maintainability.</p>"},{"location":"swarms/structs/sequential_workflow/#key-concepts-and-terminology","title":"Key Concepts and Terminology","text":"<p>Before delving into the details of the SequentialWorkflow class, let's define some key concepts and terminology that will be used throughout the documentation:</p>"},{"location":"swarms/structs/sequential_workflow/#task","title":"Task","text":"<p>A task refers to a specific unit of work that needs to be executed as part of the workflow. Each task is associated with a description and can be implemented as a callable object, such as a function or a model.</p>"},{"location":"swarms/structs/sequential_workflow/#agent","title":"Agent","text":"<p>A agent represents a callable object that can be a task within the SequentialWorkflow. Agents encapsulate the logic and functionality of a particular task. Agents can be functions, models, or any callable object that can be executed.</p>"},{"location":"swarms/structs/sequential_workflow/#sequential-execution","title":"Sequential Execution","text":"<p>Sequential execution refers to the process of running tasks one after the other in a predefined order. In a SequentialWorkflow, tasks are executed sequentially, meaning that each task starts only after the previous one has completed.</p>"},{"location":"swarms/structs/sequential_workflow/#workflow","title":"Workflow","text":"<p>A workflow is a predefined sequence of tasks that need to be executed in a specific order. It represents the overall process or pipeline that the SequentialWorkflow manages.</p>"},{"location":"swarms/structs/sequential_workflow/#dashboard-optional","title":"Dashboard (Optional)","text":"<p>A dashboard is an optional feature of the SequentialWorkflow that provides real-time monitoring and visualization of the workflow's progress. It displays information such as the current task being executed, task results, and other relevant metadata.</p>"},{"location":"swarms/structs/sequential_workflow/#max-loops","title":"Max Loops","text":"<p>The maximum number of times the entire workflow can be run. This parameter allows developers to control how many times the workflow is executed.</p>"},{"location":"swarms/structs/sequential_workflow/#autosaving","title":"Autosaving","text":"<p>Autosaving is a feature that allows the SequentialWorkflow to automatically save its state to a file at specified intervals. This feature helps in resuming a workflow from where it left off, even after interruptions.</p> <p>Now that we have a clear understanding of the key concepts and terminology, let's explore the architecture and usage of the SequentialWorkflow class in more detail.</p>"},{"location":"swarms/structs/sequential_workflow/#architecture-of-sequentialworkflow","title":"Architecture of SequentialWorkflow","text":"<p>The architecture of the SequentialWorkflow class is designed to provide a structured and flexible way to define, manage, and execute a sequence of tasks. It comprises the following core components:</p> <ol> <li> <p>Task: The Task class represents an individual unit of work within the workflow. Each task has a description, which serves as a human-readable identifier for the task. Tasks can be implemented as callable objects, allowing for great flexibility in defining their functionality.</p> </li> <li> <p>Workflow: The SequentialWorkflow class itself represents the workflow. It manages a list of tasks in the order they should be executed. Workflows can be run sequentially or asynchronously, depending on the use case.</p> </li> <li> <p>Task Execution: Task execution is the process of running each task in the workflow. Tasks are executed one after another in the order they were added to the workflow. Task results can be passed as inputs to subsequent tasks.</p> </li> <li> <p>Dashboard (Optional): The SequentialWorkflow optionally includes a dashboard feature. The dashboard provides a visual interface for monitoring the progress of the workflow. It displays information about the current task, task results, and other relevant metadata.</p> </li> <li> <p>State Management: The SequentialWorkflow supports state management, allowing developers to save and load the state of the workflow to and from JSON files. This feature is valuable for resuming workflows after interruptions or for sharing workflow configurations.</p> </li> </ol>"},{"location":"swarms/structs/sequential_workflow/#usage-of-sequentialworkflow","title":"Usage of SequentialWorkflow","text":"<p>The SequentialWorkflow class is versatile and can be employed in a wide range of applications. Its usage typically involves the following steps:</p> <ol> <li> <p>Initialization: Begin by initializing any callable objects or flows that will serve as tasks in the workflow. These callable objects can include functions, models, or any other Python objects that can be executed.</p> </li> <li> <p>Workflow Creation: Create an instance of the SequentialWorkflow class. Specify the maximum number of loops the workflow should run and whether a dashboard should be displayed.</p> </li> <li> <p>Task Addition: Add tasks to the workflow using the <code>add</code> method. Each task should be described using a human-readable description, and the associated agent (callable object) should be provided. Additional arguments and keyword arguments can be passed to the task.</p> </li> <li> <p>Task Execution: Execute the workflow using the <code>run</code> method. The tasks within the workflow will be executed sequentially, with task results passed as inputs to subsequent tasks.</p> </li> <li> <p>Accessing Results: After running the workflow, you can access the results of each task using the <code>get_task_results</code> method or by directly accessing the <code>result</code> attribute of each task.</p> </li> <li> <p>Optional Features: Optionally, you can enable features such as autosaving of the workflow state and utilize the dashboard for real-time monitoring.</p> </li> </ol>"},{"location":"swarms/structs/sequential_workflow/#installation","title":"Installation","text":"<p>Before using the Sequential Workflow library, you need to install it. You can install it via pip:</p> <pre><code>pip3 install --upgrade swarms\n</code></pre>"},{"location":"swarms/structs/sequential_workflow/#quick-start","title":"Quick Start","text":"<p>Let's begin with a quick example to demonstrate how to create and run a Sequential Workflow. In this example, we'll create a workflow that generates a 10,000-word blog on \"health and wellness\" using an AI model and then summarizes the generated content.</p> <pre><code>from swarms.models import OpenAIChat\nfrom swarms.structs import Agent\nfrom swarms.structs.sequential_workflow import SequentialWorkflow\n\n# Initialize the language model agent (e.g., GPT-3)\nllm = OpenAIChat(\n    openai_api_key=\"YOUR_API_KEY\",\n    temperature=0.5,\n    max_tokens=3000,\n)\n\n# Initialize flows for individual tasks\nflow1 = Agent(llm=llm, max_loops=1, dashboard=False)\nflow2 = Agent(llm=llm, max_loops=1, dashboard=False)\n\n# Create the Sequential Workflow\nworkflow = SequentialWorkflow(max_loops=1)\n\n# Add tasks to the workflow\nworkflow.add(\"Generate a 10,000 word blog on health and wellness.\", flow1)\nworkflow.add(\"Summarize the generated blog\", flow2)\n\n# Run the workflow\nworkflow.run()\n\n# Output the results\nfor task in workflow.tasks:\n    print(f\"Task: {task.description}, Result: {task.result}\")\n</code></pre> <p>This quick example demonstrates the basic usage of the Sequential Workflow. It creates two tasks and executes them sequentially.</p>"},{"location":"swarms/structs/sequential_workflow/#class-task","title":"Class: <code>Task</code>","text":""},{"location":"swarms/structs/sequential_workflow/#description","title":"Description","text":"<p>The <code>Task</code> class represents an individual task in the workflow. A task is essentially a callable object, such as a function or a class, that can be executed sequentially. Tasks can have arguments and keyword arguments.</p>"},{"location":"swarms/structs/sequential_workflow/#class-definition","title":"Class Definition","text":"<pre><code>class Task:\n    def __init__(self, description: str, agent: Union[Callable, Agent], args: List[Any] = [], kwargs: Dict[str, Any] = {}, result: Any = None, history: List[Any] = [])\n</code></pre>"},{"location":"swarms/structs/sequential_workflow/#parameters","title":"Parameters","text":"<ul> <li><code>description</code> (str): A description of the task.</li> <li><code>agent</code> (Union[Callable, Agent]): The callable object representing the task. It can be a function, class, or a <code>Agent</code> instance.</li> <li><code>args</code> (List[Any]): A list of positional arguments to pass to the task when executed. Default is an empty list.</li> <li><code>kwargs</code> (Dict[str, Any]): A dictionary of keyword arguments to pass to the task when executed. Default is an empty dictionary.</li> <li><code>result</code> (Any): The result of the task's execution. Default is <code>None</code>.</li> <li><code>history</code> (List[Any]): A list to store the historical results of the task. Default is an empty list.</li> </ul>"},{"location":"swarms/structs/sequential_workflow/#methods","title":"Methods","text":""},{"location":"swarms/structs/sequential_workflow/#execute","title":"<code>execute()</code>","text":"<p>Execute the task.</p> <pre><code>def execute(self):\n</code></pre> <p>This method executes the task and updates the <code>result</code> and <code>history</code> attributes of the task. It checks if the task is a <code>Agent</code> instance and if the 'task' argument is needed.</p>"},{"location":"swarms/structs/sequential_workflow/#class-sequentialworkflow","title":"Class: <code>SequentialWorkflow</code>","text":""},{"location":"swarms/structs/sequential_workflow/#description_1","title":"Description","text":"<p>The <code>SequentialWorkflow</code> class is responsible for managing a sequence of tasks and executing them in a sequential order. It provides methods for adding tasks, running the workflow, and managing the state of the tasks.</p>"},{"location":"swarms/structs/sequential_workflow/#class-definition_1","title":"Class Definition","text":"<pre><code>class SequentialWorkflow:\n    def __init__(self, max_loops: int = 1, autosave: bool = False, saved_state_filepath: Optional[str] = \"sequential_workflow_state.json\", restore_state_filepath: Optional[str] = None, dashboard: bool = False, tasks: List[Task] = [])\n</code></pre>"},{"location":"swarms/structs/sequential_workflow/#parameters_1","title":"Parameters","text":"<ul> <li><code>max_loops</code> (int): The maximum number of times to run the workflow sequentially. Default is <code>1</code>.</li> <li><code>autosave</code> (bool): Whether to enable autosaving of the workflow state. Default is <code>False</code>.</li> <li><code>saved_state_filepath</code> (Optional[str]): The file path to save the workflow state when autosave is enabled. Default is <code>\"sequential_workflow_state.json\"</code>.</li> <li><code>restore_state_filepath</code> (Optional[str]): The file path to restore the workflow state when initializing. Default is <code>None</code>.</li> <li><code>dashboard</code> (bool): Whether to display a dashboard with workflow information. Default is <code>False</code>.</li> <li><code>tasks</code> (List[Task]): A list of <code>Task</code> instances representing the tasks in the workflow. Default is an empty list.</li> </ul>"},{"location":"swarms/structs/sequential_workflow/#methods_1","title":"Methods","text":""},{"location":"swarms/structs/sequential_workflow/#addtask-str-agent-unioncallable-agent-args-kwargs","title":"<code>add(task: str, agent: Union[Callable, Agent], *args, **kwargs)</code>","text":"<p>Add a task to the workflow.</p> <pre><code>def add(self, task: str, agent: Union[Callable, Agent], *args, **kwargs) -&gt; None:\n</code></pre> <p>This method adds a new task to the workflow. You can provide a description of the task, the callable object (function, class, or <code>Agent</code> instance), and any additional positional or keyword arguments required for the task.</p>"},{"location":"swarms/structs/sequential_workflow/#reset_workflow","title":"<code>reset_workflow()</code>","text":"<p>Reset the workflow by clearing the results of each task.</p> <pre><code>def reset_workflow(self) -&gt; None:\n</code></pre> <p>This method clears the results of each task in the workflow, allowing you to start fresh without reinitializing the workflow.</p>"},{"location":"swarms/structs/sequential_workflow/#get_task_results","title":"<code>get_task_results()</code>","text":"<p>Get the results of each task in the workflow.</p> <pre><code>def get_task_results(self) -&gt; Dict[str, Any]:\n</code></pre> <p>This method returns a dictionary containing the results of each task in the workflow, where the keys are task descriptions, and the values are the corresponding results.</p>"},{"location":"swarms/structs/sequential_workflow/#remove_tasktask_description-str","title":"<code>remove_task(task_description: str)</code>","text":"<p>Remove a task from the workflow.</p> <pre><code>def remove_task(self, task_description: str) -&gt; None:\n</code></pre> <p>This method removes a specific task from the workflow based on its description.</p>"},{"location":"swarms/structs/sequential_workflow/#update_tasktask_description-str-updates","title":"<code>update_task(task_description: str, **updates)</code>","text":"<p>Update the arguments of a task in the workflow.</p> <pre><code>def update_task(self, task_description: str, **updates) -&gt; None:\n</code></pre> <p>This method allows you to update the arguments and keyword arguments of a task in the workflow. You specify the task's description and provide the updates as keyword arguments.</p>"},{"location":"swarms/structs/sequential_workflow/#save_workflow_statefilepath-optionalstr-sequential_workflow_statejson-kwargs","title":"<code>save_workflow_state(filepath: Optional[str] = \"sequential_workflow_state.json\", **kwargs)</code>","text":"<p>Save the workflow state to a JSON file.</p> <pre><code>def save_workflow_state(self, filepath: Optional[str] = \"sequential_workflow_state.json\", **kwargs) -&gt; None:\n</code></pre> <p>This method saves the current state of the workflow, including the results and history of each task, to a JSON file. You can specify the file path for saving the state.</p>"},{"location":"swarms/structs/sequential_workflow/#load_workflow_statefilepath-str-none-kwargs","title":"<code>load_workflow_state(filepath: str = None, **kwargs)</code>","text":"<p>Load the workflow state from a JSON file and restore the workflow state.</p> <pre><code>def load_workflow_state(self, filepath: str = None, **kwargs) -&gt; None:\n</code></pre> <p>This method loads a previously saved workflow state from a JSON file</p> <p>and restores the state, allowing you to continue the workflow from where it was saved. You can specify the file path for loading the state.</p>"},{"location":"swarms/structs/sequential_workflow/#run","title":"<code>run()</code>","text":"<p>Run the workflow sequentially.</p> <pre><code>def run(self) -&gt; None:\n</code></pre> <p>This method executes the tasks in the workflow sequentially. It checks if a task is a <code>Agent</code> instance and handles the agent of data between tasks accordingly.</p>"},{"location":"swarms/structs/sequential_workflow/#arun","title":"<code>arun()</code>","text":"<p>Asynchronously run the workflow.</p> <pre><code>async def arun(self) -&gt; None:\n</code></pre> <p>This method asynchronously executes the tasks in the workflow sequentially. It's suitable for use cases where asynchronous execution is required. It also handles data agent between tasks.</p>"},{"location":"swarms/structs/sequential_workflow/#workflow_bootupkwargs","title":"<code>workflow_bootup(**kwargs)</code>","text":"<p>Display a bootup message for the workflow.</p> <pre><code>def workflow_bootup(self, **kwargs) -&gt; None:\n</code></pre> <p>This method displays a bootup message when the workflow is initialized. You can customize the message by providing additional keyword arguments.</p>"},{"location":"swarms/structs/sequential_workflow/#workflow_dashboardkwargs","title":"<code>workflow_dashboard(**kwargs)</code>","text":"<p>Display a dashboard for the workflow.</p> <pre><code>def workflow_dashboard(self, **kwargs) -&gt; None:\n</code></pre> <p>This method displays a dashboard with information about the workflow, such as the number of tasks, maximum loops, and autosave settings. You can customize the dashboard by providing additional keyword arguments.</p>"},{"location":"swarms/structs/sequential_workflow/#examples","title":"Examples","text":"<p>Let's explore some examples to illustrate how to use the Sequential Workflow library effectively.</p> <p>Sure, I'll recreate the usage examples section for each method and use case using the provided foundation. Here are the examples:</p>"},{"location":"swarms/structs/sequential_workflow/#example-1-adding-tasks-to-a-sequential-workflow","title":"Example 1: Adding Tasks to a Sequential Workflow","text":"<p>In this example, we'll create a Sequential Workflow and add tasks to it.</p> <pre><code>from swarms.models import OpenAIChat\nfrom swarms.structs import Agent\nfrom swarms.structs.sequential_workflow import SequentialWorkflow\n\n# Example usage\napi_key = \"\"  # Your actual API key here\n\n# Initialize the language agent\nllm = OpenAIChat(\n    openai_api_key=api_key,\n    temperature=0.5,\n    max_tokens=3000,\n)\n\n# Initialize Agents for individual tasks\nflow1 = Agent(llm=llm, max_loops=1, dashboard=False)\nflow2 = Agent(llm=llm, max_loops=1, dashboard=False)\n\n# Create the Sequential Workflow\nworkflow = SequentialWorkflow(max_loops=1)\n\n# Add tasks to the workflow\nworkflow.add(\"Generate a 10,000 word blog on health and wellness.\", flow1)\nworkflow.add(\"Summarize the generated blog\", flow2)\n\n# Output the list of tasks in the workflow\nprint(\"Tasks in the workflow:\")\nfor task in workflow.tasks:\n    print(f\"Task: {task.description}\")\n</code></pre> <p>In this example, we create a Sequential Workflow and add two tasks to it.</p>"},{"location":"swarms/structs/sequential_workflow/#example-2-resetting-a-sequential-workflow","title":"Example 2: Resetting a Sequential Workflow","text":"<p>In this example, we'll create a Sequential Workflow, add tasks to it, and then reset it.</p> <pre><code>from swarms.models import OpenAIChat\nfrom swarms.structs import Agent\nfrom swarms.structs.sequential_workflow import SequentialWorkflow\n\n# Example usage\napi_key = \"\"  # Your actual API key here\n\n# Initialize the language agent\nllm = OpenAIChat(\n    openai_api_key=api_key,\n    temperature=0.5,\n    max_tokens=3000,\n)\n\n# Initialize Agents for individual tasks\nflow1 = Agent(llm=llm, max_loops=1, dashboard=False)\nflow2 = Agent(llm=llm, max_loops=1, dashboard=False)\n\n# Create the Sequential Workflow\nworkflow = SequentialWorkflow(max_loops=1)\n\n# Add tasks to the workflow\nworkflow.add(\"Generate a 10,000 word blog on health and wellness.\", flow1)\nworkflow.add(\"Summarize the generated blog\", flow2)\n\n# Reset the workflow\nworkflow.reset_workflow()\n\n# Output the list of tasks in the workflow after resetting\nprint(\"Tasks in the workflow after resetting:\")\nfor task in workflow.tasks:\n    print(f\"Task: {task.description}\")\n</code></pre> <p>In this example, we create a Sequential Workflow, add two tasks to it, and then reset the workflow, clearing all task results.</p>"},{"location":"swarms/structs/sequential_workflow/#example-3-getting-task-results-from-a-sequential-workflow","title":"Example 3: Getting Task Results from a Sequential Workflow","text":"<p>In this example, we'll create a Sequential Workflow, add tasks to it, run the workflow, and then retrieve the results of each task.</p> <pre><code>from swarms.models import OpenAIChat\nfrom swarms.structs import Agent\nfrom swarms.structs.sequential_workflow import SequentialWorkflow\n\n# Example usage\napi_key = \"\"  # Your actual API key here\n\n# Initialize the language agent\nllm = OpenAIChat(\n    openai_api_key=api_key,\n    temperature=0.5,\n    max_tokens=3000,\n)\n\n# Initialize Agents for individual tasks\nflow1 = Agent(llm=llm, max_loops=1, dashboard=False)\nflow2 = Agent(llm=llm, max_loops=1, dashboard=False)\n\n# Create the Sequential Workflow\nworkflow = SequentialWorkflow(max_loops=1)\n\n# Add tasks to the workflow\nworkflow.add(\"Generate a 10,000 word blog on health and wellness.\", flow1)\nworkflow.add(\"Summarize the generated blog\", flow2)\n\n# Run the workflow\nworkflow.run()\n\n# Get and display the results of each task in the workflow\nresults = workflow.get_task_results()\nfor task_description, result in results.items():\n    print(f\"Task: {task_description}, Result: {result}\")\n</code></pre> <p>In this example, we create a Sequential Workflow, add two tasks to it, run the workflow, and then retrieve and display the results of each task.</p>"},{"location":"swarms/structs/sequential_workflow/#example-4-removing-a-task-from-a-sequential-workflow","title":"Example 4: Removing a Task from a Sequential Workflow","text":"<p>In this example, we'll create a Sequential Workflow, add tasks to it, and then remove a specific task from the workflow.</p> <pre><code>from swarms.models import OpenAIChat\nfrom swarms.structs import Agent\nfrom swarms.structs.sequential_workflow import SequentialWorkflow\n\n# Example usage\napi_key = \"\"  # Your actual API key here\n\n# Initialize the language agent\nllm = OpenAIChat(\n    openai_api_key=api_key,\n    temperature=0.5,\n    max_tokens=3000,\n)\n\n# Initialize Agents for individual tasks\nflow1 = Agent(llm=llm, max_loops=1, dashboard=False)\nflow2 = Agent(llm=llm, max_loops=1, dashboard=False)\n\n# Create the Sequential Workflow\nworkflow = SequentialWorkflow(max_loops=1)\n\n# Add tasks to the workflow\nworkflow.add(\"Generate a 10,000 word blog on health and wellness.\", flow1)\nworkflow.add(\"Summarize the generated blog\", flow2)\n\n# Remove a specific task from the workflow\nworkflow.remove_task(\"Generate a 10,000 word blog on health and wellness.\")\n\n# Output the list of tasks in the workflow after removal\nprint(\"Tasks in the workflow after removing a task:\")\nfor task in workflow.tasks:\n    print(f\"Task: {task.description}\")\n</code></pre> <p>In this example, we create a Sequential Workflow, add two tasks to it, and then remove a specific task from the workflow.</p>"},{"location":"swarms/structs/sequential_workflow/#example-5-updating-task-arguments-in-a-sequential-workflow","title":"Example 5: Updating Task Arguments in a Sequential Workflow","text":"<p>In this example, we'll create a Sequential Workflow, add tasks to it, and then update the arguments of a specific task in the workflow.</p> <pre><code>from swarms.models import OpenAIChat\nfrom swarms.structs import Agent\nfrom swarms.structs.sequential_workflow import SequentialWorkflow\n\n# Example usage\napi_key = (\n    \"\"  # Your actual API key here\n)\n\n# Initialize the language agent\nllm = OpenAIChat(\n    openai_api_key=api_key,\n    temperature=0.5,\n    max_tokens=3000,\n)\n\n# Initialize Agents for individual tasks\nflow1 = Agent(llm=llm, max_loops=1, dashboard=False)\nflow2 = Agent(llm=llm, max_loops=1, dashboard=False)\n\n# Create the Sequential Workflow\nworkflow = SequentialWorkflow(max_loops=1)\n\n# Add tasks to the workflow\nworkflow.add(\"Generate a 10,000 word blog on health and wellness.\", flow1)\nworkflow.add(\"Summarize the generated blog\", flow2)\n\n# Update the arguments of a specific task in the workflow\nworkflow.update_task(\"Generate a 10,000 word blog on health and wellness.\", max_loops=2)\n\n# Output the list of tasks in the workflow after updating task arguments\nprint(\"Tasks in the workflow after updating task arguments:\")\nfor task in workflow.tasks:\n    print(f\"Task: {task.description}, Arguments: {\n\ntask.arguments}\")\n</code></pre> <p>In this example, we create a Sequential Workflow, add two tasks to it, and then update the arguments of a specific task in the workflow.</p> <p>These examples demonstrate various operations and use cases for working with a Sequential Workflow.</p>"},{"location":"swarms/structs/sequential_workflow/#why-sequentialworkflow","title":"Why <code>SequentialWorkflow</code>?","text":""},{"location":"swarms/structs/sequential_workflow/#enhancing-autonomous-agent-development","title":"Enhancing Autonomous Agent Development","text":"<p>The development of autonomous agents, whether they are conversational AI, robotic systems, or any other AI-driven application, often involves complex workflows that require a sequence of tasks to be executed in a specific order. Managing and orchestrating these tasks efficiently is crucial for building reliable and effective agents. The Sequential Workflow module serves as a valuable tool for AI engineers in achieving this goal.</p>"},{"location":"swarms/structs/sequential_workflow/#reliability-and-coordination","title":"Reliability and Coordination","text":"<p>One of the primary challenges in autonomous agent development is ensuring that tasks are executed in the correct sequence and that the results of one task can be used as inputs for subsequent tasks. The Sequential Workflow module simplifies this process by allowing AI engineers to define and manage workflows in a structured and organized manner.</p> <p>By using the Sequential Workflow module, AI engineers can achieve the following benefits:</p>"},{"location":"swarms/structs/sequential_workflow/#1-improved-reliability","title":"1. Improved Reliability","text":"<p>Reliability is a critical aspect of autonomous agents. The ability to handle errors gracefully and recover from failures is essential for building robust systems. The Sequential Workflow module offers a systematic approach to task execution, making it easier to handle errors, retry failed tasks, and ensure that the agent continues to operate smoothly.</p>"},{"location":"swarms/structs/sequential_workflow/#2-task-coordination","title":"2. Task Coordination","text":"<p>Coordinating tasks in the correct order is essential for achieving the desired outcome. The Sequential Workflow module enforces task sequencing, ensuring that each task is executed only when its dependencies are satisfied. This eliminates the risk of executing tasks out of order, which can lead to incorrect results.</p>"},{"location":"swarms/structs/sequential_workflow/#3-code-organization","title":"3. Code Organization","text":"<p>Managing complex workflows can become challenging without proper organization. The Sequential Workflow module encourages AI engineers to structure their code in a modular and maintainable way. Each task can be encapsulated as a separate unit, making it easier to understand, modify, and extend the agent's behavior.</p>"},{"location":"swarms/structs/sequential_workflow/#4-workflow-visualization","title":"4. Workflow Visualization","text":"<p>Visualization is a powerful tool for understanding and debugging workflows. The Sequential Workflow module can be extended to include a visualization dashboard, allowing AI engineers to monitor the progress of tasks, track results, and identify bottlenecks or performance issues.</p>"},{"location":"swarms/structs/sequential_workflow/#todo-future-features","title":"TODO: Future Features","text":"<p>While the Sequential Workflow module offers significant advantages, there are opportunities for further enhancement. Here is a list of potential features and improvements that can be added to make it even more versatile and adaptable for various AI engineering tasks:</p>"},{"location":"swarms/structs/sequential_workflow/#1-asynchronous-support","title":"1. Asynchronous Support","text":"<p>Adding support for asynchronous task execution can improve the efficiency of workflows, especially when dealing with tasks that involve waiting for external events or resources.</p>"},{"location":"swarms/structs/sequential_workflow/#2-context-managers","title":"2. Context Managers","text":"<p>Introducing context manager support for tasks can simplify resource management, such as opening and closing files, database connections, or network connections within a task's context.</p>"},{"location":"swarms/structs/sequential_workflow/#3-workflow-history","title":"3. Workflow History","text":"<p>Maintaining a detailed history of workflow execution, including timestamps, task durations, and input/output data, can facilitate debugging and performance analysis.</p>"},{"location":"swarms/structs/sequential_workflow/#4-parallel-processing","title":"4. Parallel Processing","text":"<p>Enhancing the module to support parallel processing with a pool of workers can significantly speed up the execution of tasks, especially for computationally intensive workflows.</p>"},{"location":"swarms/structs/sequential_workflow/#5-error-handling-strategies","title":"5. Error Handling Strategies","text":"<p>Providing built-in error handling strategies, such as retries, fallbacks, and custom error handling functions, can make the module more robust in handling unexpected failures.</p>"},{"location":"swarms/structs/sequential_workflow/#conclusion","title":"Conclusion","text":"<p>The Sequential Workflow module is a valuable tool for AI engineers working on autonomous agents and complex AI-driven applications. It offers a structured and reliable approach to defining and executing workflows, ensuring that tasks are performed in the correct sequence. By using this module, AI engineers can enhance the reliability, coordination, and maintainability of their agents.</p> <p>As the field of AI continues to evolve, the demand for efficient workflow management tools will only increase. The Sequential Workflow module is a step towards meeting these demands and empowering AI engineers to create more reliable and capable autonomous agents. With future enhancements and features, it has the potential to become an indispensable asset in the AI engineer's toolkit.</p> <p>In summary, the Sequential Workflow module provides a foundation for orchestrating complex tasks and workflows, enabling AI engineers to focus on designing intelligent agents that can perform tasks with precision and reliability.</p>"},{"location":"swarms/structs/sequential_workflow/#frequently-asked-questions-faqs","title":"Frequently Asked Questions (FAQs)","text":""},{"location":"swarms/structs/sequential_workflow/#q1-what-is-the-difference-between-a-task-and-a-agent-in-sequential-workflows","title":"Q1: What is the difference between a task and a agent in Sequential Workflows?","text":"<p>A1: In Sequential Workflows, a task refers to a specific unit of work that needs to be executed. It can be implemented as a callable object, such as a Python function, and is the fundamental building block of a workflow.</p> <p>A agent, on the other hand, is an encapsulation of a task within the workflow. Agents define the order in which tasks are executed and can be thought of as task containers. They allow you to specify dependencies, error handling, and other workflow-related configurations.</p>"},{"location":"swarms/structs/sequential_workflow/#q2-can-i-run-tasks-in-parallel-within-a-sequential-workflow","title":"Q2: Can I run tasks in parallel within a Sequential Workflow?","text":"<p>A2: Yes, you can run tasks in parallel within a Sequential Workflow by using parallel execution techniques. This advanced feature allows you to execute multiple tasks concurrently, improving performance and efficiency. You can explore this feature further in the guide's section on \"Parallel Execution.\"</p>"},{"location":"swarms/structs/sequential_workflow/#q3-how-do-i-handle-errors-within-sequential-workflows","title":"Q3: How do I handle errors within Sequential Workflows?","text":"<p>A3: Error handling within Sequential Workflows can be implemented by adding error-handling logic within your task functions. You can catch exceptions and handle errors gracefully, ensuring that your workflow can recover from unexpected scenarios. The guide also covers more advanced error handling strategies, such as retrying failed tasks and handling specific error types.</p>"},{"location":"swarms/structs/sequential_workflow/#q4-what-are-some-real-world-use-cases-for-sequential-workflows","title":"Q4: What are some real-world use cases for Sequential Workflows?","text":"<p>A4: Sequential Workflows can be applied to a wide range of real-world use cases, including:</p> <ul> <li> <p>Data ETL (Extract, Transform, Load) Processes: Automating data pipelines that involve data extraction, transformation, and loading into databases or data warehouses.</p> </li> <li> <p>Batch Processing: Running batch jobs that process large volumes of data or perform data analysis.</p> </li> <li> <p>Automation of DevOps Tasks: Streamlining DevOps processes such as deployment, provisioning, and monitoring.</p> </li> <li> <p>Cross-system Integrations: Automating interactions between different systems, services, or APIs.</p> </li> <li> <p>Report Generation: Generating reports and documents automatically based on data inputs.</p> </li> <li> <p>Workflow Orchestration: Orchestrating complex workflows involving multiple steps and dependencies.</p> </li> <li> <p>Resource Provisioning: Automatically provisioning and managing cloud resources.</p> </li> </ul> <p>These are just a few examples, and Sequential Workflows can be tailored to various automation needs across industries.</p>"},{"location":"swarms/structs/stackoverflowswarm/","title":"StackOverflowSwarm Class Documentation","text":""},{"location":"swarms/structs/stackoverflowswarm/#overview","title":"Overview","text":"<p>The <code>StackOverflowSwarm</code> class is part of the <code>swarms.structs</code> library. It is designed to simulate a collective intelligence or swarm intelligence scenario where multiple individual agents (referred to as <code>Agent</code> objects) come together to solve problems or answer questions typically found on platforms like Stack Overflow. This class is helpful in experiments involving cooperative multi-agent interactions, decision-making, and problem-solving, primarily when applied to question-and-answer scenarios.</p> <p>Swarm intelligence is modeled after social insects and natural systems where the collective behavior of decentralized, self-organized systems leads to the solving of complex tasks. <code>StackOverflowSwarm</code>, as a mini-framework within this library, provides a way to simulate such systems programmatically.</p> <p>The design of the <code>StackOverflowSwarm</code> class is intended to allow easy tracking of multi-agent interactions, the ability to autosave conversations, provide verbose outputs for monitoring purposes, and deal with problem-solving in a structured manner. This document provides a deep dive into the class' mechanisms, its architecture, and comprehensive usage examples for developers and researchers interested in swarm intelligence applications.</p>"},{"location":"swarms/structs/stackoverflowswarm/#class-definition","title":"Class Definition","text":""},{"location":"swarms/structs/stackoverflowswarm/#stackoverflowswarm-attributes","title":"StackOverflowSwarm Attributes:","text":"Attribute Type Description <code>agents</code> <code>List[Agent]</code> The list of agents in the swarm. <code>autosave</code> <code>bool</code> Flag indicating whether to automatically save the conversation. <code>verbose</code> <code>bool</code> Flag indicating whether to display verbose output. <code>save_filepath</code> <code>str</code> The filepath to save the conversation. <code>conversation</code> <code>Conversation</code> The conversation object for storing the interactions. <code>eval_agent</code> <code>Agent</code> or <code>None</code> An optional evaluation agent within the swarm (not used in provided code). <code>upvotes</code> <code>int</code> Counter for the number of upvotes per post (initialized as 0). <code>downvotes</code> <code>int</code> Counter for the number of downvotes per post (initialized as 0). <code>forum</code> <code>List</code> An empty list to represent the forum for the agents to interact."},{"location":"swarms/structs/stackoverflowswarm/#stackoverflowswarm-method-__init__","title":"StackOverflowSwarm Method: <code>__init__</code>","text":"Argument Type Default Description <code>agents</code> <code>List[Agent]</code> Required The list of agents in the swarm. <code>autosave</code> <code>bool</code> <code>False</code> Whether to automatically save the conversation. <code>verbose</code> <code>bool</code> <code>False</code> Whether to display verbose output. <code>save_filepath</code> <code>str</code> <code>\"stack_overflow_swarm.json\"</code> The filepath to save the conversation. <code>eval_agent</code> <code>Agent</code> <code>None</code> An optional eval agent (not entirely implemented). <code>*args</code> <code>variable</code> Variable length argument list. <code>**kwargs</code> <code>variable</code> Arbitrary keyword arguments."},{"location":"swarms/structs/stackoverflowswarm/#stackoverflowswarm-method-run","title":"StackOverflowSwarm Method: <code>run</code>","text":"Argument Type Description <code>task</code> <code>str</code> The task to be performed by the agents. <code>*args</code> <code>variable</code> Variable length argument list. <code>**kwargs</code> <code>variable</code> Arbitrary keyword arguments."},{"location":"swarms/structs/stackoverflowswarm/#return","title":"Return","text":"Type Description <code>List[str]</code> The conversation history as a list of strings."},{"location":"swarms/structs/stackoverflowswarm/#api-usage-and-examples","title":"API Usage and Examples","text":"<p>Initializing and Running a StackOverflowSwarm</p> <pre><code>from swarms.structs.agent import Agent\nfrom swarms.structs.stack_overflow_swarm import StackOverflowSwarm\n\n\n# Define custom Agents with some logic (placeholder for actual Agent implementation)\nclass CustomAgent(Agent):\n    def run(self, conversation, *args, **kwargs):\n        return \"This is a response from CustomAgent.\"\n\n\n# Initialize agents\nagent1 = CustomAgent(ai_name=\"Agent1\")\nagent2 = CustomAgent(ai_name=\"Agent2\")\n\n# Create a swarm\nswarm = StackOverflowSwarm(agents=[agent1, agent2], autosave=True, verbose=True)\n\n# Define a task\ntask_description = \"How can I iterate over a list in Python?\"\n\n# Run the swarm with a task\nconversation_history = swarm.run(task_description)\n\n# Output the conversation history\nprint(conversation_history)\n</code></pre>"},{"location":"swarms/structs/stackoverflowswarm/#how-the-swarm-works","title":"How the Swarm Works","text":"<p>The <code>StackOverflowSwarm</code> starts by initializing agents, autosave preferences, conversation object, upvote/downvote counters, and a forum list to manage inter-agent communication. When the <code>run</code> method is invoked, it adds the given task to the conversation, logging this addition if verbose mode is enabled.</p> <p>Each agent in the swarm runs its logic, possibly taking the current conversation history into consideration (the exact logic depends on the agent's implementation) and then responds to the task. Each agent's response is added to the conversation and logged.</p> <p>If autosave is enabled, the conversation is saved to the specified file path. The <code>run</code> method ultimately returns the conversation history as a string, which could also be a serialized JSON depending on the implementation of <code>Agent</code> and <code>Conversation</code>.</p>"},{"location":"swarms/structs/stackoverflowswarm/#considerations","title":"Considerations","text":"<ul> <li>This is a high-level conceptual example and lacks the detailed implementations of <code>Agent</code>, <code>Conversation</code>, and the actual <code>run</code> logic within each <code>Agent</code>.</li> <li>The <code>eval_agent</code> attribute and related logic have not been implemented in the provided code.</li> </ul>"},{"location":"swarms/structs/stackoverflowswarm/#common-issues","title":"Common Issues","text":"<ul> <li>Since the implementation of <code>Agent</code> and <code>Conversation</code> is not provided, one must ensure these components are compatible with the <code>StackOverflowSwarm</code> class for the interconnectivity and conversation saving/management to function correctly.</li> <li>It is essential to handle exceptions and errors within the <code>run</code> methods of each <code>Agent</code> to ensure that the failure of one agent does not halt the entire swarm.</li> </ul>"},{"location":"swarms/structs/stackoverflowswarm/#additional-resources","title":"Additional Resources","text":"<p>For further exploration into swarm intelligence, collective behavior in natural and artificial systems, and multi-agent problem solving:</p> <ol> <li>Bonabeau, E., Dorigo, M., &amp; Theraulaz, G. (1999). Swarm Intelligence: From Natural to Artificial Systems. Oxford University Press.</li> <li>Kennedy, J., Eberhart, R. C., &amp; Shi, Y. (2001). Swarm Intelligence. Morgan Kaufmann.</li> <li>Multi-Agent Systems Virtual Labs</li> <li>PyTorch \u2013 Deep Learning and Artificial Intelligence</li> </ol>"},{"location":"swarms/structs/stackoverflowswarm/#note","title":"Note","text":"<p>This documentation provides an overview of the <code>StackOverflowSwarm</code> class, its attributes, and methods. It should be adapted and expanded upon with actual code implementations for proper functionality and achieving the desired behavior in a swarm-based system.</p>"},{"location":"swarms/structs/stepinput/","title":"Module/Class Name: StepInput","text":"<p>The <code>StepInput</code> class is used to define the input parameters for the task step. It is a part of the <code>BaseModel</code> and accepts any value. This documentation will provide an overview of the class, its functionality, and usage examples.</p>"},{"location":"swarms/structs/stepinput/#overview-and-introduction","title":"Overview and Introduction","text":"<p>The <code>StepInput</code> class is an integral part of the <code>swarms.structs</code> library, allowing users to define and pass input parameters for a specific task step. This class provides flexibility by accepting any value, allowing the user to customize the input parameters according to their requirements.</p>"},{"location":"swarms/structs/stepinput/#class-definition","title":"Class Definition","text":"<p>The <code>StepInput</code> class is defined as follows:</p> <pre><code>class StepInput(BaseModel):\n    __root__: Any = Field(\n        ...,\n        description=(\"Input parameters for the task step. Any value is\" \" allowed.\"),\n        example='{\\n\"file_to_refactor\": \"models.py\"\\n}',\n    )\n</code></pre> <p>The <code>StepInput</code> class extends the <code>BaseModel</code> and contains a single field <code>__root__</code> of type <code>Any</code> with a description of accepting input parameters for the task step.</p>"},{"location":"swarms/structs/stepinput/#functionality-and-usage","title":"Functionality and Usage","text":"<p>The <code>StepInput</code> class is designed to accept any input value, providing flexibility and customization for task-specific parameters. Upon creating an instance of <code>StepInput</code>, the user can define and pass input parameters as per their requirements.</p>"},{"location":"swarms/structs/stepinput/#usage-example-1","title":"Usage Example 1:","text":"<pre><code>from swarms.structs import StepInput\n\ninput_params = {\"file_to_refactor\": \"models.py\", \"refactor_method\": \"code\"}\nstep_input = StepInput(__root__=input_params)\n</code></pre> <p>In this example, we import the <code>StepInput</code> class from the <code>swarms.structs</code> library and create an instance <code>step_input</code> by passing a dictionary of input parameters. The <code>StepInput</code> class allows any value to be passed, providing flexibility for customization.</p>"},{"location":"swarms/structs/stepinput/#usage-example-2","title":"Usage Example 2:","text":"<pre><code>from swarms.structs import StepInput\n\ninput_params = {\"input_path\": \"data.csv\", \"output_path\": \"result.csv\"}\nstep_input = StepInput(__root__=input_params)\n</code></pre> <p>In this example, we again create an instance of <code>StepInput</code> by passing a dictionary of input parameters. The <code>StepInput</code> class does not restrict the type of input, allowing users to define parameters based on their specific task requirements.</p>"},{"location":"swarms/structs/stepinput/#usage-example-3","title":"Usage Example 3:","text":"<pre><code>from swarms.structs import StepInput\n\nfile_path = \"config.json\"\nwith open(file_path) as f:\n    input_data = json.load(f)\n\nstep_input = StepInput(__root__=input_data)\n</code></pre> <p>In this example, we read input parameters from a JSON file and create an instance of <code>StepInput</code> by passing the loaded JSON data. The <code>StepInput</code> class seamlessly accepts input data from various sources, providing versatility to the user.</p>"},{"location":"swarms/structs/stepinput/#additional-information-and-tips","title":"Additional Information and Tips","text":"<p>When using the <code>StepInput</code> class, ensure that the input parameters are well-defined and align with the requirements of the task step. When passing complex data structures, such as nested dictionaries or JSON objects, ensure that the structure is valid and well-formed.</p>"},{"location":"swarms/structs/stepinput/#references-and-resources","title":"References and Resources","text":"<ul> <li>For further information on the <code>BaseModel</code> and <code>Field</code> classes, refer to the Pydantic documentation: Pydantic Documentation</li> </ul> <p>The <code>StepInput</code> class within the <code>swarms.structs</code> library is a versatile and essential component for defining task-specific input parameters. Its flexibility in accepting any value and seamless integration with diverse data sources make it a valuable asset for customizing input parameters for task steps.</p>"},{"location":"swarms/structs/swarmnetwork/","title":"swarmnetwork","text":"<pre><code># Class Name: SwarmNetwork\n\n## Overview and Introduction\nThe `SwarmNetwork` class is responsible for managing the agents pool and the task queue. It also monitors the health of the agents and scales the pool up or down based on the number of pending tasks and the current load of the agents.\n\n## Class Definition\n\nThe `SwarmNetwork` class has the following parameters:\n\n| Parameter         | Type              | Description                                                                   |\n|-------------------|-------------------|-------------------------------------------------------------------------------|\n| idle_threshold    | float             | Threshold for idle agents to trigger scaling down                             |\n| busy_threshold    | float             | Threshold for busy agents to trigger scaling up                               |\n| agents            | List[Agent]       | List of agent instances to be added to the pool                              |\n| api_enabled       | Optional[bool]    | Flag to enable/disable the API functionality                                 |\n| logging_enabled   | Optional[bool]    | Flag to enable/disable logging                                                |\n| other arguments   | *args             | Additional arguments                                                           |\n| other keyword     | **kwargs          | Additional keyword arguments                                                  |\n\n## Function Explanation and Usage\n\n### Function: `add_task`\n- Adds a task to the task queue\n- Parameters:\n  - `task`: The task to be added to the queue\n- Example:\n  ```python\n  from swarms.structs.agent import Agent\n  from swarms.structs.swarm_net import SwarmNetwork\n\n  agent = Agent()\n  swarm = SwarmNetwork(agents=[agent])\n  swarm.add_task(\"task\")\n  ```\n\n### Function: `async_add_task`\n- Asynchronous function to add a task to the task queue\n- Parameters:\n  - `task`: The task to be added to the queue\n- Example:\n  ```python\n  from swarms.structs.agent import Agent\n  from swarms.structs.swarm_net import SwarmNetwork\n\n  agent = Agent()\n  swarm = SwarmNetwork(agents=[agent])\n  await swarm.async_add_task(\"task\")\n  ```\n\n### Function: `run_single_agent`\n- Executes a task on a single agent\n- Parameters:\n  - `agent_id`: ID of the agent to run the task on\n  - `task`: The task to be executed by the agent (optional)\n- Returns:\n  - Result of the task execution\n- Example:\n  ```python\n  from swarms.structs.agent import Agent\n  from swarms.structs.swarm_net import SwarmNetwork\n\n  agent = Agent()\n  swarm = SwarmNetwork(agents=[agent])\n  swarm.run_single_agent(agent_id, \"task\")\n  ```\n\n### Function: `run_many_agents`\n- Executes a task on all the agents in the pool\n- Parameters:\n  - `task`: The task to be executed by the agents (optional)\n- Returns:\n  - List of results from each agent\n- Example:\n  ```python\n  from swarms.structs.agent import Agent\n  from swarms.structs.swarm_net import SwarmNetwork\n\n  agent = Agent()\n  swarm = SwarmNetwork(agents=[agent])\n  swarm.run_many_agents(\"task\")\n  ```\n\n### Function: `list_agents`\n- Lists all the agents in the pool\n- Returns:\n  - List of active agents\n- Example:\n  ```python\n  from swarms.structs.agent import Agent\n  from swarms.structs.swarm_net import SwarmNetwork\n\n  agent = Agent()\n  swarm = SwarmNetwork(agents=[agent])\n  swarm.list_agents()\n  ```\n\n### Function: `add_agent`\n- Adds an agent to the agent pool\n- Parameters:\n  - `agent`: Agent instance to be added to the pool\n- Example:\n  ```python\n  from swarms.structs.agent import Agent\n  from swarms.structs.swarm_net import SwarmNetwork\n\n  agent = Agent()\n  swarm = SwarmNetwork()\n  swarm.add_agent(agent)\n  ```\n\n### Function: `remove_agent`\n- Removes an agent from the agent pool\n- Parameters:\n  - `agent_id`: ID of the agent to be removed from the pool\n- Example:\n  ```python\n  from swarms.structs.agent import Agent\n  from swarms.structs.swarm_net import SwarmNetwork\n\n  agent = Agent()\n  swarm = SwarmNetwork(agents=[agent])\n  swarm.remove_agent(agent_id)\n  ```\n\n### Function: `scale_up`\n- Scales up the agent pool by adding new agents\n- Parameters:\n  - `num_agents`: Number of agents to be added (optional)\n- Example:\n  ```python\n  from swarms.structs.agent import Agent\n  from swarms.structs.swarm_net import SwarmNetwork\n\n  swarm = SwarmNetwork()\n  swarm.scale_up(num_agents=5)\n  ```\n\n### Function: `scale_down`\n- Scales down the agent pool by removing existing agents\n- Parameters:\n  - `num_agents`: Number of agents to be removed (optional)\n- Example:\n  ```python\n  from swarms.structs.agent import Agent\n  from swarms.structs.swarm_net import SwarmNetwork\n\n  swarm = SwarmNetwork(agents=[agent1, agent2, agent3, agent4, agent5])\n  swarm.scale_down(num_agents=2)\n  ```\n\n### Function: `create_apis_for_agents`\n- Creates APIs for each agent in the pool (optional)\n- Example:\n  ```python\n  from swarms.structs.agent import Agent\n  from swarms.structs.swarm_net import SwarmNetwork\n\n  agent = Agent()\n  swarm = SwarmNetwork(agents=[agent])\n  swarm.create_apis_for_agents()\n  ```\n\n## Additional Information\n- The `SwarmNetwork` class is an essential part of the swarms.structs library, enabling efficient management and scaling of agent pools.\n</code></pre>"},{"location":"swarms/structs/task/","title":"task","text":"<ul> <li>This is the class for the Task</li> <li>For the constructor, it takes in the description, agent, args, kwargs, result, history, schedule_time, scheduler, trigger, action, condition, priority, and dependencies</li> <li>The <code>execute</code> method runs the task by calling the agent or model with the arguments and keyword arguments</li> <li>It sets a trigger, action, and condition for the task</li> <li>Task completion is checked with <code>is_completed</code> method</li> <li><code>add_dependency</code> adds a task to the list of dependencies</li> <li><code>set_priority</code> sets the priority of the task</li> </ul> <pre><code># Example 1: Creating and executing a Task\nfrom swarms.models import OpenAIChat\nfrom swarms.structs import Agent, Task\n\nagent = Agent(llm=OpenAIChat(openai_api_key=\"\"), max_loops=1, dashboard=False)\ntask = Task(agent=agent)\ntask.execute(\"What's the weather in miami\")\nprint(task.result)\n\n# Example 2: Adding a dependency and setting priority\ntask2 = Task(description=\"Task 2\", agent=agent)\ntask.add_dependency(task2)\ntask.set_priority(1)\n\n# Example 3: Executing a scheduled task\ntask3 = Task(description=\"Scheduled Task\", agent=agent)\ntask3.schedule_time = datetime.datetime.now() + datetime.timedelta(minutes=30)\ntask3.handle_scheduled_task()\nprint(task3.is_completed())\n</code></pre>"},{"location":"swarms/structs/taskinput/","title":"taskinput","text":""},{"location":"swarms/structs/taskinput/#moduleclass-name-taskinput","title":"Module/Class Name: TaskInput","text":"<p>The <code>TaskInput</code> class is designed to handle the input parameters for a task. It is an abstract class that serves as the base model for input data manipulation.</p>"},{"location":"swarms/structs/taskinput/#overview-and-introduction","title":"Overview and Introduction","text":"<p>The <code>TaskInput</code> class is an essential component of the <code>swarms.structs</code> library, allowing users to define and pass input parameters to tasks. It is crucial for ensuring the correct and structured input to various tasks and processes within the library.</p>"},{"location":"swarms/structs/taskinput/#class-definition","title":"Class Definition","text":""},{"location":"swarms/structs/taskinput/#taskinput-class","title":"TaskInput Class:","text":"<ul> <li>Parameters:<ul> <li><code>__root__</code> (Any): The input parameters for the task. Any value is allowed.</li> </ul> </li> </ul>"},{"location":"swarms/structs/taskinput/#disclaimer","title":"Disclaimer:","text":"<p>It is important to note that the <code>TaskInput</code> class extends the <code>BaseModel</code> from the <code>pydantic</code> library. This means that it inherits all the properties and methods of the <code>BaseModel</code>.</p>"},{"location":"swarms/structs/taskinput/#functionality-and-usage","title":"Functionality and Usage","text":"<p>The <code>TaskInput</code> class encapsulates the input parameters in a structured format. It allows for easy validation and manipulation of input data.</p>"},{"location":"swarms/structs/taskinput/#usage-example-1-using-taskinput-for-debugging","title":"Usage Example 1: Using TaskInput for Debugging","text":"<pre><code>from pydantic import BaseModel, Field\n\nfrom swarms.structs import TaskInput\n\n\nclass DebugInput(TaskInput):\n    debug: bool\n\n\n# Creating an instance of DebugInput\ndebug_params = DebugInput(__root__={\"debug\": True})\n\n# Accessing the input parameters\nprint(debug_params.debug)  # Output: True\n</code></pre>"},{"location":"swarms/structs/taskinput/#usage-example-2-using-taskinput-for-task-modes","title":"Usage Example 2: Using TaskInput for Task Modes","text":"<pre><code>from pydantic import BaseModel, Field\n\nfrom swarms.structs import TaskInput\n\n\nclass ModeInput(TaskInput):\n    mode: str\n\n\n# Creating an instance of ModeInput\nmode_params = ModeInput(__root__={\"mode\": \"benchmarks\"})\n\n# Accessing the input parameters\nprint(mode_params.mode)  # Output: benchmarks\n</code></pre>"},{"location":"swarms/structs/taskinput/#usage-example-3-using-taskinput-with-arbitrary-parameters","title":"Usage Example 3: Using TaskInput with Arbitrary Parameters","text":"<pre><code>from pydantic import BaseModel, Field\n\nfrom swarms.structs import TaskInput\n\n\nclass ArbitraryInput(TaskInput):\n    message: str\n    quantity: int\n\n\n# Creating an instance of ArbitraryInput\narbitrary_params = ArbitraryInput(__root__={\"message\": \"Hello, world!\", \"quantity\": 5})\n\n# Accessing the input parameters\nprint(arbitrary_params.message)  # Output: Hello, world!\nprint(arbitrary_params.quantity)  # Output: 5\n</code></pre>"},{"location":"swarms/structs/taskinput/#additional-information-and-tips","title":"Additional Information and Tips","text":"<ul> <li>The <code>TaskInput</code> class can be extended to create custom input models with specific parameters tailored to individual tasks.</li> <li>The <code>Field</code> class from <code>pydantic</code> can be used to specify metadata and constraints for the input parameters.</li> </ul>"},{"location":"swarms/structs/taskinput/#references-and-resources","title":"References and Resources","text":"<ul> <li>Official <code>pydantic</code> Documentation: https://pydantic-docs.helpmanual.io/</li> <li>Additional resources on data modelling with <code>pydantic</code>: https://www.tiangolo.com/blog/2021/02/16/real-python-tutorial-modern-fastapi-pydantic/</li> </ul> <p>This documentation presents the <code>TaskInput</code> class, its usage, and practical examples for creating and handling input parameters within the <code>swarms.structs</code> library.</p>"},{"location":"swarms/structs/taskqueuebase/","title":"<code>TaskQueueBase</code>","text":""},{"location":"swarms/structs/taskqueuebase/#introduction","title":"Introduction","text":"<p>The <code>swarms.structs</code> library is a key component of a multi-agent system's task management infrastructure. It provides the necessary classes and methods to create and manage queues of tasks that can be distributed among a swarm of agents. The purpose of this documentation is to guide users through the proper use of the <code>TaskQueueBase</code> class, which serves as an abstract base class for implementing task queues.</p>"},{"location":"swarms/structs/taskqueuebase/#taskqueuebase-class","title":"TaskQueueBase Class","text":"<pre><code>import threading\nfrom abc import ABC, abstractmethod\n\n# Include any additional imports that are relevant to decorators and other classes such as Task and Agent if needed\n\n# Definition of the synchronized_queue decorator (if necessary)\n\n\nclass TaskQueueBase(ABC):\n    def __init__(self):\n        self.lock = threading.Lock()\n\n    @synchronized_queue\n    @abstractmethod\n    def add_task(self, task: Task) -&gt; bool:\n        pass\n\n    @synchronized_queue\n    @abstractmethod\n    def get_task(self, agent: Agent) -&gt; Task:\n        pass\n\n    @synchronized_queue\n    @abstractmethod\n    def complete_task(self, task_id: str):\n        pass\n\n    @synchronized_queue\n    @abstractmethod\n    def reset_task(self, task_id: str):\n        pass\n</code></pre>"},{"location":"swarms/structs/taskqueuebase/#architecture-and-purpose","title":"Architecture and Purpose","text":"<p>The <code>TaskQueueBase</code> class provides an abstract interface for task queue implementations. This class uses the <code>threading.Lock</code> to ensure mutual exclusion, making it suitable for concurrent environments. The <code>@synchronized_queue</code> decorator implies that each method should be synchronized to prevent race conditions.</p> <p>Tasks are generally represented by the <code>Task</code> class, and agents by the <code>Agent</code> class. Implementations of the <code>TaskQueueBase</code> will provide the logic to store tasks, distribute them to agents, and manage their lifecycles.</p>"},{"location":"swarms/structs/taskqueuebase/#methods-and-their-arguments","title":"Methods and Their Arguments","text":"<p>Here's an overview of each method and its arguments:</p> Method Arguments Return Type Description add_task task (Task) bool Adds a task to the queue and returns True if successfully added, False otherwise. get_task agent (Agent) Task Retrieves the next task for the given agent. complete_task task_id (str) None Marks the task identified by task_id as completed. reset_task task_id (str) None Resets the task identified by task_id, typically done if an agent fails to complete the task."},{"location":"swarms/structs/taskqueuebase/#example-usage","title":"Example Usage","text":"<p>Below are three examples of how the <code>TaskQueueBase</code> class can be implemented and used.</p> <p>Note: The actual code for decorators, Task, Agent, and concrete implementations of <code>TaskQueueBase</code> is not provided and should be created as per specific requirements.</p>"},{"location":"swarms/structs/taskqueuebase/#example-1-basic-implementation","title":"Example 1: Basic Implementation","text":"<pre><code># file: basic_queue.py\n\n# Assume synchronized_queue decorator is defined elsewhere\nfrom decorators import synchronized_queue\n\nfrom swarms.structs import Agent, Task, TaskQueueBase\n\n\nclass BasicTaskQueue(TaskQueueBase):\n    def __init__(self):\n        super().__init__()\n        self.tasks = []\n\n    @synchronized_queue\n    def add_task(self, task: Task) -&gt; bool:\n        self.tasks.append(task)\n        return True\n\n    @synchronized_queue\n    def get_task(self, agent: Agent) -&gt; Task:\n        return self.tasks.pop(0)\n\n    @synchronized_queue\n    def complete_task(self, task_id: str):\n        # Logic to mark task as completed\n        pass\n\n    @synchronized_queue\n    def reset_task(self, task_id: str):\n        # Logic to reset the task\n        pass\n\n\n# Usage\nqueue = BasicTaskQueue()\n# Add task, assuming Task object is created\nqueue.add_task(someTask)\n# Get task for an agent, assuming Agent object is created\ntask = queue.get_task(someAgent)\n</code></pre>"},{"location":"swarms/structs/taskqueuebase/#example-2-priority-queue-implementation","title":"Example 2: Priority Queue Implementation","text":"<pre><code># file: priority_queue.py\n# Similar to example 1, but tasks are managed based on priority within add_task and get_task methods\n</code></pre>"},{"location":"swarms/structs/taskqueuebase/#example-3-persistent-queue-implementation","title":"Example 3: Persistent Queue Implementation","text":"<pre><code># file: persistent_queue.py\n# An example demonstrating tasks being saved to a database or filesystem. Methods would include logic for persistence.\n</code></pre>"},{"location":"swarms/structs/taskqueuebase/#additional-information-and-common-issues","title":"Additional Information and Common Issues","text":"<p>This section would provide insights on thread safety, error handling, and best practices in working with task queues in a multi-agent system.</p>"},{"location":"swarms/structs/taskqueuebase/#references","title":"References","text":"<p>Links to further resources and any academic papers or external documentation related to task queues and multi-agent systems would be included here.</p>"},{"location":"swarms/structs/workflow/","title":"Module/Class Name: Workflow","text":"<p>===========================</p> <p>The\u00a0<code>Workflow</code>\u00a0class is a part of the\u00a0<code>swarms</code>\u00a0library and is used to create and execute a workflow of tasks. It provides a way to define a sequence of tasks and execute them in order, with the output of each task being used as the input for the next task.</p>"},{"location":"swarms/structs/workflow/#overview-and-introduction","title":"Overview and Introduction","text":"<p>The\u00a0<code>Workflow</code>\u00a0class is designed to simplify the execution of a series of tasks by providing a structured way to define and execute them. It allows for sequential execution of tasks, with the output of each task being passed as input to the next task. This makes it easy to create complex workflows and automate multi-step processes.</p>"},{"location":"swarms/structs/workflow/#class-definition-workflow","title":"Class Definition: Workflow","text":"<p>The\u00a0<code>Workflow</code>\u00a0class is a powerful tool provided by the\u00a0<code>swarms</code>\u00a0library that allows users to create and execute a sequence of tasks in a structured and automated manner. It simplifies the process of defining and executing complex workflows by providing a clear and intuitive interface.</p>"},{"location":"swarms/structs/workflow/#why-use-workflows","title":"Why Use Workflows?","text":"<p>Workflows are essential in many domains, including data processing, automation, and task management. They enable the automation of multi-step processes, where the output of one task serves as the input for the next task. By using workflows, users can streamline their work, reduce manual effort, and ensure consistent and reliable execution of tasks.</p> <p>The\u00a0<code>Workflow</code>\u00a0class provides a way to define and execute workflows in a flexible and efficient manner. It allows users to define the sequence of tasks, specify dependencies between tasks, and execute them in order. This makes it easier to manage complex processes and automate repetitive tasks.</p>"},{"location":"swarms/structs/workflow/#how-does-it-work","title":"How Does it Work?","text":"<p>The\u00a0<code>Workflow</code>\u00a0class consists of two main components: the\u00a0<code>Task</code>\u00a0class and the\u00a0<code>Workflow</code>\u00a0class itself. Let's explore each of these components in detail.</p>"},{"location":"swarms/structs/workflow/#task-class","title":"Task Class","text":"<p>The\u00a0<code>Task</code>\u00a0class represents an individual task within a workflow. Each task is defined by a string description. It contains attributes such as\u00a0<code>parents</code>,\u00a0<code>children</code>,\u00a0<code>output</code>, and\u00a0<code>structure</code>.</p> <p>The\u00a0<code>parents</code>\u00a0attribute is a list that stores references to the parent tasks of the current task. Similarly, the\u00a0<code>children</code>\u00a0attribute is a list that stores references to the child tasks of the current task. These attributes allow for the definition of task dependencies and the establishment of the workflow's structure.</p> <p>The\u00a0<code>output</code>\u00a0attribute stores the output of the task, which is generated when the task is executed. Initially, the output is set to\u00a0<code>None</code>, indicating that the task has not been executed yet.</p> <p>The\u00a0<code>structure</code>\u00a0attribute refers to the\u00a0<code>Workflow</code>\u00a0object that the task belongs to. This attribute is set when the task is added to the workflow.</p> <p>The\u00a0<code>Task</code>\u00a0class also provides methods such as\u00a0<code>add_child</code>\u00a0and\u00a0<code>execute</code>. The\u00a0<code>add_child</code>\u00a0method allows users to add child tasks to the current task, thereby defining the workflow's structure. The\u00a0<code>execute</code>\u00a0method is responsible for executing the task by running the associated agent's\u00a0<code>run</code>\u00a0method with the task as input. It returns the response generated by the agent's\u00a0<code>run</code>\u00a0method.</p>"},{"location":"swarms/structs/workflow/#workflow-class","title":"Workflow Class","text":"<p>The\u00a0<code>Workflow</code>\u00a0class is the main class that orchestrates the execution of tasks in a workflow. It takes an agent object as input, which is responsible for executing the tasks. The agent object should have a\u00a0<code>run</code>\u00a0method that accepts a task as input and returns a response.</p> <p>The\u00a0<code>Workflow</code>\u00a0class provides methods such as\u00a0<code>add</code>,\u00a0<code>run</code>, and\u00a0<code>context</code>. The\u00a0<code>add</code>\u00a0method allows users to add tasks to the workflow. It returns the newly created task object, which can be used to define task dependencies. The\u00a0<code>run</code>\u00a0method executes the workflow by running each task in order. It returns the last task in the workflow. The\u00a0<code>context</code>\u00a0method returns a dictionary containing the context information for a given task, including the parent output, parent task, and child task.</p> <p>The\u00a0<code>Workflow</code>\u00a0class also has attributes such as\u00a0<code>tasks</code>\u00a0and\u00a0<code>parallel</code>. The\u00a0<code>tasks</code>\u00a0attribute is a list that stores references to all the tasks in the workflow. The\u00a0<code>parallel</code>\u00a0attribute is a boolean flag that determines whether the tasks should be executed in parallel or sequentially.</p> <p>When executing the workflow, the\u00a0<code>run</code>\u00a0method iterates over the tasks in the workflow and executes each task in order. If the\u00a0<code>parallel</code>\u00a0flag is set to\u00a0<code>True</code>, the tasks are executed in parallel using a\u00a0<code>ThreadPoolExecutor</code>. Otherwise, the tasks are executed sequentially.</p>"},{"location":"swarms/structs/workflow/#benefits-and-use-cases","title":"Benefits and Use Cases","text":"<p>The\u00a0<code>Workflow</code>\u00a0class provides several benefits and use cases:</p> <ul> <li> <p>Automation: Workflows automate multi-step processes, reducing manual effort and increasing efficiency. By defining the sequence of tasks and their dependencies, users can automate repetitive tasks and ensure consistent execution.</p> </li> <li> <p>Flexibility: Workflows can be easily customized and modified to suit specific needs. Users can add, remove, or rearrange tasks as required, allowing for dynamic and adaptable workflows.</p> </li> <li> <p>Error Handling: Workflows provide a structured approach to error handling. If an error occurs during the execution of a task, the workflow can be designed to handle the error gracefully and continue with the remaining tasks.</p> </li> <li> <p>Collaboration: Workflows facilitate collaboration by providing a shared structure for task execution. Multiple users can contribute to the workflow by adding or modifying tasks, enabling teamwork and coordination.</p> </li> <li> <p>Reproducibility: Workflows ensure reproducibility by defining a clear sequence of tasks. By following the same workflow, users can achieve consistent results and easily reproduce previous analyses or processes.</p> </li> </ul> <p>Overall, the\u00a0<code>Workflow</code>\u00a0class is a valuable tool for managing and executing complex processes. It simplifies the creation</p>"},{"location":"swarms/structs/workflow/#class-parameters","title":"Class Parameters","text":"<ul> <li><code>agent</code>\u00a0(Any): The agent object that will be used to execute the tasks. It should have a\u00a0<code>run</code>\u00a0method that takes a task as input and returns a response.</li> <li><code>parallel</code>\u00a0(bool): If\u00a0<code>True</code>, the tasks will be executed in parallel using a\u00a0<code>ThreadPoolExecutor</code>. Default:\u00a0<code>False</code>.</li> </ul>"},{"location":"swarms/structs/workflow/#class-methods","title":"Class Methods","text":""},{"location":"swarms/structs/workflow/#addtask-str-task","title":"<code>add(task: str) -&gt; Task</code>","text":"<p>Adds a new task to the workflow.</p> <ul> <li><code>task</code>\u00a0(str): The task to be added.</li> </ul> <p>Returns:</p> <ul> <li><code>Task</code>: The newly created task object.</li> </ul>"},{"location":"swarms/structs/workflow/#runargs-task","title":"<code>run(*args) -&gt; Task</code>","text":"<p>Executes the workflow by running each task in order.</p> <p>Returns:</p> <ul> <li><code>Task</code>: The last task in the workflow.</li> </ul>"},{"location":"swarms/structs/workflow/#contexttask-task-dictstr-any","title":"<code>context(task: Task) -&gt; Dict[str, Any]</code>","text":"<p>Returns a dictionary containing the context information for a given task. The context includes the parent output, parent task, and child task.</p> <ul> <li><code>task</code>\u00a0(Task): The task for which the context information is required.</li> </ul> <p>Returns:</p> <ul> <li><code>Dict[str, Any]</code>: A dictionary containing the context information.</li> </ul>"},{"location":"swarms/structs/workflow/#task-class_1","title":"Task Class","text":"<p>The\u00a0<code>Task</code>\u00a0class is a nested class within the\u00a0<code>Workflow</code>\u00a0class. It represents an individual task in the workflow.</p>"},{"location":"swarms/structs/workflow/#task-parameters","title":"Task Parameters","text":"<ul> <li><code>task</code>\u00a0(str): The task description.</li> </ul>"},{"location":"swarms/structs/workflow/#task-methods","title":"Task Methods","text":""},{"location":"swarms/structs/workflow/#add_childchild-workflowtask","title":"<code>add_child(child: 'Workflow.Task')</code>","text":"<p>Adds a child task to the current task.</p> <ul> <li><code>child</code>\u00a0('Workflow.Task'): The child task to be added.</li> </ul>"},{"location":"swarms/structs/workflow/#execute-any","title":"<code>execute() -&gt; Any</code>","text":"<p>Executes the task by running the associated agent's\u00a0<code>run</code>\u00a0method with the task as input.</p> <p>Returns:</p> <ul> <li><code>Any</code>: The response from the agent's\u00a0<code>run</code>\u00a0method.</li> </ul>"},{"location":"swarms/structs/workflow/#functionality-and-usage","title":"Functionality and Usage","text":"<p>To use the\u00a0<code>Workflow</code>\u00a0class, follow these steps:</p> <ol> <li>Create an instance of the\u00a0<code>Workflow</code>\u00a0class, providing an agent object that has a\u00a0<code>run</code>\u00a0method. This agent will be responsible for executing the tasks in the workflow.</li> </ol> <pre><code>from swarms import Workflow\n\n# Create an instance of the Workflow class\nworkflow = Workflow(agent=my_agent)\n</code></pre> <ol> <li>Add tasks to the workflow using the\u00a0<code>add</code>\u00a0method. Each task should be a string description.</li> </ol> <pre><code># Add tasks to the workflow\ntask1 = workflow.add(\"Task 1\")\ntask2 = workflow.add(\"Task 2\")\ntask3 = workflow.add(\"Task 3\")\n</code></pre> <ol> <li>Define the sequence of tasks by adding child tasks to each task using the\u00a0<code>add_child</code>\u00a0method.</li> </ol> <pre><code># Define the sequence of tasks\ntask1.add_child(task2)\ntask2.add_child(task3)\n</code></pre> <ol> <li>Execute the workflow using the\u00a0<code>run</code>\u00a0method. This will run each task in order, with the output of each task being passed as input to the next task.</li> </ol> <pre><code># Execute the workflow\nworkflow.run()\n</code></pre> <ol> <li>Access the output of each task using the\u00a0<code>output</code>\u00a0attribute of the task object.</li> </ol> <pre><code># Access the output of each task\noutput1 = task1.output\noutput2 = task2.output\noutput3 = task3.output\n</code></pre> <ol> <li>Optionally, you can run the tasks in parallel by setting the\u00a0<code>parallel</code>\u00a0parameter to\u00a0<code>True</code>\u00a0when creating the\u00a0<code>Workflow</code>\u00a0object.</li> </ol> <pre><code># Create a parallel workflow\nparallel_workflow = Workflow(agent=my_agent, parallel=True)\n</code></pre> <ol> <li>You can also access the context information for a task using the\u00a0<code>context</code>\u00a0method. This method returns a dictionary containing the parent output, parent task, and child task for the given task.</li> </ol> <pre><code># Access the context information for a task\ncontext = workflow.context(task2)\nparent_output = context[\"parent_output\"]\nparent_task = context[\"parent\"]\nchild_task = context[\"child\"]\n</code></pre>"},{"location":"swarms/tokenizers/anthropictokenizer/","title":"AnthropicTokenizer Documentation","text":""},{"location":"swarms/tokenizers/anthropictokenizer/#introduction","title":"Introduction","text":"<p>This documentation intends to provide a complete and in-depth guide for using the <code>AnthropicTokenizer</code> class within the <code>swarms.tokenizers</code> library. The <code>AnthropicTokenizer</code> is designed specifically to interface with Anthropic's AI models, primarily used for text tokenization and metadata handling.</p> <p>Understanding how to use this tokenizer effectively is crucial for developers and researchers working with natural language processing, machine learning, and text analysis using Anthropic AI models.</p> <p>The purpose of the <code>AnthropicTokenizer</code> is to convert raw text into a sequence of tokens that can be fed into Anthropic AI models for various tasks. Tokenization is a fundamental step in text processing pipelines and affects the performance of AI models.</p>"},{"location":"swarms/tokenizers/anthropictokenizer/#class-definition-anthropictokenizer","title":"Class Definition: AnthropicTokenizer","text":"<p><code>AnthropicTokenizer</code> extends the functionality of a base tokenizer to provide features specifically needed for Anthropic AI models. The class is designed to manage tokenization processes such as counting tokens and ensuring that the token count is under a specified limit, which is essential for effective and efficient model performance.</p> <p>Class Signature:</p> <p>Parameters:</p> Parameter Name Type Description Default Value <code>max_tokens</code> <code>int</code> Maximum number of tokens permitted. <code>500</code> <code>client</code> <code>Anthropic</code> Instance of an <code>Anthropic</code> client for tokenization services. <code>None</code> <code>model</code> <code>str</code> Identifier for the Anthropic model in use. <code>\"claude-2.1\"</code> <p>Methods and their descriptions:</p> Method Name Return Type Description <code>__post_init__</code> <code>None</code> Initializes default parameters and client instance. <code>default_max_tokens</code> <code>int</code> Returns the default maximum number of tokens. <code>count_tokens</code> <code>int</code> Counts tokens in the input text. Raises a ValueError if the input is not a string."},{"location":"swarms/tokenizers/anthropictokenizer/#architecture-and-mechanics","title":"Architecture and Mechanics","text":"<p>Upon instantiation, <code>AnthropicTokenizer</code> initializes its <code>max_tokens</code> limit and sets up a client to interact with the Anthropic services. The client is responsible for providing tokenization functions critical for processing the text inputs.</p> <p>The tokenizer employs a dictionary to map specific model prefixes to their maximum token counts. This allows users to adapt the tokenizer's behavior to different models with varying token limits. The <code>default_max_tokens()</code> method dynamically retrieves the token limit based on the provided model name, ensuring compatibility and flexibility.</p> <p><code>count_tokens()</code> is a critical function that calculates the number of tokens in a given text. This functionality is essential for respecting the model's token limit and ensuring accurate processing by the Anthropic AI.</p>"},{"location":"swarms/tokenizers/anthropictokenizer/#usage-examples","title":"Usage Examples","text":"<p>Before delving into detailed examples, make sure you have <code>swarms.tokenizers</code> installed and ready. If <code>anthropic</code> is an optional dependency, ensure that it's installed as well.</p>"},{"location":"swarms/tokenizers/anthropictokenizer/#1-tokenizing-with-default-settings","title":"1. Tokenizing with Default Settings","text":"<pre><code>from swarms.tokenizers import AnthropicTokenizer\n\n# Initialize the tokenizer with default settings\ntokenizer = AnthropicTokenizer()\n\n# Tokenize a sample text\ntext = \"Hello world! This is an example text to tokenize.\"\ntoken_count = tokenizer.count_tokens(text)\n\nprint(f\"Number of tokens: {token_count}\")\n</code></pre> <p>In this example, we use the <code>AnthropicTokenizer</code> to count the number of tokens in a simple text. The token count can be crucial for managing inputs to the AI model.</p>"},{"location":"swarms/tokenizers/anthropictokenizer/#2-tokenizing-with-custom-model","title":"2. Tokenizing with Custom Model","text":"<pre><code>from swarms.tokenizers import AnthropicTokenizer\n\n# Define a custom model\ncustom_model = \"claude\"\n\n# Initialize the tokenizer with a custom model and max_tokens\ntokenizer = AnthropicTokenizer(model=custom_model, max_tokens=1000)\n\n# Process a larger text\nlarge_text = \"...\"  # Assume large_text is a string with meaningful content\n\ntoken_count = tokenizer.count_tokens(large_text)\nif token_count &gt; tokenizer.max_tokens:\n    print(\"Text exceeds the maximum token limit.\")\nelse:\n    print(f\"Token count within limit: {token_count}\")\n</code></pre> <p>This snippet demonstrates setting up the tokenizer for a custom model and a higher maximum token limit. It is helpful when dealing with texts larger than the default token limit.</p>"},{"location":"swarms/tokenizers/anthropictokenizer/#3-handling-error-in-token-count-function","title":"3. Handling Error in Token Count Function","text":"<pre><code>from swarms.tokenizers import AnthropicTokenizer\n\n# Initialize the tokenizer\ntokenizer = AnthropicTokenizer()\n\n# Attempt to tokenize a non-string input (which will raise an error)\nnon_string_input = [\"This\", \"is\", \"a\", \"list\", \"not\", \"a\", \"string\"]\n\ntry:\n    tokenizer.count_tokens(non_string_input)\nexcept ValueError as e:\n    print(f\"Error: {e}\")\n</code></pre> <p>This example illustrates the error management within the <code>count_tokens</code> method. It is important to handle exceptions gracefully, particularly when a non-string input is provided.</p>"},{"location":"swarms/tokenizers/anthropictokenizer/#additional-tips-and-considerations","title":"Additional Tips and Considerations","text":"<ul> <li>Always ensure the input text is a string before calling <code>count_tokens</code> to avoid unnecessary errors.</li> <li>Be aware of the <code>max_tokens</code> limit since larger models might have significantly higher limits than defaults.</li> <li>When tokenizing large datasets, batch processing with a loop or parallelization might provide better performance.</li> </ul>"},{"location":"swarms/tokenizers/anthropictokenizer/#resources-and-references","title":"Resources and References","text":"<p>Given that <code>AnthropicTokenizer</code> interacts with an AI model and optional dependencies, it is beneficial to refer to the official documentation and guides specific to those components:</p> <ul> <li>Anthropic Model Documentation (Link would be replaced with actual URL)</li> <li>swarms.tokenizers Installation Guide</li> <li>Python <code>dataclasses</code> Documentation</li> </ul> <p>Additionally, literature on best practices for tokenization and natural language processing will contribute to a more effective use of the tokenizer:</p> <ul> <li>Smith, B. (Year). \"Advanced Tokenization Techniques for NLP Models.\" Journal of Machine Learning.</li> <li>Caruthers, M. (Year). \"Text Pre-processing and Tokenization for Deep Learning.\"</li> </ul> <p>By following the provided documentation and recommended practices, developers and researchers can harness the power of <code>AnthropicTokenizer</code> to its full potential, facilitating optimal use of Anthropic's AI models for varied text processing tasks.</p>"},{"location":"swarms/tokenizers/basetokenizer/","title":"Documentation for <code>swarms.tokenizers.BaseTokenizer</code>","text":""},{"location":"swarms/tokenizers/basetokenizer/#overview-and-introduction","title":"Overview and Introduction","text":"<p>The <code>swarms.tokenizers</code> library is designed to provide flexible and efficient tokenization utilities for natural language processing (NLP) tasks. The <code>BaseTokenizer</code> class serves as a foundational abstract class from which specific tokenizer implementations can be derived. This class outlines essential functions and properties all tokenizers should have, ensuring consistency and capturing common behaviors required for processing textual data.</p>"},{"location":"swarms/tokenizers/basetokenizer/#class-definition-basetokenizer","title":"Class Definition: <code>BaseTokenizer</code>","text":""},{"location":"swarms/tokenizers/basetokenizer/#attributes-and-methods","title":"Attributes and Methods","text":"Name Type Description <code>max_tokens</code> <code>int</code> Maximum number of tokens the tokenizer can process. <code>stop_token</code> <code>str</code> Token used to denote the end of processing. <code>stop_sequences</code> <code>List[str]</code> (read-only) List of stop sequences initialized post-instantiation. <code>count_tokens_left</code> Method: <code>(text) -&gt; int</code> Computes the number of tokens that can still be added given the text. <code>count_tokens</code> Abstract Method: <code>(text) -&gt; int</code> Returns the number of tokens in the given text."},{"location":"swarms/tokenizers/basetokenizer/#functionality-and-usage","title":"Functionality and Usage","text":"<p>The <code>BaseTokenizer</code> class provides the structure for creating tokenizers. It includes methods for counting the tokens in a given text and determining how many more tokens can be added without exceeding the <code>max_tokens</code> limit. This class should be subclassed, and the <code>count_tokens</code> method must be implemented in subclasses to provide the specific token counting logic.</p>"},{"location":"swarms/tokenizers/basetokenizer/#example-subclassing-basetokenizer","title":"Example: Subclassing <code>BaseTokenizer</code>","text":"<pre><code>from swarms.tokenizers import BaseTokenizer\n\n\nclass SimpleTokenizer(BaseTokenizer):\n    def count_tokens(self, text: Union[str, List[dict]]) -&gt; int:\n        if isinstance(text, str):\n            # Split text by spaces as a simple tokenization approach\n            return len(text.split())\n        elif isinstance(text, list):\n            # Assume list of dictionaries with 'token' key\n            return sum(len(item[\"token\"].split()) for item in text)\n        else:\n            raise TypeError(\"Unsupported type for text\")\n\n\n# Usage example\ntokenizer = SimpleTokenizer(max_tokens=100)\ntext = \"This is an example sentence to tokenize.\"\nprint(tokenizer.count_tokens(text))  # Outputs: 7 (assuming space tokenization)\nremaining_tokens = tokenizer.count_tokens_left(text)\nprint(remaining_tokens)  # Outputs: 93\n</code></pre>"},{"location":"swarms/tokenizers/basetokenizer/#note","title":"Note:","text":"<p>Understand that the <code>stop_sequences</code> and <code>stop_token</code> in this particular implementation are placeholders to illustrate the pattern. The actual logic may differ based on specific tokenizer requirements.</p>"},{"location":"swarms/tokenizers/basetokenizer/#additional-information-and-tips","title":"Additional Information and Tips","text":"<ul> <li>Tokenization is a vital step in text processing for NLP. It should be tailored to the requirements of the application.</li> <li>Ensure that tokenizer definitions are in sync with the models and datasets being used.</li> </ul>"},{"location":"swarms/tokenizers/basetokenizer/#references-and-resources","title":"References and Resources","text":"<p>For a deeper understanding of tokenization and its role in NLP, refer to:</p> <ul> <li>Natural Language Processing (NLP) in Python \u2014 Tokenization</li> <li>Hugging Face Tokenizers - a popular library for tokenization, particularly in the context of transformer models.</li> </ul>"},{"location":"swarms/tokenizers/coheretokenizer/","title":"CohereTokenizer Documentation","text":"<p>The <code>CohereTokenizer</code> class is designed to interface with Cohere language models and provides methods for tokenizing text inputs. This tokenizer plays a crucial role in preparing data for a Cohere model, which operates on tokens rather than raw text.</p>"},{"location":"swarms/tokenizers/coheretokenizer/#class-name-coheretokenizer","title":"Class Name: <code>CohereTokenizer</code>","text":""},{"location":"swarms/tokenizers/coheretokenizer/#overview","title":"Overview","text":"<p>The <code>CohereTokenizer</code> class is essential for interacting with Cohere models that require tokenized input. As models often operate on tokens, having an intuitive and efficient tokenizer directly linked to the model simplifies preprocessing tasks. This tokenizer counts the tokens in the given text, helping users to manage and understand the tokens they can work with, given limitations like the model's maximum token count.</p>"},{"location":"swarms/tokenizers/coheretokenizer/#architecture-and-how-the-class-works","title":"Architecture and How the Class Works","text":"<p>The <code>CohereTokenizer</code> is built as a data class, ensuring that it is lightweight and focused solely on its data attributes and methods related to tokenization. The class relies on an instance of a Cohere <code>Client</code>, which needs to be instantiated with an API key from Cohere before use. </p> <p>Upon instantiation, the <code>CohereTokenizer</code> holds a reference to a specific Cohere model and interfaces with the <code>Client</code> to tokenize text accordingly. It provides a simple utility (<code>count_tokens</code>) to count the number of tokens that a string, or a list of strings, would be broken down into by the Cohere API.</p>"},{"location":"swarms/tokenizers/coheretokenizer/#purpose-and-usage","title":"Purpose and Usage","text":"<p>The <code>CohereTokenizer</code> is specifically made for users who are working with Cohere language models. It's designed to help them in preprocessing steps by converting text into tokens and determining how many tokens their text segments contain. This is crucial for ensuring that inputs do not exceed the model's maximum token count, as exceeding this limit can result in errors or truncated text.</p>"},{"location":"swarms/tokenizers/coheretokenizer/#class-definition","title":"Class Definition","text":"<pre><code>@dataclass\nclass CohereTokenizer:\n    model: str\n    client: Client\n    DEFAULT_MODEL: str = \"command\"\n    DEFAULT_MAX_TOKENS: int = 2048\n    max_tokens: int = DEFAULT_MAX_TOKENS\n</code></pre>"},{"location":"swarms/tokenizers/coheretokenizer/#parameters","title":"Parameters","text":"Parameter Type Description Default Value <code>model</code> <code>str</code> Specifies the Cohere model to be used for tokenization. None <code>client</code> <code>Client</code> An instance of the Cohere client, initialized with an API key. None <code>DEFAULT_MODEL</code> <code>str</code> The default model to use if none is specified. \"command\" <code>DEFAULT_MAX_TOKENS</code> <code>int</code> Default maximum number of tokens the model accepts. 2048 <code>max_tokens</code> <code>int</code> Maximum number of tokens; it can be altered to fit the model. <code>DEFAULT_MAX_TOKENS</code>"},{"location":"swarms/tokenizers/coheretokenizer/#methods","title":"Methods","text":"<p>The <code>CohereTokenizer</code> class contains the following method:</p>"},{"location":"swarms/tokenizers/coheretokenizer/#count_tokens","title":"<code>count_tokens</code>","text":"<pre><code>def count_tokens(self, text: str | list) -&gt; int:\n    \"\"\"\n    Count the number of tokens in the given text.\n\n    Args:\n        text (str | list): The input text to tokenize.\n\n    Returns:\n        int: The number of tokens in the text.\n\n    Raises:\n        ValueError: If the input text is not a string.\n    \"\"\"\n</code></pre>"},{"location":"swarms/tokenizers/coheretokenizer/#functionality-and-usage-example","title":"Functionality and Usage Example","text":"<p>Below are examples demonstrating how to use <code>CohereTokenizer</code>.</p>"},{"location":"swarms/tokenizers/coheretokenizer/#counting-tokens","title":"Counting Tokens","text":""},{"location":"swarms/tokenizers/coheretokenizer/#initialization","title":"Initialization","text":"<p>First, the Cohere client must be initialized and passed in to create an instance of <code>CohereTokenizer</code>.</p> <pre><code>from cohere import Client\n\nfrom swarms.tokenizers import CohereTokenizer\n\n# Initialize Cohere client with your API key\ncohere_client = Client(\"your-api-key\")\n\n# Instantiate the tokenizer\ntokenizer = CohereTokenizer(model=\"your-model-name\", client=cohere_client)\n</code></pre>"},{"location":"swarms/tokenizers/coheretokenizer/#count-tokens-example-1","title":"Count Tokens Example 1","text":"<p>Counting tokens for a single string.</p> <pre><code>text_to_tokenize = \"Hello, World!\"\ntoken_count = tokenizer.count_tokens(text_to_tokenize)\nprint(f\"Number of tokens: {token_count}\")\n</code></pre>"},{"location":"swarms/tokenizers/coheretokenizer/#count-tokens-example-2","title":"Count Tokens Example 2","text":"<p>Trying to pass a list instead of a single string, which would raise an error.</p> <pre><code>texts_to_tokenize = [\"Hello, World!\", \"Another piece of text.\"]\ntry:\n    token_count = tokenizer.count_tokens(texts_to_tokenize)\nexcept ValueError as e:\n    print(f\"Error: {e}\")\n</code></pre> <p>The above code would print <code>Error: Text must be a string.</code> as the <code>count_tokens</code> function expects a string, not a list.</p>"},{"location":"swarms/tokenizers/coheretokenizer/#additional-information-and-tips","title":"Additional Information and Tips","text":"<p>When working with the <code>CohereTokenizer</code>, here are some key points to keep in mind:</p> <ul> <li>The token count is important to know because Cohere models have a maximum token limit for input. If your text exceeds this limit, it must be split or truncated before being passed to the model.</li> <li>It is always a good practice to catch exceptions when using methods like <code>count_tokens</code> to handle unexpected inputs gracefully.</li> <li>Remember to replace <code>'your-api-key'</code> and <code>'your-model-name'</code> with your actual Cohere API key and desired model name.</li> </ul>"},{"location":"swarms/tokenizers/coheretokenizer/#references-and-resources","title":"References and Resources","text":"<p>For more detailed information, refer to the following resources:</p> <ul> <li>Cohere API documentation</li> <li>Data Classes in Python</li> </ul>"},{"location":"swarms/tokenizers/huggingfacetokenizer/","title":"HuggingFaceTokenizer Documentation","text":"<p><code>HuggingFaceTokenizer</code> is a comprehensive Python class that leverages the Hugging Face <code>transformers</code> library to tokenize text using the SentencePiece tokenization mechanism. This class serves as a convenient wrapper for initializing and using tokenizer models from Hugging Face's transformer models, enabling easy integration of tokenizer functionality in various NLP tasks.</p> <p>Purpose and Architecture:</p> <p>Tokenization is a critical step in processing natural language wherein text is broken down into smaller elements (tokens), which can be further used for text analysis, language modeling, and other computational linguistics tasks. The <code>HuggingFaceTokenizer</code> provides methods to encode text (turning strings into lists of token IDs) and decode lists of token IDs back into human-readable text.</p> <p>Table of Contents:</p> <ul> <li>Overview</li> <li>Initialization</li> <li>Properties</li> <li>Methods</li> <li>Usage Examples</li> <li>References and Resources</li> </ul>"},{"location":"swarms/tokenizers/huggingfacetokenizer/#overview","title":"Overview","text":"<p>The <code>HuggingFaceTokenizer</code> class is designed to streamline the process of tokenizing text for natural language processing (NLP). It encapsulates various functionalities, such as encoding text into tokens, decoding tokens into text, and identifying token IDs for special tokens.</p>"},{"location":"swarms/tokenizers/huggingfacetokenizer/#initialization","title":"Initialization","text":"<p><code>HuggingFaceTokenizer</code> is initialized by providing the directory containing the pretrained tokenizer model files. During its initialization, it configures its internal state for tokenization processes, prepares access to vocabulary, and establishes necessary properties for subsequent tokenization tasks.</p>"},{"location":"swarms/tokenizers/huggingfacetokenizer/#constructor-parameters","title":"Constructor Parameters","text":"Parameter Data Type Description Default model_dir <code>str</code> The directory containing the tokenizer model files. None"},{"location":"swarms/tokenizers/huggingfacetokenizer/#attributes","title":"Attributes","text":"Attribute Data Type Description vocab_size <code>int</code> The size of the vocabulary used by the tokenizer. bos_token_id <code>int</code> The token ID representing the beginning of sequence token. eos_token_id <code>int</code> The token ID representing the end of sequence token. prefix_space_tokens <code>Set[int]</code> A set of token IDs without a prefix space."},{"location":"swarms/tokenizers/huggingfacetokenizer/#methods","title":"Methods","text":""},{"location":"swarms/tokenizers/huggingfacetokenizer/#vocabulary-related-methods","title":"Vocabulary Related Methods","text":""},{"location":"swarms/tokenizers/huggingfacetokenizer/#vocab_size","title":"<code>vocab_size</code>","text":"<p>Returns the size of the tokenizer's vocabulary.</p>"},{"location":"swarms/tokenizers/huggingfacetokenizer/#bos_token_id","title":"<code>bos_token_id</code>","text":"<p>Returns the token ID used for the beginning of a sentence.</p>"},{"location":"swarms/tokenizers/huggingfacetokenizer/#eos_token_id","title":"<code>eos_token_id</code>","text":"<p>Returns the token ID used for the end of a sentence.</p>"},{"location":"swarms/tokenizers/huggingfacetokenizer/#prefix_space_tokens","title":"<code>prefix_space_tokens</code>","text":"<p>Returns a set of token IDs that start without prefix spaces.</p>"},{"location":"swarms/tokenizers/huggingfacetokenizer/#tokenization-methods","title":"Tokenization Methods","text":""},{"location":"swarms/tokenizers/huggingfacetokenizer/#encode","title":"<code>encode</code>","text":"<p>Encodes a given text into a sequence of token IDs.</p>"},{"location":"swarms/tokenizers/huggingfacetokenizer/#decode","title":"<code>decode</code>","text":"<p>Decodes a given sequence of token IDs into human-readable text.</p>"},{"location":"swarms/tokenizers/huggingfacetokenizer/#indexes_containing_token","title":"<code>indexes_containing_token</code>","text":"<p>Returns a list of token IDs that potentially could be decoded into the given token.</p>"},{"location":"swarms/tokenizers/huggingfacetokenizer/#__call__","title":"<code>__call__</code>","text":"<p>Tokenizes given text when the object is called like a function.</p>"},{"location":"swarms/tokenizers/huggingfacetokenizer/#usage-examples","title":"Usage Examples","text":""},{"location":"swarms/tokenizers/huggingfacetokenizer/#1-initializing-the-tokenizer","title":"1. Initializing the Tokenizer","text":"<pre><code>from swarms.tokenizers import HuggingFaceTokenizer\n\n# Initialize the tokenizer with the path to your tokenizer model.\ntokenizer = HuggingFaceTokenizer(\"/path/to/your/model_dir\")\n</code></pre>"},{"location":"swarms/tokenizers/huggingfacetokenizer/#2-encoding-text","title":"2. Encoding Text","text":"<pre><code># Tokenize a single sentence.\nsentence = \"The quick brown fox jumps over the lazy dog.\"\ntoken_ids = tokenizer.encode(sentence)\nprint(token_ids)\n</code></pre>"},{"location":"swarms/tokenizers/huggingfacetokenizer/#3-decoding-tokens","title":"3. Decoding Tokens","text":"<pre><code># Assuming 'token_ids' contains a list of token IDs\ndecoded_text = tokenizer.decode(token_ids)\nprint(decoded_text)\n</code></pre>"},{"location":"swarms/tokenizers/huggingfacetokenizer/#4-getting-special-token-ids","title":"4. Getting Special Token IDs","text":"<pre><code># Get the beginning of sequence token ID\nbos_id = tokenizer.bos_token_id\nprint(f\"BOS token ID: {bos_id}\")\n\n# Get the end of sequence token ID\neos_id = tokenizer.eos_token_id\nprint(f\"EOS token ID: {eos_id}\")\n</code></pre>"},{"location":"swarms/tokenizers/huggingfacetokenizer/#5-using-the-tokenizer","title":"5. Using the Tokenizer","text":"<pre><code># Tokenize a prompt directly by calling the object with a string.\ntext = \"Hello, world!\"\ntoken_ids = tokenizer(text)\nprint(token_ids)\n</code></pre>"},{"location":"swarms/tokenizers/huggingfacetokenizer/#references-and-resources","title":"References and Resources","text":"<p>For more in-depth information on the Hugging Face <code>transformers</code> library and SentencePiece, refer to the following resources:</p> <ul> <li>Hugging Face <code>transformers</code> library documentation: https://huggingface.co/docs/transformers/index</li> <li>SentencePiece repository and documentation: https://github.com/google/sentencepiece</li> </ul> <p>This documentation provides an introductory overview of the <code>HuggingFaceTokenizer</code> class. For a more extensive guide on the various parameters, functionalities, and advanced usage scenarios, users should refer to the detailed library documentation and external resources provided above.</p>"},{"location":"swarms/tokenizers/openaitokenizer/","title":"OpenAITokenizer","text":"<p>The <code>OpenAITokenizer</code> class is a versatile and intuitive tokenizer designed for use with OpenAI's various language models, including the powerful GPT series. This class addresses the need to efficiently tokenize text for submission to OpenAI's API endpoints, managing different models and their unique tokenization schemes with ease.</p> <p>Utility of <code>OpenAITokenizer</code> centers around its key features: - Support for multiple OpenAI models including GPT-3 and GPT-4. - Dynamic token counting that considers model-specific details. - Straightforward API intended for easy integration with larger systems.</p>"},{"location":"swarms/tokenizers/openaitokenizer/#architecture-and-design","title":"Architecture and Design","text":"<p>The class adheres to a simple yet effective design, offering methods for calculating token lengths and embedded properties that manage model-specific characteristics such as maximum tokens and encodings. A data class structure is used for clean initializations and better management of class data.</p> <p>The <code>OpenAITokenizer</code> uses a property-based approach and a method-based approach to provide users with a variety of functionalities essential for preparing text input for OpenAI models.</p>"},{"location":"swarms/tokenizers/openaitokenizer/#attributes","title":"Attributes","text":"<p>The class contains several key constants and properties that define defaults and settings for use with different models:</p> Attribute Type Description <code>DEFAULT_OPENAI_GPT_3_COMPLETION_MODEL</code> <code>str</code> Default completion model for OpenAI GPT-3. <code>DEFAULT_OPENAI_GPT_3_CHAT_MODEL</code> <code>str</code> Default chat model for OpenAI GPT-3. <code>DEFAULT_OPENAI_GPT_4_MODEL</code> <code>str</code> Default model for OpenAI GPT-4. <code>DEFAULT_ENCODING</code> <code>str</code> Default encoding for text. <code>DEFAULT_MAX_TOKENS</code> <code>int</code> Default maximum number of tokens based on the model. <code>TOKEN_OFFSET</code> <code>int</code> Token offset applicable to some models. <code>MODEL_PREFIXES_TO_MAX_TOKENS</code> <code>dict</code> Mapping of model prefixes to their respective max tokens. <code>EMBEDDING_MODELS</code> <code>list</code> List of embedding models supported. <code>model</code> <code>str</code> Name of the model currently being used."},{"location":"swarms/tokenizers/openaitokenizer/#methods","title":"Methods","text":"<p>The <code>OpenAITokenizer</code> class offers a variety of methods:</p> Method Arguments Return Type Description <code>__post_init__</code> None <code>None</code> Method called after the class has been initialized to set up default values. <code>encoding</code> None <code>Encoding</code> Getter method that retrieves the encoding based on the specified model. <code>default_max_tokens</code> None <code>int</code> Calculates the default max tokens based on the current model or defaults if not model-specific. <code>count_tokens</code> <code>text: str \\| list[dict]</code>, <code>model: str</code> <code>int</code> Counts the number of tokens within a given text or a list of messages. <code>len</code> <code>text: str \\| list[dict]</code>, <code>model: str</code> <code>int</code> Wrapper for <code>count_tokens</code>, providing a more intuitive naming convention."},{"location":"swarms/tokenizers/openaitokenizer/#usage-examples","title":"Usage Examples","text":"<p>Given the extensive nature of this class, several examples are provided for each method, detailing how to use the <code>OpenAITokenizer</code> in different contexts.</p>"},{"location":"swarms/tokenizers/openaitokenizer/#example-1-initializing-the-tokenizer","title":"Example 1: Initializing the Tokenizer","text":"<pre><code>from swarms.tokenizers import OpenAITokenizer\n\ntokenizer = OpenAITokenizer(model=\"gpt-4\")\n</code></pre> <p>This example creates a new instance of <code>OpenAITokenizer</code> set to work with the GPT-4 model.</p>"},{"location":"swarms/tokenizers/openaitokenizer/#example-2-counting-tokens","title":"Example 2: Counting Tokens","text":"<pre><code>text = \"Hello, this is an example text to tokenize.\"\n\n# Initialize the tokenizer\ntokenizer = OpenAITokenizer(model=\"gpt-4\")\n\n# Count tokens\nnum_tokens = tokenizer.count_tokens(text)\nprint(f\"Number of tokens: {num_tokens}\")\n</code></pre> <p>This code snippet demonstrates how to count the number of tokens in a string of text using the specified model's encoding.</p>"},{"location":"swarms/tokenizers/openaitokenizer/#example-3-custom-model-token-counting","title":"Example 3: Custom Model Token Counting","text":"<pre><code>messages = [\n    {\"name\": \"Alice\", \"message\": \"Hello! How are you?\"},\n    {\"name\": \"Bob\", \"message\": \"I'm good! Just working on some code.\"},\n]\n\ntokenizer = OpenAITokenizer(model=\"gpt-3.5-turbo\")\n\n# Count tokens for a list of messages\nnum_tokens = tokenizer.len(messages, model=\"gpt-3.5-turbo-0613\")\nprint(f\"Total tokens for messages: {num_tokens}\")\n</code></pre> <p>In this example, we're invoking the <code>len</code> method to count the tokens in a conversation thread. Each message is represented as a dictionary with a <code>name</code> and <code>message</code> field.</p>"},{"location":"swarms/tokenizers/sentencepiecetokenizer/","title":"swarms.tokenizers Documentation","text":"<p><code>swarms.tokenizers</code> is a PyTorch-like tokenization library designed to facilitate natural language processing (NLP) tasks by converting text inputs into a form that machine learning models can interpret. In this documentation, we will outline how to utilize the <code>SentencePieceTokenizer</code> class from the <code>swarms.tokenizers</code> library, which offers sentencepiece tokenization, a language-independent subword tokenizer and detokenizer.</p>"},{"location":"swarms/tokenizers/sentencepiecetokenizer/#purpose-and-architecture-of-sentencepiecetokenizer","title":"Purpose and Architecture of <code>SentencePieceTokenizer</code>","text":"<p>The <code>SentencePieceTokenizer</code> class uses a pre-trained sentencepiece model to tokenize and detokenize texts. SentencePiece is an unsupervised text tokenizer and detokenizer that allows the generation of a subword vocabulary from raw data. By breaking text down into subword units (like wordpieces or byte-pair-encodings), SentencePiece handles languages without a clear word boundary and can improve the performance of text processing in neural network models.</p> <p>In <code>SentencePieceTokenizer</code>, the tokenization process is language-agnostic and encompasses a range of tokenization strategies, such as byte pair encoding (BPE), unigram, or a combination of both. The class is designed with ease of use in mind, allowing seamless integration with other components of the NLP pipeline.</p>"},{"location":"swarms/tokenizers/sentencepiecetokenizer/#class-definition","title":"Class Definition","text":"<pre><code>class SentencePieceTokenizer:\n    \"\"\"\n    Tokenizer of sentencepiece.\n\n    Args:\n        model_file (str): the path of the tokenizer model\n    \"\"\"\n</code></pre>"},{"location":"swarms/tokenizers/sentencepiecetokenizer/#initialization-parameters","title":"Initialization Parameters","text":"Property/Method Type Description <code>model_file</code> <code>str</code> The path to the pretrained sentencepiece model file."},{"location":"swarms/tokenizers/sentencepiecetokenizer/#methods-and-usage","title":"Methods and Usage","text":"<p>Below, we detail the methods available in <code>SentencePieceTokenizer</code>, including their parameters, their functionality, and usage examples.</p>"},{"location":"swarms/tokenizers/sentencepiecetokenizer/#method-__init__","title":"Method: <code>__init__</code>","text":"<p>Instantiates an instance of the <code>SentencePieceTokenizer</code> with the specified sentencepiece model.</p>"},{"location":"swarms/tokenizers/sentencepiecetokenizer/#parameters","title":"Parameters","text":"Parameter Type Description <code>model_file</code> <code>str</code> The path to the pretrained sentencepiece model file."},{"location":"swarms/tokenizers/sentencepiecetokenizer/#example","title":"Example","text":"<pre><code>from swarms.tokenizers import SentencePieceTokenizer\n\ntokenizer = SentencePieceTokenizer(model_file=\"your_model.model\")\n</code></pre>"},{"location":"swarms/tokenizers/sentencepiecetokenizer/#properties-vocabulary-information","title":"Properties: Vocabulary Information","text":"<p>These properties provide access to various vocabulary-specific information.</p>"},{"location":"swarms/tokenizers/sentencepiecetokenizer/#vocab_size","title":"<code>vocab_size</code>","text":""},{"location":"swarms/tokenizers/sentencepiecetokenizer/#bos_token_id","title":"<code>bos_token_id</code>","text":""},{"location":"swarms/tokenizers/sentencepiecetokenizer/#eos_token_id","title":"<code>eos_token_id</code>","text":""},{"location":"swarms/tokenizers/sentencepiecetokenizer/#example_1","title":"Example","text":"<pre><code>vocab_size = tokenizer.vocab_size\nprint(f\"Vocabulary size: {vocab_size}\")\n\nbos_id = tokenizer.bos_token_id\neos_id = tokenizer.eos_token_id\nprint(f\"BOS token ID: {bos_id}, EOS token ID: {eos_id}\")\n</code></pre>"},{"location":"swarms/tokenizers/sentencepiecetokenizer/#method-indexes_containing_token","title":"Method: <code>indexes_containing_token</code>","text":"<p>Finds possible tokenizer indexes that, when decoded, may contain the input token.</p>"},{"location":"swarms/tokenizers/sentencepiecetokenizer/#parameters_1","title":"Parameters","text":"Parameter Type Description <code>token</code> <code>str</code> The token for which possible indexes are to be found."},{"location":"swarms/tokenizers/sentencepiecetokenizer/#returns","title":"Returns","text":"<ul> <li><code>List[int]</code>: List of tokenizer indexes that might contain the token.</li> </ul>"},{"location":"swarms/tokenizers/sentencepiecetokenizer/#example_2","title":"Example","text":"<pre><code>indexes = tokenizer.indexes_containing_token(\"\u2581the\")\nprint(f\"Indexes containing '\u2581the': {indexes}\")\n</code></pre>"},{"location":"swarms/tokenizers/sentencepiecetokenizer/#method-encode","title":"Method: <code>encode</code>","text":"<p>Tokenizes a text prompt into a list of token IDs.</p>"},{"location":"swarms/tokenizers/sentencepiecetokenizer/#parameters_2","title":"Parameters","text":"Parameter Type Description <code>s</code> <code>str</code> The text prompt to tokenize. <code>add_bos</code> <code>bool</code> If <code>True</code>, it adds the beginning-of-sentence token. (default: <code>True</code>)"},{"location":"swarms/tokenizers/sentencepiecetokenizer/#returns_1","title":"Returns","text":"<ul> <li><code>List[int]</code>: List of token IDs representing the text prompt.</li> </ul>"},{"location":"swarms/tokenizers/sentencepiecetokenizer/#example_3","title":"Example","text":"<pre><code>encoded_ids = tokenizer.encode(\"Hello, world!\", add_bos=True)\nprint(f\"Encoded token IDs: {encoded_ids}\")\n</code></pre>"},{"location":"swarms/tokenizers/sentencepiecetokenizer/#method-decode","title":"Method: <code>decode</code>","text":"<p>Detokenizes a list of token IDs into text.</p>"},{"location":"swarms/tokenizers/sentencepiecetokenizer/#parameters_3","title":"Parameters","text":"Parameter Type Description <code>t</code> <code>List[int]</code> A list of token IDs to detokenize. <code>offset</code> <code>Optional[int]</code> For incremental decoding. Defaults to <code>None</code>, which means it is not applied."},{"location":"swarms/tokenizers/sentencepiecetokenizer/#returns_2","title":"Returns","text":"<ul> <li><code>str</code>: Text representation of the decoded token IDs.</li> </ul>"},{"location":"swarms/tokenizers/sentencepiecetokenizer/#example_4","title":"Example","text":"<pre><code>decoded_text = tokenizer.decode([bos_id] + encoded_ids)\nprint(f\"Decoded text: {decoded_text}\")\n</code></pre>"},{"location":"swarms/tokenizers/sentencepiecetokenizer/#method-__call__","title":"Method: <code>__call__</code>","text":"<p>Tokenizes prompts when the class instance is used as a callable.</p>"},{"location":"swarms/tokenizers/sentencepiecetokenizer/#parameters_4","title":"Parameters","text":"Parameter Type Description <code>s</code> <code>Union[str, Sequence[str]]</code> Text prompts to tokenize. <code>add_bos</code> <code>bool</code> If <code>True</code>, it adds the beginning-of-sentence token. (default: <code>False</code>) <code>add_eos</code> <code>bool</code> If <code>True</code>, it adds the end-of-sentence token. (default: <code>False</code>)"},{"location":"swarms/tokenizers/sentencepiecetokenizer/#returns_3","title":"Returns","text":"<ul> <li><code>addict.Addict</code>: Object with <code>input_ids</code> containing the list of token IDs.</li> </ul>"},{"location":"swarms/tokenizers/sentencepiecetokenizer/#example_5","title":"Example","text":"<pre><code>input_data = tokenizer(\"Let's tokenize this sentence.\")\nprint(f\"Tokenized input IDs: {input_data.input_ids}\")\n</code></pre>"},{"location":"swarms/tokenizers/sentencepiecetokenizer/#additional-information-and-tips","title":"Additional Information and Tips","text":"<p>The library has efficient internals that cache information for performance benefits. For example, <code>indexes_containing_token</code> uses a deque to store the most recent lookups, which saves computation time by avoiding re-traversing the vocabulary.</p>"},{"location":"swarms/tokenizers/sentencepiecetokenizer/#conclusion","title":"Conclusion","text":"<p>This documentation provides an in-depth explanation of <code>swarms.tokenizers</code> with a focus on the <code>SentencePieceTokenizer</code> class. By following the examples and guidance detailed above, users should be able to effectively use the tokenizers for their NLP tasks. Users are also encouraged to refer to further resources and the official SentencePiece documentation for more advanced use cases and configurations.</p>"},{"location":"swarms/tokenizers/tokenizer/","title":"<code>Tokenizer</code> Class Documentation","text":"<p>The <code>Tokenizer</code> class is a flexible and robust tokenization tool designed to efficiently tokenize prompts into a sequence of token IDs or convert token IDs back into readable text. The class works by initializing with a path to a pretrained tokenization model and supports different tokenization backends based on the availability of configs and pretrained models.</p>"},{"location":"swarms/tokenizers/tokenizer/#initialization-configuration","title":"Initialization &amp; Configuration","text":""},{"location":"swarms/tokenizers/tokenizer/#parameters","title":"Parameters:","text":"Parameter Type Description Required model_file str Path to the tokenizer model or directory Yes"},{"location":"swarms/tokenizers/tokenizer/#attributes","title":"Attributes:","text":"Attribute Type Description vocab_size int Size of the tokenizer's vocabulary bos_token_id int ID of the beginning-of-sequence token eos_token_id int ID of the end-of-sequence token"},{"location":"swarms/tokenizers/tokenizer/#methods","title":"Methods:","text":"Method Returns Description encode(s, add_bos=True, **kwargs) list[int] Tokenizes a prompt and returns token IDs. decode(t, offset=None) str Decodes a list of token IDs to a string. call(s) list[int] Tokenize prompts when the instance is called directly. indexes_containing_token(token) list[int] Returns indexes in the vocabulary that may contain the token."},{"location":"swarms/tokenizers/tokenizer/#usage-examples","title":"Usage Examples","text":""},{"location":"swarms/tokenizers/tokenizer/#tokenizing-a-prompt","title":"Tokenizing a Prompt","text":"<pre><code>from swarms.tokenizers import Tokenizer\n\ntokenizer = Tokenizer(\"/path/to/tokenizer.model\")\n\n# Tokenize a single prompt string\nprompt = \"Hello, world!\"\ntoken_ids = tokenizer.encode(prompt)\nprint(token_ids)\n</code></pre>"},{"location":"swarms/tokenizers/tokenizer/#decoding-token-ids","title":"Decoding Token IDs","text":"<pre><code># Decode token IDs back into text\ndecoded_text = tokenizer.decode(token_ids)\nprint(decoded_text)\n</code></pre>"},{"location":"swarms/tokenizers/tokenizer/#incremental-decoding","title":"Incremental Decoding","text":"<pre><code># Incremental decoding with offset (useful for streaming applications)\npartial_tokens = [token_ids[0]]  # simulate partially received tokens\ndecoded_partial = tokenizer.decode(partial_tokens, offset=0)\nprint(decoded_partial)\n</code></pre>"},{"location":"swarms/tokenizers/tokenizer/#properties-access","title":"Properties Access","text":"<pre><code># Access vocabulary size and special token IDs\nprint(\"Vocabulary Size:\", tokenizer.vocab_size)\nprint(\"BOS Token ID:\", tokenizer.bos_token_id)\nprint(\"EOS Token ID:\", tokenizer.eos_token_id)\n</code></pre>"},{"location":"swarms/tokenizers/tokenizer/#indexes-containing-token","title":"Indexes Containing Token","text":"<pre><code># Find indexes that may output a specific token during decoding\ntoken = \"world\"\nindexes = tokenizer.indexes_containing_token(token)\nprint(\"Token Indexes:\", indexes)\n</code></pre>"},{"location":"swarms/utils/check_device/","title":"check_device","text":""},{"location":"swarms/utils/check_device/#modulefunction-name-check_device","title":"Module/Function Name: check_device","text":"<p>The <code>check_device</code> is a utility function in PyTorch designed to identify and return the appropriate device(s) for CUDA processing. If CUDA is not available, a CPU device is returned. If CUDA is available, the function returns a list of all available GPU devices.</p> <p>The function examines the CUDA availability, checks for multiple GPUs, and finds additional properties for each device.</p>"},{"location":"swarms/utils/check_device/#function-signature-and-arguments","title":"Function Signature and Arguments","text":"<p>Signature: <pre><code>def check_device(\n    log_level: Any = logging.INFO,\n    memory_threshold: float = 0.8,\n    capability_threshold: float = 3.5,\n    return_type: str = \"list\",\n) -&gt; Union[torch.device, List[torch.device]]\n</code></pre></p> Parameter Data Type Default Value Description <code>log_level</code> Any logging.INFO The log level. <code>memory_threshold</code> float 0.8 It is used to check the threshold of memory used on the GPU(s). <code>capability_threshold</code> float 3.5 It is used to consider only those GPU(s) which have higher compute capability compared to the threshold. <code>return_type</code> str \"list\" Depending on the <code>return_type</code> either a list of devices can be returned or a single device. <p>This function does not take any mandatory argument. However, it supports optional arguments such as <code>log_level</code>, <code>memory_threshold</code>, <code>capability_threshold</code>, and <code>return_type</code>.</p> <p>Returns:</p> <ul> <li>A single torch.device if one device or list of torch.devices if multiple CUDA devices are available, else returns the CPU device if CUDA is not available.</li> </ul>"},{"location":"swarms/utils/check_device/#usage-and-examples","title":"Usage and Examples","text":""},{"location":"swarms/utils/check_device/#example-1-basic-usage","title":"Example 1: Basic Usage","text":"<pre><code>import logging\n\nimport torch\n\nfrom swarms.utils import check_device\n\n# Basic usage\ndevice = check_device(\n    log_level=logging.INFO,\n    memory_threshold=0.8,\n    capability_threshold=3.5,\n    return_type=\"list\",\n)\n</code></pre>"},{"location":"swarms/utils/check_device/#example-2-using-cpu-when-cuda-is-not-available","title":"Example 2: Using CPU when CUDA is not available","text":"<pre><code>import torch\n\nfrom swarms.utils import check_device\n\n# When CUDA is not available\ndevice = check_device()\nprint(device)  # If CUDA is not available it should return torch.device('cpu')\n</code></pre>"},{"location":"swarms/utils/check_device/#example-3-multiple-gpu-available","title":"Example 3: Multiple GPU Available","text":"<pre><code>import torch\n\nfrom swarms.utils import check_device\n\n# When multiple GPUs are available\ndevice = check_device()\nprint(device)  # Should return a list of available GPU devices\n</code></pre>"},{"location":"swarms/utils/check_device/#tips-and-additional-information","title":"Tips and Additional Information","text":"<ul> <li>This function is useful when a user wants to exploit CUDA capabilities for faster computation but unsure of the available devices. This function abstracts all the necessary checks and provides a list of CUDA devices to the user.</li> <li>The <code>memory_threshold</code> and <code>capability_threshold</code> are utilized to filter the GPU devices. The GPUs which have memory usage above the <code>memory_threshold</code> and compute capability below the <code>capability_threshold</code> are not considered.</li> <li>As of now, CPU does not have memory or capability values, therefore, in the respective cases, it will be returned as default without any comparison.</li> </ul>"},{"location":"swarms/utils/check_device/#relevant-resources","title":"Relevant Resources","text":"<ul> <li>For more details about the CUDA properties functions used (<code>torch.cuda.get_device_capability, torch.cuda.get_device_properties</code>), please refer to the official PyTorch CUDA semantics documentation.</li> <li>For more information about Torch device objects, you can refer to the official PyTorch device documentation.</li> <li>For a better understanding of how the <code>logging</code> module works in Python, see the official Python logging documentation.</li> </ul>"},{"location":"swarms/utils/display_markdown_message/","title":"display_markdown_message","text":""},{"location":"swarms/utils/display_markdown_message/#module-name-display_markdown_message","title":"Module Name: <code>display_markdown_message</code>","text":""},{"location":"swarms/utils/display_markdown_message/#introduction","title":"Introduction","text":"<p><code>display_markdown_message</code> is a useful utility function for creating visually-pleasing markdown messages within Python scripts. This function automatically manages multiline strings with lots of indentation and makes single-line messages with \"&gt;\" tags easy to read, providing users with convenient and elegant logging or messaging capacity.</p>"},{"location":"swarms/utils/display_markdown_message/#function-definition-and-arguments","title":"Function Definition and Arguments","text":"<p>Function Definition: <pre><code>def display_markdown_message(message: str, color: str = \"cyan\"):\n    ```\nThis function accepts two parameters:\n\n|Parameter  |Type |Default Value |Description |\n|---        |---  |---           |---         |\n|message    |str  |None          |This is the message that is to be displayed. This should be a string. It can contain markdown syntax.|\n|color      |str  |\"cyan\"        |This allows you to choose the color of the message. Default is \"cyan\". Accepts any valid color name.|\n\n## Functionality and Usage\n\nThis utility function is used to display a markdown formatted message on the console. It accepts a message as a string and an optional color for the message. The function is ideal for generating stylized print outputs such as headers, status updates or pretty notifications.\n\nBy default, any text within the string which is enclosed within `&gt;` tags or `---` is treated specially:\n\n-  Lines encased in `&gt;` tags are rendered as a blockquote in markdown.\n-  Lines consisting of `---` are rendered as horizontal rules.\n\nThe function automatically strips off leading and trailing whitespaces from any line within the message, maintaining aesthetic consistency in your console output.\n\n### Usage Examples\n\n#### Basic Example\n\n```python\ndisplay_markdown_message(\"&gt; This is an important message\", color=\"red\")\n</code></pre></p> <p>Output: <pre><code>&gt; **This is an important message**\n</code></pre></p> <p>This example will print out the string \"This is an important message\" in red color, enclosed in a blockquote tag.</p>"},{"location":"swarms/utils/display_markdown_message/#multiline-example","title":"Multiline Example","text":"<pre><code>message = \"\"\"\n&gt; Header\n\nMy normal message here.\n\n---\n\nAnother important information\n\"\"\"\ndisplay_markdown_message(message, color=\"green\")\n</code></pre> <p>Output: <pre><code>&gt; **Header**\n\nMy normal message here.\n_____\n\nAnother important information\n</code></pre> The output is a green colored markdown styled text with the \"Header\" enclosed in a blockquote, followed by the phrase \"My normal message here\", a horizontal rule, and finally another phrase, \"Another important information\".</p>"},{"location":"swarms/utils/display_markdown_message/#additional-information","title":"Additional Information","text":"<p>Use newline characters <code>\\n</code> to separate the lines of the message. Remember, each line of the message is stripped of leading and trailing whitespaces. If you have special markdown requirements, you may need to revise the input message string accordingly.</p> <p>Also, keep in mind the console or terminal's ability to display the chosen color. If a particular console does not support the chosen color, the output may fallback to the default console color.</p> <p>For a full list of color names supported by the <code>Console</code> module, refer to the official Console documentation.</p>"},{"location":"swarms/utils/display_markdown_message/#references-and-resources","title":"References and Resources","text":"<ul> <li>Python Strings: https://docs.python.org/3/tutorial/introduction.html#strings</li> <li>Python Markdown: https://pypi.org/project/markdown/</li> <li>Console module: https://console.readthedocs.io/</li> </ul>"},{"location":"swarms/utils/extract_code_from_markdown/","title":"extract_code_from_markdown","text":""},{"location":"swarms/utils/extract_code_from_markdown/#swarmsutils-module","title":"swarms.utils Module","text":"<p>The <code>swarms.utils</code> module provides utility functions designed to facilitate specific tasks within the main Swarm codebase. The function <code>extract_code_from_markdown</code> is a critical function within this module that we will document in this example.</p>"},{"location":"swarms/utils/extract_code_from_markdown/#overview-and-introduction","title":"Overview and Introduction","text":"<p>Many software projects use Markdown extensively for writing documentation, tutorials, and other text documents that can be easily rendered and viewed in different formats, including HTML.</p> <p>The <code>extract_code_from_markdown</code> function plays a crucial role within the swarms.utils library. As developers write large volumes of Markdown, they often need to isolate code snippets from the whole Markdown file body. These isolated snippets can be used to generate test cases, transform into other languages, or analyze for metrics.</p>"},{"location":"swarms/utils/extract_code_from_markdown/#function-definition-extract_code_from_markdown","title":"Function Definition: <code>extract_code_from_markdown</code>","text":"<pre><code>def extract_code_from_markdown(markdown_content: str) -&gt; str:\n    \"\"\"\n    Extracts code blocks from a Markdown string and returns them as a single string.\n\n    Args:\n    - markdown_content (str): The Markdown content as a string.\n\n    Returns:\n    - str: A single string containing all the code blocks separated by newlines.\n    \"\"\"\n    # Regular expression for fenced code blocks\n    pattern = r\"```(?:\\w+\\n)?(.*?)```\"\n    matches = re.findall(pattern, markdown_content, re.DOTALL)\n\n    # Concatenate all code blocks separated by newlines\n    return \"\\n\".join(code.strip() for code in matches)\n</code></pre>"},{"location":"swarms/utils/extract_code_from_markdown/#arguments","title":"Arguments","text":"<p>The function <code>extract_code_from_markdown</code> takes one argument:</p> Argument Description Type Default Value markdown_content The input markdown content as a string str N/A"},{"location":"swarms/utils/extract_code_from_markdown/#function-explanation-and-usage","title":"Function Explanation and Usage","text":"<p>This function uses a regular expression to find all fenced code blocks in a Markdown string. The pattern <code>r\"```(?:\\w+\\n)?(.*?)```\"</code> matches strings that start and end with three backticks, optionally followed by a newline and then any number of any characters (the <code>.*?</code> part) until the first occurrence of another triple backtick set.</p> <p>Once we have the matches, we join all the code blocks into a single string, each block separated by a newline.</p> <p>The method's functionality is particularly useful when we need to extract code blocks from markdown content for secondary processing, such as syntax highlighting or execution in a different environment.</p>"},{"location":"swarms/utils/extract_code_from_markdown/#usage-examples","title":"Usage Examples","text":"<p>Below are three examples of how you might use this function:</p>"},{"location":"swarms/utils/extract_code_from_markdown/#example-1","title":"Example 1:","text":"<p>Extracting code blocks from a simple markdown string.</p> <pre><code>from swarms.utils import extract_code_from_markdown\n\nmarkdown_string = \"\"\"# Example\nThis is an example of a code block:\n```python\nprint(\"Hello World!\")\n``` \"\"\"\nprint(extract_code_from_markdown(markdown_string))\n</code></pre>"},{"location":"swarms/utils/extract_code_from_markdown/#example-2","title":"Example 2:","text":"<p>Extracting code blocks from a markdown file. </p> <pre><code>import re\n\n\ndef extract_code_from_markdown(markdown_content: str) -&gt; str:\n    pattern = r\"```(?:\\w+\\n)?(.*?)```\"\n    matches = re.findall(pattern, markdown_content, re.DOTALL)\n    return \"\\n\".join(code.strip() for code in matches)\n\n\n# Assume that 'example.md' contains multiple code blocks\nwith open(\"example.md\") as file:\n    markdown_content = file.read()\nprint(extract_code_from_markdown(markdown_content))\n</code></pre>"},{"location":"swarms/utils/extract_code_from_markdown/#example-3","title":"Example 3:","text":"<p>Using the function in a pipeline to extract and then analyze code blocks.</p> <pre><code>import re\n\n\ndef extract_code_from_markdown(markdown_content: str) -&gt; str:\n    pattern = r\"```(?:\\w+\\n)?(.*?)```\"\n    matches = re.findall(pattern, markdown_content, re.DOTALL)\n    return \"\\n\".join(code.strip() for code in matches)\n\n\ndef analyze_code_blocks(code: str):\n    # Add your analysis logic here\n    pass\n\n\n# Assume that 'example.md' contains multiple code blocks\nwith open(\"example.md\") as file:\n    markdown_content = file.read()\ncode_blocks = extract_code_from_markdown(markdown_content)\nanalyze_code_blocks(code_blocks)\n</code></pre>"},{"location":"swarms/utils/extract_code_from_markdown/#conclusion","title":"Conclusion","text":"<p>This concludes the detailed documentation of the <code>extract_code_from_markdown</code> function from the swarms.utils module. With this documentation, you should be able to understand the function's purpose, how it works, its parameters, and see examples of how to use it effectively.</p>"},{"location":"swarms/utils/find_image_path/","title":"find_image_path","text":"<p>Firstly, we will divide this documentation into multiple sections.</p>"},{"location":"swarms/utils/find_image_path/#overview","title":"Overview","text":"<p>The module swarms.utils has the main goal of providing necessary utility functions that are crucial during the creation of the swarm intelligence frameworks. These utility functions can include common operations such as handling input-output operations for files, handling text parsing, and handling basic mathematical computations necessary during the creation of swarm intelligence models. </p> <p>The current function <code>find_image_path</code> in the module is aimed at extracting an image path from a given text document.</p>"},{"location":"swarms/utils/find_image_path/#function-detailed-explanation","title":"Function Detailed Explanation","text":""},{"location":"swarms/utils/find_image_path/#definition","title":"Definition","text":"<p>The function <code>find_image_path</code> takes a singular argument as an input:</p> <pre><code>def find_image_path(text):\n    # function body\n</code></pre>"},{"location":"swarms/utils/find_image_path/#parameter","title":"Parameter","text":"<p>The parameter <code>text</code> in the function is a string that represents the document or text from which the function is trying to extract all paths to the images present. The function scans the given text, looking for absolute or relative paths to image files (.png, .jpg, .jpeg) on the disk.</p> Parameter Name Data Type Default Value Description <code>text</code> <code>str</code> - The text content to scan for image paths"},{"location":"swarms/utils/find_image_path/#return-value","title":"Return Value","text":"<p>The return value of the function <code>find_image_path</code>  is a string that represents the longest existing image path extracted from the input text. If no image paths exist within the text, the function returns <code>None</code>.</p> Return Value Data Type Description Path <code>str</code> Longest image path found in the text or <code>None</code> if no path found"},{"location":"swarms/utils/find_image_path/#functions-code","title":"Function's Code","text":"<p>The function <code>find_image_path</code> performs text parsing and pattern recognition to find image paths within the provided text. The function uses <code>regular expressions (re)</code> module to detect all potential paths.</p> <pre><code>def find_image_path(text):\n    pattern = r\"([A-Za-z]:\\\\[^:\\n]*?\\.(png|jpg|jpeg|PNG|JPG|JPEG))|(/[^:\\n]*?\\.(png|jpg|jpeg|PNG|JPG|JPEG))\"\n    matches = [match.group() for match in re.finditer(pattern, text) if match.group()]\n    matches += [match.replace(\"\\\\\", \"\") for match in matches if match]\n    existing_paths = [match for match in matches if os.path.exists(match)]\n    return max(existing_paths, key=len) if existing_paths else None\n</code></pre>"},{"location":"swarms/utils/find_image_path/#usage-examples","title":"Usage Examples","text":"<p>Let's consider examples of how the function <code>find_image_path</code> can be used in different scenarios.</p> <p>Example 1:</p> <p>Consider the case where a text without any image path is provided.</p> <pre><code>from swarms.utils import find_image_path\n\ntext = \"There are no image paths in this text\"\nprint(find_image_path(text))  # Outputs: None\n</code></pre> <p>Example 2:</p> <p>Consider the case where the text has multiple image paths.</p> <pre><code>from swarms.utils import find_image_path\n\ntext = \"Here is an image path: /home/user/image1.png. Here is another one: C:\\\\Users\\\\User\\\\Documents\\\\image2.jpeg\"\nprint(\n    find_image_path(text)\n)  # Outputs: the longest image path (depends on your file system and existing files)\n</code></pre> <p>Example 3:</p> <p>In the final example, we consider a case where the text has an image path, but the file does not exist.</p> <pre><code>from swarms.utils import find_image_path\n\ntext = \"Here is an image path: /home/user/non_existant.png\"\nprint(find_image_path(text))  # Outputs: None\n</code></pre>"},{"location":"swarms/utils/find_image_path/#closing-notes","title":"Closing Notes","text":"<p>In conclusion, the <code>find_image_path</code> function is crucial in the <code>swarms.utils</code> module as it supports a key operation of identifying image paths within given input text. This allows users to automate the extraction of such data from larger documents/text. However, it's important to note the function returns only existing paths in your file system and only the longest if multiple exist.</p>"},{"location":"swarms/utils/limit_tokens_from_string/","title":"limit_tokens_from_string","text":""},{"location":"swarms/utils/limit_tokens_from_string/#introduction","title":"Introduction","text":"<p>The <code>Swarms.utils</code> library contains utility functions used across codes that handle machine learning and other operations. The <code>Swarms.utils</code> library includes a notable function named <code>limit_tokens_from_string()</code>. This function particularly limits the number of tokens in a given string. </p>"},{"location":"swarms/utils/limit_tokens_from_string/#function-limit_tokens_from_string","title":"Function: limit_tokens_from_string()","text":"<p>Within the <code>Swarms.utils</code> library, there is a method <code>limit_tokens_from_string(string: str, model: str = \"gpt-4\", limit: int = 500) -&gt; str:</code></p>"},{"location":"swarms/utils/limit_tokens_from_string/#description","title":"Description","text":"<p>The function <code>limit_tokens_from_string()</code> limits the number of tokens in a given string based on the specified threshold. It is primarily useful when you are handling large text data and need to chunk or limit your text to a certain length. Limiting token length could be useful in various scenarios such as when working with data with limited computational resources, or when dealing with models that accept a specific maximum limit of text. </p>"},{"location":"swarms/utils/limit_tokens_from_string/#parameters","title":"Parameters","text":"Parameter Type Default Value Description <code>string</code> <code>str</code> <code>None</code> The input string from which the tokens need to be limited. <code>model</code> <code>str</code> <code>\"gpt-4\"</code> The model used to encode and decode the token. The function defaults to <code>gpt-4</code> but you can specify any model supported by <code>tiktoken</code>. If a model is not found, it falls back to use <code>gpt2</code> <code>limit</code> <code>int</code> <code>500</code> The limit up to which the tokens have to be sliced. Default limit is 500."},{"location":"swarms/utils/limit_tokens_from_string/#returns","title":"Returns","text":"Return Type Description <code>out</code> <code>str</code> A string that is constructed back from the encoded tokens that have been limited to a count of <code>limit</code>"},{"location":"swarms/utils/limit_tokens_from_string/#method-detail-and-usage-examples","title":"Method Detail and Usage Examples","text":"<p>The method <code>limit_tokens_from_string()</code> takes in three parameters - <code>string</code>, <code>model</code>, and <code>limit</code>. </p> <p>First, it tries to get the encoding for the model specified in the <code>model</code> argument using <code>tiktoken.encoding_for_model(model)</code>. In case the specified model is not found, the function uses <code>gpt2</code> model encoding as a fallback.</p> <p>Next, the input <code>string</code> is tokenized using the <code>encode</code> method on the <code>encoding</code> tensor. This results in the <code>encoded</code> tensor.</p> <p>Then, the function slices the <code>encoded</code> tensor to get the first <code>limit</code> number of tokens.</p> <p>Finally, the function converts back the tokens into the string using the <code>decode</code> method of the <code>encoding</code> tensor. The resulting string <code>out</code> is returned.</p>"},{"location":"swarms/utils/limit_tokens_from_string/#example-1","title":"Example 1:","text":"<pre><code>from swarms.utils import limit_tokens_from_string\n\n# longer input string\nstring = \"This is a very long string that needs to be tokenized. This string might exceed the maximum token limit, so it will need to be truncated.\"\n\n# lower token limit\nlimit = 10\n\noutput = limit_tokens_from_string(string, limit=limit)\n</code></pre>"},{"location":"swarms/utils/limit_tokens_from_string/#example-2","title":"Example 2:","text":"<pre><code>from swarms.utils import limit_tokens_from_string\n\n# longer input string with different model\nstring = \"This string will be tokenized using gpt2 model. If the string is too long, it will be truncated.\"\n\n# model\nmodel = \"gpt2\"\n\noutput = limit_tokens_from_string(string, model=model)\n</code></pre>"},{"location":"swarms/utils/limit_tokens_from_string/#example-3","title":"Example 3:","text":"<pre><code>from swarms.utils import limit_tokens_from_string\n\n# try with a random model string\nstring = \"In case the method does not find the specified model, it will fall back to gpt2 model.\"\n\n# model\nmodel = \"gpt-4\"\n\noutput = limit_tokens_from_string(string, model=model)\n</code></pre> <p>Note: If specifying a model not supported by <code>tiktoken</code> intentionally, it will fall back to <code>gpt2</code> model for encoding.</p>"},{"location":"swarms/utils/load_model_torch/","title":"load_model_torch","text":""},{"location":"swarms/utils/load_model_torch/#load_model_torch-utility-function-documentation","title":"load_model_torch: Utility Function Documentation","text":""},{"location":"swarms/utils/load_model_torch/#introduction","title":"Introduction:","text":"<p><code>load_model_torch</code> is a utility function in the <code>swarms.utils</code> library that is designed to load a saved PyTorch model and move it to the designated device. It provides flexibility allowing the user to specify the model file location, the device where the loaded model should be moved to, whether to strictly enforce the keys in the state dictionary to match the keys returned by the model's <code>state_dict()</code>, and many more.</p> <p>Moreover, if the saved model file only contains the state dictionary, but not the model architecture, you can pass the model architecture as an argument. </p>"},{"location":"swarms/utils/load_model_torch/#function-definition-and-parameters","title":"Function Definition and Parameters:","text":"<pre><code>def load_model_torch(\n    model_path: str = None,\n    device: torch.device = None,\n    model: nn.Module = None,\n    strict: bool = True,\n    map_location=None,\n    *args,\n    **kwargs,\n) -&gt; nn.Module:\n</code></pre> <p>The following table describes the parameters in detail:</p> Name Type Default Value Description model_path str None A string specifying the path to the saved model file on disk. Required device torch.device None A <code>torch.device</code> object that specifies the target device for the loaded model. If not provided, the function checks for the availability of a GPU and uses it if available. If not, it defaults to CPU. model nn.Module None An instance of <code>torch.nn.Module</code> representing the model's architecture. This parameter is required if the model file only contains the model's state dictionary and not the model architecture. strict bool True A boolean that determines whether to strictly enforce that the keys in the state dictionary match the keys returned by the model's <code>state_dict()</code> function. If set to <code>True</code>, the function will raise a KeyError when the state dictionary and <code>state_dict()</code> keys do not match. map_location callable None A function to remap the storage locations of the loaded model's parameters. Useful for loading models saved on a device type that is different from the current one. args, *kwargs - - Additional arguments and keyword arguments to be passed to <code>torch.load</code>. <p>Returns: </p> <ul> <li><code>torch.nn.Module</code> - The loaded model after moving it to the desired device.</li> </ul> <p>Raises:</p> <ul> <li><code>FileNotFoundError</code> - If the saved model file is not found at the specified path.</li> <li><code>RuntimeError</code> - If there was an error while loading the model.</li> </ul>"},{"location":"swarms/utils/load_model_torch/#example-of-usage","title":"Example of Usage:","text":"<p>This function can be used directly inside your code as shown in the following examples:</p>"},{"location":"swarms/utils/load_model_torch/#example-1","title":"Example 1:","text":"<p>Loading a model without specifying a device results in the function choosing the most optimal available device automatically.</p> <pre><code>import torch.nn as nn\n\nfrom swarms.utils import load_model_torch\n\n# Assume `mymodel.pth` is in the current directory\nmodel_path = \"./mymodel.pth\"\n\n\n# Define your model architecture if the model file only contains state dict\nclass MyModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear = nn.Linear(10, 2)\n\n    def forward(self, x):\n        return self.linear(x)\n\n\nmodel = MyModel()\n\n# Load the model\nloaded_model = load_model_torch(model_path, model=model)\n\n# Now you can use the loaded model for prediction or further training\n</code></pre>"},{"location":"swarms/utils/load_model_torch/#example-2","title":"Example 2:","text":"<p>Explicitly specifying a device.</p> <pre><code># Assume `mymodel.pth` is in the current directory\nmodel_path = \"./mymodel.pth\"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load the model\nloaded_model = load_model_torch(model_path, device=device)\n</code></pre>"},{"location":"swarms/utils/load_model_torch/#example-3","title":"Example 3:","text":"<p>Using a model file that contains only the state dictionary, not the model architecture.</p> <pre><code># Assume `mymodel_state_dict.pth` is in the current directory\nmodel_path = \"./mymodel_state_dict.pth\"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Define your model architecture\nmodel = MyModel()\n\n# Load the model\nloaded_model = load_model_torch(model_path, device=device, model=model)\n</code></pre> <p>This gives you an insight on how to use <code>load_model_torch</code> utility function from <code>swarms.utils</code> library efficiently. Always remember to pass the model path argument while the other arguments can be optional based on your requirements. Furthermore, handle exceptions properly for smooth functioning of your PyTorch related projects.</p>"},{"location":"swarms/utils/math_eval/","title":"math_eval","text":"<p>The <code>math_eval</code> function is a python decorator that wraps around a function to run two functions on the same inputs and compare their results. The decorator can be used for testing functions that are expected to have equivalent functionality, or in situations where two different methods are used to calculate or retrieve a value, and the results need to be compared.</p> <p>The <code>math_eval</code> function in this case accepts two functions as parameters: <code>func1</code> and <code>func2</code>, and returns a decorator. This returned decorator, when applied to a function, enhances that function to execute both <code>func1</code> and <code>func2</code>, and compare the results.</p> <p>This can be particularly useful in situations when you are implementing a new function and wants to compare its behavior and results with that of an existing one under the same set of input parameters. It also logs the results if they do not match which could be quite useful during the debug process.</p>"},{"location":"swarms/utils/math_eval/#usage-example","title":"Usage Example","text":"<p>Let's say you have two functions: <code>ground_truth</code> and <code>generated_func</code>, that have similar functionalities or serve the same purpose. You are writing a new function called <code>test_func</code>, and you'd like to compare the results of <code>ground_truth</code> and <code>generated_func</code> when <code>test_func</code> is run. Here is how you would use the <code>math_eval</code> decorator:</p> <pre><code>@math_eval(ground_truth, generated_func)\ndef test_func(x):\n    return x\n\n\nresult1, result2 = test_func(5)\nprint(f\"Result from ground_truth: {result1}\")\nprint(f\"Result from generated_func: {result2}\")\n</code></pre>"},{"location":"swarms/utils/math_eval/#parameters","title":"Parameters","text":"Parameter Data Type Description func1 Callable The first function whose result you want to compare. func2 Callable The second function whose result you want to compare. <p>The data types for <code>func1</code> and <code>func2</code> cannot be specified as they can be any python function (or callable object). The decorator verifies that they are callable and exceptions are handled within the decorator function.</p>"},{"location":"swarms/utils/math_eval/#return-values","title":"Return Values","text":"<p>The <code>math_eval</code> function does not return a direct value, since it is a decorator. When applied to a function, it alters the behavior of the wrapped function to return two values:</p> <ol> <li><code>result1</code>: The result of running <code>func1</code> with the given input parameters.</li> <li><code>result2</code>: The result of running <code>func2</code> with the given input parameters.</li> </ol> <p>These two return values are provided in that order as a tuple.</p>"},{"location":"swarms/utils/math_eval/#source-code","title":"Source Code","text":"<p>Here's how to implement the <code>math_eval</code> decorator:</p> <p><pre><code>import functools\nimport logging\n\n\ndef math_eval(func1, func2):\n    \"\"\"Math evaluation decorator.\"\"\"\n\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            try:\n                result1 = func1(*args, **kwargs)\n            except Exception as e:\n                logging.error(f\"Error in func1: {e}\")\n                result1 = None\n\n            try:\n                result2 = func2(*args, **kwargs)\n            except Exception as e:\n                logging.error(f\"Error in func2: {e}\")\n                result2 = None\n\n            if result1 != result2:\n                logging.warning(f\"Outputs do not match: {result1} != {result2}\")\n\n            return result1, result2\n\n        return wrapper\n\n    return decorator\n</code></pre> Please note that the code is logging exceptions to facilitate debugging, but the actual processing and handling of the exception would depend on how you want your application to respond to exceptions. Therefore, you may want to customize the error handling depending upon your application's requirements.</p>"},{"location":"swarms/utils/metrics_decorator/","title":"metrics_decorator","text":"<p>This documentation explains the use and functionality of the <code>metrics_decorator</code> function in the LLM (Large Language Models). </p>"},{"location":"swarms/utils/metrics_decorator/#the-metrics_decorator-function-is-a-standard-python-decorator-that-augments-a-specific-function-by-wrapping-extra-functionality-around-it-it-is-commonly-used-for-things-like-timing-logging-or-memoization","title":"The <code>metrics_decorator</code> function is a standard Python decorator that augments a specific function by wrapping extra functionality around it. It is commonly used for things like timing, logging or memoization.","text":"<p>The <code>metrics_decorator</code> in LLM is specially designed to measure and calculate three key performance metrics when generating language models:</p> <ol> <li><code>Time to First Token</code>: Measures the elapsed time from the start of function execution until the generation of the first token. </li> <li><code>Generation Latency</code>: It measures the total time taken for a complete run.</li> <li><code>Throughput</code>: Calculates the rate of production of tokens per unit of time.</li> </ol> <pre><code>def metrics_decorator(func: Callable):\n    \"\"\"\n\n    Metrics decorator for LLM\n\n    Args:\n        func (Callable): The function to be decorated.\n\n    \"\"\"\n\n    @wraps(func)\n    def wrapper(self, *args, **kwargs):\n        \"\"\"\n        An inner function that wraps the decorated function. It calculates 'Time to First Token',\n        'Generation Latency' and 'Throughput' metrics.\n\n        Args:\n            self : The object instance.\n            *args : Variable length argument list of the decorated function.\n            **kwargs : Arbitrary keyword arguments of the decorated function.\n        \"\"\"\n\n        # Measure Time to First Token\n        start_time = time.time()\n        result = func(self, *args, **kwargs)\n        first_token_time = time.time()\n\n        # Measure Generation Latency\n        end_time = time.time()\n\n        # Calculate Throughput (assuming the function returns a list of tokens)\n        throughput = len(result) / (end_time - start_time)\n\n        return f\"\"\"\n                 Time to First Token: {first_token_time - start_time}\n                 Generation Latency: {end_time - start_time}\n                 Throughput: {throughput}\n               \"\"\"\n\n    return wrapper\n</code></pre>"},{"location":"swarms/utils/metrics_decorator/#example-usage","title":"Example Usage","text":"<p>Now let's discuss the usage of the <code>metrics_decorator</code> function with an example.</p> <p>Assuming that we have a language generation function called <code>text_generator()</code> that generates a list of tokens.</p> <pre><code>@metrics_decorator\ndef text_generator(self, text: str):\n    \"\"\"\n    Args:\n        text (str): The input text.\n\n    Returns:\n        A list of tokens generated from the input text.\n    \"\"\"\n    # language generation implementation goes here\n    return tokens\n\n\n# Instantiate the class and call the decorated function\nobj = ClassName()\nobj.text_generator(\"Hello, world!\")\n</code></pre> <p>When the decorated <code>text_generator()</code> function is called, it will measure and return:</p> <ul> <li>Time elapsed until the first token is generated.</li> <li>The total execution time of the function.</li> <li>The rate of tokens generation per unit time.</li> </ul> <p>This example provides a basic overview of how a function can be decorated with the <code>metrics_decorator</code>. The provided <code>func</code> argument could be any method from any class, as long as it complies with the structure defined in <code>metrics_decorator</code>. It is worth noting that the decorated function must return a list of tokens for the <code>Throughput</code> metric to work correctly.</p> <p>Remember, applying the <code>metrics_decorator</code> does not affect the original functionality of the decorated function, it just adds additional measurement and logging capabilities to it. It's a great utility for tracking and optimizing the performance of your language models.</p>"},{"location":"swarms/utils/pdf_to_text/","title":"pdf_to_text","text":""},{"location":"swarms/utils/pdf_to_text/#introduction","title":"Introduction","text":"<p>The function <code>pdf_to_text</code> is a Python utility for converting a PDF file into a string of text content. It leverages the <code>pypdf</code> library, an excellent Python library for processing PDF files. The function takes in a PDF file's path and reads its content, subsequently returning the extracted textual data.</p> <p>This function can be very useful when you want to extract textual information from PDF files automatically. For instance, when processing a large number of documents, performing textual analysis, or when you're dealing with text data that is only available in PDF format.</p>"},{"location":"swarms/utils/pdf_to_text/#class-function-definition","title":"Class / Function Definition","text":"<p><code>pdf_to_text</code> is a standalone function defined as follows:</p> <pre><code>def pdf_to_text(pdf_path: str) -&gt; str:\n</code></pre>"},{"location":"swarms/utils/pdf_to_text/#parameters","title":"Parameters","text":"Parameter Type Description pdf_path str The path to the PDF file to be converted"},{"location":"swarms/utils/pdf_to_text/#returns","title":"Returns","text":"Return Value Type Description text str The text extracted from the PDF file."},{"location":"swarms/utils/pdf_to_text/#raises","title":"Raises","text":"Exception Description FileNotFoundError If the PDF file is not found at the specified path. Exception If there is an error in reading the PDF file."},{"location":"swarms/utils/pdf_to_text/#function-description","title":"Function Description","text":"<p><code>pdf_to_text</code> utilises the <code>PdfReader</code> function from the <code>pypdf</code> library to read the PDF file. If the PDF file does not exist at the specified path or there was an error while reading the file, appropriate exceptions will be raised. It then iterates through each page in the PDF and uses the <code>extract_text</code> function to extract the text content from each page. These contents are then concatenated into a single variable and returned as the result.</p>"},{"location":"swarms/utils/pdf_to_text/#usage-examples","title":"Usage Examples","text":"<p>To use this function, you first need to install the <code>pypdf</code> library. It can be installed via pip:</p> <pre><code>!pip install pypdf\n</code></pre> <p>Then, you should import the <code>pdf_to_text</code> function:</p> <pre><code>from swarms.utils import pdf_to_text\n</code></pre> <p>Here is an example of how to use <code>pdf_to_text</code>:</p> <pre><code># Define the path to the pdf file\npdf_path = \"sample.pdf\"\n\n# Use the function to extract text\ntext = pdf_to_text(pdf_path)\n\n# Print the extracted text\nprint(text)\n</code></pre>"},{"location":"swarms/utils/pdf_to_text/#tips-and-additional-information","title":"Tips and Additional Information","text":"<ul> <li>Ensure that the PDF file path is valid and that the file exists at the specified location. If the file does not exist, a <code>FileNotFoundError</code> will be raised.</li> <li>This function reads the text from the PDF. It does not handle images, graphical elements, or any non-text content.</li> <li>If the PDF contains scanned images rather than textual data, the <code>extract_text</code> function may not be able to extract any text. In such cases, you would require OCR (Optical Character Recognition) tools to extract the text. </li> <li>Be aware of the possibility that the output string might contain special characters or escape sequences because they were part of the PDF's content. You might need to clean the resulting text according to your requirements.</li> <li>The function uses the pypdf library to facilitate the PDF reading and text extraction. For any issues related to PDF manipulation, consult the pypdf library documentation.</li> </ul>"},{"location":"swarms/utils/prep_torch_inference/","title":"prep_torch_inference","text":"<p><pre><code>def prep_torch_inference(\n    model_path: str = None,\n    device: torch.device = None,\n    *args,\n    **kwargs,\n):\n    \"\"\"\n    Prepare a Torch model for inference.\n\n    Args:\n        model_path (str): Path to the model file.\n        device (torch.device): Device to run the model on.\n        *args: Additional positional arguments.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        torch.nn.Module: The prepared model.\n    \"\"\"\n    try:\n        model = load_model_torch(model_path, device)\n        model.eval()\n        return model\n    except Exception as e:\n        # Add error handling code here\n        print(f\"Error occurred while preparing Torch model: {e}\")\n        return None\n</code></pre> This method is part of the 'swarms.utils' module. It accepts a model file path and a torch device as input and returns a model that is ready for inference.</p>"},{"location":"swarms/utils/prep_torch_inference/#detailed-functionality","title":"Detailed Functionality","text":"<p>The method loads a PyTorch model from the file specified by <code>model_path</code>. This model is then moved to the specified <code>device</code> if it is provided. Subsequently, the method sets the model to evaluation mode by calling <code>model.eval()</code>. This is a crucial step when preparing a model for inference, as certain layers like dropout or batch normalization behave differently during training vs during evaluation. In the case of any exception (e.g., the model file not found or the device unavailable), it prints an error message and returns <code>None</code>.</p>"},{"location":"swarms/utils/prep_torch_inference/#parameters","title":"Parameters","text":"Parameter Type Description Default model_path str Path to the model file. None device torch.device Device to run the model on. None args tuple Additional positional arguments. None kwargs dict Additional keyword arguments. None"},{"location":"swarms/utils/prep_torch_inference/#returns","title":"Returns","text":"Type Description torch.nn.Module The prepared model ready for inference. Returns <code>None</code> if any exception occurs."},{"location":"swarms/utils/prep_torch_inference/#usage-examples","title":"Usage Examples","text":"<p>Here are some examples of how you can use the <code>prep_torch_inference</code> method. Before that, you need to import the necessary modules as follows:</p> <pre><code>import torch\n\nfrom swarms.utils import load_model_torch, prep_torch_inference\n</code></pre>"},{"location":"swarms/utils/prep_torch_inference/#example-1-load-a-model-for-inference-on-cpu","title":"Example 1: Load a model for inference on CPU","text":"<pre><code>model_path = \"saved_model.pth\"\nmodel = prep_torch_inference(model_path)\n\nif model is not None:\n    print(\"Model loaded successfully and is ready for inference.\")\nelse:\n    print(\"Failed to load the model.\")\n</code></pre>"},{"location":"swarms/utils/prep_torch_inference/#example-2-load-a-model-for-inference-on-cuda-device","title":"Example 2: Load a model for inference on CUDA device","text":"<pre><code>model_path = \"saved_model.pth\"\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = prep_torch_inference(model_path, device)\n\nif model is not None:\n    print(f\"Model loaded successfully on device {device} and is ready for inference.\")\nelse:\n    print(\"Failed to load the model.\")\n</code></pre>"},{"location":"swarms/utils/prep_torch_inference/#example-3-load-a-model-with-additional-arguments-for-load_model_torch","title":"Example 3: Load a model with additional arguments for <code>load_model_torch</code>","text":"<pre><code>model_path = \"saved_model.pth\"\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# Suppose load_model_torch accepts an additional argument, map_location\nmodel = prep_torch_inference(model_path, device, map_location=device)\n\nif model is not None:\n    print(f\"Model loaded successfully on device {device} and is ready for inference.\")\nelse:\n    print(\"Failed to load the model.\")\n</code></pre> <p>Please note, you need to ensure the given model path does exist and the device is available on your machine, else <code>prep_torch_inference</code> method will return <code>None</code>. Depending on the complexity and size of your models, loading them onto a specific device might take a while. So it's important that you take this into consideration when designing your machine learning workflows.</p>"},{"location":"swarms/utils/print_class_parameters/","title":"print_class_parameters","text":""},{"location":"swarms/utils/print_class_parameters/#module-function-name-print_class_parameters","title":"Module Function Name: print_class_parameters","text":"<p>The <code>print_class_parameters</code> function is a utility function developed to help developers and users alike in retrieving and printing the parameters of a class constructor in Python, either in standard output or returned as a dictionary if the <code>api_format</code> is set to <code>True</code>.</p> <p>This utility function utilizes the <code>inspect</code> module to fetch the signature of the class constructor and fetches the parameters from the obtained signature. The parameter values and their respective types are then outputted.</p> <p>This function allows developers to easily inspect and understand the class' constructor parameters without the need to individually go through the class structure. This eases the testing and debugging process for developers and users alike, aiding in generating more efficient and readable code.</p> <p>Function Definition:</p> <p><pre><code>def print_class_parameters(cls, api_format: bool = False):\n</code></pre> Parameters:</p> Parameter Type Description Default value cls type The Python class to inspect. None api_format bool Flag to determine if the output should be returned in dictionary format (if set to True) or printed out (if set to False) False <p>Functionality and Usage:</p> <p>Inside the <code>print_class_parameters</code> function, it starts by getting the signature of the constructor of the inputted class by invoking <code>inspect.signature(cls.__init__)</code>. It then extracts the parameters from the signature and stores it in the <code>params</code> variable.</p> <p>If the <code>api_format</code> argument is set to <code>True</code>, instead of printing the parameters and their types, it stores them inside a dictionary where each key-value pair is a parameter name and its type. It then returns this dictionary.</p> <p>If <code>api_format</code> is set to <code>False</code> or not set at all (defaulting to False), the function iterates over the parameters and prints the parameter name and its type. \"self\" parameters are excluded from the output as they are inherent to all class methods in Python.</p> <p>A possible exception that may occur during the execution of this function is during the invocation of the <code>inspect.signature()</code> function call. If the inputted class does not have an <code>__init__</code> method or any error occurs during the retrieval of the class constructor's signature, an exception will be triggered. In that case, an error message that includes the error details is printed out.</p> <p>Usage and Examples:</p> <p>Assuming the existence of a class:</p> <pre><code>class Agent:\n    def __init__(self, x: int, y: int):\n        self.x = x\n        self.y = y\n</code></pre> <p>One could use <code>print_class_parameters</code> in its typical usage:</p> <pre><code>print_class_parameters(Agent)\n</code></pre> <p>Results in:</p> <pre><code>Parameter: x, Type: &lt;class 'int'&gt;\nParameter: y, Type: &lt;class 'int'&gt;\n</code></pre> <p>Or, with <code>api_format</code> set to <code>True</code></p> <pre><code>output = print_class_parameters(Agent, api_format=True)\nprint(output)\n</code></pre> <p>Results in:</p> <pre><code>{'x': \"&lt;class 'int'&gt;\", 'y': \"&lt;class 'int'&gt;\"}\n</code></pre> <p>Note:</p> <p>The function <code>print_class_parameters</code> is not limited to custom classes. It can inspect built-in Python classes such as <code>list</code>, <code>dict</code>, and others. However, it is most useful when inspecting custom-defined classes that aren't inherently documented in Python or third-party libraries.</p> <p>Source Code</p> <pre><code>def print_class_parameters(cls, api_format: bool = False):\n    \"\"\"\n    Print the parameters of a class constructor.\n\n    Parameters:\n    cls (type): The class to inspect.\n\n    Example:\n    &gt;&gt;&gt; print_class_parameters(Agent)\n    Parameter: x, Type: &lt;class 'int'&gt;\n    Parameter: y, Type: &lt;class 'int'&gt;\n    \"\"\"\n    try:\n        # Get the parameters of the class constructor\n        sig = inspect.signature(cls.__init__)\n        params = sig.parameters\n\n        if api_format:\n            param_dict = {}\n            for name, param in params.items():\n                if name == \"self\":\n                    continue\n                param_dict[name] = str(param.annotation)\n            return param_dict\n\n        # Print the parameters\n        for name, param in params.items():\n            if name == \"self\":\n                continue\n            print(f\"Parameter: {name}, Type: {param.annotation}\")\n\n    except Exception as e:\n        print(f\"An error occurred while inspecting the class: {e}\")\n</code></pre>"},{"location":"swarms/workers/","title":"Module Name: Worker","text":"<p>The <code>Worker</code> class encapsulates the idea of a semi-autonomous agent that utilizes a large language model to execute tasks. The module provides a unified interface for AI-driven task execution while combining a series of tools and utilities. It sets up memory storage and retrieval mechanisms for contextual recall and offers an option for human involvement, making it a versatile and adaptive agent for diverse applications.</p>"},{"location":"swarms/workers/#class-definition","title":"Class Definition:","text":"<pre><code>class Worker:\n</code></pre>"},{"location":"swarms/workers/#parameters","title":"Parameters:","text":"<ul> <li><code>model_name</code> (str, default: \"gpt-4\"): Name of the language model.</li> <li><code>openai_api_key</code> (str, Optional): API key for accessing OpenAI's models.</li> <li><code>ai_name</code> (str, default: \"Autobot Swarm Worker\"): Name of the AI agent.</li> <li><code>ai_role</code> (str, default: \"Worker in a swarm\"): Role description of the AI agent.</li> <li><code>external_tools</code> (list, Optional): A list of external tool objects to be used.</li> <li><code>human_in_the_loop</code> (bool, default: False): If set to <code>True</code>, it indicates that human intervention may be required.</li> <li><code>temperature</code> (float, default: 0.5): Sampling temperature for the language model's output. Higher values make the output more random, and lower values make it more deterministic.</li> </ul>"},{"location":"swarms/workers/#methods","title":"Methods:","text":""},{"location":"swarms/workers/#__init__","title":"<code>__init__</code>:","text":"<p>Initializes the Worker class.</p>"},{"location":"swarms/workers/#setup_tools","title":"<code>setup_tools</code>:","text":"<p>Sets up the tools available to the worker. Default tools include reading and writing files, processing CSV data, querying websites, and taking human input. Additional tools can be appended through the <code>external_tools</code> parameter.</p>"},{"location":"swarms/workers/#setup_memory","title":"<code>setup_memory</code>:","text":"<p>Initializes memory systems using embeddings and a vector store for the worker.</p>"},{"location":"swarms/workers/#setup_agent","title":"<code>setup_agent</code>:","text":"<p>Sets up the primary agent using the initialized tools, memory, and language model.</p>"},{"location":"swarms/workers/#run","title":"<code>run</code>:","text":"<p>Executes a given task using the agent.</p>"},{"location":"swarms/workers/#__call__","title":"<code>__call__</code>:","text":"<p>Makes the Worker class callable. When an instance of the class is called, it will execute the provided task using the agent.</p>"},{"location":"swarms/workers/#usage-examples","title":"Usage Examples:","text":""},{"location":"swarms/workers/#example-1-basic-usage-with-default-parameters","title":"Example 1: Basic usage with default parameters:","text":"<pre><code>from swarms import Worker\nfrom swarms.models import OpenAIChat\n\nllm = OpenAIChat(\n    # enter your api key\n    openai_api_key=\"\",\n    temperature=0.5,\n)\n\nnode = Worker(\n    llm=llm,\n    ai_name=\"Optimus Prime\",\n    openai_api_key=\"\",\n    ai_role=\"Worker in a swarm\",\n    external_tools=None,\n    human_in_the_loop=False,\n    temperature=0.5,\n)\n\ntask = \"What were the winning boston marathon times for the past 5 years (ending in 2022)? Generate a table of the year, name, country of origin, and times.\"\nresponse = node.run(task)\nprint(response)\n</code></pre>"},{"location":"swarms/workers/#example-2-usage-with-custom-tools","title":"Example 2: Usage with custom tools:","text":"<pre><code>import os\n\nimport interpreter\n\nfrom swarms.agents.hf_agents import HFAgent\nfrom swarms.agents.omni_modal_agent import OmniModalAgent\nfrom swarms.models import OpenAIChat\nfrom swarms.tools.autogpt import tool\nfrom swarms.workers import Worker\n\n# Initialize API Key\napi_key = \"\"\n\n\n# Initialize the language model,\n# This model can be swapped out with Anthropic, ETC, Huggingface Models like Mistral, ETC\nllm = OpenAIChat(\n    openai_api_key=api_key,\n    temperature=0.5,\n)\n\n\n# wrap a function with the tool decorator to make it a tool, then add docstrings for tool documentation\n@tool\ndef hf_agent(task: str = None):\n    \"\"\"\n    An tool that uses an openai model to call and respond to a task by search for a model on huggingface\n    It first downloads the model then uses it.\n\n    Rules: Don't call this model for simple tasks like generating a summary, only call this tool for multi modal tasks like generating images, videos, speech, etc\n\n    \"\"\"\n    agent = HFAgent(model=\"text-davinci-003\", api_key=api_key)\n    response = agent.run(task, text=\"\u00a1Este es un API muy agradable!\")\n    return response\n\n\n# wrap a function with the tool decorator to make it a tool\n@tool\ndef omni_agent(task: str = None):\n    \"\"\"\n    An tool that uses an openai Model to utilize and call huggingface models and guide them to perform a task.\n\n    Rules: Don't call this model for simple tasks like generating a summary, only call this tool for multi modal tasks like generating images, videos, speech\n    The following tasks are what this tool should be used for:\n\n    Tasks omni agent is good for:\n    --------------\n    document-question-answering\n    image-captioning\n    image-question-answering\n    image-segmentation\n    speech-to-text\n    summarization\n    text-classification\n    text-question-answering\n    translation\n    huggingface-tools/text-to-image\n    huggingface-tools/text-to-video\n    text-to-speech\n    huggingface-tools/text-download\n    huggingface-tools/image-transformation\n    \"\"\"\n    agent = OmniModalAgent(llm)\n    response = agent.run(task)\n    return response\n\n\n# Code Interpreter\n@tool\ndef compile(task: str):\n    \"\"\"\n    Open Interpreter lets LLMs run code (Python, Javascript, Shell, and more) locally.\n    You can chat with Open Interpreter through a ChatGPT-like interface in your terminal\n    by running $ interpreter after installing.\n\n    This provides a natural-language interface to your computer's general-purpose capabilities:\n\n    Create and edit photos, videos, PDFs, etc.\n    Control a Chrome browser to perform research\n    Plot, clean, and analyze large datasets\n    ...etc.\n    \u26a0\ufe0f Note: You'll be asked to approve code before it's run.\n\n    Rules: Only use when given to generate code or an application of some kind\n    \"\"\"\n    task = interpreter.chat(task, return_messages=True)\n    interpreter.chat()\n    interpreter.reset(task)\n\n    os.environ[\"INTERPRETER_CLI_AUTO_RUN\"] = True\n    os.environ[\"INTERPRETER_CLI_FAST_MODE\"] = True\n    os.environ[\"INTERPRETER_CLI_DEBUG\"] = True\n\n\n# Append tools to an list\ntools = [hf_agent, omni_agent, compile]\n\n\n# Initialize a single Worker node with previously defined tools in addition to it's\n# predefined tools\nnode = Worker(\n    llm=llm,\n    ai_name=\"Optimus Prime\",\n    openai_api_key=api_key,\n    ai_role=\"Worker in a swarm\",\n    external_tools=tools,\n    human_in_the_loop=False,\n    temperature=0.5,\n)\n\n# Specify task\ntask = \"What were the winning boston marathon times for the past 5 years (ending in 2022)? Generate a table of the year, name, country of origin, and times.\"\n\n# Run the node on the task\nresponse = node.run(task)\n\n# Print the response\nprint(response)\n</code></pre>"},{"location":"swarms/workers/#example-3-usage-with-human-in-the-loop","title":"Example 3: Usage with human in the loop:","text":"<pre><code>from swarms import Worker\nfrom swarms.models import OpenAIChat\n\nllm = OpenAIChat(\n    # enter your api key\n    openai_api_key=\"\",\n    temperature=0.5,\n)\n\nnode = Worker(\n    llm=llm,\n    ai_name=\"Optimus Prime\",\n    openai_api_key=\"\",\n    ai_role=\"Worker in a swarm\",\n    external_tools=None,\n    human_in_the_loop=True,\n    temperature=0.5,\n)\n\ntask = \"What were the winning boston marathon times for the past 5 years (ending in 2022)? Generate a table of the year, name, country of origin, and times.\"\nresponse = node.run(task)\nprint(response)\n</code></pre>"},{"location":"swarms/workers/#mathematical-description","title":"Mathematical Description:","text":"<p>Conceptually, the <code>Worker</code> class can be seen as a function:</p> <p>[ W(t, M, K, T, H, \\theta) \\rightarrow R ]</p> <p>Where:</p> <ul> <li>( W ) = Worker function</li> <li>( t ) = task to be performed</li> <li>( M ) = Model (e.g., \"gpt-4\")</li> <li>( K ) = OpenAI API key</li> <li>( T ) = Set of Tools available</li> <li>( H ) = Human involvement flag (True/False)</li> <li>( \\theta ) = Temperature parameter</li> <li>( R ) = Result of the task</li> </ul> <p>This mathematical abstraction provides a simple view of the <code>Worker</code> class's capability to transform a task input into a desired output using a combination of AI and toolsets.</p>"},{"location":"swarms/workers/#notes","title":"Notes:","text":"<p>The Worker class acts as a bridge between raw tasks and the tools &amp; AI required to accomplish them. The setup ensures flexibility and versatility. The decorators used in the methods (e.g., log_decorator, error_decorator) emphasize the importance of logging, error handling, and performance measurement, essential for real-world applications.</p>"},{"location":"swarms/workers/abstract_worker/","title":"AbstractWorker Class","text":"<p>====================</p> <p>The\u00a0<code>AbstractWorker</code>\u00a0class is an abstract class for AI workers. An AI worker can communicate with other workers and perform actions. Different workers can differ in what actions they perform in the\u00a0<code>receive</code>\u00a0method.</p>"},{"location":"swarms/workers/abstract_worker/#class-definition","title":"Class Definition","text":"<pre><code>class AbstractWorker:\n    \"\"\"(In preview) An abstract class for AI worker.\n\n    An worker can communicate with other workers and perform actions.\n    Different workers can differ in what actions they perform in the `receive` method.\n    \"\"\"\n</code></pre>"},{"location":"swarms/workers/abstract_worker/#initialization","title":"Initialization","text":"<p>The\u00a0<code>AbstractWorker</code>\u00a0class is initialized with a single parameter:</p> <ul> <li><code>name</code>\u00a0(str): The name of the worker.</li> </ul> <pre><code>def __init__(\n    self,\n    name: str,\n):\n    \"\"\"\n    Args:\n        name (str): name of the worker.\n    \"\"\"\n    self._name = name\n</code></pre>"},{"location":"swarms/workers/abstract_worker/#properties","title":"Properties","text":"<p>The\u00a0<code>AbstractWorker</code>\u00a0class has a single property:</p> <ul> <li><code>name</code>: Returns the name of the worker.</li> </ul> <pre><code>@property\ndef name(self):\n    \"\"\"Get the name of the worker.\"\"\"\n    return self._name\n</code></pre>"},{"location":"swarms/workers/abstract_worker/#methods","title":"Methods","text":"<p>The\u00a0<code>AbstractWorker</code>\u00a0class has several methods:</p>"},{"location":"swarms/workers/abstract_worker/#run","title":"<code>run</code>","text":"<p>The\u00a0<code>run</code>\u00a0method is used to run the worker agent once. It takes a single parameter:</p> <ul> <li><code>task</code>\u00a0(str): The task to be run.</li> </ul> <pre><code>def run(\n    self,\n    task: str\n):\n    \"\"\"Run the worker agent once\"\"\"\n</code></pre>"},{"location":"swarms/workers/abstract_worker/#send","title":"<code>send</code>","text":"<p>The\u00a0<code>send</code>\u00a0method is used to send a message to another worker. It takes three parameters:</p> <ul> <li><code>message</code>\u00a0(Union[Dict, str]): The message to be sent.</li> <li><code>recipient</code>\u00a0(AbstractWorker): The recipient of the message.</li> <li><code>request_reply</code>\u00a0(Optional[bool]): If set to\u00a0<code>True</code>, the method will request a reply from the recipient.</li> </ul> <pre><code>def send(\n    self,\n    message: Union[Dict, str],\n    recipient: AbstractWorker,\n    request_reply: Optional[bool] = None\n):\n    \"\"\"(Abstract method) Send a message to another worker.\"\"\"\n</code></pre>"},{"location":"swarms/workers/abstract_worker/#a_send","title":"<code>a_send</code>","text":"<p>The\u00a0<code>a_send</code>\u00a0method is the asynchronous version of the\u00a0<code>send</code>\u00a0method. It takes the same parameters as the\u00a0<code>send</code>\u00a0method.</p> <pre><code>async def a_send(\n    self,\n    message: Union[Dict, str],\n    recipient: AbstractWorker,\n    request_reply: Optional[bool] = None\n):\n    \"\"\"(Abstract async method) Send a message to another worker.\"\"\"\n</code></pre>"},{"location":"swarms/workers/abstract_worker/#receive","title":"<code>receive</code>","text":"<p>The\u00a0<code>receive</code>\u00a0method is used to receive a message from another worker. It takes three parameters:</p> <ul> <li><code>message</code>\u00a0(Union[Dict, str]): The message to be received.</li> <li><code>sender</code>\u00a0(AbstractWorker): The sender of the message.</li> <li><code>request_reply</code>\u00a0(Optional[bool]): If set to\u00a0<code>True</code>, the method will request a reply from the sender.</li> </ul> <pre><code>def receive(\n    self,\n    message: Union[Dict, str],\n    sender: AbstractWorker,\n    request_reply: Optional[bool] = None\n):\n    \"\"\"(Abstract method) Receive a message from another worker.\"\"\"\n</code></pre>"},{"location":"swarms/workers/abstract_worker/#a_receive","title":"<code>a_receive</code>","text":"<p>The\u00a0<code>a_receive</code>\u00a0method is the asynchronous version of the\u00a0<code>receive</code>\u00a0method. It takes the same parameters as the\u00a0<code>receive</code>\u00a0method.</p> <pre><code>async def a_receive(\n    self,\n    message: Union[Dict, str],\n    sender: AbstractWorker,\n    request_reply: Optional[bool] = None\n):\n    \"\"\"(Abstract async method) Receive a message from another worker.\"\"\"\n</code></pre>"},{"location":"swarms/workers/abstract_worker/#reset","title":"<code>reset</code>","text":"<p>The\u00a0<code>reset</code>\u00a0method is used to reset the worker.</p> <pre><code>def reset(self):\n    \"\"\"(Abstract method) Reset the worker.\"\"\"\n</code></pre>"},{"location":"swarms/workers/abstract_worker/#generate_reply","title":"<code>generate_reply</code>","text":"<p>The\u00a0<code>generate_reply</code>\u00a0method is used to generate a reply based on the received messages. It takes two parameters:</p> <ul> <li><code>messages</code>\u00a0(Optional[List[Dict]]): A list of messages received.</li> <li><code>sender</code>\u00a0(AbstractWorker): The sender of the messages.</li> </ul> <p>The method returns a string, a dictionary, or\u00a0<code>None</code>. If\u00a0<code>None</code>\u00a0is returned, no reply is generated.</p> <pre><code>def generate_reply(\n    self,\n    messages: Optional[List[Dict]] = None,\n    sender: AbstractWorker,\n    **kwargs,\n) -&gt; Union[str, Dict, None]:\n    \"\"\"(Abstract method) Generate a reply based on the received messages.\n\n    Args:\n        messages (list[dict]): a list of messages received.\n        sender: sender of an Agent instance.\n    Returns:\n        str or dict or None: the generated reply. If None, no reply is generated.\n    \"\"\"\n</code></pre>"},{"location":"swarms/workers/abstract_worker/#a_generate_reply","title":"<code>a_generate_reply</code>","text":"<p>The\u00a0<code>a_generate_reply</code>\u00a0method is the asynchronous version of the\u00a0<code>generate_reply</code>\u00a0method. It</p> <p>takes the same parameters as the\u00a0<code>generate_reply</code>\u00a0method.</p> <pre><code>async def a_generate_reply(\n    self,\n    messages: Optional[List[Dict]] = None,\n    sender: AbstractWorker,\n    **kwargs,\n) -&gt; Union[str, Dict, None]:\n    \"\"\"(Abstract async method) Generate a reply based on the received messages.\n\n    Args:\n        messages (list[dict]): a list of messages received.\n        sender: sender of an Agent instance.\n    Returns:\n        str or dict or None: the generated reply. If None, no reply is generated.\n    \"\"\"\n</code></pre>"},{"location":"swarms/workers/abstract_worker/#usage-examples","title":"Usage Examples","text":""},{"location":"swarms/workers/abstract_worker/#example-1-creating-an-abstractworker","title":"Example 1: Creating an AbstractWorker","text":"<pre><code>from swarms.worker.base import AbstractWorker\n\nworker = AbstractWorker(name=\"Worker1\")\nprint(worker.name)  # Output: Worker1\n</code></pre> <p>In this example, we create an instance of\u00a0<code>AbstractWorker</code>\u00a0named \"Worker1\" and print its name.</p>"},{"location":"swarms/workers/abstract_worker/#example-2-sending-a-message","title":"Example 2: Sending a Message","text":"<pre><code>from swarms.worker.base import AbstractWorker\n\nworker1 = AbstractWorker(name=\"Worker1\")\nworker2 = AbstractWorker(name=\"Worker2\")\n\nmessage = {\"content\": \"Hello, Worker2!\"}\nworker1.send(message, worker2)\n</code></pre> <p>In this example, \"Worker1\" sends a message to \"Worker2\". The message is a dictionary with a single key-value pair.</p>"},{"location":"swarms/workers/abstract_worker/#example-3-receiving-a-message","title":"Example 3: Receiving a Message","text":"<pre><code>from swarms.worker.base import AbstractWorker\n\nworker1 = AbstractWorker(name=\"Worker1\")\nworker2 = AbstractWorker(name=\"Worker2\")\n\nmessage = {\"content\": \"Hello, Worker2!\"}\nworker1.send(message, worker2)\n\nreceived_message = worker2.receive(message, worker1)\nprint(received_message)  # Output: {\"content\": \"Hello, Worker2!\"}\n</code></pre> <p>In this example, \"Worker1\" sends a message to \"Worker2\". \"Worker2\" then receives the message and prints it.</p>"},{"location":"swarms/workers/abstract_worker/#notes","title":"Notes","text":"<ul> <li>The\u00a0<code>AbstractWorker</code>\u00a0class is an abstract class, which means it cannot be instantiated directly. Instead, it should be subclassed, and at least the\u00a0<code>send</code>,\u00a0<code>receive</code>,\u00a0<code>reset</code>, and\u00a0<code>generate_reply</code>\u00a0methods should be overridden.</li> <li>The\u00a0<code>send</code>\u00a0and\u00a0<code>receive</code>\u00a0methods are abstract methods, which means they must be implemented in any subclass of\u00a0<code>AbstractWorker</code>.</li> <li>The\u00a0<code>a_send</code>,\u00a0<code>a_receive</code>, and\u00a0<code>a_generate_reply</code>\u00a0methods are asynchronous methods, which means they return a coroutine that can be awaited using the\u00a0<code>await</code>\u00a0keyword.</li> <li>The\u00a0<code>generate_reply</code>\u00a0method is used to generate a reply based on the received messages. The exact implementation of this method will depend on the specific requirements of your application.</li> <li>The\u00a0<code>reset</code>\u00a0method is used to reset the state of the worker. The exact implementation of this method will depend on the specific requirements of your application.</li> </ul>"},{"location":"swarms/workers/base/","title":"<code>AbstractWorker</code> Documentation","text":""},{"location":"swarms/workers/base/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction</li> <li>Abstract Worker<ol> <li>Class Definition</li> <li>Attributes</li> <li>Methods</li> </ol> </li> <li>Tutorial: Creating Custom Workers</li> <li>Conclusion</li> </ol>"},{"location":"swarms/workers/base/#1-introduction","title":"1. Introduction","text":"<p>Welcome to the documentation for the Swarms library, a powerful tool for building and simulating swarm architectures. This library provides a foundation for creating and managing autonomous workers that can communicate, collaborate, and perform various tasks in a coordinated manner.</p> <p>In this documentation, we will cover the <code>AbstractWorker</code> class, which serves as the fundamental building block for creating custom workers in your swarm simulations. We will explain the class's architecture, attributes, and methods in detail, providing practical examples to help you understand how to use it effectively.</p> <p>Whether you want to simulate a team of autonomous robots, a group of AI agents, or any other swarm-based system, the Swarms library is here to simplify the process and empower you to build complex simulations.</p>"},{"location":"swarms/workers/base/#2-abstract-worker","title":"2. Abstract Worker","text":""},{"location":"swarms/workers/base/#21-class-definition","title":"2.1 Class Definition","text":"<p>The <code>AbstractWorker</code> class is an abstract base class that serves as the foundation for creating worker agents in your swarm simulations. It defines a set of methods that should be implemented by subclasses to customize the behavior of individual workers.</p> <p>Here is the class definition:</p> <pre><code>class AbstractWorker:\n    def __init__(self, name: str):\n        \"\"\"\n        Args:\n            name (str): Name of the worker.\n        \"\"\"\n\n    @property\n    def name(self):\n        \"\"\"Get the name of the worker.\"\"\"\n\n    def run(self, task: str):\n        \"\"\"Run the worker agent once.\"\"\"\n\n    def send(\n        self, message: Union[Dict, str], recipient, request_reply: Optional[bool] = None\n    ):\n        \"\"\"Send a message to another worker.\"\"\"\n\n    async def a_send(\n        self, message: Union[Dict, str], recipient, request_reply: Optional[bool] = None\n    ):\n        \"\"\"Send a message to another worker asynchronously.\"\"\"\n\n    def receive(\n        self, message: Union[Dict, str], sender, request_reply: Optional[bool] = None\n    ):\n        \"\"\"Receive a message from another worker.\"\"\"\n\n    async def a_receive(\n        self, message: Union[Dict, str], sender, request_reply: Optional[bool] = None\n    ):\n        \"\"\"Receive a message from another worker asynchronously.\"\"\"\n\n    def reset(self):\n        \"\"\"Reset the worker.\"\"\"\n\n    def generate_reply(\n        self, messages: Optional[List[Dict]] = None, sender=None, **kwargs\n    ) -&gt; Union[str, Dict, None]:\n        \"\"\"Generate a reply based on received messages.\"\"\"\n\n    async def a_generate_reply(\n        self, messages: Optional[List[Dict]] = None, sender=None, **kwargs\n    ) -&gt; Union[str, Dict, None]:\n        \"\"\"Generate a reply based on received messages asynchronously.\"\"\"\n</code></pre>"},{"location":"swarms/workers/base/#22-attributes","title":"2.2 Attributes","text":"<ul> <li><code>name (str)</code>: The name of the worker, which is set during initialization.</li> </ul>"},{"location":"swarms/workers/base/#23-methods","title":"2.3 Methods","text":"<p>Now, let's delve into the methods provided by the <code>AbstractWorker</code> class and understand their purposes and usage.</p>"},{"location":"swarms/workers/base/#__init__self-name-str","title":"<code>__init__(self, name: str)</code>","text":"<p>The constructor method initializes a worker with a given name.</p> <p>Parameters: - <code>name (str)</code>: The name of the worker.</p> <p>Usage Example:</p> <pre><code>worker = AbstractWorker(\"Worker1\")\n</code></pre>"},{"location":"swarms/workers/base/#name-property","title":"<code>name</code> (Property)","text":"<p>The <code>name</code> property allows you to access the name of the worker.</p> <p>Usage Example:</p> <pre><code>worker_name = worker.name\n</code></pre>"},{"location":"swarms/workers/base/#runself-task-str","title":"<code>run(self, task: str)</code>","text":"<p>The <code>run()</code> method is a placeholder for running the worker. You can customize this method in your subclass to define the specific actions the worker should perform.</p> <p>Parameters: - <code>task (str)</code>: A task description or identifier.</p> <p>Usage Example (Customized Subclass):</p> <pre><code>class MyWorker(AbstractWorker):\n    def run(self, task: str):\n        print(f\"{self.name} is performing task: {task}\")\n\n\nworker = MyWorker(\"Worker1\")\nworker.run(\"Collect data\")\n</code></pre>"},{"location":"swarms/workers/base/#sendself-message-uniondict-str-recipient-request_reply-optionalbool-none","title":"<code>send(self, message: Union[Dict, str], recipient, request_reply: Optional[bool] = None)</code>","text":"<p>The <code>send()</code> method allows the worker to send a message to another worker or recipient. The message can be either a dictionary or a string.</p> <p>Parameters: - <code>message (Union[Dict, str])</code>: The message to be sent. - <code>recipient</code>: The recipient worker or entity. - <code>request_reply (Optional[bool])</code>: If <code>True</code>, the sender requests a reply from the recipient. If <code>False</code>, no reply is requested. Default is <code>None</code>.</p> <p>Usage Example:</p> <pre><code>worker1 = AbstractWorker(\"Worker1\")\nworker2 = AbstractWorker(\"Worker2\")\n\nmessage = \"Hello, Worker2!\"\nworker1.send(message, worker2)\n</code></pre>"},{"location":"swarms/workers/base/#a_sendself-message-uniondict-str-recipient-request_reply-optionalbool-none","title":"<code>a_send(self, message: Union[Dict, str], recipient, request_reply: Optional[bool] = None)</code>","text":"<p>The <code>a_send()</code> method is an asynchronous version of the <code>send()</code> method, allowing the worker to send messages asynchronously.</p> <p>Parameters: (Same as <code>send()</code>)</p> <p>Usage Example:</p> <pre><code>import asyncio\n\n\nasync def main():\n    worker1 = AbstractWorker(\"Worker1\")\n    worker2 = AbstractWorker(\"Worker2\")\n\n    message = \"Hello, Worker2!\"\n    await worker1.a_send(message, worker2)\n\n\nloop = asyncio.get_event_loop()\nloop.run_until_complete(main())\n</code></pre>"},{"location":"swarms/workers/base/#receiveself-message-uniondict-str-sender-request_reply-optionalbool-none","title":"<code>receive(self, message: Union[Dict, str], sender, request_reply: Optional[bool] = None)</code>","text":"<p>The <code>receive()</code> method allows the worker to receive messages from other workers or senders. You can customize this method in your subclass to define how the worker handles incoming messages.</p> <p>Parameters: - <code>message (Union[Dict, str])</code>: The received message. - <code>sender</code>: The sender worker or entity. - <code>request_reply (Optional[bool])</code>: Indicates whether a reply is requested. Default is <code>None</code>.</p> <p>Usage Example (Customized Subclass):</p> <pre><code>class MyWorker(AbstractWorker):\n    def receive(self, message: Union[Dict, str], sender, request_reply: Optional[bool] = None):\n        if isinstance(message, str):\n            print(f\"{self.name} received a text message from {sender.name}: {message}\")\n        elif isinstance(message, dict):\n            print(f\"{self.name} received a dictionary message from {sender.name}: {message}\")\n\nworker1 = MyWorker(\"Worker1\")\nworker2 = MyWorker(\"Worker2\")\n\nmessage1 =\n\n \"Hello, Worker2!\"\nmessage2 = {\"data\": 42}\n\nworker1.receive(message1, worker2)\nworker1.receive(message2, worker2)\n</code></pre>"},{"location":"swarms/workers/base/#a_receiveself-message-uniondict-str-sender-request_reply-optionalbool-none","title":"<code>a_receive(self, message: Union[Dict, str], sender, request_reply: Optional[bool] = None)</code>","text":"<p>The <code>a_receive()</code> method is an asynchronous version of the <code>receive()</code> method, allowing the worker to receive messages asynchronously.</p> <p>Parameters: (Same as <code>receive()</code>)</p> <p>Usage Example:</p> <pre><code>import asyncio\n\n\nasync def main():\n    worker1 = AbstractWorker(\"Worker1\")\n    worker2 = AbstractWorker(\"Worker2\")\n\n    message1 = \"Hello, Worker2!\"\n    message2 = {\"data\": 42}\n\n    await worker1.a_receive(message1, worker2)\n    await worker1.a_receive(message2, worker2)\n\n\nloop = asyncio.get_event_loop()\nloop.run_until_complete(main())\n</code></pre>"},{"location":"swarms/workers/base/#resetself","title":"<code>reset(self)</code>","text":"<p>The <code>reset()</code> method is a placeholder for resetting the worker. You can customize this method in your subclass to define how the worker should reset its state.</p> <p>Usage Example (Customized Subclass):</p> <pre><code>class MyWorker(AbstractWorker):\n    def reset(self):\n        print(f\"{self.name} has been reset.\")\n\n\nworker = MyWorker(\"Worker1\")\nworker.reset()\n</code></pre>"},{"location":"swarms/workers/base/#generate_replyself-messages-optionallistdict-none-sendernone-kwargs-unionstr-dict-none","title":"<code>generate_reply(self, messages: Optional[List[Dict]] = None, sender=None, **kwargs) -&gt; Union[str, Dict, None]</code>","text":"<p>The <code>generate_reply()</code> method is a placeholder for generating a reply based on received messages. You can customize this method in your subclass to define the logic for generating replies.</p> <p>Parameters: - <code>messages (Optional[List[Dict]])</code>: A list of received messages. - <code>sender</code>: The sender of the reply. - <code>kwargs</code>: Additional keyword arguments.</p> <p>Returns: - <code>Union[str, Dict, None]</code>: The generated reply. If <code>None</code>, no reply is generated.</p> <p>Usage Example (Customized Subclass):</p> <pre><code>class MyWorker(AbstractWorker):\n    def generate_reply(\n        self, messages: Optional[List[Dict]] = None, sender=None, **kwargs\n    ) -&gt; Union[str, Dict, None]:\n        if messages:\n            # Generate a reply based on received messages\n            return f\"Received {len(messages)} messages from {sender.name}.\"\n        else:\n            return None\n\n\nworker1 = MyWorker(\"Worker1\")\nworker2 = MyWorker(\"Worker2\")\n\nmessage = \"Hello, Worker2!\"\nreply = worker2.generate_reply([message], worker1)\n\nif reply:\n    print(f\"{worker2.name} generated a reply: {reply}\")\n</code></pre>"},{"location":"swarms/workers/base/#a_generate_replyself-messages-optionallistdict-none-sendernone-kwargs-unionstr-dict-none","title":"<code>a_generate_reply(self, messages: Optional[List[Dict]] = None, sender=None, **kwargs) -&gt; Union[str, Dict, None]</code>","text":"<p>The <code>a_generate_reply()</code> method is an asynchronous version of the <code>generate_reply()</code> method, allowing the worker to generate replies asynchronously.</p> <p>Parameters: (Same as <code>generate_reply()</code>)</p> <p>Returns: - <code>Union[str, Dict, None]</code>: The generated reply. If <code>None</code>, no reply is generated.</p> <p>Usage Example:</p> <pre><code>import asyncio\n\n\nasync def main():\n    worker1 = AbstractWorker(\"Worker1\")\n    worker2 = AbstractWorker(\"Worker2\")\n\n    message = \"Hello, Worker2!\"\n    reply = await worker2.a_generate_reply([message], worker1)\n\n    if reply:\n        print(f\"{worker2.name} generated a reply: {reply}\")\n\n\nloop = asyncio.get_event_loop()\nloop.run_until_complete(main())\n</code></pre>"},{"location":"swarms/workers/base/#3-tutorial-creating-custom-workers","title":"3. Tutorial: Creating Custom Workers","text":"<p>In this tutorial, we will walk you through the process of creating custom workers by subclassing the <code>AbstractWorker</code> class. You can tailor these workers to perform specific tasks and communicate with other workers in your swarm simulations.</p>"},{"location":"swarms/workers/base/#step-1-create-a-custom-worker-class","title":"Step 1: Create a Custom Worker Class","text":"<p>Start by creating a custom worker class that inherits from <code>AbstractWorker</code>. Define the <code>run()</code> and <code>receive()</code> methods to specify the behavior of your worker.</p> <pre><code>class CustomWorker(AbstractWorker):\n    def run(self, task: str):\n        print(f\"{self.name} is performing task: {task}\")\n\n    def receive(\n        self, message: Union[Dict, str], sender, request_reply: Optional[bool] = None\n    ):\n        if isinstance(message, str):\n            print(f\"{self.name} received a text message from {sender.name}: {message}\")\n        elif isinstance(message, dict):\n            print(\n                f\"{self.name} received a dictionary message from {sender.name}: {message}\"\n            )\n</code></pre>"},{"location":"swarms/workers/base/#step-2-create-custom-worker-instances","title":"Step 2: Create Custom Worker Instances","text":"<p>Instantiate your custom worker instances and give them unique names.</p> <pre><code>worker1 = CustomWorker(\"Worker1\")\nworker2 = CustomWorker(\"Worker2\")\n</code></pre>"},{"location":"swarms/workers/base/#step-3-run-custom-workers","title":"Step 3: Run Custom Workers","text":"<p>Use the <code>run()</code> method to make your custom workers perform tasks.</p> <pre><code>worker1.run(\"Collect data\")\nworker2.run(\"Process data\")\n</code></pre>"},{"location":"swarms/workers/base/#step-4-communicate-between-workers","title":"Step 4: Communicate Between Workers","text":"<p>Use the <code>send()</code> method to send messages between workers. You can customize the <code>receive()</code> method to define how your workers handle incoming messages.</p> <pre><code>worker1.send(\"Hello, Worker2!\", worker2)\nworker2.send({\"data\": 42}, worker1)\n\n# Output will show the messages received by the workers\n</code></pre>"},{"location":"swarms/workers/base/#step-5-generate-replies","title":"Step 5: Generate Replies","text":"<p>Customize the <code>generate_reply()</code> method to allow your workers to generate replies based on received messages.</p> <pre><code>class CustomWorker(AbstractWorker):\n    def generate_reply(\n        self, messages: Optional[List[Dict]] = None, sender=None, **kwargs\n    ) -&gt; Union[str, Dict, None]:\n        if messages:\n            # Generate a reply based on received messages\n            return f\"Received {len(messages)} messages from {sender.name}.\"\n        else:\n            return None\n</code></pre> <p>Now, your custom workers can generate replies to incoming messages.</p> <pre><code>reply = worker2.generate_reply([\"Hello, Worker2!\"], worker1)\n\nif reply:\n    print(f\"{worker2.name} generated a reply: {reply}\")\n</code></pre>"},{"location":"swarms/workers/base/#4-conclusion","title":"4. Conclusion","text":"<p>Congratulations! You've learned how to use the Swarms library to create and customize worker agents for swarm simulations. You can now build complex swarm architectures, simulate autonomous systems, and experiment with various communication and task allocation strategies.</p> <p>Feel free to explore the Swarms library further and adapt it to your specific use cases. If you have any questions or need assistance, refer to the extensive documentation and resources available.</p> <p>Happy swarming!</p>"}]}